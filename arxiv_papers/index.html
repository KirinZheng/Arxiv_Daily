
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../biorxiv_papers/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.38">
    
    
      
        <title>Arxiv Papers - Arxiv Daily</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8c3ca2c6.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#arxiv-papers" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Arxiv Daily" class="md-header__button md-logo" aria-label="Arxiv Daily" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Arxiv Daily
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Arxiv Papers
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Arxiv Daily" class="md-nav__button md-logo" aria-label="Arxiv Daily" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Arxiv Daily
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Arxiv Papers
  </span>
  

      </a>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../biorxiv_papers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BioRxiv Papers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../medrxiv_papers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MedRxiv Papers
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="arxiv-papers">Arxiv Papers</h1>
<table>
<thead>
<tr>
<th>标题</th>
<th>摘要</th>
<th>作者</th>
<th>PDF链接</th>
<th>代码仓库</th>
<th>Title</th>
<th>Abstract</th>
</tr>
</thead>
<tbody>
<tr>
<td>用于乳腺摄影对比语言-图像预训练的多视角与多尺度对齐</td>
<td>对比语言-图像预训练（CLIP）在医学图像分析中显示出潜力，但需要大量数据和计算资源。由于这些限制，现有的CLIP在医学成像中的应用主要集中在胸部X光等拥有丰富图像报告数据的模态上，而许多其他重要模态尚未得到充分探索。在此，我们首次将完整的CLIP模型应用于乳腺摄影，这面临着显著的挑战，包括标签数据稀缺、高分辨率图像中感兴趣区域较小以及数据不平衡。我们首先为乳腺摄影开发了一个专门的监督框架，利用其多视角特性。此外，我们设计了一个对称局部对齐模块，以更好地关注高分辨率图像中的细节特征。最后，我们采用了一种参数高效的微调方法，用于预先训练了医学知识的大型语言模型，以应对数据限制。我们的多视角和多尺度对齐（MaMA）方法在两个大型真实世界乳腺摄影数据集EMBED和RSNA-Mammo上，针对三种不同任务的表现优于最先进的基线方法，且模型大小仅为最大基线的52%。</td>
<td>Yuexi Du</td>
<td><a href="http://arxiv.org/pdf/2409.18119v1">PDF</a></td>
<td>N/A</td>
<td>Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography</td>
<td>Contrastive Language-Image Pre-training (CLIP) shows promise in medical image analysis but requires substantial data and computational resources. Due to these restrictions, existing CLIP applications in medical imaging focus mainly on modalities like chest X-rays that have abundant image-report data available, leaving many other important modalities under-explored. Here, we propose the first adaptation of the full CLIP model to mammography, which presents significant challenges due to labeled data scarcity, high-resolution images with small regions of interest, and data imbalance. We first develop a specialized supervision framework for mammography that leverages its multi-view nature. Furthermore, we design a symmetric local alignment module to better focus on detailed features in high-resolution images. Lastly, we incorporate a parameter-efficient fine-tuning approach for large language models pre-trained with medical knowledge to address data limitations. Our multi-view and multi-scale alignment (MaMA) method outperforms state-of-the-art baselines for three different tasks on two large real-world mammography datasets, EMBED and RSNA-Mammo, with only 52% model size compared with the largest baseline.</td>
</tr>
<tr>
<td>开放世界评估：检索多样化视角</td>
<td>我们研究了如何检索一组涵盖复杂且有争议问题的各种观点的文档（例如，ChatGPT是否会带来更多危害而非益处？）。我们构建了一个主观问题检索多样性基准（BERDS），其中每个示例包含一个问题及其相关联的多样化观点，这些观点来源于调查问卷和辩论网站。在此数据上，结合语料库的检索器被评估为能够呈现包含多样观点的文档集合。我们的框架与大多数检索任务不同，因为文档的相关性不能通过简单的字符串匹配来决定。相反，我们构建了一个基于语言模型的自动评估器，用于判断每个检索到的文档是否包含某种观点。这使我们能够评估三种不同类型的语料库（维基百科、网页快照以及通过搜索引擎检索页面即时构建的语料库）与检索器配对时的性能。检索多样化的文档仍然具有挑战性，现有检索器的输出仅在33.74%的示例中涵盖了所有观点。我们进一步研究了查询扩展和以多样性为中心的重新排序方法的影响，并分析了检索器的盲从性。总的来说，我们为未来处理复杂查询的检索多样性研究奠定了基础。</td>
<td>Hung-Ting Chen</td>
<td><a href="http://arxiv.org/pdf/2409.18110v1">PDF</a></td>
<td>N/A</td>
<td>Open-World Evaluation for Retrieving Diverse Perspectives</td>
<td>We study retrieving a set of documents that covers various perspectives on a complex and contentious question (e.g., will ChatGPT do more harm than good?). We curate a Benchmark for Retrieval Diversity for Subjective questions (BERDS), where each example consists of a question and diverse perspectives associated with the question, sourced from survey questions and debate websites. On this data, retrievers paired with a corpus are evaluated to surface a document set that contains diverse perspectives. Our framing diverges from most retrieval tasks in that document relevancy cannot be decided by simple string matches to references. Instead, we build a language model based automatic evaluator that decides whether each retrieved document contains a perspective. This allows us to evaluate the performance of three different types of corpus (Wikipedia, web snapshot, and corpus constructed on the fly with retrieved pages from the search engine) paired with retrievers. Retrieving diverse documents remains challenging, with the outputs from existing retrievers covering all perspectives on only 33.74% of the examples. We further study the impact of query expansion and diversity-focused reranking approaches and analyze retriever sycophancy. Together, we lay the foundation for future studies in retrieval diversity handling complex queries.</td>
</tr>
<tr>
<td>寻找犀牛而不寻找犀牛：利用南非犀牛栖息地的多模态影像进行主动学习</td>
<td>地球上许多魅力十足的巨型动物正因人类活动而濒临灭绝，尤其是犀牛，由于非洲的偷猎危机，它们面临着灭绝的风险。监测犀牛的移动对于其保护至关重要，但遗憾的是，由于犀牛行踪隐秘，这一任务一直难以实现。因此，我们提出了一种新颖的方法，即绘制群体排泄地点（称为“粪堆”）的地图，这些地点提供了关于犀牛空间行为的信息，对反偷猎、管理和重新引入工作具有重要价值。本文首次通过构建分类器，利用遥感热成像、RGB图像和LiDAR图像，在被动和主动学习环境中检测并绘制了犀牛粪堆的位置。由于现有主动学习方法在我们数据集中的极端类别不平衡问题下表现不佳，我们设计了MultimodAL，这是一个采用排序技术和多模态的主动学习系统，能够在标签数量减少94%的情况下，与被动学习模型达到竞争性表现。因此，我们的方法在使用于类似规模的数据集时，可以节省超过76小时的标注时间。出乎意料的是，我们的粪堆地图揭示了犀牛粪堆并非随机分布在整个景观中，而是呈现出聚集分布。因此，护林员应集中在粪堆密度高的区域，以加强反偷猎工作，这与联合国目标15.7相一致。</td>
<td>Lucia Gordon</td>
<td><a href="http://arxiv.org/pdf/2409.18104v1">PDF</a></td>
<td>N/A</td>
<td>Find Rhinos without Finding Rhinos: Active Learning with Multimodal Imagery of South African Rhino Habitats</td>
<td>Much of Earth's charismatic megafauna is endangered by human activities, particularly the rhino, which is at risk of extinction due to the poaching crisis in Africa. Monitoring rhinos' movement is crucial to their protection but has unfortunately proven difficult because rhinos are elusive. Therefore, instead of tracking rhinos, we propose the novel approach of mapping communal defecation sites, called middens, which give information about rhinos' spatial behavior valuable to anti-poaching, management, and reintroduction efforts. This paper provides the first-ever mapping of rhino midden locations by building classifiers to detect them using remotely sensed thermal, RGB, and LiDAR imagery in passive and active learning settings. As existing active learning methods perform poorly due to the extreme class imbalance in our dataset, we design MultimodAL, an active learning system employing a ranking technique and multimodality to achieve competitive performance with passive learning models with 94% fewer labels. Our methods could therefore save over 76 hours in labeling time when used on a similarly-sized dataset. Unexpectedly, our midden map reveals that rhino middens are not randomly distributed throughout the landscape; rather, they are clustered. Consequently, rangers should be targeted at areas with high midden densities to strengthen anti-poaching efforts, in line with UN Target 15.7.</td>
</tr>
<tr>
<td>MALPOLON：一种用于深度物种分布建模的框架</td>
<td>本文介绍了一个名为MALPOLON的深度物种分布模型（deep-SDM）框架。该框架使用Python编写，基于PyTorch库构建，旨在帮助仅具备一般Python语言技能的用户（如生态建模者）轻松进行深度物种分布模型的训练和推理，并促进这些用户测试和应用深度学习方法来构建新的SDM模型。对于更高级的用户，框架的模块化设计允许他们通过覆盖现有类来运行更具体的实验，同时利用一键式示例在多个分类任务上训练神经网络，使用自定义或提供的原始及预处理数据集。MALPOLON框架在GitHub和PyPi上开源，并附有详尽的文档和在各种场景中使用的示例。该框架提供简便的安装方式、基于YAML的配置、并行计算、多GPU利用、基准和基础模型用于性能评估，以及丰富的教程和文档，旨在提升生态学家和研究人员的可访问性和性能扩展性。</td>
<td>Theo Larcher</td>
<td><a href="http://arxiv.org/pdf/2409.18102v1">PDF</a></td>
<td>N/A</td>
<td>MALPOLON: A Framework for Deep Species Distribution Modeling</td>
<td>This paper describes a deep-SDM framework, MALPOLON. Written in Python and built upon the PyTorch library, this framework aims to facilitate training and inferences of deep species distribution models (deep-SDM) and sharing for users with only general Python language skills (e.g., modeling ecologists) who are interested in testing deep learning approaches to build new SDMs. More advanced users can also benefit from the framework's modularity to run more specific experiments by overriding existing classes while taking advantage of press-button examples to train neural networks on multiple classification tasks using custom or provided raw and pre-processed datasets. The framework is open-sourced on GitHub and PyPi along with extensive documentation and examples of use in various scenarios. MALPOLON offers straightforward installation, YAML-based configuration, parallel computing, multi-GPU utilization, baseline and foundational models for benchmarking, and extensive tutorials/documentation, aiming to enhance accessibility and performance scalability for ecologists and researchers.</td>
</tr>
<tr>
<td>自监督预训练在心血管磁共振电影分割中的应用</td>
<td>自监督预训练（SSP）在从大规模未标注数据集中学习方面显示出有希望的结果，因此可能对自动化心血管磁共振（CMR）短轴电影分割有用。然而，关于SSP对分割益处的不一致报告使得将其应用于CMR变得困难。因此，本研究旨在评估SSP方法在CMR电影分割中的效果。为此，使用了296名受试者（90618张2D切片）的短轴电影堆栈进行未标注预训练，采用了四种SSP方法：SimCLR、位置对比学习、DINO和掩码图像建模（MIM）。对于每种SSP方法，以及从头开始训练2D基线模型，使用了不同数量的受试者子集进行有监督微调。微调后的模型与基线模型在140名受试者的测试数据集上使用3D Dice相似系数（DSC）进行比较。SSP方法在最大的有监督微调子集上并未显示出优于基线的性能提升（DSC = 0.89）。当仅有10名受试者（231张2D切片）可用于有监督训练时，使用MIM的SSP（DSC = 0.86）优于从头开始训练（DSC = 0.82）。本研究发现，当标注训练数据稀缺时，SSP对CMR电影分割具有价值，但在有充足标注数据时，对最先进的深度学习方法并无帮助。此外，SSP方法的选择至关重要。代码已公开发布于：https://github.com/q-cardIA/ssp-cmr-cine-segmentation。</td>
<td>Rob A. J. de Mooij</td>
<td><a href="http://arxiv.org/pdf/2409.18100v1">PDF</a></td>
<td>N/A</td>
<td>Self-supervised Pretraining for Cardiovascular Magnetic Resonance Cine Segmentation</td>
<td>Self-supervised pretraining (SSP) has shown promising results in learning from large unlabeled datasets and, thus, could be useful for automated cardiovascular magnetic resonance (CMR) short-axis cine segmentation. However, inconsistent reports of the benefits of SSP for segmentation have made it difficult to apply SSP to CMR. Therefore, this study aimed to evaluate SSP methods for CMR cine segmentation.   To this end, short-axis cine stacks of 296 subjects (90618 2D slices) were used for unlabeled pretraining with four SSP methods; SimCLR, positional contrastive learning, DINO, and masked image modeling (MIM). Subsets of varying numbers of subjects were used for supervised fine-tuning of 2D models for each SSP method, as well as to train a 2D baseline model from scratch. The fine-tuned models were compared to the baseline using the 3D Dice similarity coefficient (DSC) in a test dataset of 140 subjects.   The SSP methods showed no performance gains with the largest supervised fine-tuning subset compared to the baseline (DSC = 0.89). When only 10 subjects (231 2D slices) are available for supervised training, SSP using MIM (DSC = 0.86) improves over training from scratch (DSC = 0.82).   This study found that SSP is valuable for CMR cine segmentation when labeled training data is scarce, but does not aid state-of-the-art deep learning methods when ample labeled data is available. Moreover, the choice of SSP method is important. The code is publicly available at: https://github.com/q-cardIA/ssp-cmr-cine-segmentation</td>
</tr>
<tr>
<td>在遵循自然语言指令之前推断人类的意图</td>
<td>为了让AI代理对人类有用，它们应当能够遵循自然语言指令，在人类环境中完成日常的合作任务。然而，真实的人类指令本身具有模糊性，因为说话者假设听者对其隐藏的目标和意图有足够的先验知识。标准的语言基础和规划方法无法解决这种模糊性，因为它们没有将人类的内在目标建模为环境中的额外部分可观察因素。我们提出了一种新的框架，即“遵循带有社会和具身推理的指令”（Follow Instructions with Social and Embodied Reasoning, FISER），旨在更好地遵循合作具身任务中的自然语言指令。我们的框架明确地将人类目标和意图作为中间推理步骤进行推断。我们实现了一系列基于Transformer的模型，并在一个具有挑战性的基准测试HandMeThat上进行了评估。实证结果表明，在使用行动计划之前，通过社会推理明确推断人类意图的方法优于纯粹的端到端方法。我们还与一些强基线进行了比较，包括在最大可用预训练语言模型上进行的“思维链”提示，发现FISER在所研究的具身社会推理任务中表现更佳，达到了HandMeThat上的最新技术水平。</td>
<td>Yanming Wan</td>
<td><a href="http://arxiv.org/pdf/2409.18073v1">PDF</a></td>
<td>N/A</td>
<td>Infer Human's Intentions Before Following Natural Language Instructions</td>
<td>For AI agents to be helpful to humans, they should be able to follow natural language instructions to complete everyday cooperative tasks in human environments. However, real human instructions inherently possess ambiguity, because the human speakers assume sufficient prior knowledge about their hidden goals and intentions. Standard language grounding and planning methods fail to address such ambiguities because they do not model human internal goals as additional partially observable factors in the environment. We propose a new framework, Follow Instructions with Social and Embodied Reasoning (FISER), aiming for better natural language instruction following in collaborative embodied tasks. Our framework makes explicit inferences about human goals and intentions as intermediate reasoning steps. We implement a set of Transformer-based models and evaluate them over a challenging benchmark, HandMeThat. We empirically demonstrate that using social reasoning to explicitly infer human intentions before making action plans surpasses purely end-to-end approaches. We also compare our implementation with strong baselines, including Chain of Thought prompting on the largest available pre-trained language models, and find that FISER provides better performance on the embodied social reasoning tasks under investigation, reaching the state-of-the-art on HandMeThat.</td>
</tr>
<tr>
<td>通过统计物理学和控制理论实现持续学习的最佳协议</td>
<td>人工神经网络在按顺序学习多个任务时，常常会遇到灾难性遗忘的问题，因为在新任务上的训练会降低之前已学习任务的表现。最近的一些理论工作通过在预定义的训练协议下分析合成框架中的学习曲线来解决这一问题。然而，这些协议依赖于启发式方法，缺乏对其最优性的坚实理论基础评估。在本文中，我们通过结合使用统计物理技术推导出的训练动力学的精确方程与最优控制方法，填补了这一空白。我们将这种方法应用于持续学习和多任务问题的教师-学生模型，得到了一种最大化性能同时最小化遗忘的任务选择协议理论。我们的理论分析提供了非平凡但可解释的策略，用于缓解灾难性遗忘，揭示了最优学习协议如何调节已确立的影响，例如任务相似性对遗忘的影响。最后，我们在真实世界数据上验证了我们的理论发现。</td>
<td>Francesco Mori</td>
<td><a href="http://arxiv.org/pdf/2409.18061v1">PDF</a></td>
<td>N/A</td>
<td>Optimal Protocols for Continual Learning via Statistical Physics and Control Theory</td>
<td>Artificial neural networks often struggle with catastrophic forgetting when learning multiple tasks sequentially, as training on new tasks degrades the performance on previously learned ones. Recent theoretical work has addressed this issue by analysing learning curves in synthetic frameworks under predefined training protocols. However, these protocols relied on heuristics and lacked a solid theoretical foundation assessing their optimality. In this paper, we fill this gap combining exact equations for training dynamics, derived using statistical physics techniques, with optimal control methods. We apply this approach to teacher-student models for continual learning and multi-task problems, obtaining a theory for task-selection protocols maximising performance while minimising forgetting. Our theoretical analysis offers non-trivial yet interpretable strategies for mitigating catastrophic forgetting, shedding light on how optimal learning protocols can modulate established effects, such as the influence of task similarity on forgetting. Finally, we validate our theoretical findings on real-world data.</td>
</tr>
<tr>
<td>具有多个规划时域的逆强化学习</td>
<td>在这项工作中，我们研究了一个逆强化学习（IRL）问题，其中专家们在共享奖励函数下进行规划，但具有不同的、未知的规划视野。在没有折扣因子知识的情况下，奖励函数的可行解集更大，这使得现有的IRL方法更难识别出奖励函数。为了克服这一挑战，我们开发了能够学习具有代理特定折扣因子的全局多代理奖励函数的算法，这些算法能够重构专家策略。我们描述了这两种算法中奖励函数和折扣因子的可行解空间，并展示了所学奖励函数在多个领域中的泛化能力。</td>
<td>Jiayu Yao</td>
<td><a href="http://arxiv.org/pdf/2409.18051v1">PDF</a></td>
<td>N/A</td>
<td>Inverse Reinforcement Learning with Multiple Planning Horizons</td>
<td>In this work, we study an inverse reinforcement learning (IRL) problem where the experts are planning under a shared reward function but with different, unknown planning horizons. Without the knowledge of discount factors, the reward function has a larger feasible solution set, which makes it harder for existing IRL approaches to identify a reward function. To overcome this challenge, we develop algorithms that can learn a global multi-agent reward function with agent-specific discount factors that reconstruct the expert policies. We characterize the feasible solution space of the reward function and discount factors for both algorithms and demonstrate the generalizability of the learned reward function across multiple domains.</td>
</tr>
<tr>
<td>重访任何地点：通过图像分割检索实现视觉地点识别</td>
<td>准确识别重访地点对于具身智能体进行定位和导航至关重要。这要求视觉表征在相机视角和场景外观存在强烈变化的情况下仍能保持独特性。现有的视觉地点识别流程对“整个”图像进行编码并搜索匹配项。这在匹配从不同相机视角拍摄的同一地点的两张图像时面临一个根本性挑战：“重叠部分的相似性可能被非重叠部分的不相似性所主导”。我们通过编码和搜索“图像片段”而非整个图像来解决这一问题。我们提出使用开放集图像分割将图像分解为“有意义”的实体（即物体和背景）。这使我们能够创建一种新的图像表征，即由多个连接片段及其相邻片段的重叠子图组成的集合，称为超级片段（SuperSegment）。此外，为了高效地将这些超级片段编码为紧凑的向量表示，我们提出了一种新颖的特征聚合因子分解表示法。我们证明，检索这些部分表示比基于整个图像的检索能显著提高识别召回率。我们基于片段的方法，称为SegVLAD，在多种基准数据集上为地点识别设定了新的技术水平，并且适用于通用和任务特化的图像编码器。最后，我们通过在一个物体实例检索任务上评估我们的方法，展示了该方法在“重访任何事物”方面的潜力，该任务通过识别特定地点的目标物体，连接了视觉地点识别和目标导向导航这两个不同的研究领域。源代码：https://github.com/AnyLoc/Revisit-Anything。</td>
<td>Kartik Garg</td>
<td><a href="http://arxiv.org/pdf/2409.18049v1">PDF</a></td>
<td>N/A</td>
<td>Revisit Anything: Visual Place Recognition via Image Segment Retrieval</td>
<td>Accurately recognizing a revisited place is crucial for embodied agents to localize and navigate. This requires visual representations to be distinct, despite strong variations in camera viewpoint and scene appearance. Existing visual place recognition pipelines encode the "whole" image and search for matches. This poses a fundamental challenge in matching two images of the same place captured from different camera viewpoints: "the similarity of what overlaps can be dominated by the dissimilarity of what does not overlap". We address this by encoding and searching for "image segments" instead of the whole images. We propose to use open-set image segmentation to decompose an image into `meaningful' entities (i.e., things and stuff). This enables us to create a novel image representation as a collection of multiple overlapping subgraphs connecting a segment with its neighboring segments, dubbed SuperSegment. Furthermore, to efficiently encode these SuperSegments into compact vector representations, we propose a novel factorized representation of feature aggregation. We show that retrieving these partial representations leads to significantly higher recognition recall than the typical whole image based retrieval. Our segments-based approach, dubbed SegVLAD, sets a new state-of-the-art in place recognition on a diverse selection of benchmark datasets, while being applicable to both generic and task-specialized image encoders. Finally, we demonstrate the potential of our method to ``revisit anything'' by evaluating our method on an object instance retrieval task, which bridges the two disparate areas of research: visual place recognition and object-goal navigation, through their common aim of recognizing goal objects specific to a place. Source code: https://github.com/AnyLoc/Revisit-Anything.</td>
</tr>
<tr>
<td>IFCap：用于零样本描述生成的类图像检索与基于频率的实体过滤</td>
<td>近期图像描述生成领域的进展探索了仅使用文本进行训练的方法，以克服成对图像-文本数据集的局限性。然而，现有的仅使用文本的训练方法往往忽视了在训练过程中使用文本数据与在推理过程中使用图像之间的模态差异。为了解决这一问题，我们提出了一种名为“类图像检索”的新方法，该方法通过将文本特征与视觉相关特征对齐来缓解模态差异。我们的方法通过设计一个融合模块，将检索到的描述与输入特征相结合，进一步提高了生成描述的准确性。此外，我们还引入了一种基于频率的实体过滤技术，显著提升了描述质量。我们将这些方法整合到一个统一的框架中，称之为IFCap（$\textbf{I}$mage-like Retrieval and $\textbf{F}$requency-based Entity Filtering for Zero-shot $\textbf{Cap}$tioning）。通过广泛的实验验证，我们简单而强大的方法展示了其有效性，在图像描述生成和视频描述生成方面，相较于仅基于文本训练的零样本描述生成，我们的方法显著优于当前最先进的方法。</td>
<td>Soeun Lee</td>
<td><a href="http://arxiv.org/pdf/2409.18046v1">PDF</a></td>
<td>N/A</td>
<td>IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning</td>
<td>Recent advancements in image captioning have explored text-only training methods to overcome the limitations of paired image-text data. However, existing text-only training methods often overlook the modality gap between using text data during training and employing images during inference. To address this issue, we propose a novel approach called Image-like Retrieval, which aligns text features with visually relevant features to mitigate the modality gap. Our method further enhances the accuracy of generated captions by designing a Fusion Module that integrates retrieved captions with input features. Additionally, we introduce a Frequency-based Entity Filtering technique that significantly improves caption quality. We integrate these methods into a unified framework, which we refer to as IFCap ($\textbf{I}$mage-like Retrieval and $\textbf{F}$requency-based Entity Filtering for Zero-shot $\textbf{Cap}$tioning). Through extensive experimentation, our straightforward yet powerful approach has demonstrated its efficacy, outperforming the state-of-the-art methods by a significant margin in both image captioning and video captioning compared to zero-shot captioning based on text-only training.</td>
</tr>
<tr>
<td>揭示预训练在直接语音翻译中的作用</td>
<td>直接语音到文本翻译系统面临的一个重要问题是数据稀缺。一个常见的解决方案是在自动语音识别上预训练编码器，从而在训练过程中牺牲了效率。在本研究中，我们比较了使用预训练编码器的系统、传统方法以及从零开始训练的系统的训练动态。我们观察到，在整个训练过程中，随机初始化的模型在预测时难以从语音输入中整合信息。因此，我们假设这一问题源于有效训练直接语音翻译编码器的困难。从零开始训练的模型需要同时学习声学和语义建模，而预训练的模型则只需专注于后者。基于这些发现，我们提出在解码器交叉注意力机制中进行细微调整，以在训练早期步骤中整合源信息。我们表明，通过这一调整，从零开始训练的模型可以实现与预训练模型相当的性能，同时减少了训练时间。</td>
<td>Belen Alastruey</td>
<td><a href="http://arxiv.org/pdf/2409.18044v1">PDF</a></td>
<td>N/A</td>
<td>Unveiling the Role of Pretraining in Direct Speech Translation</td>
<td>Direct speech-to-text translation systems encounter an important drawback in data scarcity. A common solution consists on pretraining the encoder on automatic speech recognition, hence losing efficiency in the training process. In this study, we compare the training dynamics of a system using a pretrained encoder, the conventional approach, and one trained from scratch. We observe that, throughout the training, the randomly initialized model struggles to incorporate information from the speech inputs for its predictions. Hence, we hypothesize that this issue stems from the difficulty of effectively training an encoder for direct speech translation. While a model trained from scratch needs to learn acoustic and semantic modeling simultaneously, a pretrained one can just focus on the latter. Based on these findings, we propose a subtle change in the decoder cross-attention to integrate source information from earlier steps in training. We show that with this change, the model trained from scratch can achieve comparable performance to the pretrained one, while reducing the training time.</td>
</tr>
<tr>
<td>EMOVA：赋予语言模型以生动的情感，使其能够看、听和说</td>
<td>GPT-4o，一个能够实现多样化情感和语调的语音对话的全模态模型，标志着全模态基础模型的里程碑。然而，在开源社区中，使大型语言模型能够感知和生成图像、文本和语音的全流程处理，并利用公开数据仍然是一个挑战。现有的视觉-语言模型依赖于外部工具进行语音处理，而语音-语言模型在视觉理解能力上仍然有限甚至缺失。为了填补这一空白，我们提出了EMOVA（情感全在的语音助手），以赋予大型语言模型端到端的语音能力，同时保持领先的视觉-语言性能。通过语义-声学解耦的语音标记器，我们惊奇地发现，全模态对齐可以进一步增强视觉-语言和语音能力，相比于相应的双模态对齐模型。此外，我们还提出了一个轻量级的风格模块，用于灵活的语音风格控制（如情感和音调）。首次，EMOVA在视觉-语言和语音基准测试中均达到了最先进的性能，并且同时支持带有生动情感的全模态语音对话。</td>
<td>Kai Chen</td>
<td><a href="http://arxiv.org/pdf/2409.18042v1">PDF</a></td>
<td>N/A</td>
<td>EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions</td>
<td>GPT-4o, an omni-modal model that enables vocal conversations with diverse emotions and tones, marks a milestone for omni-modal foundation models. However, empowering Large Language Models to perceive and generate images, texts, and speeches end-to-end with publicly available data remains challenging in the open-source community. Existing vision-language models rely on external tools for the speech processing, while speech-language models still suffer from limited or even without vision-understanding abilities. To address this gap, we propose EMOVA (EMotionally Omni-present Voice Assistant), to enable Large Language Models with end-to-end speech capabilities while maintaining the leading vision-language performance. With a semantic-acoustic disentangled speech tokenizer, we notice surprisingly that omni-modal alignment can further enhance vision-language and speech abilities compared with the corresponding bi-modal aligned counterparts. Moreover, a lightweight style module is proposed for flexible speech style controls (e.g., emotions and pitches). For the first time, EMOVA achieves state-of-the-art performance on both the vision-language and speech benchmarks, and meanwhile, supporting omni-modal spoken dialogue with vivid emotions.</td>
</tr>
<tr>
<td>使用自然语言处理自动检测和分析说服性文本中的权力词汇</td>
<td>权力词汇是指能够引发强烈情感反应并显著影响读者行为的术语，在营销、政治和励志写作等领域中发挥着至关重要的作用。本研究提出了一种使用自定义词典和Python中的TextBlob库自动检测和分析说服性文本中权力词汇的方法。通过识别给定文本中权力词汇的存在及其频率，我们旨在对其进行分类并分析它们对情感和读者参与度的影响。本研究考察了跨多个领域的多样化数据集，以提供关于权力词汇有效性的见解，为内容创作者、广告商和政策制定者提供实际应用。</td>
<td>Sahil Garje</td>
<td><a href="http://arxiv.org/pdf/2409.18033v1">PDF</a></td>
<td>N/A</td>
<td>Automated Detection and Analysis of Power Words in Persuasive Text Using Natural Language Processing</td>
<td>Power words are terms that evoke strong emotional responses and significantly influence readers' behavior, playing a crucial role in fields like marketing, politics, and motivational writing. This study proposes a methodology for the automated detection and analysis of power words in persuasive text using a custom lexicon and the TextBlob library in Python. By identifying the presence and frequency of power words within a given text, we aim to classify and analyze their impact on sentiment and reader engagement. This research examines diverse datasets across various domains to provide insights into the effectiveness of power words, offering practical applications for content creators, advertisers, and policymakers.</td>
</tr>
<tr>
<td>FlowBench：一个面向复杂几何体的流体模拟大规模基准测试</td>
<td>模拟流体在任意形状周围的流动是解决各种工程问题的关键。然而，在复杂几何形状上模拟流体物理仍然在数值计算上具有挑战性，并且计算资源密集，特别是在使用传统的偏微分方程（PDE）求解器时。机器学习方法提供了创建快速且适应性强的PDE求解器的诱人机会。然而，用于评估这些方法性能的基准数据集非常稀缺，尤其是对于复杂几何形状上的流体物理。我们引入了FlowBench，这是一个包含超过10,000个样本的数据集，用于神经网络模拟器，目前比任何公开可用的流体物理数据集都要大。FlowBench包含了跨越复杂几何形状（参数化与非参数化）的流动模拟数据，涵盖了多种流动条件（雷诺数和格拉晓夫数），捕捉了多种流动现象（稳态与瞬态；强制对流与自由对流），并且适用于2D和3D。FlowBench包含超过10,000个数据样本，每个样本都是使用一个经过充分验证的模拟器框架进行完全解析的直接数值模拟的结果，该框架设计用于模拟复杂几何形状中的传输现象。对于每个样本，我们包含了在3种不同分辨率下的速度、压力和温度场数据，以及几个与工程相关的汇总统计特征（如升力系数和阻力系数，以及努塞尔数）。我们设想FlowBench将有助于评估复杂几何形状、耦合流动现象和数据充分性之间的相互作用对当前及未来神经PDE求解器性能的影响。我们列举了几种评估指标，以帮助对神经PDE求解器的性能进行排序。我们基准测试了几种基线方法的性能，包括FNO、CNO、WNO和DeepONet。</td>
<td>Ronak Tali</td>
<td><a href="http://arxiv.org/pdf/2409.18032v1">PDF</a></td>
<td>N/A</td>
<td>FlowBench: A Large Scale Benchmark for Flow Simulation over Complex Geometries</td>
<td>Simulating fluid flow around arbitrary shapes is key to solving various engineering problems. However, simulating flow physics across complex geometries remains numerically challenging and computationally resource-intensive, particularly when using conventional PDE solvers. Machine learning methods offer attractive opportunities to create fast and adaptable PDE solvers. However, benchmark datasets to measure the performance of such methods are scarce, especially for flow physics across complex geometries. We introduce FlowBench, a dataset for neural simulators with over 10K samples, which is currently larger than any publicly available flow physics dataset. FlowBench contains flow simulation data across complex geometries (\textit{parametric vs. non-parametric}), spanning a range of flow conditions (\textit{Reynolds number and Grashoff number}), capturing a diverse array of flow phenomena (\textit{steady vs. transient; forced vs. free convection}), and for both 2D and 3D. FlowBench contains over 10K data samples, with each sample the outcome of a fully resolved, direct numerical simulation using a well-validated simulator framework designed for modeling transport phenomena in complex geometries. For each sample, we include velocity, pressure, and temperature field data at 3 different resolutions and several summary statistics features of engineering relevance (such as coefficients of lift and drag, and Nusselt numbers). %Additionally, we include masks and signed distance fields for each shape. We envision that FlowBench will enable evaluating the interplay between complex geometry, coupled flow phenomena, and data sufficiency on the performance of current, and future, neural PDE solvers. We enumerate several evaluation metrics to help rank order the performance of neural PDE solvers. We benchmark the performance of several baseline methods including FNO, CNO, WNO, and DeepONet.</td>
</tr>
<tr>
<td>大型语言模型中代码的组合硬度 -- 一个概率视角</td>
<td>在使用大型语言模型（LLM）进行复杂分析任务（如代码生成）时，一种常见的做法是在模型的上下文窗口内为整个任务采样一个解决方案。先前的研究表明，在模型的上下文中进行子任务分解（即思维链）有助于解决此类任务。在这项工作中，我们指出LLM在同一上下文窗口内执行多个子任务的能力存在局限性——即上下文内的组合难度，这表明在多智能体系统中分解问题具有优势。组合难度通过生成复杂度指标来量化，即采样至少一个正确解决方案所需的LLM生成次数。我们发现，相对于在多个智能体之间分配问题，在同一上下文中解决组合问题的生成复杂度存在差距，并且随着解决方案长度的增加，这一差距呈指数级增长。我们通过理论证明和实证演示验证了我们的结果。</td>
<td>Yotam Wolf</td>
<td><a href="http://arxiv.org/pdf/2409.18028v1">PDF</a></td>
<td>N/A</td>
<td>Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspective</td>
<td>A common practice in large language model (LLM) usage for complex analytical tasks such as code generation, is to sample a solution for the entire task within the model's context window. Previous works have shown that subtask decomposition within the model's context (chain of thought), is beneficial for solving such tasks. In this work, we point a limitation of LLMs' ability to perform several sub-tasks within the same context window - an in-context hardness of composition, pointing to an advantage for distributing a decomposed problem in a multi-agent system of LLMs. The hardness of composition is quantified by a generation complexity metric, i.e., the number of LLM generations required to sample at least one correct solution. We find a gap between the generation complexity of solving a compositional problem within the same context relative to distributing it among multiple agents, that increases exponentially with the solution's length. We prove our results theoretically and demonstrate them empirically.</td>
</tr>
<tr>
<td>从对抗角度看AI安全的机器遗忘问题</td>
<td>大型语言模型经过微调，以拒绝回答有关危险知识的问题，但这些保护措施往往可以被绕过。遗忘方法旨在彻底消除模型的危险能力，使其无法被对手利用。本研究从对抗性角度探讨了遗忘与传统安全后训练之间的根本差异。我们证明，尽管先前被认为对遗忘无效的现有越狱方法，在谨慎应用时可以取得成功。此外，我们开发了多种自适应方法，恢复了大部分被认为已遗忘的能力。例如，我们展示了通过对10个不相关的示例进行微调，或在激活空间中移除特定方向，可以恢复使用RMU（一种最先进的遗忘方法）编辑的模型的大部分危险能力。我们的发现挑战了当前遗忘方法的鲁棒性，并对其相对于安全训练的优势提出了质疑。</td>
<td>Jakub Łucki</td>
<td><a href="http://arxiv.org/pdf/2409.18025v1">PDF</a></td>
<td>N/A</td>
<td>An Adversarial Perspective on Machine Unlearning for AI Safety</td>
<td>Large language models are finetuned to refuse questions about hazardous knowledge, but these protections can often be bypassed. Unlearning methods aim at completely removing hazardous capabilities from models and make them inaccessible to adversaries. This work challenges the fundamental differences between unlearning and traditional safety post-training from an adversarial perspective. We demonstrate that existing jailbreak methods, previously reported as ineffective against unlearning, can be successful when applied carefully. Furthermore, we develop a variety of adaptive methods that recover most supposedly unlearned capabilities. For instance, we show that finetuning on 10 unrelated examples or removing specific directions in the activation space can recover most hazardous capabilities for models edited with RMU, a state-of-the-art unlearning method. Our findings challenge the robustness of current unlearning approaches and question their advantages over safety training.</td>
</tr>
<tr>
<td>DARE：具有鲁棒性评估的多样化视觉问答</td>
<td>视觉语言模型（VLMs）扩展了仅文本大型语言模型和仅视觉模型的显著能力，并且能够从多模态视觉文本输入中学习和处理信息。尽管现代VLMs在许多标准图像分类和图像文本匹配任务中表现出色，但它们在许多关键的视觉语言（VL）推理能力上仍显不足，如计数和空间推理。此外，尽管它们对指令和/或评估协议的小变化可能非常脆弱，但现有的基准测试未能评估其鲁棒性（或更确切地说，缺乏鲁棒性）。为了将具有挑战性的VL场景与全面的鲁棒性评估相结合，我们引入了DARE，即多样化的视觉问答与鲁棒性评估，这是一个精心创建和策划的多项选择VQA基准。DARE评估VLM在五个不同类别上的表现，并包括基于提示、答案选项子集、输出格式和正确答案数量变化的四种鲁棒性评估。在其他一系列发现中，我们报告称，最先进的VLMs在大多数类别的问题上仍显吃力，并且在测试的鲁棒性评估中无法持续达到其峰值性能。在选项子集中的最差表现比标准情况下的表现低达34%。开源VLMs如LLaVA 1.6和Idefics2的鲁棒性无法与闭源模型如GPT-4和Gemini相媲美，但即使是后者对不同变化的适应性也非常脆弱。</td>
<td>Hannah Sterz</td>
<td><a href="http://arxiv.org/pdf/2409.18023v1">PDF</a></td>
<td>N/A</td>
<td>DARE: Diverse Visual Question Answering with Robustness Evaluation</td>
<td>Vision Language Models (VLMs) extend remarkable capabilities of text-only large language models and vision-only models, and are able to learn from and process multi-modal vision-text input. While modern VLMs perform well on a number of standard image classification and image-text matching tasks, they still struggle with a number of crucial vision-language (VL) reasoning abilities such as counting and spatial reasoning. Moreover, while they might be very brittle to small variations in instructions and/or evaluation protocols, existing benchmarks fail to evaluate their robustness (or rather the lack of it). In order to couple challenging VL scenarios with comprehensive robustness evaluation, we introduce DARE, Diverse Visual Question Answering with Robustness Evaluation, a carefully created and curated multiple-choice VQA benchmark. DARE evaluates VLM performance on five diverse categories and includes four robustness-oriented evaluations based on the variations of: prompts, the subsets of answer options, the output format and the number of correct answers. Among a spectrum of other findings, we report that state-of-the-art VLMs still struggle with questions in most categories and are unable to consistently deliver their peak performance across the tested robustness evaluations. The worst case performance across the subsets of options is up to 34% below the performance in the standard case. The robustness of the open-source VLMs such as LLaVA 1.6 and Idefics2 cannot match the closed-source models such as GPT-4 and Gemini, but even the latter remain very brittle to different variations.</td>
</tr>
<tr>
<td>将超导光电网络与经典神经动力学联系起来</td>
<td>由超导光电突触、树突和神经元组成的电路，其描述方式是通过数值复杂且形式晦涩的耦合微分方程。参考文献1表明，超导环神经元的现象学模型消除了求解描述突触和树突的约瑟夫森电路方程的需求。该模型的最初目标是减少模拟所需的时间，然而，该模型的另一个好处是增加了对底层神经电路操作的透明度，以及关于环神经元与其他物理系统连接的概念清晰度。虽然原始模型通过仅考虑树突输出的低通版本简化了约瑟夫森结动力学的处理，但该模型对由半导体发射电路产生的尖峰采用了尴尬的处理方式，这需要显式检查阈值交叉和达到胞体阈值的时间步长的不同处理。在这里，我们扩展了该模型，以简化来自胞体的尖峰处理，再次利用了神经系统中尖峰事件的下游接收者几乎总是执行低通滤波的事实。我们提供了第一和第二现象学模型之间的比较，量化了额外近似的准确性。我们确定了电路参数空间中扩展模型运行良好的区域和运行不佳的区域。对于某些电路参数，可以表示下游树突对单个尖峰以及尖峰重合或序列的响应，这表明该模型不仅仅是速率编码的简化。控制方程几乎与神经科学文献中用于建模泄漏积分器树突和神经元的方程相同。</td>
<td>Jeffrey M. Shainline</td>
<td><a href="http://arxiv.org/pdf/2409.18016v1">PDF</a></td>
<td>N/A</td>
<td>Relating Superconducting Optoelectronic Networks to Classical Neurodynamics</td>
<td>The circuits comprising superconducting optoelectronic synapses, dendrites, and neurons are described by numerically cumbersome and formally opaque coupled differential equations. Reference 1 showed that a phenomenological model of superconducting loop neurons eliminates the need to solve the Josephson circuit equations that describe synapses and dendrites. The initial goal of the model was to decrease the time required for simulations, yet an additional benefit of the model was increased transparency of the underlying neural circuit operations and conceptual clarity regarding the connection of loop neurons to other physical systems. Whereas the original model simplified the treatment of the Josephson-junction dynamics, essentially by only considering low-pass versions of the dendritic outputs, the model resorted to an awkward treatment of spikes generated by semiconductor transmitter circuits that required explicitly checking for threshold crossings and distinct treatment of time steps wherein somatic threshold is reached. Here we extend that model to simplify the treatment of spikes coming from somas, again making use of the fact that in neural systems the downstream recipients of spike events almost always perform low-pass filtering. We provide comparisons between the first and second phenomenological models, quantifying the accuracy of the additional approximations. We identify regions of circuit parameter space in which the extended model works well and regions where it works poorly. For some circuit parameters it is possible to represent the downstream dendritic response to a single spike as well as coincidences or sequences of spikes, indicating the model is not simply a reduction to rate coding. The governing equations are shown to be nearly identical to those ubiquitous in the neuroscience literature for modeling leaky-integrator dendrites and neurons.</td>
</tr>
<tr>
<td>基于细胞嵌入图的空间时间学习</td>
<td>数据驱动的物理系统模拟近年来引起了广泛关注，其中许多神经网络模型被开发出来。特别是基于网格的图神经网络（GNNs）在预测任意几何域上的时空动态方面展示了巨大的潜力。然而，GNNs中现有的节点-边消息传递机制限制了模型的表示学习能力。在本文中，我们提出了一种嵌入单元格的GNN模型（简称CeGNN），以提升性能来学习时空动态。具体来说，我们在节点-边消息传递过程中引入了一个可学习的单元属性，从而更好地捕捉区域特征的空间依赖性。这种策略本质上将局部聚合方案从一阶（例如，从边到节点）升级到更高阶（例如，从体积到边，再到节点），从而在消息传递中利用了体积信息。同时，设计了一种新颖的特征增强块，通过将潜在特征视为基函数，进一步提高了CeGNN的性能并缓解了过平滑问题。在各种偏微分方程（PDE）系统和一项真实世界数据集上的广泛实验表明，CeGNN相比其他基线模型表现更优，特别是在几个PDE系统上将预测误差降低了多达一个数量级。</td>
<td>Yuan Mi</td>
<td><a href="http://arxiv.org/pdf/2409.18013v1">PDF</a></td>
<td>N/A</td>
<td>Spatiotemporal Learning on Cell-embedded Graphs</td>
<td>Data-driven simulation of physical systems has recently kindled significant attention, where many neural models have been developed. In particular, mesh-based graph neural networks (GNNs) have demonstrated significant potential in predicting spatiotemporal dynamics across arbitrary geometric domains. However, the existing node-edge message passing mechanism in GNNs limits the model's representation learning ability. In this paper, we proposed a cell-embedded GNN model (aka CeGNN) to learn spatiotemporal dynamics with lifted performance. Specifically, we introduce a learnable cell attribution to the node-edge message passing process, which better captures the spatial dependency of regional features. Such a strategy essentially upgrades the local aggregation scheme from the first order (e.g., from edge to node) to a higher order (e.g., from volume to edge and then to node), which takes advantage of volumetric information in message passing. Meanwhile, a novel feature-enhanced block is designed to further improve the performance of CeGNN and relieve the over-smoothness problem, via treating the latent features as basis functions. The extensive experiments on various PDE systems and one real-world dataset demonstrate that CeGNN achieves superior performance compared with other baseline models, particularly reducing the prediction error with up to 1 orders of magnitude on several PDE systems.</td>
</tr>
<tr>
<td>多语言长上下文检索与推理评估</td>
<td>最近的大型语言模型（LLMs）在处理长上下文方面展示了令人印象深刻的能力，其中一些在合成检索任务中表现出近乎完美的召回率。然而，这些评估主要集中在英语文本上，并且涉及长上下文中的单一句子目标。我们的工作研究了LLM性能如何推广到多语言环境中，其中包含多个隐藏的目标句子。我们对几种长上下文LLM在五种语言（英语、越南语、印度尼西亚语、斯瓦希里语和索马里语）的检索和推理任务上进行了全面评估。这些语言共享拉丁字母，但属于不同的语言家族和资源水平。我们的分析揭示了语言之间显著的性能差距。表现最佳的模型如Gemini-1.5和GPT-4o，在英语中单一句子目标的准确率约为96%，而在索马里语中约为36%。然而，当处理三个目标句子时，这一准确率在英语中下降到40%，在索马里语中下降到0%。我们的研究结果突显了长上下文LLM在处理更长上下文、增加目标句子数量或低资源语言时面临的挑战。</td>
<td>Ameeta Agrawal</td>
<td><a href="http://arxiv.org/pdf/2409.18006v1">PDF</a></td>
<td>N/A</td>
<td>Multilingual Evaluation of Long Context Retrieval and Reasoning</td>
<td>Recent large language models (LLMs) demonstrate impressive capabilities in handling long contexts, some exhibiting near-perfect recall on synthetic retrieval tasks. However, these evaluations have mainly focused on English text and involved a single target sentence within lengthy contexts. Our work investigates how LLM performance generalizes to multilingual settings with multiple hidden target sentences. We comprehensively evaluate several long-context LLMs on retrieval and reasoning tasks across five languages: English, Vietnamese, Indonesian, Swahili, and Somali. These languages share the Latin script but belong to distinct language families and resource levels. Our analysis reveals a significant performance gap between languages. The best-performing models such as Gemini-1.5 and GPT-4o, achieve around 96% accuracy in English to around 36% in Somali with a single target sentence. However, this accuracy drops to 40% in English and 0% in Somali when dealing with three target sentences. Our findings highlight the challenges long-context LLMs face when processing longer contexts, an increase in the number of target sentences, or languages of lower resource levels.</td>
</tr>
<tr>
<td>基于高斯过程和时空核的安全时变优化</td>
<td>确保安全是序列决策问题中的一个关键方面，例如机器人技术或过程控制。底层系统的复杂性通常使得找到最优决策变得困难，尤其是在安全关键系统随时间变化的情况下。为了克服在未知时变安全约束下优化未知时变奖励的问题，我们提出了TVSafeOpt，这是一种基于贝叶斯优化和时空核的新算法。该算法能够在不需要显式变化检测的情况下安全地跟踪时变的安全区域。当优化问题变得静止时，我们还为该算法提供了最优性保证。我们展示了TVSafeOpt在合成数据上与SafeOpt相比，在安全性和最优性方面都表现出色。对气体压缩机的实际案例研究评估证实，TVSafeOpt在解决具有未知奖励和安全函数的时变优化问题时能够确保安全。</td>
<td>Jialin Li</td>
<td><a href="http://arxiv.org/pdf/2409.18000v1">PDF</a></td>
<td>N/A</td>
<td>Safe Time-Varying Optimization based on Gaussian Processes with Spatio-Temporal Kernel</td>
<td>Ensuring safety is a key aspect in sequential decision making problems, such as robotics or process control. The complexity of the underlying systems often makes finding the optimal decision challenging, especially when the safety-critical system is time-varying. Overcoming the problem of optimizing an unknown time-varying reward subject to unknown time-varying safety constraints, we propose TVSafeOpt, a new algorithm built on Bayesian optimization with a spatio-temporal kernel. The algorithm is capable of safely tracking a time-varying safe region without the need for explicit change detection. Optimality guarantees are also provided for the algorithm when the optimization problem becomes stationary. We show that TVSafeOpt compares favorably against SafeOpt on synthetic data, both regarding safety and optimality. Evaluation on a realistic case study with gas compressors confirms that TVSafeOpt ensures safety when solving time-varying optimization problems with unknown reward and safety functions.</td>
</tr>
<tr>
<td>PhoCoLens：无镜头成像中的逼真一致重建</td>
<td>无透镜相机在尺寸、重量和成本方面相较于传统的基于透镜的系统具有显著优势。由于没有聚焦透镜，无透镜相机依赖于计算算法从多路复用测量中恢复场景。然而，当前的算法在处理不准确的前向成像模型和不足的先验信息以重建高质量图像方面存在困难。为了克服这些限制，我们提出了一种新颖的两阶段方法，用于一致且逼真的无透镜图像重建。我们的方法的第一阶段通过采用空间变化的去卷积方法，专注于准确重建低频内容，该方法能够适应点扩散函数（PSF）在整个相机视场中的变化，从而确保数据一致性。第二阶段通过结合预训练扩散模型的生成先验来增强图像的逼真度。通过以第一阶段获取的低频内容为条件，扩散模型有效地重建了通常在无透镜成像过程中丢失的高频细节，同时保持了图像的保真度。与现有的方法相比，我们的方法在数据保真度和视觉质量之间实现了更优越的平衡，这一点通过两个流行的无透镜系统——PhlatCam和DiffuserCam——得到了验证。项目网站：https://phocolens.github.io/。</td>
<td>Xin Cai</td>
<td><a href="http://arxiv.org/pdf/2409.17996v1">PDF</a></td>
<td>N/A</td>
<td>PhoCoLens: Photorealistic and Consistent Reconstruction in Lensless Imaging</td>
<td>Lensless cameras offer significant advantages in size, weight, and cost compared to traditional lens-based systems. Without a focusing lens, lensless cameras rely on computational algorithms to recover the scenes from multiplexed measurements. However, current algorithms struggle with inaccurate forward imaging models and insufficient priors to reconstruct high-quality images. To overcome these limitations, we introduce a novel two-stage approach for consistent and photorealistic lensless image reconstruction. The first stage of our approach ensures data consistency by focusing on accurately reconstructing the low-frequency content with a spatially varying deconvolution method that adjusts to changes in the Point Spread Function (PSF) across the camera's field of view. The second stage enhances photorealism by incorporating a generative prior from pre-trained diffusion models. By conditioning on the low-frequency content retrieved in the first stage, the diffusion model effectively reconstructs the high-frequency details that are typically lost in the lensless imaging process, while also maintaining image fidelity. Our method achieves a superior balance between data fidelity and visual quality compared to existing methods, as demonstrated with two popular lensless systems, PhlatCam and DiffuserCam. Project website: https://phocolens.github.io/.</td>
</tr>
<tr>
<td>使用扩散的联合定位与规划</td>
<td>扩散模型已成功应用于机器人学中的问题，如操控和车辆路径规划。在这项工作中，我们探索了它们在端到端导航中的应用——包括感知和规划——通过考虑在已知但任意的2D环境中联合执行全局定位和路径规划的问题。特别是，我们引入了一种扩散模型，该模型在给定以自我为中心的LIDAR扫描、任意地图和期望目标位置的情况下，在全局参考框架中生成无碰撞路径。为此，我们在SE(2)路径空间中实现扩散，并描述了如何根据障碍物和传感器观测来调节去噪过程。在我们的评估中，我们展示了所提出的条件技术能够推广到与训练环境外观显著不同的真实地图，展示了我们模型准确描述模糊解决方案的能力，并进行了广泛的仿真实验，展示了我们模型作为实时端到端定位和规划堆栈的使用。</td>
<td>L. Lao Beyer</td>
<td><a href="http://arxiv.org/pdf/2409.17995v1">PDF</a></td>
<td>N/A</td>
<td>Joint Localization and Planning using Diffusion</td>
<td>Diffusion models have been successfully applied to robotics problems such as manipulation and vehicle path planning. In this work, we explore their application to end-to-end navigation -- including both perception and planning -- by considering the problem of jointly performing global localization and path planning in known but arbitrary 2D environments. In particular, we introduce a diffusion model which produces collision-free paths in a global reference frame given an egocentric LIDAR scan, an arbitrary map, and a desired goal position. To this end, we implement diffusion in the space of paths in SE(2), and describe how to condition the denoising process on both obstacles and sensor observations. In our evaluation, we show that the proposed conditioning techniques enable generalization to realistic maps of considerably different appearance than the training environment, demonstrate our model's ability to accurately describe ambiguous solutions, and run extensive simulation experiments showcasing our model's use as a real-time, end-to-end localization and planning stack.</td>
</tr>
<tr>
<td>LoopSR：针对足式机器人终身策略适应的循环仿真与现实方法</td>
<td>强化学习（RL）通过从模拟到现实的迁移，展示了其在足式运动中的显著且可泛化的能力。然而，尽管像领域随机化这样的自适应方法有望使策略对多样化的环境更具鲁棒性，但根据无免费午餐定理，这种全面性可能会在任何特定环境中降低策略的性能，导致在现实世界部署时产生次优解。为了解决这一问题，我们提出了一种名为LoopSR的终身策略适应框架，该框架利用基于Transformer的编码器将现实世界的轨迹投影到潜在空间，并相应地在模拟中重建现实世界的环境以进行进一步改进。我们采用了自编码器架构和对比学习方法，以更好地提取现实世界动力学的特征。持续训练的模拟参数是通过结合解码器预测的参数和从模拟轨迹数据集中检索的参数得出的。通过利用持续训练，LoopSR在数据效率方面优于强大的基线，仅需有限的数据量即可在模拟到模拟和模拟到现实的实验中取得卓越的性能。</td>
<td>Peilin Wu</td>
<td><a href="http://arxiv.org/pdf/2409.17992v1">PDF</a></td>
<td>N/A</td>
<td>LoopSR: Looping Sim-and-Real for Lifelong Policy Adaptation of Legged Robots</td>
<td>Reinforcement Learning (RL) has shown its remarkable and generalizable capability in legged locomotion through sim-to-real transfer. However, while adaptive methods like domain randomization are expected to make policy more robust to diverse environments, such comprehensiveness potentially detracts from the policy's performance in any specific environment according to the No Free Lunch theorem, leading to a suboptimal solution once deployed in the real world. To address this issue, we propose a lifelong policy adaptation framework named LoopSR, which utilizes a transformer-based encoder to project real-world trajectories into a latent space, and accordingly reconstruct the real-world environments back in simulation for further improvement. Autoencoder architecture and contrastive learning methods are adopted to better extract the characteristics of real-world dynamics. The simulation parameters for continual training are derived by combining predicted parameters from the decoder with retrieved parameters from the simulation trajectory dataset. By leveraging the continual training, LoopSR achieves superior data efficiency compared with strong baselines, with only a limited amount of data to yield eminent performance in both sim-to-sim and sim-to-real experiments.</td>
</tr>
<tr>
<td>高维分类问题的维度无关学习率</td>
<td>我们研究了在$RBV^2$空间中具有决策边界的分类函数的近似和估计问题。$RBV^2$类型的函数自然地作为正则化神经网络学习问题的解出现，并且神经网络可以在不受到维度灾难影响的情况下近似这些函数。我们修改了现有结果，证明了每个$RBV^2$函数都可以通过具有有界权重的神经网络来近似。随后，我们证明了存在一个具有有界权重的神经网络来近似分类函数。我们利用这些界限来量化估计速率。最后，我们进行了一项数值研究，分析了不同正则性条件对决策边界的影响。</td>
<td>Andres Felipe Lerma-Pineda</td>
<td><a href="http://arxiv.org/pdf/2409.17991v1">PDF</a></td>
<td>N/A</td>
<td>Dimension-independent learning rates for high-dimensional classification problems</td>
<td>We study the problem of approximating and estimating classification functions that have their decision boundary in the $RBV^2$ space. Functions of $RBV^2$ type arise naturally as solutions of regularized neural network learning problems and neural networks can approximate these functions without the curse of dimensionality. We modify existing results to show that every $RBV^2$ function can be approximated by a neural network with bounded weights. Thereafter, we prove the existence of a neural network with bounded weights approximating a classification function. And we leverage these bounds to quantify the estimation rates. Finally, we present a numerical study that analyzes the effect of different regularity conditions on the decision boundaries.</td>
</tr>
<tr>
<td>从纵向社交媒体数据中提取情感聚合，并使用时间适配器进行大型语言模型的处理</td>
<td>本文提出将时间对齐的大型语言模型（LLMs）作为社交媒体数据纵向分析的工具。我们对Llama 3 8B模型的时间适配器进行了微调，基于一批英国Twitter用户的完整时间线数据，并利用已建立的问卷提取情感和态度的纵向聚合数据。我们通过与代表性的英国调查数据进行对比验证，发现多个集体情感指标存在显著的正相关关系。所获得的估计值在多个训练种子和提示语句的设定下均表现出稳健性，并与使用传统分类模型在标注数据上训练提取的集体情感相一致。据我们所知，这是首次通过时间适配器将LLMs中的情感分析扩展到纵向情境的工作。我们的研究为社交媒体数据的纵向分析开辟了新的途径。</td>
<td>Georg Ahnert</td>
<td><a href="http://arxiv.org/pdf/2409.17990v1">PDF</a></td>
<td>N/A</td>
<td>Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models</td>
<td>This paper proposes temporally aligned Large Language Models (LLMs) as a tool for longitudinal analysis of social media data. We fine-tune Temporal Adapters for Llama 3 8B on full timelines from a panel of British Twitter users, and extract longitudinal aggregates of emotions and attitudes with established questionnaires. We validate our estimates against representative British survey data and find strong positive, significant correlations for several collective emotions. The obtained estimates are robust across multiple training seeds and prompt formulations, and in line with collective emotions extracted using a traditional classification model trained on labeled data. To the best of our knowledge, this is the first work to extend the analysis of affect in LLMs to a longitudinal setting through Temporal Adapters. Our work enables new approaches towards the longitudinal analysis of social media data.</td>
</tr>
<tr>
<td>动态图上的Transformer超拉普拉斯编码</td>
<td>全连接图变换器（GT）在静态图社区中迅速崭露头角，成为消息传递模型的替代方案，后者存在表达能力不足、过度压缩和覆盖不足的问题。然而，在动态环境中，通过在多个快照中将所有节点与自注意力机制互联，GT失去了结构和时间信息。在这项工作中，我们引入了时空变换器的超拉普拉斯编码（SLATE），这是一种新的时空编码方法，旨在利用GT架构的同时保留时空信息。具体来说，我们将离散时间动态图转换为多层图，并利用其相关超拉普拉斯矩阵的谱特性。我们的第二个贡献是通过交叉注意力机制显式建模节点间的成对关系，为动态链接预测提供了准确的边表示。SLATE在9个数据集上优于基于消息传递图神经网络与循环模型（如LSTM）结合的众多最先进方法，以及动态图变换器。代码和重现我们结果的说明将开源发布。</td>
<td>Yannis Karmim</td>
<td><a href="http://arxiv.org/pdf/2409.17986v1">PDF</a></td>
<td>N/A</td>
<td>Supra-Laplacian Encoding for Transformer on Dynamic Graphs</td>
<td>Fully connected Graph Transformers (GT) have rapidly become prominent in the static graph community as an alternative to Message-Passing models, which suffer from a lack of expressivity, oversquashing, and under-reaching. However, in a dynamic context, by interconnecting all nodes at multiple snapshots with self-attention, GT loose both structural and temporal information. In this work, we introduce Supra-LAplacian encoding for spatio-temporal TransformErs (SLATE), a new spatio-temporal encoding to leverage the GT architecture while keeping spatio-temporal information. Specifically, we transform Discrete Time Dynamic Graphs into multi-layer graphs and take advantage of the spectral properties of their associated supra-Laplacian matrix. Our second contribution explicitly model nodes' pairwise relationships with a cross-attention mechanism, providing an accurate edge representation for dynamic link prediction. SLATE outperforms numerous state-of-the-art methods based on Message-Passing Graph Neural Networks combined with recurrent models (e.g LSTM), and Dynamic Graph Transformers, on 9 datasets. Code and instructions to reproduce our results will be open-sourced.</td>
</tr>
<tr>
<td>多用户语义通信中的去中心化资源分配超博弈理论</td>
<td>语义通信（SC）是一种新兴的通信范式，其中无线设备仅从数据源发送相关信息，同时依赖计算资源来再生缺失的数据点。然而，由于协调所需的计算和通信开销，多用户SC系统的设计变得更加具有挑战性。现有的学习语义语言和执行资源分配的解决方案往往未能捕捉到多用户SC中涉及的计算和通信权衡。为了解决这一差距，提出了一种新颖的分散式计算和通信资源分配框架。通过应用斯塔克伯格超博弈理论，解决了在分散方式下高效分配通信和计算资源（用于推理）以最大化终端用户任务体验质量的挑战。利用二级超博弈的概念，开发了新的分析公式来模拟用户对彼此通信和控制策略的误解。此外，对学习到的资源分配协议的均衡分析考察了计算和通信策略在考虑误解的情况下向局部斯塔克伯格均衡的收敛性。仿真结果表明，与不考虑误解的最先进方法相比，所提出的斯塔克伯格超博弈在保持用户高体验质量的同时，实现了通信和计算资源的有效利用。</td>
<td>Christo Kurisummoottil Thomas</td>
<td><a href="http://arxiv.org/pdf/2409.17985v1">PDF</a></td>
<td>N/A</td>
<td>Hypergame Theory for Decentralized Resource Allocation in Multi-user Semantic Communications</td>
<td>Semantic communications (SC) is an emerging communication paradigm in which wireless devices can send only relevant information from a source of data while relying on computing resources to regenerate missing data points. However, the design of a multi-user SC system becomes more challenging because of the computing and communication overhead required for coordination. Existing solutions for learning the semantic language and performing resource allocation often fail to capture the computing and communication tradeoffs involved in multiuser SC. To address this gap, a novel framework for decentralized computing and communication resource allocation in multiuser SC systems is proposed. The challenge of efficiently allocating communication and computing resources (for reasoning) in a decentralized manner to maximize the quality of task experience for the end users is addressed through the application of Stackelberg hyper game theory. Leveraging the concept of second-level hyper games, novel analytical formulations are developed to model misperceptions of the users about each other's communication and control strategies. Further, equilibrium analysis of the learned resource allocation protocols examines the convergence of the computing and communication strategies to a local Stackelberg equilibria, considering misperceptions. Simulation results show that the proposed Stackelberg hyper game results in efficient usage of communication and computing resources while maintaining a high quality of experience for the users compared to state-of-the-art that does not account for the misperceptions.</td>
</tr>
<tr>
<td>HydraViT：为可扩展的ViT堆叠头部</td>
<td>Vision Transformers（ViTs）的架构，特别是多头注意力（MHA）机制，对硬件提出了巨大的需求。在具有不同约束条件的设备（如手机）上部署ViTs需要多种不同大小的模型。然而，这种方法存在局限性，例如需要分别训练和存储每个所需的模型。本文介绍了HydraViT，这是一种新颖的方法，通过堆叠注意力头来实现可扩展的ViT，从而解决了这些局限性。通过在训练过程中反复改变每个层中嵌入维度的尺寸及其在MHA中相应注意力头的数量，HydraViT诱导出多个子网络。因此，HydraViT在广泛的硬件环境中实现了适应性，同时保持了性能。我们的实验结果表明，HydraViT在实现可扩展的ViT方面具有高效性，最多可包含10个子网络，覆盖了广泛的资源约束范围。与基线相比，HydraViT在ImageNet-1K上实现了相同的GMACs下高达5个百分点的更高准确率，以及相同的吞吐量下高达7个百分点的更高准确率，使其成为硬件可用性多样或随时间变化的场景中的有效解决方案。源代码可在https://github.com/ds-kiel/HydraViT获取。</td>
<td>Janek Haberer</td>
<td><a href="http://arxiv.org/pdf/2409.17978v1">PDF</a></td>
<td>N/A</td>
<td>HydraViT: Stacking Heads for a Scalable ViT</td>
<td>The architecture of Vision Transformers (ViTs), particularly the Multi-head Attention (MHA) mechanism, imposes substantial hardware demands. Deploying ViTs on devices with varying constraints, such as mobile phones, requires multiple models of different sizes. However, this approach has limitations, such as training and storing each required model separately. This paper introduces HydraViT, a novel approach that addresses these limitations by stacking attention heads to achieve a scalable ViT. By repeatedly changing the size of the embedded dimensions throughout each layer and their corresponding number of attention heads in MHA during training, HydraViT induces multiple subnetworks. Thereby, HydraViT achieves adaptability across a wide spectrum of hardware environments while maintaining performance. Our experimental results demonstrate the efficacy of HydraViT in achieving a scalable ViT with up to 10 subnetworks, covering a wide range of resource constraints. HydraViT achieves up to 5 p.p. more accuracy with the same GMACs and up to 7 p.p. more accuracy with the same throughput on ImageNet-1K compared to the baselines, making it an effective solution for scenarios where hardware availability is diverse or varies over time. Source code available at https://github.com/ds-kiel/HydraViT.</td>
</tr>
<tr>
<td>BEATS：通过BackVerify和基于自适应消歧的高效树搜索优化LLM的数学能力</td>
<td>大型语言模型（LLMs）在广泛的任务和领域中展现了卓越的性能。然而，由于数学的严谨性和逻辑性，它们在解决数学问题时仍面临困难。先前的研究采用了监督微调（SFT）、提示工程和基于搜索的方法来提升LLMs的数学问题解决能力。尽管如此，这些方法的性能仍不尽如人意，且需要大量的计算资源。为解决这一问题，我们提出了一种新颖的方法——BEATS，以增强数学问题解决能力。我们的方法利用了新设计的提示，引导模型逐步重写、推进并基于前一步生成答案。此外，我们引入了一种新的后验证技术，利用LLMs验证生成答案的正确性。同时，我们采用了一种剪枝树搜索来优化搜索时间，同时保持强大的性能。值得注意的是，我们的方法将Qwen2-7b-Instruct的分数从36.94提升至61.52，超过了GPT4在MATH基准测试中的42.5分。</td>
<td>Linzhuang Sun</td>
<td><a href="http://arxiv.org/pdf/2409.17972v1">PDF</a></td>
<td>N/A</td>
<td>BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search</td>
<td>Large Language Models (LLMs) have exhibited exceptional performance across a broad range of tasks and domains. However, they still encounter difficulties in solving mathematical problems due to the rigorous and logical nature of mathematics. Previous studies have employed techniques such as supervised fine-tuning (SFT), prompt engineering, and search-based methods to improve the mathematical problem-solving abilities of LLMs. Despite these efforts, their performance remains suboptimal and demands substantial computational resources. To address this issue, we propose a novel approach, BEATS, to enhance mathematical problem-solving abilities. Our method leverages newly designed prompts that guide the model to iteratively rewrite, advance by one step, and generate answers based on previous steps. Additionally, we introduce a new back-verification technique that uses LLMs to validate the correctness of the generated answers. Furthermore, we employ a pruning tree search to optimize search time while achieving strong performance. Notably, our method improves Qwen2-7b-Instruct's score from 36.94 to 61.52, outperforming GPT4's 42.5 on the MATH benchmark.</td>
</tr>
<tr>
<td>关于视觉语言组合性的艰难正面事实</td>
<td>几项基准测试得出结论，我们最好的视觉语言模型（例如CLIP）在组合性方面存在不足。给定一张图片，这些基准测试会考察模型在一组组合性干扰项中识别其相关描述的能力。对此，近期的一系列提议通过使用干扰项作为硬负样本对CLIP进行微调，展示了改进效果。我们的调查揭示，这些改进实际上被大大夸大了——因为现有基准测试并未探究微调后的视觉语言模型是否对硬正样本保持不变。通过精心策划包含112,382个硬负样本和硬正样本的评估数据集，我们发现引入硬正样本会使CLIP的性能下降12.9%，而人类的表现则轻松达到99%。使用硬负样本微调的CLIP性能下降幅度更大，高达38.7%。基于这一发现，我们随后制作了一个包含1,775,259个图像-文本训练集，其中既有硬负样本也有硬正样本的描述。通过同时训练这两种样本，我们在现有基准测试中看到了改进，同时也在硬正样本上的表现有所提升，表明组合性方面的改进更为稳健。我们的工作表明，未来研究需要严格测试并提升CLIP对相关“正”概念之间语义关系的理解。</td>
<td>Amita Kamath</td>
<td><a href="http://arxiv.org/pdf/2409.17958v1">PDF</a></td>
<td>N/A</td>
<td>The Hard Positive Truth about Vision-Language Compositionality</td>
<td>Several benchmarks have concluded that our best vision-language models (e.g., CLIP) are lacking in compositionality. Given an image, these benchmarks probe a model's ability to identify its associated caption amongst a set of compositional distractors. In response, a surge of recent proposals show improvements by finetuning CLIP with distractors as hard negatives. Our investigations reveal that these improvements have, in fact, been significantly overstated -- because existing benchmarks do not probe whether finetuned vision-language models remain invariant to hard positives. By curating an evaluation dataset with 112,382 hard negatives and hard positives, we uncover that including hard positives decreases CLIP's performance by 12.9%, while humans perform effortlessly at 99%. CLIP finetuned with hard negatives results in an even larger decrease, up to 38.7%. With this finding, we then produce a 1,775,259 image-text training set with both hard negative and hard positive captions. By training with both, we see improvements on existing benchmarks while simultaneously improving performance on hard positives, indicating a more robust improvement in compositionality. Our work suggests the need for future research to rigorously test and improve CLIP's understanding of semantic relationships between related "positive" concepts.</td>
</tr>
<tr>
<td>针对LLMs的弱至强后门攻击：基于对比知识蒸馏的方法</td>
<td>尽管大型语言模型（LLMs）因其卓越的能力而被广泛应用，但已被证明容易受到后门攻击。这些攻击通过毒化训练样本和全参数微调引入了针对LLMs的目标漏洞。然而，这种后门攻击受到限制，因为它们需要大量的计算资源，尤其是随着LLMs规模的增加。此外，参数高效微调（PEFT）提供了一种替代方案，但其受限的参数更新可能会阻碍触发器与目标标签的对齐。在本研究中，我们首先验证了使用PEFT的后门攻击可能在实现可行性能方面遇到挑战。为了解决这些问题并提高使用PEFT的后门攻击的有效性，我们提出了一种基于对比知识蒸馏（W2SAttack）的由弱到强的新型后门攻击算法。具体来说，我们通过全参数微调毒化小规模语言模型，使其作为教师模型。然后，教师模型通过对比知识蒸馏将后门秘密传递给大规模学生模型，后者采用PEFT。理论分析表明，W2SAttack有可能增强后门攻击的效果。我们在四个语言模型、四个后门攻击算法和两种不同架构的教师模型上展示了W2SAttack在分类任务中的优越性能。实验结果显示，针对PEFT的后门攻击成功率接近100%。</td>
<td>Shuai Zhao</td>
<td><a href="http://arxiv.org/pdf/2409.17946v1">PDF</a></td>
<td>N/A</td>
<td>Weak-To-Strong Backdoor Attacks for LLMs with Contrastive Knowledge Distillation</td>
<td>Despite being widely applied due to their exceptional capabilities, Large Language Models (LLMs) have been proven to be vulnerable to backdoor attacks. These attacks introduce targeted vulnerabilities into LLMs by poisoning training samples and full-parameter fine-tuning. However, this kind of backdoor attack is limited since they require significant computational resources, especially as the size of LLMs increases. Besides, parameter-efficient fine-tuning (PEFT) offers an alternative but the restricted parameter updating may impede the alignment of triggers with target labels. In this study, we first verify that backdoor attacks with PEFT may encounter challenges in achieving feasible performance. To address these issues and improve the effectiveness of backdoor attacks with PEFT, we propose a novel backdoor attack algorithm from weak to strong based on contrastive knowledge distillation (W2SAttack). Specifically, we poison small-scale language models through full-parameter fine-tuning to serve as the teacher model. The teacher model then covertly transfers the backdoor to the large-scale student model through contrastive knowledge distillation, which employs PEFT. Theoretical analysis reveals that W2SAttack has the potential to augment the effectiveness of backdoor attacks. We demonstrate the superior performance of W2SAttack on classification tasks across four language models, four backdoor attack algorithms, and two different architectures of teacher models. Experimental results indicate success rates close to 100% for backdoor attacks targeting PEFT.</td>
</tr>
<tr>
<td>关于技术术语翻译：机器翻译缩略语的翻译工作流程</td>
<td>专业翻译人员将文档从源语言（SL）翻译为目标语言（TL）的典型工作流程，并不总是专注于许多自然语言处理（NLP）中的语言模型所做的事情——预测一系列单词中的下一个单词。尽管像英语和法语这样的高资源语言在使用BLEU和COMET等常见度量标准进行测量时，被报告达到了接近人类的水平，但我们发现一个重要的步骤被忽略了：技术术语的翻译，特别是缩略词。一些公开可用的最先进的机器翻译系统，如Google Translate，在处理缩略词时可能会出错——根据我们的研究，错误率高达50%。本文通过在SL-TL（FR-EN）翻译工作流程中提出一个额外的步骤来解决机器翻译系统中的缩略词歧义问题，首先我们提供了一个新的缩略词语料库供公众使用，然后实验了一种基于搜索的阈值算法，与Google Translate和OpusMT相比，该算法实现了近10%的提升。</td>
<td>Richard Yue</td>
<td><a href="http://arxiv.org/pdf/2409.17943v1">PDF</a></td>
<td>N/A</td>
<td>On Translating Technical Terminology: A Translation Workflow for Machine-Translated Acronyms</td>
<td>The typical workflow for a professional translator to translate a document from its source language (SL) to a target language (TL) is not always focused on what many language models in natural language processing (NLP) do - predict the next word in a series of words. While high-resource languages like English and French are reported to achieve near human parity using common metrics for measurement such as BLEU and COMET, we find that an important step is being missed: the translation of technical terms, specifically acronyms. Some state-of-the art machine translation systems like Google Translate which are publicly available can be erroneous when dealing with acronyms - as much as 50% in our findings. This article addresses acronym disambiguation for MT systems by proposing an additional step to the SL-TL (FR-EN) translation workflow where we first offer a new acronym corpus for public consumption and then experiment with a search-based thresholding algorithm that achieves nearly 10% increase when compared to Google Translate and OpusMT.</td>
</tr>
<tr>
<td>使用深度学习方法从翻译记忆中预测机器翻译的锚定文本</td>
<td>翻译记忆库（TMs）是专业翻译工具——计算机辅助翻译（CAT）工具的核心。为了使用CAT工具进行翻译，译者利用TM来收集与所需翻译片段（s'）相似的翻译。许多CAT工具提供模糊匹配算法，以定位TM中与s'距离相近的片段（s）。在找到两个相似片段后，CAT工具会展示包含源语言片段及其目标语言翻译的平行片段（s, t）。此外，CAT工具还包含模糊匹配修复（FMR）技术，这些技术会自动使用TM中的平行片段来创建新的TM条目，这些条目包含原始片段的修改版本，旨在作为s'的翻译。大多数FMR技术使用机器翻译作为“修复”那些需要修改的词汇的方法。在本文中，我们展示了对于那些锚定的词汇，我们可以使用基于机器学习方法的其他技术，如Word2Vec、BERT，甚至是ChatGPT。具体来说，我们展示了对于遵循连续词袋（CBOW）范式的锚定词，Word2Vec、BERT和GPT-4可以用于实现与神经机器翻译相似，甚至在某些情况下更好的结果，以将法语中的锚定词翻译成英语。</td>
<td>Richard Yue</td>
<td><a href="http://arxiv.org/pdf/2409.17939v1">PDF</a></td>
<td>N/A</td>
<td>Predicting Anchored Text from Translation Memories for Machine Translation Using Deep Learning Methods</td>
<td>Translation memories (TMs) are the backbone for professional translation tools called computer-aided translation (CAT) tools. In order to perform a translation using a CAT tool, a translator uses the TM to gather translations similar to the desired segment to translate (s'). Many CAT tools offer a fuzzy-match algorithm to locate segments (s) in the TM that are close in distance to s'. After locating two similar segments, the CAT tool will present parallel segments (s, t) that contain one segment in the source language along with its translation in the target language. Additionally, CAT tools contain fuzzy-match repair (FMR) techniques that will automatically use the parallel segments from the TM to create new TM entries containing a modified version of the original with the idea in mind that it will be the translation of s'. Most FMR techniques use machine translation as a way of "repairing" those words that have to be modified. In this article, we show that for a large part of those words which are anchored, we can use other techniques that are based on machine learning approaches such as Word2Vec. BERT, and even ChatGPT. Specifically, we show that for anchored words that follow the continuous bag-of-words (CBOW) paradigm, Word2Vec, BERT, and GPT-4 can be used to achieve similar and, for some cases, better results than neural machine translation for translating anchored words from French to English.</td>
</tr>
<tr>
<td>通过主动推理实现边缘设备上的自适应流处理</td>
<td>当前物联网（IoT）的情景正在经历数据量的持续增长，这些数据以持续流的形式生成，因此需要新颖的架构和逻辑解决方案来处理这些数据。将数据处理推向计算频谱的边缘，可以确保更好的负载分布，原则上还能降低延迟并提高隐私性。然而，管理这样的结构是复杂的，尤其是在需要确保应用程序所有者和基础设施管理者指定的要求（也称为服务级别目标，SLOs）时。尽管有大量的基于机器学习（ML）的管理解决方案提案，研究人员和从业者仍在努力保证长期的预测和控制，以及准确的问题排查。因此，我们提出了一种基于主动推理（AIF）的新型ML范式——这是一个来自神经科学的观念，描述了大脑如何持续预测和评估感官信息以减少长期意外。我们将其在一个异构的真实流处理用例中实现并评估，其中基于AIF的代理持续优化三个SLOs的满足度，这三个SLOs对应于在多个设备上运行的三个自动驾驶服务。该代理使用因果知识逐步发展出对其行动与需求满足度之间关系的理解，以及哪些配置应优先考虑。通过这种方法，我们的代理最多需要三十次迭代即可收敛到最优解，展示了在短时间内提供准确结果的能力。此外，得益于AIF及其因果结构，我们的方法保证了决策过程的完全透明性，使得结果的解释和问题排查变得轻而易举。</td>
<td>Boris Sedlak</td>
<td><a href="http://arxiv.org/pdf/2409.17937v1">PDF</a></td>
<td>N/A</td>
<td>Adaptive Stream Processing on Edge Devices through Active Inference</td>
<td>The current scenario of IoT is witnessing a constant increase on the volume of data, which is generated in constant stream, calling for novel architectural and logical solutions for processing it. Moving the data handling towards the edge of the computing spectrum guarantees better distribution of load and, in principle, lower latency and better privacy. However, managing such a structure is complex, especially when requirements, also referred to Service Level Objectives (SLOs), specified by applications' owners and infrastructure managers need to be ensured. Despite the rich number of proposals of Machine Learning (ML) based management solutions, researchers and practitioners yet struggle to guarantee long-term prediction and control, and accurate troubleshooting. Therefore, we present a novel ML paradigm based on Active Inference (AIF) -- a concept from neuroscience that describes how the brain constantly predicts and evaluates sensory information to decrease long-term surprise. We implement it and evaluate it in a heterogeneous real stream processing use case, where an AIF-based agent continuously optimizes the fulfillment of three SLOs for three autonomous driving services running on multiple devices. The agent used causal knowledge to gradually develop an understanding of how its actions are related to requirements fulfillment, and which configurations to favor. Through this approach, our agent requires up to thirty iterations to converge to the optimal solution, showing the capability of offering accurate results in a short amount of time. Furthermore, thanks to AIF and its causal structures, our method guarantees full transparency on the decision making, making the interpretation of the results and the troubleshooting effortless.</td>
</tr>
<tr>
<td>样本压缩释放：实值损失的新泛化界</td>
<td>样本压缩理论为那些可以通过训练数据集的子集和一条（短）消息字符串完全定义的预测器提供了泛化保证，通常这条消息被定义为一个二进制序列。以往的工作为零一损失提供了泛化边界，这在应用于深度学习方法时显得尤为限制。在本文中，我们提出了一个通用框架，用于推导适用于实值损失的新样本压缩边界。我们通过在不同类型的模型（例如神经网络和决策森林）上评估这些边界，展示了它们的紧密性和多功能性，这些模型是使用Pick-To-Learn（P2L）元算法训练的，该算法将任何机器学习预测器的训练方法转化为生成样本压缩预测器。与现有的P2L边界相比，我们的边界在非一致性情况下仍然有效。</td>
<td>Mathieu Bazinet</td>
<td><a href="http://arxiv.org/pdf/2409.17932v1">PDF</a></td>
<td>N/A</td>
<td>Sample compression unleashed : New generalization bounds for real valued losses</td>
<td>The sample compression theory provides generalization guarantees for predictors that can be fully defined using a subset of the training dataset and a (short) message string, generally defined as a binary sequence. Previous works provided generalization bounds for the zero-one loss, which is restrictive, notably when applied to deep learning approaches. In this paper, we present a general framework for deriving new sample compression bounds that hold for real-valued losses. We empirically demonstrate the tightness of the bounds and their versatility by evaluating them on different types of models, e.g., neural networks and decision forests, trained with the Pick-To-Learn (P2L) meta-algorithm, which transforms the training method of any machine-learning predictor to yield sample-compressed predictors. In contrast to existing P2L bounds, ours are valid in the non-consistent case.</td>
</tr>
<tr>
<td>智能能源管理：基于深度学习和物联网的剩余使用寿命预测与充电自动化系统</td>
<td>电池的剩余使用寿命（RUL）是了解电池剩余寿命和充电需求的重要参数。本研究项目的目标是开发基于机器学习的电池RUL数据集模型。开发了不同的机器学习模型来分类车辆的RUL，并模拟了物联网（IoT）概念，以自动化充电系统并管理任何对齐的故障。绘制的图形描绘了使用Blynk IoT平台各种车辆参数之间的关系。结果显示，开发的catboost、多层感知器（MLP）、门控循环单元（GRU）和混合模型能够以超过99%的准确率将RUL分类为三个类别。通过tkinter GUI输入数据，模拟基于人工智能（AI）的充电，并通过pyserial后端将数据输入Esp-32微控制器，使模型预测的充放电成为可能。此外，通过物联网系统，可以断开充电、监控和分析以实现自动化。结果表明，在MLP、catboost模型上可以获得99%的准确率，在GRU模型上可以获得类似的准确率，最后可以通过模型预测触发继电器，用于自动化充电和节能机制。通过展示基于Blynk平台的监控和自动化现象，我们进一步提出了监控参数和自动化系统的创新方法。</td>
<td>Biplov Paneru</td>
<td><a href="http://arxiv.org/pdf/2409.17931v1">PDF</a></td>
<td>N/A</td>
<td>Intelligent Energy Management: Remaining Useful Life Prediction and Charging Automation System Comprised of Deep Learning and the Internet of Things</td>
<td>Remaining Useful Life (RUL) of battery is an important parameter to know the battery's remaining life and need for recharge. The goal of this research project is to develop machine learning-based models for the battery RUL dataset. Different ML models are developed to classify the RUL of the vehicle, and the IoT (Internet of Things) concept is simulated for automating the charging system and managing any faults aligning. The graphs plotted depict the relationship between various vehicle parameters using the Blynk IoT platform. Results show that the catboost, Multi-Layer Perceptron (MLP), Gated Recurrent Unit (GRU), and hybrid model developed could classify RUL into three classes with 99% more accuracy. The data is fed using the tkinter GUI for simulating artificial intelligence (AI)-based charging, and with a pyserial backend, data can be entered into the Esp-32 microcontroller for making charge discharge possible with the model's predictions. Also, with an IoT system, the charging can be disconnected, monitored, and analyzed for automation. The results show that an accuracy of 99% can be obtained on models MLP, catboost model and similar accuracy on GRU model can be obtained, and finally relay-based triggering can be made by prediction through the model used for automating the charging and energy-saving mechanism. By showcasing an exemplary Blynk platform-based monitoring and automation phenomenon, we further present innovative ways of monitoring parameters and automating the system.</td>
</tr>
<tr>
<td>《Lou数据集》——探索性别公平语言对德语文本分类的影响</td>
<td>性别公平语言，一种不断发展的德语语言变体，通过涵盖所有性别或使用中性形式来促进包容性。然而，在评估这种语言转变对使用语言模型（LMs）进行分类的影响方面，资源严重不足，这些模型可能并未接受过此类变体的训练。为了填补这一空白，我们推出了Lou，这是首个包含高质量重构文本的德语文本分类数据集，涵盖了立场检测和毒性分类等七项任务。在Lou上评估16种单语和多语言LMs的结果显示，性别公平语言显著影响了预测结果，包括标签翻转、确定性降低以及注意力模式的变化。然而，现有评估仍然有效，因为原始实例和重构实例的LM排名并无显著差异。尽管我们提供了关于性别公平语言对德语文本分类影响的初步见解，但这些发现很可能适用于其他语言，因为在多语言和英语LMs中观察到了一致的模式。</td>
<td>Andreas Waldis</td>
<td><a href="http://arxiv.org/pdf/2409.17929v1">PDF</a></td>
<td>N/A</td>
<td>The Lou Dataset -- Exploring the Impact of Gender-Fair Language in German Text Classification</td>
<td>Gender-fair language, an evolving German linguistic variation, fosters inclusion by addressing all genders or using neutral forms. Nevertheless, there is a significant lack of resources to assess the impact of this linguistic shift on classification using language models (LMs), which are probably not trained on such variations. To address this gap, we present Lou, the first dataset featuring high-quality reformulations for German text classification covering seven tasks, like stance detection and toxicity classification. Evaluating 16 mono- and multi-lingual LMs on Lou shows that gender-fair language substantially impacts predictions by flipping labels, reducing certainty, and altering attention patterns. However, existing evaluations remain valid, as LM rankings of original and reformulated instances do not significantly differ. While we offer initial insights on the effect on German text classification, the findings likely apply to other languages, as consistent patterns were observed in multi-lingual and English LMs.</td>
</tr>
<tr>
<td>开创性的文本到图像知识编辑可靠评估：利用细粒度数据集与创新标准</td>
<td>在预训练阶段，文本到图像（T2I）扩散模型将其中的事实知识编码到模型参数中。这些参数化的事实使得模型能够生成逼真的图像，但随着时间的推移，这些知识可能会变得过时，从而导致对当前世界状态的错误描述。知识编辑技术旨在有针对性地更新模型知识。然而，面对编辑数据集不足和评估标准不可靠的双重挑战，T2I知识编辑的发展在有效推广注入知识方面遇到了困难。在这项工作中，我们设计了一个T2I知识编辑框架，全面涵盖了三个阶段：首先，我们精心制作了一个数据集<strong>CAKE</strong>，包含释义和多对象测试，以实现对知识推广的更细致评估。其次，我们提出了一种新的标准，<strong>自适应CLIP阈值</strong>，以有效过滤当前标准下的虚假成功图像，并实现可靠的编辑评估。最后，我们引入了<strong>MPE</strong>，一种简单但有效的T2I知识编辑方法。MPE不是调整参数，而是精确识别并编辑条件文本提示中过时的部分，以适应最新的知识。MPE的直接实现（基于上下文学习）在整体性能上优于之前的模型编辑器。我们希望这些努力能够进一步促进T2I知识编辑方法的忠实评估。</td>
<td>Hengrui Gu</td>
<td><a href="http://arxiv.org/pdf/2409.17928v1">PDF</a></td>
<td>N/A</td>
<td>Pioneering Reliable Assessment in Text-to-Image Knowledge Editing: Leveraging a Fine-Grained Dataset and an Innovative Criterion</td>
<td>During pre-training, the Text-to-Image (T2I) diffusion models encode factual knowledge into their parameters. These parameterized facts enable realistic image generation, but they may become obsolete over time, thereby misrepresenting the current state of the world. Knowledge editing techniques aim to update model knowledge in a targeted way. However, facing the dual challenges posed by inadequate editing datasets and unreliable evaluation criterion, the development of T2I knowledge editing encounter difficulties in effectively generalizing injected knowledge. In this work, we design a T2I knowledge editing framework by comprehensively spanning on three phases: First, we curate a dataset \textbf{CAKE}, comprising paraphrase and multi-object test, to enable more fine-grained assessment on knowledge generalization. Second, we propose a novel criterion, \textbf{adaptive CLIP threshold}, to effectively filter out false successful images under the current criterion and achieve reliable editing evaluation. Finally, we introduce \textbf{MPE}, a simple but effective approach for T2I knowledge editing. Instead of tuning parameters, MPE precisely recognizes and edits the outdated part of the conditioning text-prompt to accommodate the up-to-date knowledge. A straightforward implementation of MPE (Based on in-context learning) exhibits better overall performance than previous model editors. We hope these efforts can further promote faithful evaluation of T2I knowledge editing methods.</td>
</tr>
<tr>
<td>Atlas-Chat：将大型语言模型适应于低资源的摩洛哥阿拉伯方言</td>
<td>我们推出了Atlas-Chat，这是首个专门为阿拉伯方言开发的大型语言模型集合。聚焦于摩洛哥阿拉伯语，即达里亚语（Darija），我们通过整合现有的达里亚语资源，手动和合成地创建新数据集，并严格控制质量地翻译英语指令，构建了我们的指令数据集。在数据集上微调的Atlas-Chat-9B和2B模型，在遵循达里亚语指令和执行标准自然语言处理任务方面表现出卓越的能力。值得注意的是，我们的模型在表现上优于最先进的以及专门针对阿拉伯语的LLM，如LLaMa、Jais和AceGPT，例如，在我们的新引入的涵盖判别和生成任务的达里亚语评估套件中，在DarijaMMLU上，我们的模型比更大的13B模型实现了13%的性能提升。此外，我们对各种微调策略和基础模型选择进行了实验分析，以确定最佳配置。我们所有的资源都是公开可访问的，并且我们相信我们的工作为低资源语言变体的指令微调提供了全面的设计方法，这些语言变体往往被当代LLM忽视，转而倾向于数据丰富的语言。</td>
<td>Guokan Shang</td>
<td><a href="http://arxiv.org/pdf/2409.17912v1">PDF</a></td>
<td>N/A</td>
<td>Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan Arabic Dialect</td>
<td>We introduce Atlas-Chat, the first-ever collection of large language models specifically developed for dialectal Arabic. Focusing on Moroccan Arabic, also known as Darija, we construct our instruction dataset by consolidating existing Darija language resources, creating novel datasets both manually and synthetically, and translating English instructions with stringent quality control. Atlas-Chat-9B and 2B models, fine-tuned on the dataset, exhibit superior ability in following Darija instructions and performing standard NLP tasks. Notably, our models outperform both state-of-the-art and Arabic-specialized LLMs like LLaMa, Jais, and AceGPT, e.g., achieving a 13% performance boost over a larger 13B model on DarijaMMLU, in our newly introduced evaluation suite for Darija covering both discriminative and generative tasks. Furthermore, we perform an experimental analysis of various fine-tuning strategies and base model choices to determine optimal configurations. All our resources are publicly accessible, and we believe our work offers comprehensive design methodologies of instruction-tuning for low-resource language variants, which are often neglected in favor of data-rich languages by contemporary LLMs.</td>
</tr>
<tr>
<td>通过伪代码提示进行大语言模型的图推理</td>
<td>大型语言模型（LLMs）在自然语言处理领域的各种推理任务中最近取得了显著的成功。这种成功也激发了将LLMs应用于与图相关的任务中。其中，最近的研究探索了LLMs是否能够解决诸如计算图的连通分量数量或计算两个节点之间的最短路径距离等图问题。尽管LLMs具备初步的图推理能力，但它们在解决一些看似简单的问题时可能仍然会遇到困难。在本文中，我们研究了通过伪代码指令进行提示是否能提高LLMs在解决图问题上的表现。我们的实验表明，使用伪代码指令通常能够提升所有考虑的LLMs的性能。图、伪代码提示和评估代码已公开发布。</td>
<td>Konstantinos Skianis</td>
<td><a href="http://arxiv.org/pdf/2409.17906v1">PDF</a></td>
<td>N/A</td>
<td>Graph Reasoning with Large Language Models via Pseudo-code Prompting</td>
<td>Large language models (LLMs) have recently achieved remarkable success in various reasoning tasks in the field of natural language processing. This success of LLMs has also motivated their use in graph-related tasks. Among others, recent work has explored whether LLMs can solve graph problems such as counting the number of connected components of a graph or computing the shortest path distance between two nodes. Although LLMs possess preliminary graph reasoning abilities, they might still struggle to solve some seemingly simple problems. In this paper, we investigate whether prompting via pseudo-code instructions can improve the performance of LLMs in solving graph problems. Our experiments demonstrate that using pseudo-code instructions generally improves the performance of all considered LLMs. The graphs, pseudo-code prompts, and evaluation code are publicly available.</td>
</tr>
<tr>
<td>设计短阶段CDC-XPUF：在物联网设备中平衡可靠性、成本和安全性</td>
<td>物联网（IoT）设备的快速扩展要求强大且资源高效的安全解决方案。物理不可克隆函数（PUFs）通过利用硬件固有的变化生成独特的加密密钥，提供了一种有前景的方法。然而，传统的PUF如仲裁PUF（APUF）和异或仲裁PUF（XOR-PUF）容易受到机器学习（ML）和基于可靠性的攻击。在本研究中，我们探讨了组件差异性挑战异或PUF（CDC-XPUF），这是一种较少研究的变体，以解决这些脆弱性。我们提出了一种优化的CDC-XPUF设计，该设计结合了预选择策略以提高可靠性，并引入了一种新颖的轻量级架构以减少硬件开销。严格的测试表明，我们的设计显著降低了资源消耗，保持了对ML攻击的强大抵抗力，并提高了可靠性，有效缓解了基于可靠性的攻击。这些结果突显了CDC-XPUF作为资源受限的物联网系统中广泛部署的安全且高效候选方案的潜力。</td>
<td>Gaoxiang Li</td>
<td><a href="http://arxiv.org/pdf/2409.17902v1">PDF</a></td>
<td>N/A</td>
<td>Designing Short-Stage CDC-XPUFs: Balancing Reliability, Cost, and Security in IoT Devices</td>
<td>The rapid expansion of Internet of Things (IoT) devices demands robust and resource-efficient security solutions. Physically Unclonable Functions (PUFs), which generate unique cryptographic keys from inherent hardware variations, offer a promising approach. However, traditional PUFs like Arbiter PUFs (APUFs) and XOR Arbiter PUFs (XOR-PUFs) are susceptible to machine learning (ML) and reliability-based attacks. In this study, we investigate Component-Differentially Challenged XOR-PUFs (CDC-XPUFs), a less explored variant, to address these vulnerabilities. We propose an optimized CDC-XPUF design that incorporates a pre-selection strategy to enhance reliability and introduces a novel lightweight architecture to reduce hardware overhead. Rigorous testing demonstrates that our design significantly lowers resource consumption, maintains strong resistance to ML attacks, and improves reliability, effectively mitigating reliability-based attacks. These results highlight the potential of CDC-XPUFs as a secure and efficient candidate for widespread deployment in resource-constrained IoT systems.</td>
</tr>
<tr>
<td>通过自监督表示重新审视情感语音和音乐中的声学相似性</td>
<td>语音和音乐的情感识别由于其声学重叠而具有相似性，这引发了在不同领域之间转移知识的兴趣。然而，语音和音乐之间共享的声学线索，特别是由自监督学习（SSL）模型编码的线索，在很大程度上仍未被探索，因为用于语音和音乐的SSL模型很少被应用于跨领域研究。在这项工作中，我们重新审视了情感语音和音乐之间的声学相似性，首先分析了用于语音情感识别（SER）和音乐情感识别（MER）的SSL模型的逐层行为。此外，我们通过在两阶段微调过程中比较几种方法来进行跨领域适应，探讨了有效利用音乐进行SER和语音进行MER的方法。最后，我们使用Frechet音频距离探索了情感语音和音乐之间的声学相似性，揭示了语音和音乐SSL模型中存在的情感偏差问题。我们的研究结果表明，尽管语音和音乐SSL模型确实捕捉到了共享的声学特征，但由于其训练策略和领域特异性，它们在不同情感下的行为可能会有所不同。此外，参数高效的微调可以利用彼此的知识来提高SER和MER的性能。本研究为情感语音和音乐之间的声学相似性提供了新的见解，并强调了跨领域泛化的潜力，以改进SER和MER系统。</td>
<td>Yujia Sun</td>
<td><a href="http://arxiv.org/pdf/2409.17899v1">PDF</a></td>
<td>N/A</td>
<td>Revisiting Acoustic Similarity in Emotional Speech and Music via Self-Supervised Representations</td>
<td>Emotion recognition from speech and music shares similarities due to their acoustic overlap, which has led to interest in transferring knowledge between these domains. However, the shared acoustic cues between speech and music, particularly those encoded by Self-Supervised Learning (SSL) models, remain largely unexplored, given the fact that SSL models for speech and music have rarely been applied in cross-domain research. In this work, we revisit the acoustic similarity between emotion speech and music, starting with an analysis of the layerwise behavior of SSL models for Speech Emotion Recognition (SER) and Music Emotion Recognition (MER). Furthermore, we perform cross-domain adaptation by comparing several approaches in a two-stage fine-tuning process, examining effective ways to utilize music for SER and speech for MER. Lastly, we explore the acoustic similarities between emotional speech and music using Frechet audio distance for individual emotions, uncovering the issue of emotion bias in both speech and music SSL models. Our findings reveal that while speech and music SSL models do capture shared acoustic features, their behaviors can vary depending on different emotions due to their training strategies and domain-specificities. Additionally, parameter-efficient fine-tuning can enhance SER and MER performance by leveraging knowledge from each other. This study provides new insights into the acoustic similarity between emotional speech and music, and highlights the potential for cross-domain generalization to improve SER and MER systems.</td>
</tr>
<tr>
<td>无模型与基于模型的强化学习在风况变化下固定翼无人机姿态控制中的比较</td>
<td>本文评估并比较了无模型和基于模型的强化学习在固定翼无人机姿态控制中的性能，以PID作为参考点。比较重点在于它们在模拟环境中处理不同飞行动力学和风扰动的能力。我们的结果显示，时间差分模型预测控制代理在不同参考难度下的跟踪精度和鲁棒性方面优于PID控制器和其他无模型强化学习方法，特别是在非线性飞行状态下。此外，我们引入执行器波动作为评估能量效率和执行器磨损的关键指标，并测试了文献中的两种不同方法：动作变化惩罚和动作策略平滑的条件化。我们还分别评估了所有控制方法在受到随机湍流和阵风影响时的表现，以衡量它们对跟踪性能的影响，观察其局限性，并概述它们对马尔可夫决策过程形式的影响。</td>
<td>David Olivares</td>
<td><a href="http://arxiv.org/pdf/2409.17896v1">PDF</a></td>
<td>N/A</td>
<td>Model-Free versus Model-Based Reinforcement Learning for Fixed-Wing UAV Attitude Control Under Varying Wind Conditions</td>
<td>This paper evaluates and compares the performance of model-free and model-based reinforcement learning for the attitude control of fixed-wing unmanned aerial vehicles using PID as a reference point. The comparison focuses on their ability to handle varying flight dynamics and wind disturbances in a simulated environment. Our results show that the Temporal Difference Model Predictive Control agent outperforms both the PID controller and other model-free reinforcement learning methods in terms of tracking accuracy and robustness over different reference difficulties, particularly in nonlinear flight regimes. Furthermore, we introduce actuation fluctuation as a key metric to assess energy efficiency and actuator wear, and we test two different approaches from the literature: action variation penalty and conditioning for action policy smoothness. We also evaluate all control methods when subject to stochastic turbulence and gusts separately, so as to measure their effects on tracking performance, observe their limitations and outline their implications on the Markov decision process formalism.</td>
</tr>
<tr>
<td>EMMA-500：增强大型语言模型的海量多语言适应性</td>
<td>在本研究中，我们推出了EMMA-500，这是一个大规模的多语言语言模型，旨在增强多语言性能，特别关注提升低资源语言的覆盖率。该模型在涵盖546种语言的文本上进行了持续训练。为了支持这种持续预训练，我们编制了MaLA语料库，这是一个全面的多语言数据集，融合了来自不同领域的精选数据集。利用这一语料库，我们对Llama 2 7B模型进行了广泛的持续预训练，从而生成了EMMA-500。该模型在众多基准测试中表现出色，包括一系列多语言任务和本研究中开发的开放式生成基准测试PolyWrite。我们的研究结果突显了持续预训练在扩展大型语言模型语言能力方面的有效性，尤其是在代表性不足的语言方面，显著提升了跨语言迁移、任务泛化能力和语言适应性。</td>
<td>Shaoxiong Ji</td>
<td><a href="http://arxiv.org/pdf/2409.17892v1">PDF</a></td>
<td>N/A</td>
<td>EMMA-500: Enhancing Massively Multilingual Adaptation of Large Language Models</td>
<td>In this work, we introduce EMMA-500, a large-scale multilingual language model continue-trained on texts across 546 languages designed for enhanced multilingual performance, focusing on improving language coverage for low-resource languages. To facilitate continual pre-training, we compile the MaLA corpus, a comprehensive multilingual dataset enriched with curated datasets across diverse domains. Leveraging this corpus, we conduct extensive continual pre-training of the Llama 2 7B model, resulting in EMMA-500, which demonstrates robust performance across a wide collection of benchmarks, including a comprehensive set of multilingual tasks and PolyWrite, an open-ended generation benchmark developed in this study. Our results highlight the effectiveness of continual pre-training in expanding large language models' language capacity, particularly for underrepresented languages, demonstrating significant gains in cross-lingual transfer, task generalization, and language adaptability.</td>
</tr>
<tr>
<td>基于注意力机制的并行CNN-GRU多源数据电力负荷预测方法</td>
<td>准确的电力负荷预测对于提高能源效率和保障电力供应质量至关重要。考虑到电力负荷预测问题不仅涉及历史负荷变化等动态因素，还涉及气候条件等在特定时期内保持不变的静态因素。从模型无关的角度出发，本文提出了一种并行结构网络，以从动态和静态数据中提取重要信息。首先，基于复杂性学习理论，证明了通过并行结构集成的模型相比单个基学习器具有更强的泛化能力。此外，基学习器之间的独立性越高，并行结构模型的泛化能力越强。这表明机器学习模型的结构本身蕴含着重要的信息。在此理论基础上，采用并行卷积神经网络（CNN）-门控循环单元（GRU）注意力模型（PCGA）来解决电力负荷预测问题，旨在有效整合动态和静态特征的影响。CNN模块负责从静态数据中捕捉空间特征，而GRU模块则捕捉动态时间序列数据中的长期依赖关系。注意力层旨在聚焦于并行CNN-GRU提取的空间-时间特征中的关键信息。为了验证并行结构模型在提取和整合多源信息方面的优势，进行了一系列实验。</td>
<td>Chao Min</td>
<td><a href="http://arxiv.org/pdf/2409.17889v1">PDF</a></td>
<td>N/A</td>
<td>A multi-source data power load forecasting method using attention mechanism-based parallel cnn-gru</td>
<td>Accurate power load forecasting is crucial for improving energy efficiency and ensuring power supply quality. Considering the power load forecasting problem involves not only dynamic factors like historical load variations but also static factors such as climate conditions that remain constant over specific periods. From the model-agnostic perspective, this paper proposes a parallel structure network to extract important information from both dynamic and static data. Firstly, based on complexity learning theory, it is demonstrated that models integrated through parallel structures exhibit superior generalization abilities compared to individual base learners. Additionally, the higher the independence between base learners, the stronger the generalization ability of the parallel structure model. This suggests that the structure of machine learning models inherently contains significant information. Building on this theoretical foundation, a parallel convolutional neural network (CNN)-gate recurrent unit (GRU) attention model (PCGA) is employed to address the power load forecasting issue, aiming to effectively integrate the influences of dynamic and static features. The CNN module is responsible for capturing spatial characteristics from static data, while the GRU module captures long-term dependencies in dynamic time series data. The attention layer is designed to focus on key information from the spatial-temporal features extracted by the parallel CNN-GRU. To substantiate the advantages of the parallel structure model in extracting and integrating multi-source information, a series of experiments are conducted.</td>
</tr>
<tr>
<td>一种用于识别非线性动力系统响应因果关系的方法</td>
<td>预测非线性动力系统在随机宽带激励下的响应，在结构动力学和神经科学等多个科学领域中具有重要意义。构建数据驱动模型需要系统的输入和输出实验测量数据，但很难确定模型不准确性是源于建模错误还是噪声。本文提出了一种新方法，无需高保真模型，即可从存在输出噪声的系统测量数据中，按频率识别输入输出数据的因果成分。利用现有模型计算的输出预测，与输出的噪声测量数据进行最优组合，以预测系统的输入。该算法的参数用于平衡这两种输出信号，并用于计算作为因果关系度量的非线性相干性指标。此方法适用于广泛的非线性动力系统类别。目前，在没有完整基准模型的情况下，尚无解决此问题的方案。</td>
<td>Joseph Massingham</td>
<td><a href="http://arxiv.org/pdf/2409.17872v1">PDF</a></td>
<td>N/A</td>
<td>A method for identifying causality in the response of nonlinear dynamical systems</td>
<td>Predicting the response of nonlinear dynamical systems subject to random, broadband excitation is important across a range of scientific disciplines, such as structural dynamics and neuroscience. Building data-driven models requires experimental measurements of the system input and output, but it can be difficult to determine whether inaccuracies in the model stem from modelling errors or noise. This paper presents a novel method to identify the causal component of the input-output data from measurements of a system in the presence of output noise, as a function of frequency, without needing a high fidelity model. An output prediction, calculated using an available model, is optimally combined with noisy measurements of the output to predict the input to the system. The parameters of the algorithm balance the two output signals and are utilised to calculate a nonlinear coherence metric as a measure of causality. This method is applicable to a broad class of nonlinear dynamical systems. There are currently no solutions to this problem in the absence of a complete benchmark model.</td>
</tr>
<tr>
<td>GPU张量核心上大型语言模型的有效任意精度加速</td>
<td>大型语言模型（LLMs）已被广泛应用，但在高效推理方面面临挑战。尽管量化方法降低了计算需求，但任意精度的超低比特量化受到有限的GPU张量核心支持和低效内存管理的阻碍，导致加速效果不佳。为应对这些挑战，我们提出了一种全面的任意精度LLMs加速方案。核心在于，我们引入了一种新颖的双极性-INT数据格式，该格式促进了并行计算并支持对称量化，有效减少了数据冗余。基于此，我们实现了一种任意精度的矩阵乘法方案，该方案在比特级别分解和恢复矩阵，实现了灵活的精度同时最大化GPU张量核心的利用率。此外，我们开发了一种高效的矩阵预处理方法，优化了后续计算的数据布局。最后，我们设计了一种面向数据恢复的内存管理系统，策略性地利用快速共享内存，显著提升了内核执行速度并最小化了内存访问延迟。实验结果表明，我们的方法有效，矩阵乘法速度相比NVIDIA的CUTLASS提高了13倍。当集成到LLMs中时，我们实现了高达6.7倍的推理加速。这些改进显著提升了LLM推理效率，使得LLMs的应用更加广泛和响应迅速。</td>
<td>Shaobo Ma</td>
<td><a href="http://arxiv.org/pdf/2409.17870v1">PDF</a></td>
<td>N/A</td>
<td>Efficient Arbitrary Precision Acceleration for Large Language Models on GPU Tensor Cores</td>
<td>Large language models (LLMs) have been widely applied but face challenges in efficient inference. While quantization methods reduce computational demands, ultra-low bit quantization with arbitrary precision is hindered by limited GPU Tensor Core support and inefficient memory management, leading to suboptimal acceleration. To address these challenges, we propose a comprehensive acceleration scheme for arbitrary precision LLMs. At its core, we introduce a novel bipolar-INT data format that facilitates parallel computing and supports symmetric quantization, effectively reducing data redundancy. Building on this, we implement an arbitrary precision matrix multiplication scheme that decomposes and recovers matrices at the bit level, enabling flexible precision while maximizing GPU Tensor Core utilization. Furthermore, we develop an efficient matrix preprocessing method that optimizes data layout for subsequent computations. Finally, we design a data recovery-oriented memory management system that strategically utilizes fast shared memory, significantly enhancing kernel execution speed and minimizing memory access latency. Experimental results demonstrate our approach's effectiveness, with up to 13\times speedup in matrix multiplication compared to NVIDIA's CUTLASS. When integrated into LLMs, we achieve up to 6.7\times inference acceleration. These improvements significantly enhance LLM inference efficiency, enabling broader and more responsive applications of LLMs.</td>
</tr>
<tr>
<td>实施北欧-波罗的海联邦健康数据网络：案例报告</td>
<td>背景：跨国界集中收集和处理医疗数据面临重大挑战，包括隐私问题、数据异质性和法律障碍。为了应对其中一些挑战，我们组建了一个跨学科联盟，开发了一个由五个国家的六个机构组成的联邦健康数据网络，以促进北欧-波罗的海地区在健康数据二次使用方面的合作。本报告旨在提供我们在开发该网络过程中的早期见解。方法：我们采用了混合方法，结合实验设计和实施科学，评估影响我们网络实施的因素。结果：从技术上讲，我们的实验表明，与集中式模拟相比，该网络在功能上没有显著的性能下降。结论：虽然跨学科方法具有解决建立此类协作网络相关挑战的潜力，但我们的发现突显了不确定的监管环境正在追赶以及显著的运营成本。</td>
<td>Taridzo Chomutare</td>
<td><a href="http://arxiv.org/pdf/2409.17865v1">PDF</a></td>
<td>N/A</td>
<td>Implementing a Nordic-Baltic Federated Health Data Network: a case report</td>
<td>Background: Centralized collection and processing of healthcare data across national borders pose significant challenges, including privacy concerns, data heterogeneity and legal barriers. To address some of these challenges, we formed an interdisciplinary consortium to develop a feder-ated health data network, comprised of six institutions across five countries, to facilitate Nordic-Baltic cooperation on secondary use of health data. The objective of this report is to offer early insights into our experiences developing this network. Methods: We used a mixed-method ap-proach, combining both experimental design and implementation science to evaluate the factors affecting the implementation of our network. Results: Technically, our experiments indicate that the network functions without significant performance degradation compared to centralized simu-lation. Conclusion: While use of interdisciplinary approaches holds a potential to solve challeng-es associated with establishing such collaborative networks, our findings turn the spotlight on the uncertain regulatory landscape playing catch up and the significant operational costs.</td>
</tr>
<tr>
<td>一种用于冷启动和缺失模态场景推荐的多元单分支嵌入网络</td>
<td>大多数推荐系统采用协同过滤（CF），并基于过去的集体互动提供推荐。因此，当可用的互动很少或没有时，CF算法的性能会下降，这种情况被称为冷启动。为了解决这个问题，以往的工作依赖于利用协同数据和用户或物品的辅助信息的模型。类似于多模态学习，这些模型旨在在共享嵌入空间中结合协同和内容表示。在这项工作中，我们提出了一种新颖的多模态推荐技术，基于多模态单分支嵌入网络推荐（SiBraR）。利用权重共享，SiBraR在不同模态上使用相同的单分支嵌入网络对交互数据和多模态辅助信息进行编码。这使得SiBraR在包括冷启动在内的缺失模态场景中表现有效。我们在来自三个不同推荐领域（音乐、电影和电子商务）的大规模推荐数据集上进行了广泛的实验，并提供了多模态内容信息（音频、文本、图像、标签和交互），结果显示SiBraR在冷启动场景中显著优于CF以及最先进的内容推荐系统，在暖启动场景中也具有竞争力。我们展示了SiBraR在缺失模态场景中的推荐是准确的，并且模型能够将不同模态映射到共享嵌入空间的同一区域，从而减少了模态差距。</td>
<td>Christian Ganhör</td>
<td><a href="http://arxiv.org/pdf/2409.17864v1">PDF</a></td>
<td>N/A</td>
<td>A Multimodal Single-Branch Embedding Network for Recommendation in Cold-Start and Missing Modality Scenarios</td>
<td>Most recommender systems adopt collaborative filtering (CF) and provide recommendations based on past collective interactions. Therefore, the performance of CF algorithms degrades when few or no interactions are available, a scenario referred to as cold-start. To address this issue, previous work relies on models leveraging both collaborative data and side information on the users or items. Similar to multimodal learning, these models aim at combining collaborative and content representations in a shared embedding space. In this work we propose a novel technique for multimodal recommendation, relying on a multimodal Single-Branch embedding network for Recommendation (SiBraR). Leveraging weight-sharing, SiBraR encodes interaction data as well as multimodal side information using the same single-branch embedding network on different modalities. This makes SiBraR effective in scenarios of missing modality, including cold start. Our extensive experiments on large-scale recommendation datasets from three different recommendation domains (music, movie, and e-commerce) and providing multimodal content information (audio, text, image, labels, and interactions) show that SiBraR significantly outperforms CF as well as state-of-the-art content-based RSs in cold-start scenarios, and is competitive in warm scenarios. We show that SiBraR's recommendations are accurate in missing modality scenarios, and that the model is able to map different modalities to the same region of the shared embedding space, hence reducing the modality gap.</td>
</tr>
</tbody>
</table>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.d6f25eb3.min.js"></script>
      
    
  </body>
</html>