# Arxiv Papers

| 标题  | 摘要 | 作者 | PDF链接 | 代码仓库 | Title | Abstract | 
|-------|---------|----------|-----------|------------------|--------------------|---------|
| PhysGen：基于刚体物理的图像到视频生成 | 我们提出了PhysGen，这是一种新颖的图像到视频生成方法，它将单张图像和输入条件（例如，施加在图像中物体上的力和扭矩）转换为生成逼真、物理上合理且时间上一致的视频。我们的核心见解是将基于模型的物理模拟与数据驱动的视频生成过程相结合，从而实现合理的图像空间动力学。我们系统的心脏是三个核心组件：（i）一个图像理解模块，有效地捕捉图像的几何形状、材料和物理参数；（ii）一个图像空间动力学模拟模型，利用刚体物理学和推断的参数来模拟现实行为；（iii）一个基于图像的渲染和细化模块，利用生成性视频扩散技术生成包含模拟运动的逼真视频片段。生成的视频在物理和外观上都极为逼真，甚至可以精确控制，通过定量比较和全面的用户研究，展示了优于现有数据驱动图像到视频生成工作的卓越结果。PhysGen生成的视频可用于各种下游应用，例如将图像转换为逼真动画或允许用户与图像互动并创建各种动态效果。项目页面：https://stevenlsw.github.io/physgen/ | Shaowei Liu | [PDF](http://arxiv.org/pdf/2409.18964v1) | N/A | PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation | We present PhysGen, a novel image-to-video generation method that converts a single image and an input condition (e.g., force and torque applied to an object in the image) to produce a realistic, physically plausible, and temporally consistent video. Our key insight is to integrate model-based physical simulation with a data-driven video generation process, enabling plausible image-space dynamics. At the heart of our system are three core components: (i) an image understanding module that effectively captures the geometry, materials, and physical parameters of the image; (ii) an image-space dynamics simulation model that utilizes rigid-body physics and inferred parameters to simulate realistic behaviors; and (iii) an image-based rendering and refinement module that leverages generative video diffusion to produce realistic video footage featuring the simulated motion. The resulting videos are realistic in both physics and appearance and are even precisely controllable, showcasing superior results over existing data-driven image-to-video generation works through quantitative comparison and comprehensive user study. PhysGen's resulting videos can be used for various downstream applications, such as turning an image into a realistic animation or allowing users to interact with the image and create various dynamics. Project page: https://stevenlsw.github.io/physgen/ |
| 探索视觉状态空间模型中的令牌剪枝 | 状态空间模型（SSMs）相较于变压器中的注意力模块，具有保持线性计算复杂度的优势，并且已被应用于视觉任务中，作为一种新型强大的视觉基础模型。受到视觉变压器（ViTs）中最终预测仅基于最信息丰富的子集的观察启发，我们采取了通过基于标记的剪枝来提高基于SSM的视觉模型效率的新步骤。然而，直接应用为ViTs设计的现有标记剪枝技术未能带来良好的性能，即使在广泛微调后也是如此。为了解决这一问题，我们重新审视了SSMs独特的计算特性，并发现简单应用会破坏标记的顺序位置。这一发现促使我们为基于SSM的视觉模型设计一种新颖且通用的标记剪枝方法。我们首先引入了一种剪枝感知隐藏状态对齐方法，以稳定剩余标记的邻域，从而提升性能。此外，基于我们的详细分析，我们提出了一种适用于SSM模型的标记重要性评估方法，以指导标记剪枝。通过高效的实现和实际加速方法，我们的方法带来了实际的加速效果。广泛的实验表明，我们的方法能够在不同任务中显著减少计算量，同时对性能影响最小。值得注意的是，我们在ImageNet上实现了81.7%的准确率，同时将剪枝后的PlainMamba-L3的FLOPs减少了41.6%。此外，我们的工作为理解基于SSM的视觉模型的行为提供了更深入的见解，为未来的研究奠定了基础。 | Zheng Zhan | [PDF](http://arxiv.org/pdf/2409.18962v1) | N/A | Exploring Token Pruning in Vision State Space Models | State Space Models (SSMs) have the advantage of keeping linear computational complexity compared to attention modules in transformers, and have been applied to vision tasks as a new type of powerful vision foundation model. Inspired by the observations that the final prediction in vision transformers (ViTs) is only based on a subset of most informative tokens, we take the novel step of enhancing the efficiency of SSM-based vision models through token-based pruning. However, direct applications of existing token pruning techniques designed for ViTs fail to deliver good performance, even with extensive fine-tuning. To address this issue, we revisit the unique computational characteristics of SSMs and discover that naive application disrupts the sequential token positions. This insight motivates us to design a novel and general token pruning method specifically for SSM-based vision models. We first introduce a pruning-aware hidden state alignment method to stabilize the neighborhood of remaining tokens for performance enhancement. Besides, based on our detailed analysis, we propose a token importance evaluation method adapted for SSM models, to guide the token pruning. With efficient implementation and practical acceleration methods, our method brings actual speedup. Extensive experiments demonstrate that our approach can achieve significant computation reduction with minimal impact on performance across different tasks. Notably, we achieve 81.7\% accuracy on ImageNet with a 41.6\% reduction in the FLOPs for pruned PlainMamba-L3. Furthermore, our work provides deeper insights into understanding the behavior of SSM-based vision models for future research. |
| 在最小假设下扩散概率模型的$O(d/T)$收敛理论 | 基于分数的扩散模型通过学习逆转一个扩散过程来生成新数据，该过程将来自目标分布的数据扰动成噪声，在各种生成任务中取得了显著的成功。尽管它们在实证表现上具有优越性，但现有的理论保证往往受到严格假设或次优收敛率的限制。在本文中，我们在最少的假设下为一种流行的基于随机微分方程（SDE）的采样器建立了快速收敛理论。我们的分析表明，在提供$\ell_{2}$精确的分数函数估计的情况下，目标分布与生成分布之间的总变差距离被上界为$O(d/T)$（忽略对数因子），其中$d$是数据维度，$T$是步数。这一结果适用于任何具有有限一阶矩的目标分布。据我们所知，这不仅改进了基于SDE的采样器的现有收敛理论，还改进了另一种基于常微分方程（ODE）的采样器的收敛理论，同时对目标数据分布和分数估计施加了最少的假设。这一成就通过一组新颖的分析工具实现，这些工具提供了对反向过程中每一步误差传播的细致刻画。 | Gen Li | [PDF](http://arxiv.org/pdf/2409.18959v1) | N/A | $O(d/T)$ Convergence Theory for Diffusion Probabilistic Models under Minimal Assumptions | Score-based diffusion models, which generate new data by learning to reverse a diffusion process that perturbs data from the target distribution into noise, have achieved remarkable success across various generative tasks. Despite their superior empirical performance, existing theoretical guarantees are often constrained by stringent assumptions or suboptimal convergence rates. In this paper, we establish a fast convergence theory for a popular SDE-based sampler under minimal assumptions. Our analysis shows that, provided $\ell_{2}$-accurate estimates of the score functions, the total variation distance between the target and generated distributions is upper bounded by $O(d/T)$ (ignoring logarithmic factors), where $d$ is the data dimensionality and $T$ is the number of steps. This result holds for any target distribution with finite first-order moment. To our knowledge, this improves upon existing convergence theory for both the SDE-based sampler and another ODE-based sampler, while imposing minimal assumptions on the target data distribution and score estimates. This is achieved through a novel set of analytical tools that provides a fine-grained characterization of how the error propagates at each step of the reverse process. |
| LML：语言模型学习数据集以进行数据增强预测 | 本文介绍了一种利用大型语言模型（LLMs）进行分类任务的新方法，这类任务通常由机器学习（ML）模型处理。与依赖大量数据清洗和特征工程的ML模型不同，这种方法通过LLMs简化了流程。本文提出了一种名为“语言模型学习（LML）”的新概念，由一种称为“数据增强预测（DAP）”的新方法驱动。分类过程通过LLMs实现，类似于人类手动探索和理解数据，并参考数据做出分类决策。训练数据被总结和评估，以确定导致每个标签分类的最显著特征。在DAP过程中，系统利用数据总结自动创建查询，用于从数据集中检索相关行。LLM使用数据总结和相关行生成分类，即使在处理复杂数据时也能确保令人满意的准确性。DAP中使用数据总结和相似数据，确保了上下文感知的决策制定。所提出的方法在提示中使用“扮演可解释的机器学习模型”的词语，通过允许用户审查每个预测背后的逻辑，增强了预测的可解释性。在某些测试案例中，系统准确率超过90%，证明了系统的有效性及其在各种场景中超越传统ML模型的潜力。代码可在https://github.com/Pro-GenAI/LML-DAP获取。 | Praneeth Vadlapati | [PDF](http://arxiv.org/pdf/2409.18957v1) | N/A | LML: Language Model Learning a Dataset for Data-Augmented Prediction | This paper introduces a new approach to using Large Language Models (LLMs) for classification tasks, which are typically handled using Machine Learning (ML) models. Unlike ML models that rely heavily on data cleaning and feature engineering, this method streamlines the process using LLMs. This paper proposes a new concept called "Language Model Learning (LML)" powered by a new method called "Data-Augmented Prediction (DAP)". The classification is performed by LLMs using a method similar to humans manually exploring and understanding the data and deciding classifications using data as a reference. Training data is summarized and evaluated to determine the features that lead to the classification of each label the most. In the process of DAP, the system uses the data summary to automatically create a query, which is used to retrieve relevant rows from the dataset. A classification is generated by the LLM using data summary and relevant rows, ensuring satisfactory accuracy even with complex data. Usage of data summary and similar data in DAP ensures context-aware decision-making. The proposed method uses the words "Act as an Explainable Machine Learning Model" in the prompt to enhance the interpretability of the predictions by allowing users to review the logic behind each prediction. In some test cases, the system scored an accuracy above 90%, proving the effectiveness of the system and its potential to outperform conventional ML models in various scenarios. The code is available at https://github.com/Pro-GenAI/LML-DAP |
| RepairBench：程序修复前沿模型的排行榜 | AI驱动的程序修复利用AI模型通过生成补丁来修复有缺陷的软件。AI的快速发展无疑影响了程序修复的最先进性能。然而，要把握这一进展，需要频繁且标准化的评估。我们提出了RepairBench，一个用于AI驱动程序修复的新型排行榜。RepairBench的关键特点是：1）它是基于执行的：所有补丁都会针对测试套件进行编译和执行；2）它以频繁且标准化的方式评估前沿模型。RepairBench利用两个高质量的基准测试，Defects4J和GitBug-Java，来评估前沿模型在实际程序修复任务中的表现。我们公开发布了RepairBench的评估框架。随着新前沿模型的发布，我们将更新排行榜。 | André Silva | [PDF](http://arxiv.org/pdf/2409.18952v1) | N/A | RepairBench: Leaderboard of Frontier Models for Program Repair | AI-driven program repair uses AI models to repair buggy software by producing patches. Rapid advancements in AI surely impact state-of-the-art performance of program repair. Yet, grasping this progress requires frequent and standardized evaluations. We propose RepairBench, a novel leaderboard for AI-driven program repair. The key characteristics of RepairBench are: 1) it is execution-based: all patches are compiled and executed against a test suite, 2) it assesses frontier models in a frequent and standardized way. RepairBench leverages two high-quality benchmarks, Defects4J and GitBug-Java, to evaluate frontier models against real-world program repair tasks. We publicly release the evaluation framework of RepairBench. We will update the leaderboard as new frontier models are released. |
| 光谱小波丢弃：小波域中的正则化 | 正则化技术有助于防止过拟合，从而提高卷积神经网络（CNN）的泛化能力。过拟合的一个原因是网络不同部分之间的复杂共适应性，这使得CNN依赖于它们的联合响应，而不是鼓励每个部分独立学习有用的特征表示。频域操作是一种强大的策略，通过利用频率分解来修改具有时间和空间一致性的数据。本研究引入了光谱小波丢弃（Spectral Wavelet Dropout, SWD），这是一种新颖的正则化方法，包括两种变体：1D-SWD和2D-SWD。这些变体通过随机丢弃特征图离散小波分解中的细节频带，来提高CNN的泛化能力。我们的方法与现有的光谱“傅里叶”丢弃（2D-SFD）有所不同，后者是在傅里叶域中消除系数。值得注意的是，SWD只需要一个超参数，而SFD需要两个。我们还通过实现一维版本的光谱“傅里叶”丢弃（1D-SFD）来扩展文献，为全面比较奠定了基础。我们的评估显示，在CIFAR-10/100基准测试中，1D和2D SWD变体相对于1D-SFD和2D-SFD都表现出竞争性的性能。具体而言，1D-SWD相比1D/2D-SFD具有显著更低的计算复杂度。在Pascal VOC目标检测基准测试中，SWD变体在性能上超越了1D-SFD和2D-SFD，并且在训练过程中表现出更低的计算复杂度。 | Rinor Cakaj | [PDF](http://arxiv.org/pdf/2409.18951v1) | N/A | Spectral Wavelet Dropout: Regularization in the Wavelet Domain | Regularization techniques help prevent overfitting and therefore improve the ability of convolutional neural networks (CNNs) to generalize. One reason for overfitting is the complex co-adaptations among different parts of the network, which make the CNN dependent on their joint response rather than encouraging each part to learn a useful feature representation independently. Frequency domain manipulation is a powerful strategy for modifying data that has temporal and spatial coherence by utilizing frequency decomposition. This work introduces Spectral Wavelet Dropout (SWD), a novel regularization method that includes two variants: 1D-SWD and 2D-SWD. These variants improve CNN generalization by randomly dropping detailed frequency bands in the discrete wavelet decomposition of feature maps. Our approach distinguishes itself from the pre-existing Spectral "Fourier" Dropout (2D-SFD), which eliminates coefficients in the Fourier domain. Notably, SWD requires only a single hyperparameter, unlike the two required by SFD. We also extend the literature by implementing a one-dimensional version of Spectral "Fourier" Dropout (1D-SFD), setting the stage for a comprehensive comparison. Our evaluation shows that both 1D and 2D SWD variants have competitive performance on CIFAR-10/100 benchmarks relative to both 1D-SFD and 2D-SFD. Specifically, 1D-SWD has a significantly lower computational complexity compared to 1D/2D-SFD. In the Pascal VOC Object Detection benchmark, SWD variants surpass 1D-SFD and 2D-SFD in performance and demonstrate lower computational complexity during training. |
| 实现除法归一化的递归神经电路的无条件稳定性 | 在递归神经模型中，稳定性是一个重大挑战，尤其是在开发能够无缝训练的生物学上合理的神经动力学模型时。传统的皮层电路模型由于动力系统中广泛的非线性特性而难以训练，导致优化问题具有难以施加的非线性稳定性约束。相反，递归神经网络（RNNs）在涉及序列数据的任务中表现出色，但缺乏生物学上的合理性和可解释性。在这项工作中，我们通过将动态分裂归一化（DN）与ORGaNICs的稳定性联系起来，解决了这些挑战。ORGaNICs是一种生物学上合理的递归皮层电路模型，能够动态实现DN，并已被证明能够模拟广泛的神经生理现象。通过使用李雅普诺夫间接方法，我们证明了当递归权重矩阵为单位矩阵时，任意维度的ORGaNICs电路具有无条件局部稳定性的显著特性。因此，我们将ORGaNICs与耦合阻尼谐振子系统联系起来，从而能够推导出电路的能量函数，提供电路及其单个神经元所追求的规范性原则。此外，对于一般的递归权重矩阵，我们证明了二维模型的稳定性，并通过实证表明在高维度下稳定性仍然成立。最后，我们展示了由于ORGaNICs的内在稳定性特性和自适应时间常数，它可以通过时间反向传播进行训练，而无需梯度裁剪/缩放，从而解决了梯度爆炸、消失和振荡的问题。通过在RNN基准测试中评估模型的性能，我们发现ORGaNICs在静态图像分类任务中优于其他神经动力学模型，并且在序列任务中与LSTM表现相当。 | Shivang Rawat | [PDF](http://arxiv.org/pdf/2409.18946v1) | N/A | Unconditional stability of a recurrent neural circuit implementing divisive normalization | Stability in recurrent neural models poses a significant challenge, particularly in developing biologically plausible neurodynamical models that can be seamlessly trained. Traditional cortical circuit models are notoriously difficult to train due to expansive nonlinearities in the dynamical system, leading to an optimization problem with nonlinear stability constraints that are difficult to impose. Conversely, recurrent neural networks (RNNs) excel in tasks involving sequential data but lack biological plausibility and interpretability. In this work, we address these challenges by linking dynamic divisive normalization (DN) to the stability of ORGaNICs, a biologically plausible recurrent cortical circuit model that dynamically achieves DN and has been shown to simulate a wide range of neurophysiological phenomena. By using the indirect method of Lyapunov, we prove the remarkable property of unconditional local stability for an arbitrary-dimensional ORGaNICs circuit when the recurrent weight matrix is the identity. We thus connect ORGaNICs to a system of coupled damped harmonic oscillators, which enables us to derive the circuit's energy function, providing a normative principle of what the circuit, and individual neurons, aim to accomplish. Further, for a generic recurrent weight matrix, we prove the stability of the 2D model and demonstrate empirically that stability holds in higher dimensions. Finally, we show that ORGaNICs can be trained by backpropagation through time without gradient clipping/scaling, thanks to its intrinsic stability property and adaptive time constants, which address the problems of exploding, vanishing, and oscillating gradients. By evaluating the model's performance on RNN benchmarks, we find that ORGaNICs outperform alternative neurodynamical models on static image classification tasks and perform comparably to LSTMs on sequential tasks. |
| Ruler：一种用于控制大型语言模型生成长度的模型无关方法 | 大型语言模型的指令跟随能力使得人类能够以自然的方式与AI代理进行交互。然而，当需要生成特定长度的响应时，大型语言模型往往难以满足用户的需求，因为它们在准确感知数值约束方面存在固有的困难。为了探索大型语言模型在控制生成响应长度方面的能力，我们提出了目标长度生成任务（TLG），并设计了两种度量标准：精确匹配（PM）和灵活匹配（FM），以评估模型在遵守指定响应长度方面的表现。此外，我们引入了一种新颖的、与模型无关的方法，称为Ruler，它利用元长度标记（MLT）来增强大型语言模型在长度约束指令下的指令跟随能力。具体而言，Ruler赋予LLMs根据指令中的长度约束生成指定长度响应的能力。此外，当长度约束未明确提供时，Ruler能够自动生成适当的MLT，展示了出色的多功能性和泛化能力。综合实验表明，Ruler在目标长度生成任务上对不同LLMs的有效性，例如，在PM上平均获得27.97的增益，在FM上平均获得29.57的增益。此外，我们还进行了广泛的消融实验，以进一步证实Ruler的功效和泛化能力。我们的代码和数据可在https://github.com/Geaming2002/Ruler获取。 | Jiaming Li | [PDF](http://arxiv.org/pdf/2409.18943v1) | N/A | Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models | The instruction-following ability of large language models enables humans to interact with AI agents in a natural way. However, when required to generate responses of a specific length, large language models often struggle to meet users' needs due to their inherent difficulty in accurately perceiving numerical constraints. To explore the ability of large language models to control the length of generated responses, we propose the Target Length Generation Task (TLG) and design two metrics, Precise Match (PM) and Flexible Match (FM) to evaluate the model's performance in adhering to specified response lengths. Furthermore, we introduce a novel, model-agnostic approach called Ruler, which employs Meta Length Tokens (MLTs) to enhance the instruction-following ability of large language models under length-constrained instructions. Specifically, Ruler equips LLMs with the ability to generate responses of a specified length based on length constraints within the instructions. Moreover, Ruler can automatically generate appropriate MLT when length constraints are not explicitly provided, demonstrating excellent versatility and generalization. Comprehensive experiments show the effectiveness of Ruler across different LLMs on Target Length Generation Task, e.g., at All Level 27.97 average gain on PM, 29.57 average gain on FM. In addition, we conduct extensive ablation experiments to further substantiate the efficacy and generalization of Ruler. Our code and data is available at https://github.com/Geaming2002/Ruler. |
| AIPatient：利用电子健康记录和大型语言模型驱动的智能工作流程模拟患者 | 模拟患者系统在现代医学教育和研究中扮演着至关重要的角色，提供安全、综合的学习环境，并支持临床决策的模拟。大型语言模型（LLM）可以通过高保真度和低成本地复制医疗状况和医患互动，从而推进模拟患者系统的发展。然而，确保这些系统的有效性和可信度仍然是一个挑战，因为它们需要一个庞大、多样且精确的患者知识库，以及一个强大且稳定的知识传递给用户。在此，我们开发了AIPatient，一个先进的模拟患者系统，以AIPatient知识图谱（AIPatient KG）为输入，并以推理检索增强生成（Reasoning RAG）代理工作流程为生成核心。AIPatient KG从重症监护医学信息集市（MIMIC）-III数据库的电子健康记录（EHR）中采样数据，生成了一个临床多样且相关性强的1,495名患者的队列，知识库的有效性高（F1 0.89）。Reasoning RAG利用六个由LLM驱动的代理，涵盖检索、KG查询生成、抽象、检查、重写和总结等任务。该代理框架在基于EHR的医学问答（QA）中达到了94.15%的整体准确率，优于不使用代理或仅部分集成代理的基准。我们的系统还表现出高可读性（Flesch阅读易度中位数77.23；Flesch Kincaid年级中位数5.6）、鲁棒性（ANOVA F值0.6126，p<0.1）和稳定性（ANOVA F值0.782，p<0.1）。AIPatient系统的良好表现突显了其在支持广泛应用方面的潜力，包括医学教育、模型评估和系统集成。 | Huizi Yu | [PDF](http://arxiv.org/pdf/2409.18924v1) | N/A | AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow | Simulated patient systems play a crucial role in modern medical education and research, providing safe, integrative learning environments and enabling clinical decision-making simulations. Large Language Models (LLM) could advance simulated patient systems by replicating medical conditions and patient-doctor interactions with high fidelity and low cost. However, ensuring the effectiveness and trustworthiness of these systems remains a challenge, as they require a large, diverse, and precise patient knowledgebase, along with a robust and stable knowledge diffusion to users. Here, we developed AIPatient, an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning RAG) agentic workflow as the generation backbone. AIPatient KG samples data from Electronic Health Records (EHRs) in the Medical Information Mart for Intensive Care (MIMIC)-III database, producing a clinically diverse and relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89). Reasoning RAG leverages six LLM powered agents spanning tasks including retrieval, KG query generation, abstraction, checker, rewrite, and summarization. This agentic framework reaches an overall accuracy of 94.15% in EHR-based medical Question Answering (QA), outperforming benchmarks that use either no agent or only partial agent integration. Our system also presents high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade 5.6), robustness (ANOVA F-value 0.6126, p<0.1), and stability (ANOVA F-value 0.782, p<0.1). The promising performance of the AIPatient system highlights its potential to support a wide range of applications, including medical education, model evaluation, and system integration. |
| A-FedPD：对齐双重漂移是所有联邦原始-对偶学习所需的 | 作为一种流行的范式，联邦学习（FL）蓬勃发展，旨在在边缘客户端上分布式处理大规模异构数据集。由于带宽限制和安全考虑，它巧妙地将原始问题分解为多个子问题，以便并行解决，从而使原始对偶解在联邦学习中具有巨大的应用价值。本文回顾了经典联邦原始对偶方法的最新发展，并指出在非凸场景下这些方法存在一个严重的共同缺陷，我们称之为由于部分参与训练下长期不活跃客户端的对偶滞后性引起的“对偶漂移”。为进一步解决这一问题，我们提出了一种新颖的对齐联邦原始对偶（A-FedPD）方法，该方法构建虚拟对偶更新，以对齐全局共识和那些长期未参与的本地客户端的局部对偶变量。同时，我们对A-FedPD方法在光滑非凸目标上的优化和泛化效率进行了全面分析，证实了其高效性和实用性。在几个经典联邦学习设置上进行了大量实验，以验证我们提出的方法的有效性。 | Yan Sun | [PDF](http://arxiv.org/pdf/2409.18915v1) | N/A | A-FedPD: Aligning Dual-Drift is All Federated Primal-Dual Learning Needs | As a popular paradigm for juggling data privacy and collaborative training, federated learning (FL) is flourishing to distributively process the large scale of heterogeneous datasets on edged clients. Due to bandwidth limitations and security considerations, it ingeniously splits the original problem into multiple subproblems to be solved in parallel, which empowers primal dual solutions to great application values in FL. In this paper, we review the recent development of classical federated primal dual methods and point out a serious common defect of such methods in non-convex scenarios, which we say is a "dual drift" caused by dual hysteresis of those longstanding inactive clients under partial participation training. To further address this problem, we propose a novel Aligned Federated Primal Dual (A-FedPD) method, which constructs virtual dual updates to align global consensus and local dual variables for those protracted unparticipated local clients. Meanwhile, we provide a comprehensive analysis of the optimization and generalization efficiency for the A-FedPD method on smooth non-convex objectives, which confirms its high efficiency and practicality. Extensive experiments are conducted on several classical FL setups to validate the effectiveness of our proposed method. |
| 用于提取因果集体智能的软性措施 | 理解和建模集体智能对于解决复杂的社会系统至关重要。模糊认知图（FCMs）作为一种有向图，提供了编码因果心理模型的强大工具，但从文本中提取高完整性的FCMs具有挑战性。本研究提出了一种利用大型语言模型（LLMs）来自动化提取FCM的方法。我们引入了新的基于图的相似性度量，并通过Elo评分系统将其输出与人类判断进行关联来评估这些度量。结果显示与人类评估呈正相关，但即使是最优的度量方法在捕捉FCM细微差别方面也存在局限性。微调LLMs可以提高性能，但现有度量仍显不足。本研究强调了针对FCM提取定制软相似性度量的必要性，通过自然语言处理推进集体智能建模。 | Maryam Berijanian | [PDF](http://arxiv.org/pdf/2409.18911v1) | N/A | Soft Measures for Extracting Causal Collective Intelligence | Understanding and modeling collective intelligence is essential for addressing complex social systems. Directed graphs called fuzzy cognitive maps (FCMs) offer a powerful tool for encoding causal mental models, but extracting high-integrity FCMs from text is challenging. This study presents an approach using large language models (LLMs) to automate FCM extraction. We introduce novel graph-based similarity measures and evaluate them by correlating their outputs with human judgments through the Elo rating system. Results show positive correlations with human evaluations, but even the best-performing measure exhibits limitations in capturing FCM nuances. Fine-tuning LLMs improves performance, but existing measures still fall short. This study highlights the need for soft similarity measures tailored to FCM extraction, advancing collective intelligence modeling with NLP. |
| 最小遗憾的最佳臂识别 | 受现实应用需求的驱动，这些应用要求进行负责任的实验，我们引入了带有最小遗憾的最佳臂识别（BAI）问题。这种多臂老虎机问题的创新变体优雅地结合了其最普遍的两个目标：遗憾最小化和BAI。更具体地说，智能体的目标是在规定的置信水平$\delta$下识别出最佳臂，同时最小化到停止时间为止的累积遗憾。我们专注于单参数指数族分布，利用信息论技术建立了预期累积遗憾的实例依赖下界。此外，我们提出了一个有趣的不可能结果，突显了固定置信度BAI中累积遗憾和样本复杂性之间的紧张关系。作为补充，我们设计和分析了Double KL-UCB算法，该算法在置信水平趋近于零时达到渐近最优。值得注意的是，该算法采用两种不同的置信界限，以随机方式指导臂的选择。我们的研究揭示了遗憾最小化和BAI之间内在联系的新视角。 | Junwen Yang | [PDF](http://arxiv.org/pdf/2409.18909v1) | N/A | Best Arm Identification with Minimal Regret | Motivated by real-world applications that necessitate responsible experimentation, we introduce the problem of best arm identification (BAI) with minimal regret. This innovative variant of the multi-armed bandit problem elegantly amalgamates two of its most ubiquitous objectives: regret minimization and BAI. More precisely, the agent's goal is to identify the best arm with a prescribed confidence level $\delta$, while minimizing the cumulative regret up to the stopping time. Focusing on single-parameter exponential families of distributions, we leverage information-theoretic techniques to establish an instance-dependent lower bound on the expected cumulative regret. Moreover, we present an intriguing impossibility result that underscores the tension between cumulative regret and sample complexity in fixed-confidence BAI. Complementarily, we design and analyze the Double KL-UCB algorithm, which achieves asymptotic optimality as the confidence level tends to zero. Notably, this algorithm employs two distinct confidence bounds to guide arm selection in a randomized manner. Our findings elucidate a fresh perspective on the inherent connections between regret minimization and BAI. |
| 医疗数据联邦学习中的隐私威胁深入分析 | 联邦学习作为一种有前途的机器学习技术，正在医疗领域中崭露头角，用于分析医疗图像，因为它被认为是一种有效的方法来保护敏感的患者数据并遵守隐私法规。然而，最近的研究表明，联邦学习的默认设置可能会无意中将私人训练数据暴露给隐私攻击。因此，这种隐私风险的程度以及在医疗领域中的潜在缓解策略仍然不明确。在本文中，我们对医疗数据联邦学习中的隐私风险分析和缓解做出了三个原创性贡献。首先，我们提出了一个综合框架MedPFL，用于分析联邦学习环境中处理医疗数据时的隐私风险，并开发有效的隐私保护缓解策略。其次，通过我们的实证分析，我们展示了联邦学习处理医疗图像时存在的严重隐私风险，其中攻击者可以通过执行隐私攻击准确地重建私人医疗图像。第三，我们说明了在联邦学习中，添加随机噪声的常见防御机制可能并不总是有效地保护医疗图像免受隐私攻击，这为保护医疗数据的隐私带来了独特而紧迫的挑战。此外，本文还讨论了联邦学习环境中医疗数据隐私保护相关的几个独特研究问题。我们在几个基准医疗图像数据集上进行了广泛的实验，以分析和缓解联邦学习中与医疗数据相关的隐私风险。 | Badhan Chandra Das | [PDF](http://arxiv.org/pdf/2409.18907v1) | N/A | In-depth Analysis of Privacy Threats in Federated Learning for Medical Data | Federated learning is emerging as a promising machine learning technique in the medical field for analyzing medical images, as it is considered an effective method to safeguard sensitive patient data and comply with privacy regulations. However, recent studies have revealed that the default settings of federated learning may inadvertently expose private training data to privacy attacks. Thus, the intensity of such privacy risks and potential mitigation strategies in the medical domain remain unclear. In this paper, we make three original contributions to privacy risk analysis and mitigation in federated learning for medical data. First, we propose a holistic framework, MedPFL, for analyzing privacy risks in processing medical data in the federated learning environment and developing effective mitigation strategies for protecting privacy. Second, through our empirical analysis, we demonstrate the severe privacy risks in federated learning to process medical images, where adversaries can accurately reconstruct private medical images by performing privacy attacks. Third, we illustrate that the prevalent defense mechanism of adding random noises may not always be effective in protecting medical images against privacy attacks in federated learning, which poses unique and pressing challenges related to protecting the privacy of medical data. Furthermore, the paper discusses several unique research questions related to the privacy protection of medical data in the federated learning environment. We conduct extensive experiments on several benchmark medical image datasets to analyze and mitigate the privacy risks associated with federated learning for medical data. |
| 高斯噪声下的最小二乘法、正交投影与QR分解算法的概率分析 | 本文扩展了Liesen等人（2002）的工作，他们分析了在向正交矩阵Q添加一列（[Q, c]）时条件数的变化，特别关注了c与Q的列空间之间的正交性。Liesen等人（2002）在定理2.3中提出的结果假设了精确算术和Q的正交性，这在将这些结果应用于QR分解算法等数值方法时是一个强假设。在我们的工作中，我们通过推导矩阵B的条件数增加的界限来解决这一问题，而不假设完美的正交性，即使在添加的列不完全正交于B的列空间时也是如此。这一框架使我们能够分析正交化不完全且受高斯噪声影响的QR分解方法。我们还提供了在高斯噪声下正交投影和最小二乘法性能的结果，进一步支持了这一理论的发展。 | Ali Lotfi | [PDF](http://arxiv.org/pdf/2409.18905v1) | N/A | Probabilistic Analysis of Least Squares, Orthogonal Projection, and QR Factorization Algorithms Subject to Gaussian Noise | In this paper, we extend the work of Liesen et al. (2002), which analyzes how the condition number of an orthonormal matrix Q changes when a column is added ([Q, c]), particularly focusing on the perpendicularity of c to the span of Q. Their result, presented in Theorem 2.3 of Liesen et al. (2002), assumes exact arithmetic and orthonormality of Q, which is a strong assumption when applying these results to numerical methods such as QR factorization algorithms. In our work, we address this gap by deriving bounds on the condition number increase for a matrix B without assuming perfect orthonormality, even when a column is not perfectly orthogonal to the span of B. This framework allows us to analyze QR factorization methods where orthogonalization is imperfect and subject to Gaussian noise. We also provide results on the performance of orthogonal projection and least squares under Gaussian noise, further supporting the development of this theory. |
| 多源硬信息与软信息融合方法用于准确预测加密货币价格走势 | 金融和加密货币领域最重要的挑战之一是准确预测加密货币价格趋势。利用人工智能（AI）有助于应对这一挑战。加密货币市场以其显著的增长和波动性吸引了投资者和学者，他们热衷于解读和预测加密货币价格走势。这种预测所需的庞大且多样化的数据增加了任务的复杂性。在我们的研究中，我们引入了一种名为硬信息与软信息融合（HSIF）的新方法，以提高加密货币价格走势预测的准确性。我们方法中的硬信息部分包括历史价格记录和技术指标。与之互补的是，软数据部分从X（原Twitter）中提取，涵盖有关加密货币的新闻标题和推文。为了利用这些数据，我们采用了基于Transformer的双向编码表示（BERT）的情感分析方法，即金融BERT（FinBERT），该方法表现最佳。最终，我们的模型基于包含处理后的硬信息和软信息的数据集进行训练。我们采用了双向长短期记忆（BiLSTM）模型，因为双向处理信息可以捕捉序列信息中的长期依赖关系。我们的实证研究结果强调了HSIF方法相对于依赖单一数据源模型的优越性，并通过比特币相关数据进行了测试。通过融合比特币数据集中的硬信息和软信息，我们的模型在预测价格走势方面达到了约96.8%的准确率。整合信息使我们的模型能够把握社会情绪对价格波动的影响，从而补充了基于硬信息的技术分析预测。 | Saeed Mohammadi Dashtaki | [PDF](http://arxiv.org/pdf/2409.18895v1) | N/A | Multi-Source Hard and Soft Information Fusion Approach for Accurate Cryptocurrency Price Movement Prediction | One of the most important challenges in the financial and cryptocurrency field is accurately predicting cryptocurrency price trends. Leveraging artificial intelligence (AI) is beneficial in addressing this challenge. Cryptocurrency markets, marked by substantial growth and volatility, attract investors and scholars keen on deciphering and forecasting cryptocurrency price movements. The vast and diverse array of data available for such predictions increases the complexity of the task. In our study, we introduce a novel approach termed hard and soft information fusion (HSIF) to enhance the accuracy of cryptocurrency price movement forecasts. The hard information component of our approach encompasses historical price records alongside technical indicators. Complementing this, the soft data component extracts from X (formerly Twitter), encompassing news headlines and tweets about the cryptocurrency. To use this data, we use the Bidirectional Encoder Representations from Transformers (BERT)-based sentiment analysis method, financial BERT (FinBERT), which performs best. Finally, our model feeds on the information set including processed hard and soft data. We employ the bidirectional long short-term memory (BiLSTM) model because processing information in both forward and backward directions can capture long-term dependencies in sequential information. Our empirical findings emphasize the superiority of the HSIF approach over models dependent on single-source data by testing on Bitcoin-related data. By fusing hard and soft information on Bitcoin dataset, our model has about 96.8\% accuracy in predicting price movement. Incorporating information enables our model to grasp the influence of social sentiment on price fluctuations, thereby supplementing the technical analysis-based predictions derived from hard information. |
| HM3：用于预训练模型的分层多目标模型合并 | 模型融合是一种将多个大型预训练模型合并为一个性能更强、任务适应性更广的单一模型的技术。由于其能够绕过原始训练数据和进一步训练过程的需求，模型融合在大规模预训练模型开发中越来越受欢迎。然而，现有的多数模型融合方法主要集中在探索参数空间，合并具有相同架构的模型。尽管架构空间内的合并具有潜力，但由于搜索空间庞大和层兼容性挑战，这一领域仍处于初级阶段。本文通过将架构空间合并过程建模为强化学习任务，标志着向更灵活、更全面的模型融合技术迈出了重要一步。我们使用离线采样的权重向量训练策略和价值网络，这些网络随后用于在线优化合并策略。此外，引入多目标优化范式以适应用户多样的任务偏好，学习最优模型的帕累托前沿，以提供定制化的合并建议。在多种任务（包括文本翻译、数学推理和代码生成）上的实验结果验证了所提出框架在模型融合中的有效性和优越性。代码将在评审过程后公开发布。 | Yu Zhou | [PDF](http://arxiv.org/pdf/2409.18893v1) | N/A | HM3: Hierarchical Multi-Objective Model Merging for Pretrained Models | Model merging is a technique that combines multiple large pretrained models into a single model with enhanced performance and broader task adaptability. It has gained popularity in large pretrained model development due to its ability to bypass the need for original training data and further training processes. However, most existing model merging approaches focus solely on exploring the parameter space, merging models with identical architectures. Merging within the architecture space, despite its potential, remains in its early stages due to the vast search space and the challenges of layer compatibility. This paper marks a significant advance toward more flexible and comprehensive model merging techniques by modeling the architecture-space merging process as a reinforcement learning task. We train policy and value networks using offline sampling of weight vectors, which are then employed for the online optimization of merging strategies. Moreover, a multi-objective optimization paradigm is introduced to accommodate users' diverse task preferences, learning the Pareto front of optimal models to offer customized merging suggestions. Experimental results across multiple tasks, including text translation, mathematical reasoning, and code generation, validate the effectiveness and superiority of the proposed framework in model merging. The code will be made publicly available after the review process. |
| IDGen：用于LLM评估的物品区分引导生成 | 随着大型语言模型（LLMs）在处理复杂任务上的能力日益增强，评估集必须跟上这些进步，以确保其保持足够的区分度。项目区分度（ID）理论在教育评估中广泛应用，用于衡量单个测试项目区分高低分者的能力。受此理论启发，我们提出了一种基于ID的提示合成框架，用于评估LLMs，以确保评估集能够根据模型能力持续更新和优化。我们的数据合成框架注重广度和特异性，能够生成全面评估LLMs能力并揭示模型间有意义性能差异的提示，从而在各种任务和领域中有效区分其相对优劣。为生成高质量数据，我们在泛化框架中引入了自校正机制，并开发了两种模型来预测提示的区分度和难度评分，以促进我们的数据合成框架，为评估数据合成研究贡献了宝贵的工具。我们将生成的数据应用于评估五个SOTA模型，数据显示平均得分为51.92，方差为10.06。相比之下，先前的工作（如SELF-INSTRUCT和WizardLM）平均得分超过67，方差低于3.2。结果表明，我们的框架生成的数据相比之前的工作更具挑战性和区分度。我们将发布一个包含超过3000个精心设计的提示的数据集，以促进LLMs的评估研究。 | Fan Lin | [PDF](http://arxiv.org/pdf/2409.18892v1) | N/A | IDGen: Item Discrimination Induced Prompt Generation for LLM Evaluation | As Large Language Models (LLMs) grow increasingly adept at managing complex tasks, the evaluation set must keep pace with these advancements to ensure it remains sufficiently discriminative. Item Discrimination (ID) theory, which is widely used in educational assessment, measures the ability of individual test items to differentiate between high and low performers. Inspired by this theory, we propose an ID-induced prompt synthesis framework for evaluating LLMs to ensure the evaluation set can continually update and refine according to model abilities. Our data synthesis framework prioritizes both breadth and specificity. It can generate prompts that comprehensively evaluate the capabilities of LLMs while revealing meaningful performance differences between models, allowing for effective discrimination of their relative strengths and weaknesses across various tasks and domains. To produce high-quality data, we incorporate a self-correct mechanism into our generalization framework, and develop two models to predict prompt discrimination and difficulty score to facilitate our data synthesis framework, contributing valuable tools to evaluation data synthesis research. We apply our generated data to evaluate five SOTA models. Our data achieves an average score of 51.92, accompanied by a variance of 10.06. By contrast, previous works (i.e., SELF-INSTRUCT and WizardLM) obtain an average score exceeding 67, with a variance below 3.2. The results demonstrate that the data generated by our framework is more challenging and discriminative compared to previous works. We will release a dataset of over 3,000 carefully crafted prompts to facilitate evaluation research of LLMs. |
| HR-Extreme：一个用于极端天气预报的高分辨率数据集 | 大型深度学习模型在天气预报中的应用，已经显著推动了该领域的发展，其中包括高分辨率预报和延长的预测周期，如Pangu和Fuxi模型所展示的那样。尽管取得了这些成功，但以往的研究大多忽视了极端天气事件，并且专门为这类事件定制的数据集仍然有限。鉴于准确预报极端天气的至关重要性，本研究引入了一个综合数据集，该数据集包含了从NOAA提供的高分辨率快速刷新（HRRR）数据中提取的高分辨率极端天气案例，HRRR是一个3公里的实时数据集。我们还评估了当前最先进的深度学习模型和数值天气预报（NWP）系统在HR-Extreme上的表现，并提供了一个改进的基准深度学习模型，称为HR-Heim，它在总体损失和HR-Extreme上的表现均优于其他模型。我们的研究结果表明，极端天气案例的误差显著大于整体预报误差，强调了它们在天气预测中作为重要损失来源的地位。这些发现强调了未来研究需要集中精力提高极端天气预报的准确性，以增强其实际应用价值。 | Nian Ran | [PDF](http://arxiv.org/pdf/2409.18885v1) | N/A | HR-Extreme: A High-Resolution Dataset for Extreme Weather Forecasting | The application of large deep learning models in weather forecasting has led to significant advancements in the field, including higher-resolution forecasting and extended prediction periods exemplified by models such as Pangu and Fuxi. Despite these successes, previous research has largely been characterized by the neglect of extreme weather events, and the availability of datasets specifically curated for such events remains limited. Given the critical importance of accurately forecasting extreme weather, this study introduces a comprehensive dataset that incorporates high-resolution extreme weather cases derived from the High-Resolution Rapid Refresh (HRRR) data, a 3-km real-time dataset provided by NOAA. We also evaluate the current state-of-the-art deep learning models and Numerical Weather Prediction (NWP) systems on HR-Extreme, and provide a improved baseline deep learning model called HR-Heim which has superior performance on both general loss and HR-Extreme compared to others. Our results reveal that the errors of extreme weather cases are significantly larger than overall forecast error, highlighting them as an crucial source of loss in weather prediction. These findings underscore the necessity for future research to focus on improving the accuracy of extreme weather forecasts to enhance their practical utility. |
| 使用预训练语言模型从安全网精神病医院的临床记录中进行自杀表型分析的多标签分类 | 准确的自杀事件识别和分类可以带来更好的自杀预防措施，减轻操作负担，并提高高强度精神病学环境中的护理质量。预训练语言模型在从非结构化临床叙述中识别自杀倾向方面显示出潜力。我们评估了四种基于BERT的模型在使用两种微调策略（多重单标签和单一多标签）检测500份注释的精神病学评估笔记中并存的自杀事件时的表现。这些笔记被标记为自杀意念（SI）、自杀企图（SA）、自杀暴露（ES）和非自杀性自伤（NSSI）。RoBERTa在使用二元相关性时表现优于其他模型（acc=0.86, F1=0.78）。MentalBERT（F1=0.74）也超过了BioClinicalBERT（F1=0.72）。使用单一多标签分类器微调的RoBERTa进一步提高了性能（acc=0.88, F1=0.81），这表明在领域相关数据上预训练的模型和单一多标签分类策略提高了效率和性能。

关键词：基于电子健康记录的表型分析；自然语言处理；电子健康记录数据的二次利用；自杀分类；基于BERT的模型；精神病学；心理健康 | Zehan Li | [PDF](http://arxiv.org/pdf/2409.18878v1) | N/A | Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models | Accurate identification and categorization of suicidal events can yield better suicide precautions, reducing operational burden, and improving care quality in high-acuity psychiatric settings. Pre-trained language models offer promise for identifying suicidality from unstructured clinical narratives. We evaluated the performance of four BERT-based models using two fine-tuning strategies (multiple single-label and single multi-label) for detecting coexisting suicidal events from 500 annotated psychiatric evaluation notes. The notes were labeled for suicidal ideation (SI), suicide attempts (SA), exposure to suicide (ES), and non-suicidal self-injury (NSSI). RoBERTa outperformed other models using binary relevance (acc=0.86, F1=0.78). MentalBERT (F1=0.74) also exceeded BioClinicalBERT (F1=0.72). RoBERTa fine-tuned with a single multi-label classifier further improved performance (acc=0.88, F1=0.81), highlighting that models pre-trained on domain-relevant data and the single multi-label classification strategy enhance efficiency and performance.   Keywords: EHR-based Phynotyping; Natural Language Processing; Secondary Use of EHR Data; Suicide Classification; BERT-based Model; Psychiatry; Mental Health |
| CESNET-TimeSeries24：网络流量异常检测与预测的时间序列数据集 | 网络流量中的异常检测对于维护计算机网络的安全和识别恶意活动至关重要。基于预测的方法是异常检测的主要方法之一。然而，目前缺乏用于预测和异常检测技术的大量真实世界网络数据集，这可能导致对异常检测算法性能的高估。本文通过引入一个包含网络实体行为时间序列数据的数据集来填补这一空白，该数据集是从CESNET3网络中收集的。该数据集由40周内27.5万个活跃IP地址的网络流量创建。所展示数据的服务提供商来源确保了网络实体之间的高度变异性，这为预测和异常检测模型构成了独特且真实的挑战。它为基于预测的异常检测方法的实际部署提供了宝贵的见解。 | Josef Koumar | [PDF](http://arxiv.org/pdf/2409.18874v1) | N/A | CESNET-TimeSeries24: Time Series Dataset for Network Traffic Anomaly Detection and Forecasting | Anomaly detection in network traffic is crucial for maintaining the security of computer networks and identifying malicious activities. One of the primary approaches to anomaly detection are methods based on forecasting. Nevertheless, extensive real-world network datasets for forecasting and anomaly detection techniques are missing, potentially causing performance overestimation of anomaly detection algorithms. This manuscript addresses this gap by introducing a dataset comprising time series data of network entities' behavior, collected from the CESNET3 network. The dataset was created from 40 weeks of network traffic of 275 thousand active IP addresses. The ISP origin of the presented data ensures a high level of variability among network entities, which forms a unique and authentic challenge for forecasting and anomaly detection models. It provides valuable insights into the practical deployment of forecast-based anomaly detection approaches. |
| 使用条件生成对抗网络模拟乳腺MRI中的动态肿瘤对比增强 | 本文提出了一种在乳腺MRI中进行虚拟对比增强的方法，提供了一种有前景的非侵入性替代方案，以替代传统的基于对比剂的DCE-MRI采集。利用条件生成对抗网络，我们从无对比增强的MRI中预测DCE-MRI图像，包括联合生成的多个相应DCE-MRI时间点的序列，从而能够在不带来相关健康风险的情况下实现肿瘤定位和特征描述。此外，我们定性和定量地评估了合成的DCE-MRI图像，提出了一个多指标的缩放聚合度量（SAMe），评估其在肿瘤分割下游任务中的实用性，并最终分析了多序列DCE-MRI生成中的时间模式。我们的方法在生成逼真且有用的DCE-MRI序列方面展示了有前景的结果，突显了虚拟对比增强在改善乳腺癌诊断和治疗中的潜力，特别是对于那些禁忌使用对比剂的患者。 | Richard Osuala | [PDF](http://arxiv.org/pdf/2409.18872v1) | N/A | Simulating Dynamic Tumor Contrast Enhancement in Breast MRI using Conditional Generative Adversarial Networks | This paper presents a method for virtual contrast enhancement in breast MRI, offering a promising non-invasive alternative to traditional contrast agent-based DCE-MRI acquisition. Using a conditional generative adversarial network, we predict DCE-MRI images, including jointly-generated sequences of multiple corresponding DCE-MRI timepoints, from non-contrast-enhanced MRIs, enabling tumor localization and characterization without the associated health risks. Furthermore, we qualitatively and quantitatively evaluate the synthetic DCE-MRI images, proposing a multi-metric Scaled Aggregate Measure (SAMe), assessing their utility in a tumor segmentation downstream task, and conclude with an analysis of the temporal patterns in multi-sequence DCE-MRI generation. Our approach demonstrates promising results in generating realistic and useful DCE-MRI sequences, highlighting the potential of virtual contrast enhancement for improving breast cancer diagnosis and treatment, particularly for patients where contrast agent administration is contraindicated. |
| 具有和没有视觉基础的神经模型中的个体化 | 我们展示了在编码个体化信息方面，语言与视觉模型CLIP与两个纯文本模型——FastText和SBERT之间的差异。我们研究了CLIP为基质、颗粒聚集体以及各种数量物体提供的潜在表示。我们的实验表明，CLIP嵌入比仅基于文本数据训练的模型更好地捕捉了个体化中的数量差异。此外，我们从CLIP嵌入中推导出的个体化层次结构与语言学和认知科学中提出的层次结构相一致。 | Alexey Tikhonov | [PDF](http://arxiv.org/pdf/2409.18868v1) | N/A | Individuation in Neural Models with and without Visual Grounding | We show differences between a language-and-vision model CLIP and two text-only models - FastText and SBERT - when it comes to the encoding of individuation information. We study latent representations that CLIP provides for substrates, granular aggregates, and various numbers of objects. We demonstrate that CLIP embeddings capture quantitative differences in individuation better than models trained on text-only data. Moreover, the individuation hierarchy we deduce from the CLIP embeddings agrees with the hierarchies proposed in linguistics and cognitive science. |
| 位置编码图分位数神经网络用于地理数据 | 位置编码图神经网络（PE-GNNs）是建模连续空间数据的领先方法。然而，它们往往无法产生校准良好的预测分布，限制了其在不确定性量化方面的有效性。我们引入了位置编码图分位数神经网络（PE-GQNN），这是一种新颖的方法，将PE-GNNs、分位数神经网络和重新校准技术整合在一个完全非参数化的框架中，对预测分布的假设要求极低。我们提出了一种新的网络架构，当与基于分位数的损失函数结合时，能够在不增加计算复杂度的情况下，生成准确且可靠的概率模型。我们的方法为条件密度估计提供了一个灵活且稳健的框架，适用于超越空间数据的应用场景。此外，我们还引入了一种结构化的方法，将KNN预测器融入模型中，同时通过GNN层操作避免了数据泄露。在基准数据集上的实验表明，PE-GQNN在预测准确性和不确定性量化方面显著优于现有的最先进方法。 | William E. R. de Amorim | [PDF](http://arxiv.org/pdf/2409.18865v1) | N/A | Positional Encoder Graph Quantile Neural Networks for Geographic Data | Positional Encoder Graph Neural Networks (PE-GNNs) are a leading approach for modeling continuous spatial data. However, they often fail to produce calibrated predictive distributions, limiting their effectiveness for uncertainty quantification. We introduce the Positional Encoder Graph Quantile Neural Network (PE-GQNN), a novel method that integrates PE-GNNs, Quantile Neural Networks, and recalibration techniques in a fully nonparametric framework, requiring minimal assumptions about the predictive distributions. We propose a new network architecture that, when combined with a quantile-based loss function, yields accurate and reliable probabilistic models without increasing computational complexity. Our approach provides a flexible, robust framework for conditional density estimation, applicable beyond spatial data contexts. We further introduce a structured method for incorporating a KNN predictor into the model while avoiding data leakage through the GNN layer operation. Experiments on benchmark datasets demonstrate that PE-GQNN significantly outperforms existing state-of-the-art methods in both predictive accuracy and uncertainty quantification. |
| 生成结构多样图形的挑战 | 对于许多与图相关的问题，拥有一组结构多样化的图至关重要。例如，这些图可以用于测试图算法或其神经网络近似。然而，据我们所知，在文献中尚未探讨生成结构多样化图的问题。本文填补了这一空白。首先，我们讨论了如何定义图集的多样性，为什么这一任务并非易事，以及如何选择适当的多样性度量。然后，对于给定的多样性度量，我们提出了几种优化该度量的算法并进行比较：我们考虑了基于标准随机图模型的方法、局部图优化、遗传算法和神经生成模型。我们展示了通过这些方法可以显著提高图的多样性，超越基本的随机图生成器。此外，我们对生成图的分析使我们能够更好地理解图距离的性质：根据用于优化的多样性度量，所获得的图可能具有非常不同的结构特性，这为多样性度量所基于的图距离的敏感性提供了见解。 | Fedor Velikonivtsev | [PDF](http://arxiv.org/pdf/2409.18859v1) | N/A | Challenges of Generating Structurally Diverse Graphs | For many graph-related problems, it can be essential to have a set of structurally diverse graphs. For instance, such graphs can be used for testing graph algorithms or their neural approximations. However, to the best of our knowledge, the problem of generating structurally diverse graphs has not been explored in the literature. In this paper, we fill this gap. First, we discuss how to define diversity for a set of graphs, why this task is non-trivial, and how one can choose a proper diversity measure. Then, for a given diversity measure, we propose and compare several algorithms optimizing it: we consider approaches based on standard random graph models, local graph optimization, genetic algorithms, and neural generative models. We show that it is possible to significantly improve diversity over basic random graph generators. Additionally, our analysis of generated graphs allows us to better understand the properties of graph distances: depending on which diversity measure is used for optimization, the obtained graphs may possess very different structural properties which gives insights about the sensitivity of the graph distance underlying the diversity measure. |
| 两个稀疏矩阵胜过一个：利用双重稀疏分解稀疏化神经网络 | 神经网络由于其庞大的规模和复杂性，常常难以处理。为了解决这一问题，各种方法通过稀疏化或分解权重矩阵来减小模型尺寸，例如幅度剪枝和低秩或块对角分解。在本研究中，我们提出了双重稀疏分解（Double Sparse Factorization, DSF），将每个权重矩阵分解为两个稀疏矩阵。尽管精确求解此问题在计算上是不可行的，但我们提出了一种基于交替最小化与ADMM的高效启发式方法，达到了最先进的成果，实现了神经网络前所未有的稀疏化。例如，在一次性剪枝设置中，我们的方法可以将LLaMA2-13B模型的尺寸减少50%，同时保持比密集的LLaMA2-7B模型更好的性能。我们还与最先进的卷积神经网络逐层剪枝方法——最优脑压缩（Optimal Brain Compression）进行了比较，表现优异。此外，即使在进一步模型微调后，我们方法的准确性改进依然持续。代码可在以下链接获取：https://github.com/usamec/double_sparse。 | Vladimír Boža | [PDF](http://arxiv.org/pdf/2409.18850v1) | N/A | Two Sparse Matrices are Better than One: Sparsifying Neural Networks with Double Sparse Factorization | Neural networks are often challenging to work with due to their large size and complexity. To address this, various methods aim to reduce model size by sparsifying or decomposing weight matrices, such as magnitude pruning and low-rank or block-diagonal factorization. In this work, we present Double Sparse Factorization (DSF), where we factorize each weight matrix into two sparse matrices. Although solving this problem exactly is computationally infeasible, we propose an efficient heuristic based on alternating minimization via ADMM that achieves state-of-the-art results, enabling unprecedented sparsification of neural networks. For instance, in a one-shot pruning setting, our method can reduce the size of the LLaMA2-13B model by 50% while maintaining better performance than the dense LLaMA2-7B model. We also compare favorably with Optimal Brain Compression, the state-of-the-art layer-wise pruning approach for convolutional neural networks. Furthermore, accuracy improvements of our method persist even after further model fine-tuning.   Code available at: https://github.com/usamec/double_sparse. |
| 经典统计（样本内）直觉不适用：关于偏差-方差权衡、过拟合以及从固定设计到随机设计的转变的说明 | 现代机器学习（ML）现象的突然出现，如双重下降和良性过拟合，可能会让许多经典训练的统计学家感到不安——这些现象似乎与任何数据学习入门课程中传达的统计直觉的核心相悖。历史上对这些现象的早期观察缺乏通常归因于当今对更复杂的ML方法、过度参数化、插值和/或更高数据维度的依赖。在这篇笔记中，我们展示了一个更简单但很少明确讨论的原因，解释了为什么我们今天观察到的行为似乎与经典统计学教科书中教授的直觉相悖。特别是，许多直觉源于固定设计设置，其中对样本内预测误差（在噪声结果的重采样下）感兴趣，而现代ML则根据泛化误差，即随机设计中的样本外预测误差来评估其预测。在这里，我们强调从固定设计到随机设计的这一简单转变（也许令人惊讶地）对与偏差-方差权衡相关的教科书直觉产生了深远的影响，并评论了在固定设计与随机设计中观察双重下降和良性过拟合的（不）可能性。 | Alicia Curth | [PDF](http://arxiv.org/pdf/2409.18842v1) | N/A | Classical Statistical (In-Sample) Intuitions Don't Generalize Well: A Note on Bias-Variance Tradeoffs, Overfitting and Moving from Fixed to Random Designs | The sudden appearance of modern machine learning (ML) phenomena like double descent and benign overfitting may leave many classically trained statisticians feeling uneasy -- these phenomena appear to go against the very core of statistical intuitions conveyed in any introductory class on learning from data. The historical lack of earlier observation of such phenomena is usually attributed to today's reliance on more complex ML methods, overparameterization, interpolation and/or higher data dimensionality. In this note, we show that there is another reason why we observe behaviors today that appear at odds with intuitions taught in classical statistics textbooks, which is much simpler to understand yet rarely discussed explicitly. In particular, many intuitions originate in fixed design settings, in which in-sample prediction error (under resampling of noisy outcomes) is of interest, while modern ML evaluates its predictions in terms of generalization error, i.e. out-of-sample prediction error in random designs. Here, we highlight that this simple move from fixed to random designs has (perhaps surprisingly) far-reaching consequences on textbook intuitions relating to the bias-variance tradeoff, and comment on the resulting (im)possibility of observing double descent and benign overfitting in fixed versus random designs. |
| RNC：针对资源受限边缘设备的DNN高效RRAM感知NAS与编译 | 计算内存（Computing-in-memory, CIM）是一种新兴的计算范式，相比传统的冯·诺依曼架构，它在加速神经网络方面展现出显著的高并行性、低延迟和能效潜力。然而，现有研究主要集中在硬件架构与大规模神经网络的协同设计，未充分考虑资源限制。在本研究中，我们旨在为基于电阻随机存取存储器（RRAM）的加速器开发边缘友好的深度神经网络（DNNs）。为此，我们提出了一种边缘编译与资源受限的RRAM感知神经架构搜索（NAS）框架，以搜索满足特定硬件约束的优化神经网络。我们的编译方法整合了层划分、复制和网络打包，以最大化计算单元的利用率。通过采用一次性神经网络方法，结合非支配排序遗传算法II（NSGA-II）实现帕累托最优，所得网络架构可针对高精度或低延迟进行优化。编译移动友好型网络，如Squeezenet和MobilenetV3 small，可实现超过80%的利用率，相比ISAAC类框架在不同交叉资源下实现超过6倍的加速。通过NAS优化速度得到的模型实现了5至30倍的加速。本文代码可在https://github.com/ArChiiii/rram_nas_comp_pack获取。 | Kam Chi Loong | [PDF](http://arxiv.org/pdf/2409.18841v1) | N/A | RNC: Efficient RRAM-aware NAS and Compilation for DNNs on Resource-Constrained Edge Devices | Computing-in-memory (CIM) is an emerging computing paradigm, offering noteworthy potential for accelerating neural networks with high parallelism, low latency, and energy efficiency compared to conventional von Neumann architectures. However, existing research has primarily focused on hardware architecture and network co-design for large-scale neural networks, without considering resource constraints. In this study, we aim to develop edge-friendly deep neural networks (DNNs) for accelerators based on resistive random-access memory (RRAM). To achieve this, we propose an edge compilation and resource-constrained RRAM-aware neural architecture search (NAS) framework to search for optimized neural networks meeting specific hardware constraints. Our compilation approach integrates layer partitioning, duplication, and network packing to maximize the utilization of computation units. The resulting network architecture can be optimized for either high accuracy or low latency using a one-shot neural network approach with Pareto optimality achieved through the Non-dominated Sorted Genetic Algorithm II (NSGA-II). The compilation of mobile-friendly networks, like Squeezenet and MobilenetV3 small can achieve over 80% of utilization and over 6x speedup compared to ISAAC-like framework with different crossbar resources. The resulting model from NAS optimized for speed achieved 5x-30x speedup. The code for this paper is available at https://github.com/ArChiiii/rram_nas_comp_pack. |
| 构建“泛化误差”的置信区间——一项综合基准研究 | 在评估机器学习预测模型的质量时，用于衡量预测性能的泛化误差的置信区间（CIs）是一个关键工具。幸运的是，存在许多计算此类CIs的方法，并且不断有新的有前景的方法被提出。通常，这些方法结合了各种重采样程序，其中最流行的是交叉验证和自举法，以及不同的方差估计技术。然而，遗憾的是，目前尚无共识何时使用这些组合最为可靠，以及它们之间的一般比较情况。在这项工作中，我们进行了首次大规模研究，比较了泛化误差的CIs——在总共18个表格回归和分类问题上，使用四种不同的归纳器和总共八种损失函数，实证评估了13种不同的方法。我们概述了构建泛化误差CIs的方法论基础和内在挑战，并在一个统一框架中提供了所有13种方法的简要回顾。最后，根据相对覆盖频率、宽度、和运行时间评估了CI方法。基于这些发现，我们能够确定一组推荐的方法。我们还将数据集作为基准套件发布在OpenML上，并在GitHub上发布了我们的代码，以作为进一步研究的基础。 | Hannah Schulz-Kümpel | [PDF](http://arxiv.org/pdf/2409.18836v1) | N/A | Constructing Confidence Intervals for 'the' Generalization Error -- a Comprehensive Benchmark Study | When assessing the quality of prediction models in machine learning, confidence intervals (CIs) for the generalization error, which measures predictive performance, are a crucial tool. Luckily, there exist many methods for computing such CIs and new promising approaches are continuously being proposed. Typically, these methods combine various resampling procedures, most popular among them cross-validation and bootstrapping, with different variance estimation techniques. Unfortunately, however, there is currently no consensus on when any of these combinations may be most reliably employed and how they generally compare. In this work, we conduct the first large-scale study comparing CIs for the generalization error - empirically evaluating 13 different methods on a total of 18 tabular regression and classification problems, using four different inducers and a total of eight loss functions. We give an overview of the methodological foundations and inherent challenges of constructing CIs for the generalization error and provide a concise review of all 13 methods in a unified framework. Finally, the CI methods are evaluated in terms of their relative coverage frequency, width, and runtime. Based on these findings, we are able to identify a subset of methods that we would recommend. We also publish the datasets as a benchmarking suite on OpenML and our code on GitHub to serve as a basis for further studies. |
| 通过2D卷积神经网络对渲染为图像的轨迹进行分类和回归 | 轨迹可以被视为坐标的时序数据，通常来源于运动物体。轨迹分类方法对于检测不同的运动模式尤为重要，而回归方法则用于计算运动指标和预测。计算机视觉的最新进展促进了将轨迹渲染为图像并通过具有二维卷积层（CNNs）的人工神经网络进行处理。这种方法利用了CNNs从图像中学习特征空间层次结构的能力，这对于识别复杂形状是必要的。此外，它克服了其他机器学习方法需要固定数量点输入轨迹的限制。然而，将轨迹渲染为图像可能会引入一些未充分研究的人为因素，如由于在离散网格上绘制坐标而导致的信息丢失，以及由于线条粗细和走样引起的频谱变化。在本研究中，我们探讨了CNNs在解决从不同模式渲染为图像的合成轨迹的分类和回归问题上的有效性。本研究考虑的参数包括线条粗细、图像分辨率、使用运动历史（时间成分的颜色编码）和抗锯齿处理。结果强调了在运动方向至关重要的应用中，根据模型深度和运动历史选择适当的图像分辨率的重要性。 | Mariaclaudia Nicolai | [PDF](http://arxiv.org/pdf/2409.18832v1) | N/A | Classification and regression of trajectories rendered as images via 2D Convolutional Neural Networks | Trajectories can be regarded as time-series of coordinates, typically arising from motile objects. Methods for trajectory classification are particularly important to detect different movement patterns, while methods for regression to compute motility metrics and forecasting. Recent advances in computer vision have facilitated the processing of trajectories rendered as images via artificial neural networks with 2d convolutional layers (CNNs). This approach leverages the capability of CNNs to learn spatial hierarchies of features from images, necessary to recognize complex shapes. Moreover, it overcomes the limitation of other machine learning methods that require input trajectories with a fixed number of points. However, rendering trajectories as images can introduce poorly investigated artifacts such as information loss due to the plotting of coordinates on a discrete grid, and spectral changes due to line thickness and aliasing. In this study, we investigate the effectiveness of CNNs for solving classification and regression problems from synthetic trajectories that have been rendered as images using different modalities. The parameters considered in this study include line thickness, image resolution, usage of motion history (color-coding of the temporal component) and anti-aliasing. Results highlight the importance of choosing an appropriate image resolution according to model depth and motion history in applications where movement direction is critical. |
| ARLBench：用于强化学习中超参数优化的灵活高效的基准测试工具 | 超参数是可靠训练出表现优异的强化学习（RL）代理的关键因素。然而，开发和评估用于调整这些超参数的自动化方法既耗费成本又耗费时间。因此，这类方法通常仅在一个领域或算法上进行评估，这使得比较变得困难，并限制了对它们通用性的深入了解。我们提出了ARLBench，这是一个用于RL中超参数优化（HPO）的基准，它允许对多种HPO方法进行比较，同时在评估中保持高效。为了在计算资源有限的条件下也能推动RL中的HPO研究，我们选择了一组涵盖多种算法和环境组合的代表性HPO任务子集。这一选择使得仅使用之前所需计算资源的一小部分就能生成自动化RL（AutoRL）方法的性能概况，从而使更广泛的研究人员能够从事RL中的HPO工作。基于我们选择的广泛且大规模的超参数景观数据集，ARLBench为AutoRL研究提供了一个高效、灵活且面向未来的基础。基准和数据集均可通过https://github.com/automl/arlbench获取。 | Jannis Becktepe | [PDF](http://arxiv.org/pdf/2409.18827v1) | N/A | ARLBench: Flexible and Efficient Benchmarking for Hyperparameter Optimization in Reinforcement Learning | Hyperparameters are a critical factor in reliably training well-performing reinforcement learning (RL) agents. Unfortunately, developing and evaluating automated approaches for tuning such hyperparameters is both costly and time-consuming. As a result, such approaches are often only evaluated on a single domain or algorithm, making comparisons difficult and limiting insights into their generalizability. We propose ARLBench, a benchmark for hyperparameter optimization (HPO) in RL that allows comparisons of diverse HPO approaches while being highly efficient in evaluation. To enable research into HPO in RL, even in settings with low compute resources, we select a representative subset of HPO tasks spanning a variety of algorithm and environment combinations. This selection allows for generating a performance profile of an automated RL (AutoRL) method using only a fraction of the compute previously necessary, enabling a broader range of researchers to work on HPO in RL. With the extensive and large-scale dataset on hyperparameter landscapes that our selection is based on, ARLBench is an efficient, flexible, and future-oriented foundation for research on AutoRL. Both the benchmark and the dataset are available at https://github.com/automl/arlbench. |
| 瑞士家庭护理中的本地转录模型：一项跨学科案例研究 | 自然语言处理（NLP）领域的最新进展为不同领域，包括医疗行业，开启了新的应用场景。特别是，转录技术可以用于支持护理文档过程的自动化，从而为护士腾出更多时间与患者互动。然而，这一过程中面临诸多挑战，包括（a）数据隐私问题，（b）地方语言和方言，以及（c）特定领域的专业词汇。在本案例研究中，我们探讨了瑞士家庭护理文档的转录情况。我们评估了多种转录工具和模型，并使用OpenAI的Whisper进行了多次实验，涉及德语的不同变体（即方言、外国口音）以及由家庭护理领域专家手工精选的示例文本。我们的研究结果表明，即便使用现成的模型，其表现也足以成为该领域未来研究的良好起点。 | Jeremy Kramer | [PDF](http://arxiv.org/pdf/2409.18819v1) | N/A | Local Transcription Models in Home Care Nursing in Switzerland: an Interdisciplinary Case Study | Latest advances in the field of natural language processing (NLP) enable new use cases for different domains, including the medical sector. In particular, transcription can be used to support automation in the nursing documentation process and give nurses more time to interact with the patients. However, different challenges including (a) data privacy, (b) local languages and dialects, and (c) domain-specific vocabulary need to be addressed. In this case study, we investigate the case of home care nursing documentation in Switzerland. We assessed different transcription tools and models, and conducted several experiments with OpenAI Whisper, involving different variations of German (i.e., dialects, foreign accent) and manually curated example texts by a domain expert of home care nursing. Our results indicate that even the used out-of-the-box model performs sufficiently well to be a good starting point for future research in the field. |
| 利用深度学习模型从MRI图像中早期诊断阿尔茨海默病 | 众所周知，全球最常见的痴呆症原因是阿尔茨海默病（AD）。这种病症的严重程度从轻微到严重逐渐发展，并干扰人们的日常活动。早期诊断在患者护理和临床试验中起着至关重要的作用。卷积神经网络（CNN）被用来创建一个框架，用于从MRI扫描中识别特定疾病特征。痴呆症的分类涉及多种方法，如医学历史回顾、神经心理学测试和磁共振成像（MRI）。然而，从Kaggle获得的图像数据集面临一个显著的类别不平衡问题，这需要每个类别的样本均匀分布来解决。在本文中，为了解决这种不平衡，采用了合成少数类过采样技术（SMOTE）。此外，一个预训练的卷积神经网络被应用于DEMNET痴呆网络，以从AD图像中提取关键特征。所提出的模型达到了令人印象深刻的98.67%的准确率。 | Sajjad Aghasi Javid | [PDF](http://arxiv.org/pdf/2409.18814v1) | N/A | Early diagnosis of Alzheimer's disease from MRI images with deep learning model | It is acknowledged that the most common cause of dementia worldwide is Alzheimer's disease (AD). This condition progresses in severity from mild to severe and interferes with people's everyday routines. Early diagnosis plays a critical role in patient care and clinical trials. Convolutional neural networks (CNN) are used to create a framework for identifying specific disease features from MRI scans Classification of dementia involves approaches such as medical history review, neuropsychological tests, and magnetic resonance imaging (MRI). However, the image dataset obtained from Kaggle faces a significant issue of class imbalance, which requires equal distribution of samples from each class to address. In this article, to address this imbalance, the Synthetic Minority Oversampling Technique (SMOTE) is utilized. Furthermore, a pre-trained convolutional neural network has been applied to the DEMNET dementia network to extract key features from AD images. The proposed model achieved an impressive accuracy of 98.67%. |
| LLMs4Synthesis：利用大型语言模型进行科学综合 | 针对科学文献日益增长的复杂性和数量，本文提出了LLMs4Synthesis框架，旨在提升大型语言模型（LLMs）在生成高质量科学综合报告方面的能力。该框架满足了快速、连贯且富含上下文的科学见解整合需求，同时利用了开源和专有的LLMs。此外，它还探讨了LLMs在评估这些综合报告的完整性和可靠性方面的有效性，缓解了当前定量指标的不足。我们的研究通过开发处理科学论文的新方法、定义新的综合类型以及建立九项详细的质量评价标准，为该领域做出了贡献。我们提出将LLMs与强化学习和AI反馈相结合，以优化综合报告的质量，确保其符合既定标准。LLMs4Synthesis框架及其组件的开放使用，有望提升科学研究综合过程中的生成和评估效率。 | Hamed Babaei Giglou | [PDF](http://arxiv.org/pdf/2409.18812v1) | N/A | LLMs4Synthesis: Leveraging Large Language Models for Scientific Synthesis | In response to the growing complexity and volume of scientific literature, this paper introduces the LLMs4Synthesis framework, designed to enhance the capabilities of Large Language Models (LLMs) in generating high-quality scientific syntheses. This framework addresses the need for rapid, coherent, and contextually rich integration of scientific insights, leveraging both open-source and proprietary LLMs. It also examines the effectiveness of LLMs in evaluating the integrity and reliability of these syntheses, alleviating inadequacies in current quantitative metrics. Our study contributes to this field by developing a novel methodology for processing scientific papers, defining new synthesis types, and establishing nine detailed quality criteria for evaluating syntheses. The integration of LLMs with reinforcement learning and AI feedback is proposed to optimize synthesis quality, ensuring alignment with established criteria. The LLMs4Synthesis framework and its components are made available, promising to enhance both the generation and evaluation processes in scientific research synthesis. |
| 在高维空间中，根据流形假设的扩散模型的收敛性 | 去噪扩散概率模型（Denoising Diffusion Probabilistic Models, DDPM）是一种强大的最先进方法，用于从高维数据分布中生成合成数据，广泛应用于图像、音频和视频生成以及科学和其他领域的许多其他应用。流形假设指出，高维数据通常位于周围空间中的低维流形上，并且在提供的示例中广泛认为这一假设成立。尽管最近的研究结果为扩散模型如何适应流形假设提供了宝贵的见解，但它们并未捕捉到这些模型的巨大实际成功，这使得这一研究方向非常富有成果。在这项工作中，我们在流形假设下研究了DDPM，并证明了它们在学习得分方面实现了与周围维度无关的速率。在采样方面，我们获得了关于Kullback-Leibler散度与周围维度无关的速率，以及关于Wasserstein距离的$O(\sqrt{D})$速率。我们通过开发一个新框架来实现这一点，该框架将扩散模型与经过充分研究的关于高斯过程极值的理论联系起来。 | Iskander Azangulov | [PDF](http://arxiv.org/pdf/2409.18804v1) | N/A | Convergence of Diffusion Models Under the Manifold Hypothesis in High-Dimensions | Denoising Diffusion Probabilistic Models (DDPM) are powerful state-of-the-art methods used to generate synthetic data from high-dimensional data distributions and are widely used for image, audio and video generation as well as many more applications in science and beyond. The manifold hypothesis states that high-dimensional data often lie on lower-dimensional manifolds within the ambient space, and is widely believed to hold in provided examples. While recent results has provided invaluable insight into how diffusion models adapt to the manifold hypothesis, they do not capture the great empirical success of these models, making this a very fruitful research direction.   In this work, we study DDPMs under the manifold hypothesis and prove that they achieve rates independent of the ambient dimension in terms of learning the score. In terms of sampling, we obtain rates independent of the ambient dimension w.r.t. the Kullback-Leibler divergence, and $O(\sqrt{D})$ w.r.t. the Wasserstein distance. We do this by developing a new framework connecting diffusion models to the well-studied theory of extrema of Gaussian Processes. |
| 电子竞技作为奖牌项目亮相2023年亚运会：利用BERTopic和GPT-4主题微调探索公众认知 | 本研究采用LLM增强的BERTopic建模分析，考察了2023年亚运会期间公众对电子竞技的看法以及赛事中的价值共创情况。我们识别出五个主要主题，代表了公众的认知，并探讨了主要利益相关者如何在电子竞技生态系统内外共创价值。关键发现强调了社交媒体营销在影响公众意见、推广电竞赛事和品牌方面的战略性运用，突显了赛事物流和基础设施的重要性。此外，研究揭示了传统电竞生态系统之外的利益相关者所贡献的共创价值，特别是在推动国家代表性和表现方面。我们的研究结果支持了将电子竞技合法化为一项运动的持续努力，同时指出主流认可仍是一个挑战。电子竞技作为奖牌项目的纳入展示了更广泛的接受度，并有助于缓解公众的负面看法。此外，非传统利益相关者的贡献突显了跨亚文化合作在电竞中的价值。 | Tyreal Yizhou Qian | [PDF](http://arxiv.org/pdf/2409.18798v1) | N/A | Esports Debut as a Medal Event at 2023 Asian Games: Exploring Public Perceptions with BERTopic and GPT-4 Topic Fine-Tuning | This study examined the public opinions of esports at the 2023 Asian Games and value co-creation during the event using an LLM-enhanced BERTopic modeling analysis. We identified five major themes representing public perceptions, as well as how major stakeholders co-created value within and beyond the esports ecosystem. Key findings highlighted the strategic use of social media marketing to influence public opinion and promote esports events and brands, emphasizing the importance of event logistics and infrastructure. Additionally, the study revealed the co-creation value contributed by stakeholders outside the traditional esports ecosystem, particularly in promoting national representation and performance. Our findings supported the ongoing efforts to legitimize esports as a sport, noting that mainstream recognition remains a challenge. The inclusion of esports as a medal event showcased broader acceptance and helped mitigate negative public perceptions. Moreover, contributions from non-traditional stakeholders underscored the value of cross-subcultural collaborations in esports. |
| 分层联邦ADMM | 本文中，我们摒弃了广泛使用的基于梯度下降的分层联邦学习（FL）算法，开发了一种基于交替方向乘子法（ADMM）的新型分层FL框架。在此框架内，我们提出了两种新颖的FL算法，它们都在顶层使用ADMM：一种在底层采用ADMM，另一种则使用传统的基于梯度下降的方法。所提出的框架增强了隐私性，实验表明，与传统算法相比，所提出的算法在学习收敛性和准确性方面具有优越性。此外，即使局部步骤数量非常有限，底层使用梯度下降也能表现良好，而双层使用ADMM则在其他情况下带来更好的性能。 | Seyed Mohammad Azimi-Abarghouyi | [PDF](http://arxiv.org/pdf/2409.18796v1) | N/A | Hierarchical Federated ADMM | In this paper, we depart from the widely-used gradient descent-based hierarchical federated learning (FL) algorithms to develop a novel hierarchical FL framework based on the alternating direction method of multipliers (ADMM). Within this framework, we propose two novel FL algorithms, which both use ADMM in the top layer: one that employs ADMM in the lower layer and another that uses the conventional gradient descent-based approach. The proposed framework enhances privacy, and experiments demonstrate the superiority of the proposed algorithms compared to the conventional algorithms in terms of learning convergence and accuracy. Additionally, gradient descent on the lower layer performs well even if the number of local steps is very limited, while ADMM on both layers lead to better performance otherwise. |
| 关于大型语言模型诚实性的调查 | 诚实是使大型语言模型（LLM）与人类价值观对齐的基本原则，要求这些模型能够识别它们知道和不知道的内容，并能够忠实地表达其知识。尽管前景看好，当前的LLM仍然表现出显著的不诚实行为，例如自信地呈现错误答案或未能表达其已知信息。此外，对LLM诚实性的研究也面临挑战，包括诚实定义的多样性、区分已知和未知知识的困难，以及对相关研究缺乏全面理解。为了解决这些问题，我们提供了一份关于LLM诚实性的调查，涵盖了其澄清、评估方法和改进策略。此外，我们还为未来的研究提供了见解，旨在激发对该重要领域的进一步探索。 | Siheng Li | [PDF](http://arxiv.org/pdf/2409.18786v1) | N/A | A Survey on the Honesty of Large Language Models | Honesty is a fundamental principle for aligning large language models (LLMs) with human values, requiring these models to recognize what they know and don't know and be able to faithfully express their knowledge. Despite promising, current LLMs still exhibit significant dishonest behaviors, such as confidently presenting wrong answers or failing to express what they know. In addition, research on the honesty of LLMs also faces challenges, including varying definitions of honesty, difficulties in distinguishing between known and unknown knowledge, and a lack of comprehensive understanding of related research. To address these issues, we provide a survey on the honesty of LLMs, covering its clarification, evaluation approaches, and strategies for improvement. Moreover, we offer insights for future research, aiming to inspire further exploration in this important area. |
| 硬核生成：为数据增强生成困难的UNSAT问题 | 高效地确定布尔方程的可满足性——简称为SAT问题——在各种工业问题中至关重要。近年来，深度学习方法的出现为提升SAT求解带来了巨大的潜力。然而，这一领域发展的一个主要障碍是缺乏大规模、真实的训练数据集。当前大多数公开数据集要么是随机生成的，要么极其有限，仅包含来自不相关问题家族的少数示例。这些数据集不足以进行深度学习方法的有效训练。鉴于此，研究人员已开始探索生成技术，以创建更准确反映实际情况下遇到的SAT问题的数据。迄今为止，这些方法要么无法生成具有挑战性的SAT问题，要么面临时间扩展性的障碍。本文通过识别和操控问题的“难度”关键因素——即核心（cores），来解决这两个问题。尽管之前的一些工作涉及核心处理，但由于传统启发式核心检测技术的高成本，时间成本过高。我们引入了一种利用图神经网络的快速核心检测程序。我们的实证结果表明，我们可以高效生成难以解决且保留原始示例问题关键属性的问题。通过实验，我们展示了生成的合成SAT问题可以在数据增强场景中使用，以提供更优的求解器运行时间预测。 | Joseph Cotnareanu | [PDF](http://arxiv.org/pdf/2409.18778v1) | N/A | HardCore Generation: Generating Hard UNSAT Problems for Data Augmentation | Efficiently determining the satisfiability of a boolean equation -- known as the SAT problem for brevity -- is crucial in various industrial problems. Recently, the advent of deep learning methods has introduced significant potential for enhancing SAT solving. However, a major barrier to the advancement of this field has been the scarcity of large, realistic datasets. The majority of current public datasets are either randomly generated or extremely limited, containing only a few examples from unrelated problem families. These datasets are inadequate for meaningful training of deep learning methods. In light of this, researchers have started exploring generative techniques to create data that more accurately reflect SAT problems encountered in practical situations. These methods have so far suffered from either the inability to produce challenging SAT problems or time-scalability obstacles. In this paper we address both by identifying and manipulating the key contributors to a problem's ``hardness'', known as cores. Although some previous work has addressed cores, the time costs are unacceptably high due to the expense of traditional heuristic core detection techniques. We introduce a fast core detection procedure that uses a graph neural network. Our empirical results demonstrate that we can efficiently generate problems that remain hard to solve and retain key attributes of the original example problems. We show via experiment that the generated synthetic SAT problems can be used in a data augmentation setting to provide improved prediction of solver runtimes. |
| 一种在低比特GEMM残差计算中使用RSVD的方法 | 近年来硬件技术的进步为低精度应用带来了许多可能性。然而，使用低精度可能会引入显著的计算误差，这对保持计算精度构成了相当大的挑战。我们提出了低秩残差量化矩阵乘法（LRQMM）方法，该方法在密集低精度量化矩阵乘法中引入低秩近似进行残差补偿。它可以在仅增加BLAS-2级别额外时间开销的情况下，带来数倍的精度提升。此外，LRQMM是一种完全无数据的量化方法，不需要额外的数据进行预训练。它仅与低精度GEMM运算符配合使用，易于与其他方法结合。通过实验验证，LRQMM可以将直接量化矩阵乘法的误差降低1~2个数量级，而在处理较大矩阵尺寸时，计算速度仅降低约20%。在深度学习网络中，LRQMM-4bit在Resnet-50上实现了61.8%的ImageNet Top-1准确率，而直接量化的准确率仅为8.3%。 | Hongyaoxing Gu | [PDF](http://arxiv.org/pdf/2409.18772v1) | N/A | A method of using RSVD in residual calculation of LowBit GEMM | The advancements of hardware technology in recent years has brought many possibilities for low-precision applications. However, the use of low precision can introduce significant computational errors, posing a considerable challenge to maintaining the computational accuracy.   We propose low-rank residuals quantized matrix multiplication(LRQMM) method which introduces low-rank approximation in residual compensation for dense low precision quantization matrix multiplication. It can bring several times accuracy improvement with only BLAS-2 level extra time overhead. Moreover, LRQMM is a completely data-free quantization method that does not require additional data for pre-training. And it only works with low precision GEMM operator, which is easy to couple with other methods.   Through experimentation, LRQMM can reduce the error of direct quantized matrix multiplication by 1~2 orders of magnitude, when dealing with larger matrix sizes, the computational speed is only reduced by approximately 20\%. In deep learning networks, LRQMM-4bit achieves 61.8% ImageNet Top-1 accuracy in Resnet-50, while the Direct Quant accuracy is only 8.3%. |
| 从示范中学习带有隐式非线性动力学模型 | 从示范中学习（LfD）是一种训练策略的有用范式，这些策略能够解决涉及复杂动作的任务。在实践中，成功应用LfD需要克服策略执行过程中的误差累积问题，即由于误差随时间累积而导致的漂移问题以及随之而来的分布外行为。现有研究试图通过扩展数据收集、采用人在回路中的策略错误纠正、时间集成策略预测或学习动力系统模型参数来解决这一问题。在本研究中，我们提出并验证了一种克服该问题的替代方法。受储备计算的启发，我们开发了一种新型神经网络层，该层包含一个具有可调动力学特性的固定非线性动力系统。我们通过在LASA人类手写数据集上重现人类手写动作的任务，验证了我们神经网络层的有效性。通过实证实验，我们证明了将我们的层融入现有神经网络架构能够解决LfD中的误差累积问题。此外，我们还与现有方法进行了比较评估，包括策略预测的时间集成和回声状态网络（ESNs）实现。我们发现，我们的方法在手写任务上表现出更高的策略精度和鲁棒性，同时还能适应多种动力学状态并保持竞争性的延迟评分。 | Peter David Fagan | [PDF](http://arxiv.org/pdf/2409.18768v1) | N/A | Learning from Demonstration with Implicit Nonlinear Dynamics Models | Learning from Demonstration (LfD) is a useful paradigm for training policies that solve tasks involving complex motions. In practice, the successful application of LfD requires overcoming error accumulation during policy execution, i.e. the problem of drift due to errors compounding over time and the consequent out-of-distribution behaviours. Existing works seek to address this problem through scaling data collection, correcting policy errors with a human-in-the-loop, temporally ensembling policy predictions or through learning the parameters of a dynamical system model. In this work, we propose and validate an alternative approach to overcoming this issue. Inspired by reservoir computing, we develop a novel neural network layer that includes a fixed nonlinear dynamical system with tunable dynamical properties. We validate the efficacy of our neural network layer on the task of reproducing human handwriting motions using the LASA Human Handwriting Dataset. Through empirical experiments we demonstrate that incorporating our layer into existing neural network architectures addresses the issue of compounding errors in LfD. Furthermore, we perform a comparative evaluation against existing approaches including a temporal ensemble of policy predictions and an Echo State Networks (ESNs) implementation. We find that our approach yields greater policy precision and robustness on the handwriting task while also generalising to multiple dynamics regimes and maintaining competitive latency scores. |
| 绘制未来：利用图表问答进行大规模评估的LLM驱动数据可视化 | 我们提出了一种新颖的框架，利用视觉问答（VQA）模型来自动评估由大型语言模型（LLM）生成的数据可视化。传统的评估方法往往依赖于人工判断，这种方法成本高且难以扩展，或者仅关注数据准确性，而忽视了视觉传达的有效性。通过采用VQA模型，我们评估了数据表示的质量以及图表的整体传达清晰度。实验使用了两个领先的VQA基准数据集，ChartQA和PlotQA，并采用了OpenAI的GPT-3.5 Turbo和Meta的Llama 3.1 70B-Instruct模型生成的可视化数据。我们的结果表明，基于VQA性能指标，LLM生成的图表在准确性上未能达到原始非LLM生成图表的水平。此外，尽管我们的结果显示，少样本提示显著提升了图表生成的准确性，但在LLM完全匹配人类生成图表的精度之前，仍需取得显著进展。这突显了我们工作的重要性，通过无需人工标注的快速迭代，加速了研究进程，从而推动了该领域的进步。 | James Ford | [PDF](http://arxiv.org/pdf/2409.18764v1) | N/A | Charting the Future: Using Chart Question-Answering for Scalable Evaluation of LLM-Driven Data Visualizations | We propose a novel framework that leverages Visual Question Answering (VQA) models to automate the evaluation of LLM-generated data visualizations. Traditional evaluation methods often rely on human judgment, which is costly and unscalable, or focus solely on data accuracy, neglecting the effectiveness of visual communication. By employing VQA models, we assess data representation quality and the general communicative clarity of charts. Experiments were conducted using two leading VQA benchmark datasets, ChartQA and PlotQA, with visualizations generated by OpenAI's GPT-3.5 Turbo and Meta's Llama 3.1 70B-Instruct models. Our results indicate that LLM-generated charts do not match the accuracy of the original non-LLM-generated charts based on VQA performance measures. Moreover, while our results demonstrate that few-shot prompting significantly boosts the accuracy of chart generation, considerable progress remains to be made before LLMs can fully match the precision of human-generated graphs. This underscores the importance of our work, which expedites the research process by enabling rapid iteration without the need for human annotation, thus accelerating advancements in this field. |
| 几何深度学习在星系-暗晕关联中的应用：星系内禀对齐的案例研究 | 即将到来的宇宙学成像调查，如鲁宾天文台LSST，需要大规模的模拟，涵盖各种科学应用的真实星系群体。特别关注的是固有对齐（IA）现象，即星系朝向过密区域定向，如果不适当建模，可能会在弱引力透镜分析中引入显著的系统偏差。由于计算限制，模拟跨越广阔体积的与IA相关的星系形成和演化的复杂细节是不切实际的。作为替代方案，我们提出了一种基于IllustrisTNG-100模拟训练的深度生成模型，用于采样3D星系形状和方向，以准确再现固有对齐及其相关的标量特征。我们将宇宙网建模为一组图，每个图代表一个包含子星系/星系的暗物质晕。架构包括一个SO(3) $\times$ $\mathbb{R}^n$扩散生成模型，用于星系方向和$n$个标量，通过E(3)等变图神经网络实现，明确尊重我们宇宙的欧几里得对称性。该模型能够学习和预测与参考模拟统计一致的星系方向等特征。值得注意的是，我们的模型展示了联合建模欧几里得标量（星系大小、形状和颜色）和非欧几里得SO(3)量（星系方向）的能力，这些量在非线性尺度上受高度复杂的星系物理支配。 | Yesukhei Jagvaral | [PDF](http://arxiv.org/pdf/2409.18761v1) | N/A | Geometric deep learning for galaxy-halo connection: a case study for galaxy intrinsic alignments | Forthcoming cosmological imaging surveys, such as the Rubin Observatory LSST, require large-scale simulations encompassing realistic galaxy populations for a variety of scientific applications. Of particular concern is the phenomenon of intrinsic alignments (IA), whereby galaxies orient themselves towards overdensities, potentially introducing significant systematic biases in weak gravitational lensing analyses if they are not properly modeled. Due to computational constraints, simulating the intricate details of galaxy formation and evolution relevant to IA across vast volumes is impractical. As an alternative, we propose a Deep Generative Model trained on the IllustrisTNG-100 simulation to sample 3D galaxy shapes and orientations to accurately reproduce intrinsic alignments along with correlated scalar features. We model the cosmic web as a set of graphs, each graph representing a halo with nodes representing the subhalos/galaxies. The architecture consists of a SO(3) $\times$ $\mathbb{R}^n$ diffusion generative model, for galaxy orientations and $n$ scalars, implemented with E(3) equivariant Graph Neural Networks that explicitly respect the Euclidean symmetries of our Universe. The model is able to learn and predict features such as galaxy orientations that are statistically consistent with the reference simulation. Notably, our model demonstrates the ability to jointly model Euclidean-valued scalars (galaxy sizes, shapes, and colors) along with non-Euclidean valued SO(3) quantities (galaxy orientations) that are governed by highly complex galactic physics at non-linear scales. |
| TensorSocket：深度学习训练中的共享数据加载 | 训练深度学习模型是一个重复且资源密集的过程。数据科学家通常会在找到一组参数（例如，超参数调整）、模型架构（例如，神经架构搜索）等能够产生最高准确率的设置之前，训练多个模型。这些训练任务的计算效率在很大程度上取决于我们能够为训练过程提供训练数据的效率。这些任务的重复性导致相同的数据处理管道一遍又一遍地运行，加剧了对计算资源的需求和成本。在本文中，我们提出了Tensorsocket，通过使多个训练过程共享相同的数据加载器来减少深度学习训练的计算需求。Tensorsocket在共置的训练工作负载在GPU上具有高吞吐量但在CPU上数据加载吞吐量较低的情况下，缓解了CPU端的瓶颈。Tensorsocket通过减少共置训练过程中的冗余计算并利用现代GPU-GPU互连来实现这一点。我们展示了Tensorsocket的硬件和管道无关性，并使用多种训练场景对其进行了评估。我们的评估表明，Tensorsocket使得在没有数据共享的情况下不可行的场景变得可行，将训练吞吐量提高了最多100%，并且在使用云实例时，通过减少CPU端的硬件资源需求，Tensorsocket实现了50%的成本节省。此外，Tensorsocket在共享数据加载方面优于最先进的解决方案，如CoorDL和Joader。它更易于使用、维护和部署，并且在需要较少CPU资源的情况下，要么实现了更高的吞吐量，要么与其他解决方案持平。 | Ties Robroek | [PDF](http://arxiv.org/pdf/2409.18749v1) | N/A | TensorSocket: Shared Data Loading for Deep Learning Training | Training deep learning models is a repetitive and resource-intensive process. Data scientists often train several models before landing on set of parameters (e.g., hyper-parameter tuning), model architecture (e.g., neural architecture search), among other things that yields the highest accuracy. The computational efficiency of these training tasks depends highly on how well we can supply the training process with training data. The repetitive nature of these tasks results in the same data processing pipelines running over and over exacerbating the need for and costs of computational resources.   In this paper, we present Tensorsocket to reduce the computational needs of deep learning training by enabling simultaneous training processes to share the same data loader. Tensorsocket mitigates CPU-side bottlenecks in cases where the collocated training workloads have high throughput on GPU, but are held back by lower data-loading throughput on CPU. Tensorsocket achieves this by reducing redundant computations across collocated training processes and leveraging modern GPU-GPU interconnects. We demonstrate the hardware- and pipeline-agnostic nature of Tensorsocket and evaluate it using a variety of training scenarios.   Our evaluation shows that Tensorsocket enables scenarios that are infeasible without data sharing, increases training throughput by up to $100\%$, and when utilizing cloud instances, Tensorsocket achieves cost savings of $50\%$ by reducing the hardware resource needs on the CPU side. Furthermore, Tensorsocket outperforms the state-of-the-art solutions for shared data loading such as CoorDL and Joader. It is easier to use, maintain, and deploy, and either achieves higher or matches the throughput of other solutions while requiring less CPU resources. |
| 注意：带有余弦注意力的线性变压器 | 注意力机制，尤其是softmax注意力，在诸如GPT等基于transformer的模型的成功中发挥了重要作用。然而，softmax注意力相对于序列长度的二次内存复杂性，给处理更长的序列带来了显著挑战。我们引入了Cottention，这是一种新颖的注意力机制，用余弦相似度取代了softmax操作。通过利用余弦相似度的特性并重新排列注意力方程，Cottention实现了相对于序列长度的本征线性内存复杂性，使其在内存效率上天生优于softmax注意力。我们证明，Cottention可以被重新表述为一个具有有限隐藏状态的循环神经网络（RNN），从而在推理过程中实现恒定的内存使用。我们在双向BERT和因果GPT任务上评估了Cottention，展示了其与softmax注意力相当的性能，同时显著减少了内存需求。为了确保高效的计算，我们为Cottention开发了一个自定义的CUDA内核。我们的结果表明，Cottention是softmax注意力的一个有前景的替代方案，能够在不牺牲性能的情况下处理更长的序列，这得益于其本征的线性内存复杂性和在推理过程中保持恒定内存占用的能力。 | Gabriel Mongaras | [PDF](http://arxiv.org/pdf/2409.18747v1) | N/A | Cottention: Linear Transformers With Cosine Attention | Attention mechanisms, particularly softmax attention, have been instrumental in the success of transformer-based models such as GPT. However, the quadratic memory complexity of softmax attention with respect to sequence length poses significant challenges for processing longer sequences. We introduce Cottention, a novel attention mechanism that replaces the softmax operation with cosine similarity. By leveraging the properties of cosine similarity and rearranging the attention equation, Cottention achieves native linear memory complexity with respect to sequence length, making it inherently more memory-efficient than softmax attention. We demonstrate that Cottention can be reformulated as a recurrent neural network (RNN) with a finite hidden state, allowing for constant memory usage during inference. We evaluate Cottention on both the bidirectional BERT and causal GPT tasks, demonstrating comparable performance to softmax attention while significantly reducing memory requirements. To ensure efficient computation, we develop a custom CUDA kernel for Cottention. Our results show that Cottention is a promising alternative to softmax attention, enabling the processing of longer sequences without sacrificing performance, due to its native linear memory complexity and ability to maintain a constant memory footprint during inference. |
| 一种基于历史引导的区域划分进化优化方法，用于解决有限多载自动导引车条件下的柔性作业车间调度问题 | 在柔性作业车间环境下，使用自动导引车（AGV）来运输工件和加工材料是促进车间智能化的重要方式。与单载AGV相比，多载AGV可以提高AGV利用率，减少路径冲突等。因此，本研究针对有限多载AGV的柔性作业车间调度问题（FJSPMA），提出了一种历史引导的区域划分算法（HRPEO）。首先，根据多载AGV的特点设计了编码和解码规则，然后使用基于分支定界法的初始化规则生成初始种群。其次，为了防止算法陷入局部最优，算法采用了区域划分策略。该策略将解空间划分为多个区域，并测量各区域的潜力。之后，在每次迭代中将区域聚类为多个簇，并根据簇集选择个体进行进化搜索。第三，设计了一种局部搜索策略以提高算法的开发能力，该策略利用贪心方法根据FJSPMA的特点优化机器选择和运输顺序。最后，在基准测试上进行了大量实验以测试算法的性能。与多个先进算法相比，结果表明HRPEO在解决FJSPMA问题方面具有更好的优势。 | Feige Liu | [PDF](http://arxiv.org/pdf/2409.18742v1) | N/A | A History-Guided Regional Partitioning Evolutionary Optimization for Solving the Flexible Job Shop Problem with Limited Multi-load Automated Guided Vehicles | In a flexible job shop environment, using Automated Guided Vehicles (AGVs) to transport jobs and process materials is an important way to promote the intelligence of the workshop. Compared with single-load AGVs, multi-load AGVs can improve AGV utilization, reduce path conflicts, etc. Therefore, this study proposes a history-guided regional partitioning algorithm (HRPEO) for the flexible job shop scheduling problem with limited multi-load AGVs (FJSPMA). First, the encoding and decoding rules are designed according to the characteristics of multi-load AGVs, and then the initialization rule based on the branch and bound method is used to generate the initial population. Second, to prevent the algorithm from falling into a local optimum, the algorithm adopts a regional partitioning strategy. This strategy divides the solution space into multiple regions and measures the potential of the regions. After that, cluster the regions into multiple clusters in each iteration, and selects individuals for evolutionary search based on the set of clusters. Third, a local search strategy is designed to improve the exploitation ability of the algorithm, which uses a greedy approach to optimize machines selection and transportation sequence according to the characteristics of FJSPMA. Finally, a large number of experiments are carried out on the benchmarks to test the performance of the algorithm. Compared with multiple advanced algorithms, the results show that the HRPEO has a better advantage in solving FJSPMA. |
| 自回归策略优化用于约束分配任务 | 分配任务代表一类问题，其中在每个时间步必须将有限数量的资源分配给一组实体。这类任务的显著例子包括投资组合优化或跨服务器分配计算工作负载。分配任务通常受到线性约束的限制，这些约束描述了必须在任何时候严格满足的实际要求。例如，在投资组合优化中，投资者可能被要求在任何投资期间将资金分配到某个工业部门的金额不得超过30%。这些约束以复杂的方式限制了允许的分配动作空间，使得学习避免违反约束的策略变得困难。在本文中，我们提出了一种基于自回归过程的新方法，用于约束分配任务，以顺序地为每个实体采样分配。此外，我们引入了一种新颖的去偏机制，以抵消顺序采样引起的初始偏差。我们在三个不同的约束分配任务上展示了我们的方法相对于各种约束强化学习（CRL）方法的优越性能：投资组合优化、计算工作负载分配和一个综合分配基准。我们的代码可在以下链接获取：https://github.com/niklasdbs/paspo。 | David Winkel | [PDF](http://arxiv.org/pdf/2409.18735v1) | N/A | Autoregressive Policy Optimization for Constrained Allocation Tasks | Allocation tasks represent a class of problems where a limited amount of resources must be allocated to a set of entities at each time step. Prominent examples of this task include portfolio optimization or distributing computational workloads across servers. Allocation tasks are typically bound by linear constraints describing practical requirements that have to be strictly fulfilled at all times. In portfolio optimization, for example, investors may be obligated to allocate less than 30\% of the funds into a certain industrial sector in any investment period. Such constraints restrict the action space of allowed allocations in intricate ways, which makes learning a policy that avoids constraint violations difficult. In this paper, we propose a new method for constrained allocation tasks based on an autoregressive process to sequentially sample allocations for each entity. In addition, we introduce a novel de-biasing mechanism to counter the initial bias caused by sequential sampling. We demonstrate the superior performance of our approach compared to a variety of Constrained Reinforcement Learning (CRL) methods on three distinct constrained allocation tasks: portfolio optimization, computational workload distribution, and a synthetic allocation benchmark. Our code is available at: https://github.com/niklasdbs/paspo |
| 跨领域关键词提取与关键性模式 | 领域依赖性和标注主观性给有监督的关键词抽取带来了挑战。本文基于社群层面存在二阶显著性模式且可从标注的关键词抽取数据集中学习的假设，提出了一种有监督的排序方法来进行关键词抽取。该方法通过包含独立特征（如子语言领域和术语长度）和三类依赖特征——启发式特征、特异性特征和代表性特征的显著性模式来对关键词进行排序。该方法使用两种基于卷积神经网络的模型从关键词数据集中学习显著性模式，并通过自举采样策略训练这两种模型来克服标注主观性。实验表明，该方法不仅在一般有监督的关键词抽取中在十个关键词数据集上取得了平均top-10-F-measure为0.316的先进性能，而且在训练过程中未包含的四个数据集上实现了平均top-10-F-measure为0.346的跨领域鲁棒性。这种跨领域鲁棒性归因于社群层面的显著性模式数量有限且在一定程度上独立于语言领域、独立特征与依赖特征的区分，以及平衡过拟合风险和缺乏负样本训练数据的采样训练策略。 | Dongmei Zhou | [PDF](http://arxiv.org/pdf/2409.18724v1) | N/A | Cross-Domain Keyword Extraction with Keyness Patterns | Domain dependence and annotation subjectivity pose challenges for supervised keyword extraction. Based on the premises that second-order keyness patterns are existent at the community level and learnable from annotated keyword extraction datasets, this paper proposes a supervised ranking approach to keyword extraction that ranks keywords with keyness patterns consisting of independent features (such as sublanguage domain and term length) and three categories of dependent features -- heuristic features, specificity features, and representavity features. The approach uses two convolutional-neural-network based models to learn keyness patterns from keyword datasets and overcomes annotation subjectivity by training the two models with bootstrap sampling strategy. Experiments demonstrate that the approach not only achieves state-of-the-art performance on ten keyword datasets in general supervised keyword extraction with an average top-10-F-measure of 0.316 , but also robust cross-domain performance with an average top-10-F-measure of 0.346 on four datasets that are excluded in the training process. Such cross-domain robustness is attributed to the fact that community-level keyness patterns are limited in number and temperately independent of language domains, the distinction between independent features and dependent features, and the sampling training strategy that balances excess risk and lack of negative training data. |
| 可扩展的大规模项目目录序列推荐交叉熵损失 | 可扩展性问题在现代推荐系统的生产化过程中起着至关重要的作用。即使是轻量级的架构也可能由于中间计算而导致高计算负载，限制了其在实际应用中的实用性。具体来说，应用完整的交叉熵（CE）损失通常在推荐质量方面能取得最先进的性能。然而，在处理大型物品目录时，它会遭受过度的GPU内存占用。本文在序列学习设置中引入了一种新颖的可扩展交叉熵（SCE）损失函数。它近似于具有大型目录的数据集的CE损失，在不牺牲推荐质量的情况下，提高了时间和内存效率。与传统的负采样方法不同，我们的方法采用了一种选择性的GPU高效计算策略，专注于目录中最具信息量的元素，特别是那些最可能成为假阳性的元素。这是通过最大内积搜索来近似模型输出子集上的softmax分布实现的。在多个数据集上的实验结果表明，与现有方法相比，SCE能将峰值内存使用量减少高达100倍，同时保持或甚至超过它们的指标值。所提出的方法还为不同领域的大规模开发开辟了新的视角，例如大型语言模型。 | Gleb Mezentsev | [PDF](http://arxiv.org/pdf/2409.18721v1) | N/A | Scalable Cross-Entropy Loss for Sequential Recommendations with Large Item Catalogs | Scalability issue plays a crucial role in productionizing modern recommender systems. Even lightweight architectures may suffer from high computational overload due to intermediate calculations, limiting their practicality in real-world applications. Specifically, applying full Cross-Entropy (CE) loss often yields state-of-the-art performance in terms of recommendations quality. Still, it suffers from excessive GPU memory utilization when dealing with large item catalogs. This paper introduces a novel Scalable Cross-Entropy (SCE) loss function in the sequential learning setup. It approximates the CE loss for datasets with large-size catalogs, enhancing both time efficiency and memory usage without compromising recommendations quality. Unlike traditional negative sampling methods, our approach utilizes a selective GPU-efficient computation strategy, focusing on the most informative elements of the catalog, particularly those most likely to be false positives. This is achieved by approximating the softmax distribution over a subset of the model outputs through the maximum inner product search. Experimental results on multiple datasets demonstrate the effectiveness of SCE in reducing peak memory usage by a factor of up to 100 compared to the alternatives, retaining or even exceeding their metrics values. The proposed approach also opens new perspectives for large-scale developments in different domains, such as large language models. |
| 提升6G卫星网络的频谱效率：基于异步联邦逆强化学习的GAIL驱动的策略学习 | 本文提出了一种新颖的生成对抗模仿学习（GAIL）驱动的策略学习方法，用于优化非地面网络（NTN）中的波束成形、频谱分配和远程用户设备（RUE）关联。传统的无线网络优化强化学习（RL）方法通常依赖于人工设计的奖励函数，这可能需要大量的参数调整。为了克服这些限制，我们采用了逆强化学习（IRL），特别是利用GAIL框架，自动学习奖励函数而无需人工设计。我们通过异步联邦学习方法增强这一框架，使分散的多卫星系统能够协作推导出最优策略。所提出的方法旨在最大化频谱效率（SE），同时满足RUE的最小信息速率要求。为了解决这一问题的非凸、NP难性质，我们将多对一匹配理论与多智能体异步联邦逆强化学习（MA-AFIRL）框架相结合。这使得智能体能够通过异步环境交互进行学习，提高训练效率和可扩展性。专家策略使用鲸鱼优化算法（WOA）生成，为GAIL中的自动奖励函数提供训练数据。仿真结果表明，所提出的MA-AFIRL方法优于传统的RL方法，收敛性和奖励值分别提高了14.6%。这种新颖的GAIL驱动的策略学习为6G NTN优化设立了新的基准。 | Sheikh Salman Hassan | [PDF](http://arxiv.org/pdf/2409.18718v1) | N/A | Enhancing Spectrum Efficiency in 6G Satellite Networks: A GAIL-Powered Policy Learning via Asynchronous Federated Inverse Reinforcement Learning | In this paper, a novel generative adversarial imitation learning (GAIL)-powered policy learning approach is proposed for optimizing beamforming, spectrum allocation, and remote user equipment (RUE) association in NTNs. Traditional reinforcement learning (RL) methods for wireless network optimization often rely on manually designed reward functions, which can require extensive parameter tuning. To overcome these limitations, we employ inverse RL (IRL), specifically leveraging the GAIL framework, to automatically learn reward functions without manual design. We augment this framework with an asynchronous federated learning approach, enabling decentralized multi-satellite systems to collaboratively derive optimal policies. The proposed method aims to maximize spectrum efficiency (SE) while meeting minimum information rate requirements for RUEs. To address the non-convex, NP-hard nature of this problem, we combine the many-to-one matching theory with a multi-agent asynchronous federated IRL (MA-AFIRL) framework. This allows agents to learn through asynchronous environmental interactions, improving training efficiency and scalability. The expert policy is generated using the Whale optimization algorithm (WOA), providing data to train the automatic reward function within GAIL. Simulation results show that the proposed MA-AFIRL method outperforms traditional RL approaches, achieving a $14.6\%$ improvement in convergence and reward value. The novel GAIL-driven policy learning establishes a novel benchmark for 6G NTN optimization. |
| 阅读字里行间：利用ASCII艺术攻击大型语言模型和毒性检测系统以掩盖亵渎内容 | 我们介绍了一种新颖的对抗攻击家族，这些攻击利用了语言模型无法解释ASCII艺术的特点。为了评估这些攻击，我们提出了ToxASCII基准，并开发了两种自定义的ASCII艺术字体：一种利用特殊标记，另一种使用填充文本的字母形状。我们的攻击在包括OpenAI的o1-preview和LLaMA 3.1在内的十个模型上实现了完美的1.0攻击成功率。警告：本文包含用于研究目的的有害语言示例。 | Sergey Berezin | [PDF](http://arxiv.org/pdf/2409.18708v1) | N/A | Read Over the Lines: Attacking LLMs and Toxicity Detection Systems with ASCII Art to Mask Profanity | We introduce a novel family of adversarial attacks that exploit the inability of language models to interpret ASCII art. To evaluate these attacks, we propose the ToxASCII benchmark and develop two custom ASCII art fonts: one leveraging special tokens and another using text-filled letter shapes. Our attacks achieve a perfect 1.0 Attack Success Rate across ten models, including OpenAI's o1-preview and LLaMA 3.1.   Warning: this paper contains examples of toxic language used for research purposes. |
