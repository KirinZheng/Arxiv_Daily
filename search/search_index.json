{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Arxiv Daily","text":"<p>DeepSeek\uff0c\u4f60\u8bb0\u4e00\u4e0b\u6211\u505a\u5982\u4e0b\u90e8\u7f72 -- 101</p>"},{"location":"arxiv_papers/","title":"Arxiv Papers","text":"\u6807\u9898 \u6458\u8981 \u4f5c\u8005 PDF\u94fe\u63a5 \u4ee3\u7801\u4ed3\u5e93 Title Abstract RoboTwin\uff1a\u914d\u5907\u751f\u6210\u5f0f\u6570\u5b57\u5b6a\u751f\u7684\u53cc\u81c2\u673a\u5668\u4eba\u57fa\u51c6\u6d4b\u8bd5\uff08\u65e9\u671f\u7248\u672c\uff09 \u53cc\u81c2\u673a\u5668\u4eba\u53ca\u5176\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684\u6709\u6548\u534f\u4f5c\u5728\u673a\u5668\u4eba\u6280\u672f\u7684\u8fdb\u6b65\u4e2d\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u8fd9\u4e9b\u6280\u80fd\u5728\u6269\u5c55\u673a\u5668\u4eba\u5728\u591a\u6837\u5316\u73b0\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u64cd\u4f5c\u80fd\u529b\u65b9\u9762\u53d1\u6325\u7740\u91cd\u8981\u4f5c\u7528\u3002\u7136\u800c\uff0c\u8fdb\u5c55\u53d7\u5230\u4e13\u95e8\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u7684\u963b\u788d\u3002\u672c\u6587\u4ecb\u7ecd\u4e86RoboTwin\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u8fdc\u7a0b\u64cd\u4f5c\u6570\u636e\u548c\u6570\u5b57\u5b6a\u751f\u4e2d\u7684\u5408\u6210\u6570\u636e\uff0c\u4e13\u4e3a\u53cc\u81c2\u673a\u5668\u4eba\u573a\u666f\u8bbe\u8ba1\u3002\u5229\u7528COBOT Magic\u5e73\u53f0\uff0c\u6211\u4eec\u6536\u96c6\u4e86\u5173\u4e8e\u5de5\u5177\u4f7f\u7528\u548c\u4eba\u4e0e\u673a\u5668\u4eba\u4e92\u52a8\u7684\u591a\u6837\u5316\u6570\u636e\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528AI\u751f\u6210\u5185\u5bb9\u6765\u521b\u5efa\u6570\u5b57\u5b6a\u751f\uff0c\u5c062D\u56fe\u50cf\u8f6c\u5316\u4e3a\u8be6\u7ec6\u76843D\u6a21\u578b\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e13\u5bb6\u7ea7\u522b\u7684\u8bad\u7ec3\u6570\u636e\u548c\u9762\u5411\u529f\u80fd\u7684\u4efb\u52a1\u7279\u5b9a\u59ff\u6001\u5e8f\u5217\u3002\u6211\u4eec\u7684\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a1) RoboTwin\u57fa\u51c6\u6570\u636e\u96c6\uff0c2) \u9ad8\u6548\u7684\u73b0\u5b9e\u5230\u6a21\u62df\u7ba1\u9053\uff0c\u4ee5\u53ca3) \u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u81ea\u52a8\u4e13\u5bb6\u7ea7\u6570\u636e\u751f\u6210\u3002\u8fd9\u4e9b\u8fdb\u5c55\u65e8\u5728\u89e3\u51b3\u673a\u5668\u4eba\u8bad\u7ec3\u6570\u636e\u7684\u77ed\u7f3a\u95ee\u9898\uff0c\u6709\u671b\u52a0\u901f\u5f00\u53d1\u66f4\u5f3a\u5927\u548c\u591a\u529f\u80fd\u7684\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u4ee5\u5e7f\u6cdb\u5e94\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u3002\u9879\u76ee\u9875\u9762\u53ef\u5728https://robotwin-benchmark.github.io/early-version/ \u627e\u5230\u3002 Yao Mu PDF N/A RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins (early version) Effective collaboration of dual-arm robots and their tool use capabilities are increasingly important areas in the advancement of robotics. These skills play a significant role in expanding robots' ability to operate in diverse real-world environments. However, progress is impeded by the scarcity of specialized training data. This paper introduces RoboTwin, a novel benchmark dataset combining real-world teleoperated data with synthetic data from digital twins, designed for dual-arm robotic scenarios. Using the COBOT Magic platform, we have collected diverse data on tool usage and human-robot interaction. We present a innovative approach to creating digital twins using AI-generated content, transforming 2D images into detailed 3D models. Furthermore, we utilize large language models to generate expert-level training data and task-specific pose sequences oriented toward functionality. Our key contributions are: 1) the RoboTwin benchmark dataset, 2) an efficient real-to-simulation pipeline, and 3) the use of language models for automatic expert-level data generation. These advancements are designed to address the shortage of robotic training data, potentially accelerating the development of more capable and versatile robotic systems for a wide range of real-world applications. The project page is available at https://robotwin-benchmark.github.io/early-version/ \u63a9\u7801\u6269\u6563\u6a21\u578b\u5b9e\u9645\u4e0a\u662f\u65f6\u95f4\u65e0\u5173\u7684\u63a9\u7801\u6a21\u578b\uff0c\u5e76\u4e14\u5229\u7528\u4e86\u4e0d\u51c6\u786e\u7684\u5206\u7c7b\u91c7\u6837 \u63a9\u7801\u6269\u6563\u6a21\u578b\uff08MDMs\uff09\u7531\u4e8e\u5176\u5728\u79bb\u6563\u6570\u636e\u751f\u6210\u5efa\u6a21\u4e2d\u4f18\u4e8e\u5176\u4ed6\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5df2\u6210\u4e3a\u4e00\u4e2a\u70ed\u95e8\u7684\u7814\u7a76\u8bfe\u9898\uff0c\u5e76\u5728\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\u4e0e\u81ea\u56de\u5f52\u6a21\u578b\uff08ARMs\uff09\u5c55\u5f00\u7ade\u4e89\u3002\u6700\u8fd1\u5728\u7b80\u5316\u63a9\u7801\u6269\u6563\u6846\u67b6\u65b9\u9762\u7684\u52aa\u529b\u8fdb\u4e00\u6b65\u4f7f\u5176\u4e0e\u8fde\u7eed\u7a7a\u95f4\u6269\u6563\u6a21\u578b\u5bf9\u9f50\uff0c\u5e76\u63d0\u4f9b\u4e86\u66f4\u539f\u5219\u5316\u7684\u8bad\u7ec3\u548c\u91c7\u6837\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u672c\u6587\u63ed\u793a\u4e86MDMs\u7684\u8bad\u7ec3\u548c\u91c7\u6837\u5728\u7406\u8bba\u4e0a\u90fd\u4e0d\u4f9d\u8d56\u4e8e\u65f6\u95f4\u53d8\u91cf\uff0c\u8fd9\u53ef\u4ee5\u8bf4\u662f\u6269\u6563\u6a21\u578b\u7684\u5173\u952e\u7279\u5f81\uff0c\u800c\u662f\u7b49\u540c\u4e8e\u63a9\u7801\u6a21\u578b\u3002\u6211\u4eec\u5728\u91c7\u6837\u65b9\u9762\u7684\u8054\u7cfb\u662f\u901a\u8fc7\u6211\u4eec\u63d0\u51fa\u7684\u9996\u6b21\u547d\u4e2d\u91c7\u6837\u5668\uff08FHS\uff09\u5b9e\u73b0\u7684\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u8bc1\u660e\u4e86FHS\u5728\u7406\u8bba\u4e0a\u7b49\u540c\u4e8eMDMs\u7684\u539f\u59cb\u751f\u6210\u8fc7\u7a0b\uff0c\u540c\u65f6\u663e\u8457\u51cf\u8f7b\u4e86\u8017\u65f6\u7684\u7c7b\u522b\u91c7\u6837\uff0c\u5b9e\u73b0\u4e8620\u500d\u7684\u52a0\u901f\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u7814\u7a76\u6311\u6218\u4e86\u4e4b\u524d\u5173\u4e8eMDMs\u5728\u751f\u6210\u56f0\u60d1\u5ea6\u4e0a\u80fd\u8d85\u8d8aARMs\u7684\u8bf4\u6cd5\u3002\u6211\u4eec\u9996\u6b21\u53d1\u73b0\u4e86\u4e00\u4e2a\u6f5c\u5728\u7684\u6570\u503c\u95ee\u9898\uff0c\u5373\u4f7f\u572832\u4f4d\u6d6e\u70b9\u7cbe\u5ea6\u4e0b\uff0c\u4e5f\u4f1a\u5bfc\u81f4\u4e0d\u51c6\u786e\u7684\u7c7b\u522b\u91c7\u6837\u3002\u6211\u4eec\u8868\u660e\uff0c\u6570\u503c\u95ee\u9898\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u90fd\u964d\u4f4e\u4e86\u6709\u6548\u6e29\u5ea6\uff0c\u5bfc\u81f4\u5148\u524d\u6587\u732e\u4e2d\u5bf9MDMs\u751f\u6210\u7ed3\u679c\u7684\u4e0d\u516c\u5e73\u8bc4\u4f30\u3002 Kaiwen Zheng PDF N/A Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling Masked diffusion models (MDMs) have emerged as a popular research topic for generative modeling of discrete data, thanks to their superior performance over other discrete diffusion models, and are rivaling the auto-regressive models (ARMs) for language modeling tasks. The recent effort in simplifying the masked diffusion framework further leads to alignment with continuous-space diffusion models and more principled training and sampling recipes. In this paper, however, we reveal that both training and sampling of MDMs are theoretically free from the time variable, arguably the key signature of diffusion models, and are instead equivalent to masked models. The connection on the sampling aspect is drawn by our proposed first-hitting sampler (FHS). Specifically, we show that the FHS is theoretically equivalent to MDMs' original generation process while significantly alleviating the time-consuming categorical sampling and achieving a 20$\\times$ speedup. In addition, our investigation challenges previous claims that MDMs can surpass ARMs in generative perplexity. We identify, for the first time, an underlying numerical issue, even with the 32-bit floating-point precision, which results in inaccurate categorical sampling. We show that the numerical issue lowers the effective temperature both theoretically and empirically, leading to unfair assessments of MDMs' generation results in the previous literature. \u673a\u5668\u5b66\u4e60\u4e2d\u7684\u62d3\u6251\u65b9\u6cd5\uff1a\u9762\u5411\u5b9e\u8df5\u8005\u7684\u6559\u7a0b \u62d3\u6251\u673a\u5668\u5b66\u4e60\uff08TML\uff09\u662f\u4e00\u4e2a\u65b0\u5174\u9886\u57df\uff0c\u5b83\u5229\u7528\u4ee3\u6570\u62d3\u6251\u5b66\u7684\u6280\u672f\u6765\u5206\u6790\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u6355\u6349\u7684\u590d\u6742\u6570\u636e\u7ed3\u6784\u3002\u672c\u6559\u7a0b\u5168\u9762\u4ecb\u7ecd\u4e86\u4e24\u79cd\u5173\u952e\u7684TML\u6280\u672f\uff1a\u6301\u4e45\u540c\u8c03\u548cMapper\u7b97\u6cd5\uff0c\u91cd\u70b9\u5728\u4e8e\u5b9e\u9645\u5e94\u7528\u3002\u6301\u4e45\u540c\u8c03\u6355\u6349\u591a\u5c3a\u5ea6\u7684\u62d3\u6251\u7279\u5f81\uff0c\u5982\u805a\u7c7b\u3001\u73af\u548c\u7a7a\u6d1e\uff0c\u800cMapper\u7b97\u6cd5\u5219\u521b\u5efa\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u56fe\uff0c\u603b\u7ed3\u9ad8\u7ef4\u6570\u636e\u3002\u4e3a\u4e86\u63d0\u9ad8\u53ef\u8bbf\u95ee\u6027\uff0c\u6211\u4eec\u91c7\u7528\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\uff0c\u4f7f\u8bfb\u8005\u80fd\u591f\u4eb2\u8eab\u4f53\u9a8c\u5c06\u8fd9\u4e9b\u6280\u672f\u5e94\u7528\u4e8e\u76f8\u5173\u4efb\u52a1\u3002\u6211\u4eec\u63d0\u4f9b\u4e86\u9010\u6b65\u89e3\u91ca\u3001\u5b9e\u73b0\u3001\u52a8\u624b\u793a\u4f8b\u548c\u6848\u4f8b\u7814\u7a76\uff0c\u4ee5\u5c55\u793a\u8fd9\u4e9b\u5de5\u5177\u5982\u4f55\u5e94\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u95ee\u9898\u3002\u76ee\u6807\u662f\u8ba9\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u638c\u63e1\u77e5\u8bc6\u548c\u8d44\u6e90\uff0c\u5c06TML\u878d\u5165\u4ed6\u4eec\u7684\u5de5\u4f5c\u4e2d\uff0c\u63ed\u793a\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5e38\u5e38\u9690\u85cf\u7684\u6d1e\u5bdf\u3002\u6559\u7a0b\u4ee3\u7801\u53ef\u5728https://github.com/cakcora/TopologyForML\u83b7\u53d6\u3002 Baris Coskunuzer PDF N/A Topological Methods in Machine Learning: A Tutorial for Practitioners Topological Machine Learning (TML) is an emerging field that leverages techniques from algebraic topology to analyze complex data structures in ways that traditional machine learning methods may not capture. This tutorial provides a comprehensive introduction to two key TML techniques, persistent homology and the Mapper algorithm, with an emphasis on practical applications. Persistent homology captures multi-scale topological features such as clusters, loops, and voids, while the Mapper algorithm creates an interpretable graph summarizing high-dimensional data. To enhance accessibility, we adopt a data-centric approach, enabling readers to gain hands-on experience applying these techniques to relevant tasks. We provide step-by-step explanations, implementations, hands-on examples, and case studies to demonstrate how these tools can be applied to real-world problems. The goal is to equip researchers and practitioners with the knowledge and resources to incorporate TML into their work, revealing insights often hidden from conventional machine learning methods. The tutorial code is available at https://github.com/cakcora/TopologyForML LongCite\uff1a\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u957f\u4e0a\u4e0b\u6587\u95ee\u7b54\u4e2d\u751f\u6210\u7ec6\u7c92\u5ea6\u7684\u5f15\u7528 \u5c3d\u7ba1\u5f53\u524d\u7684\u957f\u4e0a\u4e0b\u6587\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u57fa\u4e8e\u5927\u91cf\u6587\u672c\u56de\u7b54\u7528\u6237\u95ee\u9898\u65b9\u9762\u5c55\u793a\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u4f46\u5176\u56de\u7b54\u4e2d\u7f3a\u4e4f\u5f15\u7528\u4f7f\u5f97\u7528\u6237\u96be\u4ee5\u9a8c\u8bc1\uff0c\u4ece\u800c\u5f15\u53d1\u4e86\u5bf9\u5176\u53ef\u4fe1\u5ea6\u7684\u62c5\u5fe7\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u80fd\u4ea7\u751f\u5e7b\u89c9\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u7684\u76ee\u6807\u662f\u4f7f\u957f\u4e0a\u4e0b\u6587LLMs\u80fd\u591f\u751f\u6210\u5e26\u6709\u7ec6\u7c92\u5ea6\u53e5\u5b50\u7ea7\u5f15\u7528\u7684\u56de\u7b54\uff0c\u4ece\u800c\u63d0\u9ad8\u5176\u5fe0\u5b9e\u5ea6\u548c\u53ef\u9a8c\u8bc1\u6027\u3002\u6211\u4eec\u9996\u5148\u4ecb\u7ecd\u4e86LongBench-Cite\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5f53\u524dLLMs\u5728\u5e26\u6709\u5f15\u7528\u7684\u957f\u4e0a\u4e0b\u6587\u95ee\u7b54\uff08LQAC\uff09\u4e2d\u6027\u80fd\u7684\u81ea\u52a8\u5316\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u663e\u8457\u7684\u6539\u8fdb\u7a7a\u95f4\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86CoF\uff08\u4ece\u7c97\u5230\u7ec6\uff09\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u6d41\u6c34\u7ebf\uff0c\u5229\u7528\u73b0\u6210\u7684LLMs\u81ea\u52a8\u751f\u6210\u5e26\u6709\u7cbe\u786e\u53e5\u5b50\u7ea7\u5f15\u7528\u7684\u957f\u4e0a\u4e0b\u6587QA\u5b9e\u4f8b\uff0c\u5e76\u5229\u7528\u8fd9\u4e00\u6d41\u6c34\u7ebf\u6784\u5efa\u4e86LongCite-45k\uff0c\u4e00\u4e2a\u5927\u89c4\u6a21\u7684LQAC SFT\u6570\u636e\u96c6\u3002\u6700\u540e\uff0c\u6211\u4eec\u4f7f\u7528LongCite-45k\u6570\u636e\u96c6\u8bad\u7ec3\u4e86LongCite-8B\u548cLongCite-9B\uff0c\u6210\u529f\u5730\u4f7f\u5b83\u4eec\u80fd\u591f\u5728\u5355\u6b21\u8f93\u51fa\u4e2d\u751f\u6210\u51c6\u786e\u7684\u56de\u7b54\u548c\u7ec6\u7c92\u5ea6\u7684\u53e5\u5b50\u7ea7\u5f15\u7528\u3002\u5728LongBench-Cite\u4e0a\u7684\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u6211\u4eec\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u5f15\u7528\u8d28\u91cf\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\uff0c\u8d85\u8fc7\u4e86\u5305\u62ecGPT-4o\u5728\u5185\u7684\u5148\u8fdb\u4e13\u6709\u6a21\u578b\u3002 jiajie Zhang PDF N/A LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA Though current long-context large language models (LLMs) have demonstrated impressive capacities in answering user questions based on extensive text, the lack of citations in their responses makes user verification difficult, leading to concerns about their trustworthiness due to their potential hallucinations. In this work, we aim to enable long-context LLMs to generate responses with fine-grained sentence-level citations, improving their faithfulness and verifiability. We first introduce LongBench-Cite, an automated benchmark for assessing current LLMs' performance in Long-Context Question Answering with Citations (LQAC), revealing considerable room for improvement. To this end, we propose CoF (Coarse to Fine), a novel pipeline that utilizes off-the-shelf LLMs to automatically generate long-context QA instances with precise sentence-level citations, and leverage this pipeline to construct LongCite-45k, a large-scale SFT dataset for LQAC. Finally, we train LongCite-8B and LongCite-9B using the LongCite-45k dataset, successfully enabling their generation of accurate responses and fine-grained sentence-level citations in a single output. The evaluation results on LongBench-Cite show that our trained models achieve state-of-the-art citation quality, surpassing advanced proprietary models including GPT-4o. \u533a\u57df\u6570\u636e\u9a71\u52a8\u7684\u5929\u6c14\u6a21\u62df\u4e0e\u5168\u7403\u62c9\u4f38\u7f51\u683c \u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u533a\u57df\u5929\u6c14\u9884\u62a5\u5e94\u7528\u7684\u6570\u636e\u9a71\u52a8\u6a21\u578b\uff08DDM\uff09\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u62c9\u4f38\u7f51\u683c\u67b6\u6784\u6269\u5c55\u4e86\u4eba\u5de5\u667a\u80fd\u9884\u62a5\u7cfb\u7edf\uff0c\u8be5\u67b6\u6784\u5728\u611f\u5174\u8da3\u7684\u533a\u57df\u63d0\u4f9b\u66f4\u9ad8\u5206\u8fa8\u7387\uff0c\u800c\u5728\u5168\u7403\u5176\u4ed6\u5730\u65b9\u4fdd\u6301\u8f83\u4f4e\u5206\u8fa8\u7387\u3002\u8be5\u6a21\u578b\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u81ea\u7136\u652f\u6301\u4efb\u610f\u591a\u5206\u8fa8\u7387\u7f51\u683c\u914d\u7f6e\u3002\u6a21\u578b\u5e94\u7528\u4e8e\u5317\u6b27\u5730\u533a\u7684\u77ed\u671f\u5929\u6c14\u9884\u6d4b\uff0c\u751f\u6210\u7a7a\u95f4\u5206\u8fa8\u7387\u4e3a2.5\u516c\u91cc\u3001\u65f6\u95f4\u5206\u8fa8\u7387\u4e3a6\u5c0f\u65f6\u7684\u9884\u62a5\u3002\u6a21\u578b\u5148\u572831\u516c\u91cc\u5206\u8fa8\u7387\u768443\u5e74\u5168\u7403ERA5\u6570\u636e\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u4f7f\u7528\u6765\u81eaMetCoOp\u96c6\u5408\u9884\u62a5\u7cfb\u7edf\uff08MEPS\uff09\u76843.3\u5e742.5\u516c\u91cc\u5206\u8fa8\u7387\u4e1a\u52a1\u5206\u6790\u6570\u636e\u8fdb\u884c\u8fdb\u4e00\u6b65\u7ec6\u5316\u3002\u6a21\u578b\u7684\u6027\u80fd\u901a\u8fc7\u632a\u5a01\u5404\u5730\u6d4b\u91cf\u7ad9\u7684\u5730\u9762\u89c2\u6d4b\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e0eMEPS\u7684\u77ed\u671f\u5929\u6c14\u9884\u62a5\u8fdb\u884c\u6bd4\u8f83\u3002DDM\u57282\u7c73\u6e29\u5ea6\u9884\u62a5\u65b9\u9762\u4f18\u4e8eMEPS\u7684\u63a7\u5236\u8fd0\u884c\u548c\u96c6\u5408\u5e73\u5747\u503c\u3002\u6a21\u578b\u8fd8\u751f\u6210\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u964d\u6c34\u548c\u98ce\u901f\u9884\u62a5\uff0c\u4f46\u663e\u793a\u51fa\u4f4e\u4f30\u6781\u7aef\u4e8b\u4ef6\u7684\u8d8b\u52bf\u3002 Thomas Nils Nipen PDF N/A Regional data-driven weather modeling with a global stretched-grid A data-driven model (DDM) suitable for regional weather forecasting applications is presented. The model extends the Artificial Intelligence Forecasting System by introducing a stretched-grid architecture that dedicates higher resolution over a regional area of interest and maintains a lower resolution elsewhere on the globe. The model is based on graph neural networks, which naturally affords arbitrary multi-resolution grid configurations.   The model is applied to short-range weather prediction for the Nordics, producing forecasts at 2.5 km spatial and 6 h temporal resolution. The model is pre-trained on 43 years of global ERA5 data at 31 km resolution and is further refined using 3.3 years of 2.5 km resolution operational analyses from the MetCoOp Ensemble Prediction System (MEPS). The performance of the model is evaluated using surface observations from measurement stations across Norway and is compared to short-range weather forecasts from MEPS. The DDM outperforms both the control run and the ensemble mean of MEPS for 2 m temperature. The model also produces competitive precipitation and wind speed forecasts, but is shown to underestimate extreme events. LongLLaVA\uff1a\u901a\u8fc7\u6df7\u5408\u67b6\u6784\u9ad8\u6548\u5730\u5c06\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u52301000\u5f20\u56fe\u50cf \u6269\u5c55\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u957f\u4e0a\u4e0b\u6587\u80fd\u529b\u5bf9\u4e8e\u89c6\u9891\u7406\u89e3\u3001\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u7406\u89e3\u548c\u591a\u6a21\u6001\u4ee3\u7406\u81f3\u5173\u91cd\u8981\u3002\u8fd9\u6d89\u53ca\u4e00\u7cfb\u5217\u7cfb\u7edf\u4f18\u5316\uff0c\u5305\u62ec\u6a21\u578b\u67b6\u6784\u3001\u6570\u636e\u6784\u5efa\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u7279\u522b\u662f\u89e3\u51b3\u8bf8\u5982\\textit{\u56fe\u50cf\u589e\u591a\u65f6\u6027\u80fd\u4e0b\u964d}\u548c\\textit{\u9ad8\u8ba1\u7b97\u6210\u672c}\u7b49\u6311\u6218\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u5c06\u6a21\u578b\u67b6\u6784\u8c03\u6574\u4e3aMamba\u548cTransformer\u5757\u7684\u6df7\u5408\u4f53\uff0c\u91c7\u7528\u591a\u56fe\u50cf\u95f4\u65f6\u95f4\u4e0e\u7a7a\u95f4\u4f9d\u8d56\u6027\u7684\u6570\u636e\u6784\u5efa\u65b9\u6cd5\uff0c\u5e76\u91c7\u7528\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u7b56\u7565\u3002\u53d1\u5e03\u7684\u6a21\u578b\\textbf{LongLLaVA}~(\\textbf{Long}-Context \\textbf{L}arge \\textbf{L}anguage \\textbf{a}nd \\textbf{V}ision \\textbf{A}ssistant)\u662f\u9996\u4e2a\u6df7\u5408MLLM\uff0c\u5b83\u5728\u6548\u7387\u548c\u6548\u679c\u4e4b\u95f4\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u5e73\u8861\u3002LongLLaVA\u4e0d\u4ec5\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\uff0c\u800c\u4e14\u4fdd\u6301\u4e86\u9ad8\u541e\u5410\u91cf\u548c\u4f4e\u5185\u5b58\u6d88\u8017\u3002\u7279\u522b\u662f\uff0c\u5b83\u53ef\u4ee5\u5728\u5355\u4e2aA100 80GB GPU\u4e0a\u5904\u7406\u8fd1\u5343\u5f20\u56fe\u50cf\uff0c\u663e\u793a\u51fa\u5728\u5e7f\u6cdb\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u524d\u666f\u3002 Xidong Wang PDF N/A LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via Hybrid Architecture Expanding the long-context capabilities of Multi-modal Large Language Models~(MLLMs) is crucial for video understanding, high-resolution image understanding, and multi-modal agents. This involves a series of systematic optimizations, including model architecture, data construction and training strategy, particularly addressing challenges such as \\textit{degraded performance with more images} and \\textit{high computational costs}. In this paper, we adapt the model architecture to a hybrid of Mamba and Transformer blocks, approach data construction with both temporal and spatial dependencies among multiple images and employ a progressive training strategy. The released model \\textbf{LongLLaVA}~(\\textbf{Long}-Context \\textbf{L}arge \\textbf{L}anguage \\textbf{a}nd \\textbf{V}ision \\textbf{A}ssistant) is the first hybrid MLLM, which achieved a better balance between efficiency and effectiveness. LongLLaVA not only achieves competitive results across various benchmarks, but also maintains high throughput and low memory consumption. Especially, it could process nearly a thousand images on a single A100 80GB GPU, showing promising application prospects for a wide range of tasks. \u57fa\u51c6\u6d4b\u8bd5\u5c11\u6837\u672c\u56fe\u50cf\u5206\u7c7b\u5668\u4e2d\u7684\u865a\u5047\u504f\u5dee \u5c11\u6837\u672c\u56fe\u50cf\u5206\u7c7b\u5668\u65e8\u5728\u4ee5\u6700\u5c11\u7684\u76d1\u7763\u548c\u6709\u9650\u7684\u6570\u636e\u6765\u8bc6\u522b\u548c\u5206\u7c7b\u65b0\u6570\u636e\uff0c\u4f46\u901a\u5e38\u8868\u73b0\u51fa\u5bf9\u7c7b\u95f4\u548c\u865a\u5047\u5c5e\u6027\u4e4b\u95f4\u7684\u865a\u5047\u5173\u8054\u7684\u4f9d\u8d56\uff0c\u8fd9\u79cd\u4f9d\u8d56\u88ab\u79f0\u4e3a\u865a\u5047\u504f\u5dee\u3002\u865a\u5047\u5173\u8054\u901a\u5e38\u5b58\u5728\u4e8e\u67d0\u4e9b\u6837\u672c\u4e2d\uff0c\u5c11\u6837\u672c\u5206\u7c7b\u5668\u53ef\u80fd\u4f1a\u53d7\u5230\u8fd9\u4e9b\u6837\u672c\u5f15\u8d77\u7684\u865a\u5047\u504f\u5dee\u7684\u5f71\u54cd\u3002\u76ee\u524d\u7f3a\u4e4f\u4e00\u4e2a\u81ea\u52a8\u5316\u7684\u57fa\u51c6\u6d4b\u8bd5\u7cfb\u7edf\u6765\u8bc4\u4f30\u5c11\u6837\u672c\u5206\u7c7b\u5668\u5bf9\u865a\u5047\u504f\u5dee\u7684\u9c81\u68d2\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u4e14\u4e25\u683c\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u79f0\u4e3aFewSTAB\uff0c\u7528\u4e8e\u516c\u5e73\u5730\u5c55\u793a\u548c\u91cf\u5316\u5c11\u6837\u672c\u5206\u7c7b\u5668\u5bf9\u865a\u5047\u504f\u5dee\u7684\u591a\u79cd\u9c81\u68d2\u6027\u7a0b\u5ea6\u3002FewSTAB\u521b\u5efa\u4e86\u5e26\u6709\u504f\u5dee\u5c5e\u6027\u7684\u5c11\u6837\u672c\u8bc4\u4f30\u4efb\u52a1\uff0c\u4ee5\u4fbf\u4f7f\u7528\u8fd9\u4e9b\u4efb\u52a1\u8fdb\u884c\u9884\u6d4b\u53ef\u80fd\u4f1a\u8868\u73b0\u51fa\u8f83\u5dee\u7684\u8868\u73b0\u3002\u4e3a\u4e86\u6784\u5efa\u8fd9\u4e9b\u4efb\u52a1\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9884\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5c5e\u6027\u6837\u672c\u9009\u62e9\u7b56\u7565\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u624b\u52a8\u6570\u636e\u96c6\u6574\u7406\u7684\u9700\u6c42\u3002\u8fd9\u4f7f\u5f97FewSTAB\u80fd\u591f\u4f7f\u7528\u4efb\u4f55\u73b0\u6709\u7684\u6d4b\u8bd5\u6570\u636e\u81ea\u52a8\u8fdb\u884c\u865a\u5047\u504f\u5dee\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002FewSTAB\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u8fd8\u4e3a\u6784\u5efa\u9c81\u68d2\u5206\u7c7b\u5668\u63d0\u4f9b\u4e86\u65b0\u7684\u8bbe\u8ba1\u6307\u5357\u3002\u6b64\u5916\uff0c\u5b83\u80fd\u591f\u5bf9\u4e0d\u540c\u7a0b\u5ea6\u7684\u865a\u5047\u504f\u5dee\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u652f\u6301\u8bbe\u8ba1\u4e0d\u540c\u9c81\u68d2\u6027\u7a0b\u5ea6\u7684\u9700\u6c42\u3002\u5176\u6709\u6548\u6027\u901a\u8fc7\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u5bf9\u5341\u79cd\u5c11\u6837\u672c\u5b66\u4e60\u65b9\u6cd5\u7684\u5b9e\u9a8c\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002\u6211\u4eec\u5e0c\u671b\u6211\u4eec\u7684\u6846\u67b6\u80fd\u591f\u6fc0\u53d1\u5bf9\u9c81\u68d2\u5c11\u6837\u672c\u5206\u7c7b\u5668\u7684\u65b0\u8bbe\u8ba1\u3002\u6211\u4eec\u7684\u4ee3\u7801\u53ef\u5728https://github.com/gtzheng/FewSTAB\u83b7\u53d6\u3002 Guangtao Zheng PDF N/A Benchmarking Spurious Bias in Few-Shot Image Classifiers Few-shot image classifiers are designed to recognize and classify new data with minimal supervision and limited data but often show reliance on spurious correlations between classes and spurious attributes, known as spurious bias. Spurious correlations commonly hold in certain samples and few-shot classifiers can suffer from spurious bias induced from them. There is an absence of an automatic benchmarking system to assess the robustness of few-shot classifiers against spurious bias. In this paper, we propose a systematic and rigorous benchmark framework, termed FewSTAB, to fairly demonstrate and quantify varied degrees of robustness of few-shot classifiers to spurious bias. FewSTAB creates few-shot evaluation tasks with biased attributes so that using them for predictions can demonstrate poor performance. To construct these tasks, we propose attribute-based sample selection strategies based on a pre-trained vision-language model, eliminating the need for manual dataset curation. This allows FewSTAB to automatically benchmark spurious bias using any existing test data. FewSTAB offers evaluation results in a new dimension along with a new design guideline for building robust classifiers. Moreover, it can benchmark spurious bias in varied degrees and enable designs for varied degrees of robustness. Its effectiveness is demonstrated through experiments on ten few-shot learning methods across three datasets. We hope our framework can inspire new designs of robust few-shot classifiers. Our code is available at https://github.com/gtzheng/FewSTAB. \u53ef\u914d\u7f6e\u7684\u57fa\u7840\u6a21\u578b\uff1a\u4ece\u6a21\u5757\u5316\u89d2\u5ea6\u6784\u5efa\u5927\u578b\u8bed\u8a00\u6a21\u578b \u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8fdb\u6b65\u8fd1\u671f\u63ed\u793a\u4e86\u4e0e\u5176\u5de8\u5927\u53c2\u6570\u9700\u6c42\u76f8\u5173\u7684\u8ba1\u7b97\u6548\u7387\u548c\u6301\u7eed\u53ef\u6269\u5c55\u6027\u65b9\u9762\u7684\u6311\u6218\uff0c\u4f7f\u5f97\u8fd9\u4e9b\u6a21\u578b\u5728\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u4e14\u9700\u8981\u591a\u79cd\u80fd\u529b\u7684\u573a\u666f\u4e2d\u7684\u5e94\u7528\u548c\u6f14\u8fdb\u65e5\u76ca\u590d\u6742\u3002\u53d7\u4eba\u7c7b\u5927\u8111\u6a21\u5757\u5316\u7ed3\u6784\u7684\u542f\u53d1\uff0c\u4e00\u79cd\u8d8b\u52bf\u662f\u5c06LLMs\u5206\u89e3\u4e3a\u4f17\u591a\u529f\u80fd\u6a21\u5757\uff0c\u5141\u8bb8\u90e8\u5206\u6a21\u5757\u8fdb\u884c\u63a8\u7406\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u7ec4\u88c5\u6a21\u5757\u6765\u5e94\u5bf9\u590d\u6742\u4efb\u52a1\uff0c\u5982\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff08mixture-of-experts\uff09\u3002\u4e3a\u4e86\u7a81\u51fa\u6a21\u5757\u5316\u65b9\u6cd5\u7684\u56fa\u6709\u6548\u7387\u548c\u53ef\u7ec4\u5408\u6027\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u201c\u7816\u5757\u201d\uff08brick\uff09\u8fd9\u4e00\u672f\u8bed\u6765\u4ee3\u8868\u6bcf\u4e2a\u529f\u80fd\u6a21\u5757\uff0c\u5e76\u5c06\u8fd9\u79cd\u6a21\u5757\u5316\u7ed3\u6784\u79f0\u4e3a\u53ef\u914d\u7f6e\u57fa\u7840\u6a21\u578b\u3002\u672c\u6587\u5168\u9762\u6982\u8ff0\u548c\u63a2\u8ba8\u4e86\u53ef\u914d\u7f6e\u57fa\u7840\u6a21\u578b\u7684\u6784\u5efa\u3001\u5e94\u7528\u53ca\u5176\u5c40\u9650\u6027\u3002\u6211\u4eec\u9996\u5148\u5c06\u6a21\u5757\u5f62\u5f0f\u5316\u4e3a\u9884\u8bad\u7ec3\u9636\u6bb5\u51fa\u73b0\u7684\u201c\u6d8c\u73b0\u7816\u5757\u201d\u2014\u2014\u529f\u80fd\u6027\u795e\u7ecf\u5206\u533a\uff0c\u4ee5\u53ca\u901a\u8fc7\u989d\u5916\u540e\u8bad\u7ec3\u6784\u5efa\u7684\u201c\u5b9a\u5236\u7816\u5757\u201d\u2014\u2014\u4ee5\u63d0\u5347LLMs\u7684\u80fd\u529b\u548c\u77e5\u8bc6\u3002\u57fa\u4e8e\u591a\u6837\u5316\u7684\u529f\u80fd\u7816\u5757\uff0c\u6211\u4eec\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u56db\u79cd\u9762\u5411\u7816\u5757\u7684\u64cd\u4f5c\uff1a\u68c0\u7d22\u4e0e\u8def\u7531\u3001\u5408\u5e76\u3001\u66f4\u65b0\u548c\u6269\u5c55\u3002\u8fd9\u4e9b\u64cd\u4f5c\u4f7f\u5f97LLMs\u80fd\u591f\u6839\u636e\u6307\u4ee4\u52a8\u6001\u914d\u7f6e\u4ee5\u5904\u7406\u590d\u6742\u4efb\u52a1\u3002\u4e3a\u9a8c\u8bc1\u6211\u4eec\u7684\u89c2\u70b9\uff0c\u6211\u4eec\u5bf9\u5e7f\u6cdb\u4f7f\u7528\u7684LLMs\u8fdb\u884c\u4e86\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b0\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff08FFN\uff09\u5c42\u9075\u5faa\u6a21\u5757\u5316\u6a21\u5f0f\uff0c\u5177\u6709\u795e\u7ecf\u5143\u7684\u529f\u80fd\u7279\u5316\u548c\u529f\u80fd\u6027\u795e\u7ecf\u5206\u533a\u3002\u6700\u540e\uff0c\u6211\u4eec\u6307\u51fa\u4e86\u51e0\u4e2a\u5f00\u653e\u95ee\u9898\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002\u603b\u4f53\u800c\u8a00\uff0c\u672c\u6587\u65e8\u5728\u4e3a\u73b0\u6709LLM\u7814\u7a76\u63d0\u4f9b\u4e00\u79cd\u65b0\u9896\u7684\u6a21\u5757\u5316\u89c6\u89d2\uff0c\u5e76\u6fc0\u53d1\u672a\u6765\u521b\u5efa\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u57fa\u7840\u6a21\u578b\u7684\u521b\u65b0\u3002 Chaojun Xiao PDF N/A Configurable Foundation Models: Building LLMs from a Modular Perspective Advancements in LLMs have recently unveiled challenges tied to computational efficiency and continual scalability due to their requirements of huge parameters, making the applications and evolution of these models on devices with limited computation resources and scenarios requiring various abilities increasingly cumbersome. Inspired by modularity within the human brain, there is a growing tendency to decompose LLMs into numerous functional modules, allowing for inference with part of modules and dynamic assembly of modules to tackle complex tasks, such as mixture-of-experts. To highlight the inherent efficiency and composability of the modular approach, we coin the term brick to represent each functional module, designating the modularized structure as configurable foundation models. In this paper, we offer a comprehensive overview and investigation of the construction, utilization, and limitation of configurable foundation models. We first formalize modules into emergent bricks - functional neuron partitions that emerge during the pre-training phase, and customized bricks - bricks constructed via additional post-training to improve the capabilities and knowledge of LLMs. Based on diverse functional bricks, we further present four brick-oriented operations: retrieval and routing, merging, updating, and growing. These operations allow for dynamic configuration of LLMs based on instructions to handle complex tasks. To verify our perspective, we conduct an empirical analysis on widely-used LLMs. We find that the FFN layers follow modular patterns with functional specialization of neurons and functional neuron partitions. Finally, we highlight several open issues and directions for future research. Overall, this paper aims to offer a fresh modular perspective on existing LLM research and inspire the future creation of more efficient and scalable foundational models. \u57ce\u5e02\u9a7e\u9a76\u6df7\u5408\u6a21\u4eff\u5b66\u4e60\u8fd0\u52a8\u89c4\u5212\u5668 \u968f\u7740\u8bf8\u5982nuPlan\u548cArgoverse\u7b49\u5f00\u6e90\u6570\u636e\u96c6\u7684\u53d1\u5e03\uff0c\u57fa\u4e8e\u5b66\u4e60\u7684\u89c4\u5212\u5668\u7814\u7a76\u5728\u8fc7\u53bb\u51e0\u5e74\u4e2d\u5f97\u5230\u4e86\u5e7f\u6cdb\u4f20\u64ad\u3002\u73b0\u6709\u7cfb\u7edf\u5728\u6a21\u4eff\u4eba\u7c7b\u9a7e\u9a76\u5458\u884c\u4e3a\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5728\u4fdd\u8bc1\u5b89\u5168\u95ed\u73af\u9a7e\u9a76\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002\u76f8\u53cd\uff0c\u57fa\u4e8e\u4f18\u5316\u7684\u89c4\u5212\u5668\u5728\u77ed\u671f\u89c4\u5212\u573a\u666f\u4e2d\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u5b89\u5168\u6027\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6df7\u5408\u8fd0\u52a8\u89c4\u5212\u5668\uff0c\u5b83\u7ed3\u5408\u4e86\u57fa\u4e8e\u5b66\u4e60\u548c\u57fa\u4e8e\u4f18\u5316\u7684\u6280\u672f\u3002\u9996\u5148\uff0c\u4e00\u4e2a\u591a\u5c42\u611f\u77e5\u5668\uff08MLP\uff09\u751f\u6210\u7c7b\u4f3c\u4e8e\u4eba\u7c7b\u7684\u8f68\u8ff9\uff0c\u7136\u540e\u7531\u4e00\u4e2a\u57fa\u4e8e\u4f18\u5316\u7684\u7ec4\u4ef6\u8fdb\u884c\u7ec6\u5316\u3002\u8be5\u7ec4\u4ef6\u4e0d\u4ec5\u6700\u5c0f\u5316\u4e86\u8ddf\u8e2a\u8bef\u5dee\uff0c\u8fd8\u8ba1\u7b97\u51fa\u4e00\u6761\u5728\u8fd0\u52a8\u5b66\u4e0a\u53ef\u884c\u4e14\u4e0e\u969c\u788d\u7269\u548c\u9053\u8def\u8fb9\u754c\u65e0\u78b0\u649e\u7684\u8f68\u8ff9\u3002\u6211\u4eec\u7684\u6a21\u578b\u6709\u6548\u5730\u5e73\u8861\u4e86\u5b89\u5168\u6027\u548c\u4eba\u7c7b\u76f8\u4f3c\u6027\uff0c\u7f13\u89e3\u4e86\u8fd9\u4e9b\u76ee\u6807\u4e4b\u95f4\u7684\u56fa\u6709\u6743\u8861\u3002\u6211\u4eec\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5728\u771f\u5b9e\u4e16\u754c\u7684\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4e0a\u90e8\u7f72\u8fdb\u4e00\u6b65\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002 Cristian Gariboldi PDF N/A Hybrid Imitation-Learning Motion Planner for Urban Driving With the release of open source datasets such as nuPlan and Argoverse, the research around learning-based planners has spread a lot in the last years. Existing systems have shown excellent capabilities in imitating the human driver behaviour, but they struggle to guarantee safe closed-loop driving. Conversely, optimization-based planners offer greater security in short-term planning scenarios. To confront this challenge, in this paper we propose a novel hybrid motion planner that integrates both learning-based and optimization-based techniques. Initially, a multilayer perceptron (MLP) generates a human-like trajectory, which is then refined by an optimization-based component. This component not only minimizes tracking errors but also computes a trajectory that is both kinematically feasible and collision-free with obstacles and road boundaries. Our model effectively balances safety and human-likeness, mitigating the trade-off inherent in these objectives. We validate our approach through simulation experiments and further demonstrate its efficacy by deploying it in real-world self-driving vehicles. \u6df1\u5165\u4e86\u89e3\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684LITE\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5 \u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5df2\u88ab\u8bc1\u660e\u662f\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\uff08TSC\uff09\u7684\u5f3a\u5927\u89e3\u51b3\u65b9\u6848\u3002\u5c3d\u7ba1\u6700\u5148\u8fdb\u7684\u67b6\u6784\u5728UCR\u548cUEA\u6863\u6848\u4e0a\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\uff0c\u4f46\u5b83\u4eec\u5177\u6709\u5927\u91cf\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u3002\u8fd9\u53ef\u80fd\u5bfc\u81f4\u8bad\u7ec3\u65f6\u95f4\u957f\uff0c\u4e8c\u6c27\u5316\u78b3\u6392\u653e\u91cf\u9ad8\uff0c\u529f\u8017\u5927\uff0c\u5e76\u53ef\u80fd\u589e\u52a0\u6bcf\u79d2\u6d6e\u70b9\u8fd0\u7b97\u6b21\u6570\uff08FLOPS\uff09\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684TSC\u67b6\u6784\uff0c\u5373\u5e26\u6709\u589e\u5f3a\u6280\u672f\u7684\u8f7b\u91cf\u7ea7Inception\uff08LITE\uff09\uff0c\u5176\u53c2\u6570\u6570\u91cf\u4ec5\u4e3a\u6700\u5148\u8fdb\u7684InceptionTime\u6a21\u578b\u76842.34%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6027\u80fd\u3002\u7531\u4e8e\u4f7f\u7528\u4e86\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\uff08DWSC\uff09\uff0c\u8be5\u67b6\u6784\u4ec5\u67099,814\u4e2a\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u5e76\u901a\u8fc7\u4e09\u79cd\u6280\u672f\u5f97\u5230\u589e\u5f3a\uff1a\u591a\u8def\u590d\u7528\u3001\u81ea\u5b9a\u4e49\u6ee4\u6ce2\u5668\u548c\u6269\u5f20\u5377\u79ef\u3002\u5728UCR\u4e0a\u8bad\u7ec3\u7684LITE\u67b6\u6784\u6bd4InceptionTime\u5feb2.78\u500d\uff0c\u4e8c\u6c27\u5316\u78b3\u548c\u529f\u8017\u51cf\u5c112.79\u500d\u3002\u4e3a\u4e86\u8bc4\u4f30\u6240\u63d0\u51fa\u67b6\u6784\u5728\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0a\u7684\u6027\u80fd\uff0c\u6211\u4eec\u8c03\u6574\u4e86LITE\u4ee5\u5904\u7406\u591a\u5143\u65f6\u95f4\u5e8f\u5217\uff0c\u6211\u4eec\u79f0\u4e4b\u4e3aLITEMV\u3002\u4e3a\u4e86\u5c06\u7406\u8bba\u5e94\u7528\u4e8e\u5b9e\u9645\uff0c\u6211\u4eec\u8fd8\u4f7f\u7528LITEMV\u5bf9\u4ee3\u8868\u4eba\u7c7b\u5eb7\u590d\u8fd0\u52a8\u7684\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660eLITEMV\u4e0d\u4ec5\u662f\u6700\u6709\u6548\u7684\u6a21\u578b\uff0c\u800c\u4e14\u5728Kimore\u6570\u636e\u96c6\u4e0a\u4e5f\u662f\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\uff0c\u8be5\u6570\u636e\u96c6\u662f\u4e00\u4e2a\u57fa\u4e8e\u9aa8\u67b6\u7684\u4eba\u7c7b\u5eb7\u590d\u8fd0\u52a8\u6570\u636e\u96c6\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u89e3\u51b3LITEMV\u7684\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u6211\u4eec\u4f7f\u7528\u7c7b\u6fc0\u6d3b\u56fe\u8fdb\u884c\u4e86\u4e00\u9879\u7814\u7a76\uff0c\u4ee5\u7406\u89e3\u6a21\u578b\u5728\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u505a\u51fa\u7684\u5206\u7c7b\u51b3\u7b56\u3002 Ali Ismail-Fawaz PDF N/A Look Into the LITE in Deep Learning for Time Series Classification Deep learning models have been shown to be a powerful solution for Time Series Classification (TSC). State-of-the-art architectures, while producing promising results on the UCR and the UEA archives , present a high number of trainable parameters. This can lead to long training with high CO2 emission, power consumption and possible increase in the number of FLoating-point Operation Per Second (FLOPS). In this paper, we present a new architecture for TSC, the Light Inception with boosTing tEchnique (LITE) with only 2.34% of the number of parameters of the state-of-the-art InceptionTime model, while preserving performance. This architecture, with only 9, 814 trainable parameters due to the usage of DepthWise Separable Convolutions (DWSC), is boosted by three techniques: multiplexing, custom filters, and dilated convolution. The LITE architecture, trained on the UCR, is 2.78 times faster than InceptionTime and consumes 2.79 times less CO2 and power. To evaluate the performance of the proposed architecture on multivariate time series data, we adapt LITE to handle multivariate time series, we call this version LITEMV. To bring theory into application, we also conducted experiments using LITEMV on multivariate time series representing human rehabilitation movements, showing that LITEMV not only is the most efficient model but also the best performing for this application on the Kimore dataset, a skeleton based human rehabilitation exercises dataset. Moreover, to address the interpretability of LITEMV, we present a study using Class Activation Maps to understand the classification decision taken by the model during evaluation. \u6784\u5efa\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u4e14\u53ef\u8c03\u63a7\u7684\u641c\u7d22\u4e0e\u6392\u5e8f\u5e73\u53f0 \u73b0\u4ee3\u7535\u5b50\u5546\u52a1\u5e73\u53f0\u63d0\u4f9b\u4e86\u6d77\u91cf\u7684\u5546\u54c1\u9009\u62e9\uff0c\u4f7f\u5f97\u987e\u5ba2\u96be\u4ee5\u627e\u5230\u4ed6\u4eec\u559c\u6b22\u4e14\u4e0e\u5f53\u524d\u4f1a\u8bdd\u610f\u56fe\u76f8\u5173\u7684\u5546\u54c1\u3002\u56e0\u6b64\uff0c\u7535\u5b50\u5546\u52a1\u5e73\u53f0\u62e5\u6709\u8fd1\u4e4e\u5b9e\u65f6\u7684\u53ef\u6269\u5c55\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u4e2a\u6027\u5316\u6392\u540d\u548c\u641c\u7d22\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u5c3d\u7ba1\u79d1\u5b66\u6587\u732e\u4e2d\u5b58\u5728\u591a\u79cd\u6784\u5efa\u6b64\u7c7b\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u4f46\u7531\u4e8e\u590d\u6742\u6027\u548c\u6027\u80fd\u9650\u5236\uff0c\u8bb8\u591a\u65b9\u6cd5\u5e76\u4e0d\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5de5\u4e1a\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u5de5\u4e1a\u6392\u540d\u7cfb\u7edf\u901a\u5e38\u91c7\u7528\u8ba1\u7b97\u6548\u7387\u9ad8\u4f46\u7b80\u5355\u7684\u68c0\u7d22\u6216\u5019\u9009\u751f\u6210\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5ffd\u7565\u4e86\u8fd1\u4e4e\u5b9e\u65f6\u7684\u548c\u5f02\u8d28\u7684\u987e\u5ba2\u4fe1\u53f7\uff0c\u5bfc\u81f4\u4e2a\u6027\u5316\u548c\u76f8\u5173\u6027\u4f53\u9a8c\u8f83\u5dee\u3002\u6b64\u5916\uff0c\u76f8\u5173\u7684\u987e\u5ba2\u4f53\u9a8c\u7531\u5b8c\u5168\u4e0d\u540c\u7684\u7cfb\u7edf\u63d0\u4f9b\uff0c\u589e\u52a0\u4e86\u590d\u6742\u6027\u3001\u7ef4\u62a4\u96be\u5ea6\u548c\u4e0d\u4e00\u81f4\u7684\u4f53\u9a8c\u3002 <p>\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4e2a\u6027\u5316\u3001\u9002\u5e94\u6027\u5f3a\u7684\u8fd1\u4e4e\u5b9e\u65f6\u6392\u540d\u5e73\u53f0\uff0c\u8be5\u5e73\u53f0\u53ef\u8de8\u591a\u79cd\u7528\u4f8b\uff08\u5982\u6d4f\u89c8\u548c\u641c\u7d22\uff09\u91cd\u590d\u4f7f\u7528\uff0c\u5e76\u80fd\u591f\u5728\u9ad8\u8d1f\u8f7d\u4e0b\uff08\u6bcf\u79d2\u6570\u5343\u6b21\u8bf7\u6c42\uff09\u4e3a\u6570\u767e\u4e07\u5546\u54c1\u548c\u987e\u5ba2\u63d0\u4f9b\u670d\u52a1\u3002\u6211\u4eec\u901a\u8fc7\u4e0d\u540c\u7684\u6392\u540d\u5c42\u4f7f\u7528\u57fa\u4e8etransformer\u7684\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u76f4\u63a5\u4ece\u987e\u5ba2\u884c\u4e3a\u5e8f\u5217\u4e2d\u5b66\u4e60\u590d\u6742\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u540c\u65f6\u80fd\u591f\u6574\u5408\u65f6\u95f4\uff08\u5982\u4f1a\u8bdd\u5185\uff09\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002\u6211\u4eec\u5728\u5927\u578b\u5728\u7ebf\u7535\u5b50\u5546\u52a1\u5e73\u53f0\u4e0a\u901a\u8fc7\u4e00\u7cfb\u5217\u5168\u9762\u7684\u79bb\u7ebf\u548c\u5728\u7ebf\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u7cfb\u7edf\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u987e\u5ba2\u4f53\u9a8c\u548c\u51c0\u6536\u5165\u65b9\u9762\u76f8\u5bf9\u4e8e\u73b0\u6709\u7cfb\u7edf\u7684\u4f18\u8d8a\u6027\u3002\u6700\u540e\uff0c\u6211\u4eec\u5206\u4eab\u4e86\u4ece\u6784\u5efa\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u7535\u5b50\u5546\u52a1\u73af\u5883\u7684\u5168\u9762\u3001\u73b0\u4ee3\u6392\u540d\u5e73\u53f0\u4e2d\u83b7\u5f97\u7684\u7ecf\u9a8c\u6559\u8bad\u3002 | Marjan Celikik | PDF | N/A | Building a Scalable, Effective, and Steerable Search and Ranking Platform | Modern e-commerce platforms offer vast product selections, making it difficult for customers to find items that they like and that are relevant to their current session intent. This is why it is key for e-commerce platforms to have near real-time scalable and adaptable personalized ranking and search systems. While numerous methods exist in the scientific literature for building such systems, many are unsuitable for large-scale industrial use due to complexity and performance limitations. Consequently, industrial ranking systems often resort to computationally efficient yet simplistic retrieval or candidate generation approaches, which overlook near real-time and heterogeneous customer signals, which results in a less personalized and relevant experience. Moreover, related customer experiences are served by completely different systems, which increases complexity, maintenance, and inconsistent experiences.   In this paper, we present a personalized, adaptable near real-time ranking platform that is reusable across various use cases, such as browsing and search, and that is able to cater to millions of items and customers under heavy load (thousands of requests per second). We employ transformer-based models through different ranking layers which can learn complex behavior patterns directly from customer action sequences while being able to incorporate temporal (e.g. in-session) and contextual information. We validate our system through a series of comprehensive offline and online real-world experiments at a large online e-commerce platform, and we demonstrate its superiority when compared to existing systems, both in terms of customer experience as well as in net revenue. Finally, we share the lessons learned from building a comprehensive, modern ranking platform for use in a large-scale e-commerce environment. | | \u54ce\u5440\uff0c\u6211\u53c8\u91c7\u6837\u4e86\u4e00\u6b21\uff1a\u91cd\u65b0\u89e3\u8bfb\u5c11\u6837\u672c\u5b66\u4e60\u4e2d\u7684\u7f6e\u4fe1\u533a\u95f4 | \u5728\u5c11\u6837\u672c\u5b66\u4e60\uff08FSL\uff09\u4e2d\u8ba1\u7b97\u7f6e\u4fe1\u533a\u95f4\uff08CI\uff09\u7684\u4e3b\u8981\u65b9\u6cd5\u662f\u901a\u8fc7\u6709\u653e\u56de\u5730\u91c7\u6837\u4efb\u52a1\uff0c\u5373\u5141\u8bb8\u76f8\u540c\u7684\u6837\u672c\u51fa\u73b0\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u3002\u8fd9\u4f7f\u5f97\u7f6e\u4fe1\u533a\u95f4\u5177\u6709\u8bef\u5bfc\u6027\uff0c\u56e0\u4e3a\u5b83\u8003\u8651\u4e86\u91c7\u6837\u5668\u7684\u968f\u673a\u6027\uff0c\u4f46\u6ca1\u6709\u8003\u8651\u6570\u636e\u672c\u8eab\u7684\u7279\u6027\u3002\u4e3a\u4e86\u91cf\u5316\u8fd9\u4e00\u95ee\u9898\u7684\u4e25\u91cd\u6027\uff0c\u6211\u4eec\u5bf9\u6709\u653e\u56de\u548c\u65e0\u653e\u56de\u8ba1\u7b97\u7684\u7f6e\u4fe1\u533a\u95f4\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\u3002\u7ed3\u679c\u663e\u793a\uff0c\u4e3b\u6d41\u65b9\u6cd5\u663e\u8457\u4f4e\u4f30\u4e86\u7f6e\u4fe1\u533a\u95f4\u3002\u8fd9\u4e00\u53d1\u73b0\u547c\u5401\u6211\u4eec\u91cd\u65b0\u8bc4\u4f30\u5728FSL\u6bd4\u8f83\u7814\u7a76\u4e2d\u5982\u4f55\u89e3\u8bfb\u7f6e\u4fe1\u533a\u95f4\u53ca\u5176\u5f97\u51fa\u7684\u7ed3\u8bba\u3002\u6211\u4eec\u7684\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528\u914d\u5bf9\u68c0\u9a8c\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u63a2\u7d22\u4e86\u901a\u8fc7\u7b56\u7565\u6027\u5730\u91c7\u6837\u7279\u5b9a\u5927\u5c0f\u7684\u4efb\u52a1\u6765\u8fdb\u4e00\u6b65\u7f29\u5c0f\uff08\u7f6e\u4fe1\u533a\u95f4\u7684\uff09\u5927\u5c0f\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u4f18\u5316\u57fa\u51c6\uff0c\u53ef\u4ee5\u5728\u4ee5\u4e0b\u94fe\u63a5\u8bbf\u95ee\uff1ahttps://github.com/RafLaf/FSL-benchmark-again\u3002 | Raphael Lafargue | PDF | N/A | Oops, I Sampled it Again: Reinterpreting Confidence Intervals in Few-Shot Learning | The predominant method for computing confidence intervals (CI) in few-shot learning (FSL) is based on sampling the tasks with replacement, i.e.\\ allowing the same samples to appear in multiple tasks. This makes the CI misleading in that it takes into account the randomness of the sampler but not the data itself. To quantify the extent of this problem, we conduct a comparative analysis between CIs computed with and without replacement. These reveal a notable underestimation by the predominant method. This observation calls for a reevaluation of how we interpret confidence intervals and the resulting conclusions in FSL comparative studies. Our research demonstrates that the use of paired tests can partially address this issue. Additionally, we explore methods to further reduce the (size of the) CI by strategically sampling tasks of a specific size. We also introduce a new optimized benchmark, which can be accessed at https://github.com/RafLaf/FSL-benchmark-again | | SNNAX -- \u5728JAX\u4e2d\u7684\u8109\u51b2\u795e\u7ecf\u7f51\u7edc | \u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNN\uff09\u6a21\u62df\u5668\u662f\u6784\u5efa\u53d7\u751f\u7269\u542f\u53d1\u7684\u6a21\u578b\u548c\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u67b6\u6784\u4ee5\u53ca\u9884\u6d4b\u5176\u6027\u80fd\u7684\u5173\u952e\u5de5\u5177\u3002\u5bf9\u4e8e\u8fd9\u6837\u7684\u5de5\u5177\uff0c\u6613\u7528\u6027\u548c\u7075\u6d3b\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6a21\u62df\u901f\u5ea6\u540c\u6837\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u6a21\u62dfSNN\u56fa\u6709\u7684\u590d\u6742\u6027\u65f6\u3002\u5728\u6b64\uff0c\u6211\u4eec\u4ecb\u7ecdSNNAX\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8eJAX\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4ee5\u7c7b\u4f3c\u4e8ePyTorch\u7684\u76f4\u89c2\u6027\u548cJAX\u7684\u6267\u884c\u901f\u5ea6\u6765\u6a21\u62df\u548c\u8bad\u7ec3\u6b64\u7c7b\u6a21\u578b\u3002SNNAX\u6a21\u578b\u6613\u4e8e\u6269\u5c55\u548c\u5b9a\u5236\uff0c\u4ee5\u9002\u5e94\u6240\u9700\u7684\u6a21\u578b\u89c4\u683c\u548c\u76ee\u6807\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u3002\u6b64\u5916\uff0cSNNAX\u63d0\u4f9b\u4e86\u4f18\u5316SNN\u8bad\u7ec3\u548c\u90e8\u7f72\u7684\u5173\u952e\u529f\u80fd\uff0c\u5982\u7075\u6d3b\u7684\u81ea\u52a8\u5fae\u5206\u548c\u5373\u65f6\u7f16\u8bd1\u3002\u6211\u4eec\u8bc4\u4f30\u5e76\u6bd4\u8f83\u4e86SNNAX\u4e0e\u5176\u4ed6\u5e38\u7528\u7684\u7528\u4e8e\u7f16\u7a0bSNN\u7684\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6846\u67b6\u3002\u6211\u4eec\u63d0\u4f9b\u4e86\u5173\u952e\u7684\u6027\u80fd\u6307\u6807\u3001\u6700\u4f73\u5b9e\u8df5\u3001\u5728SNNAX\u4e2d\u6a21\u62dfSNN\u7684\u6587\u6863\u5316\u793a\u4f8b\uff0c\u5e76\u5b9e\u73b0\u4e86\u6587\u732e\u4e2d\u4f7f\u7528\u7684\u51e0\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u3002 | Jamie Lohoff | PDF | N/A | SNNAX -- Spiking Neural Networks in JAX | Spiking Neural Networks (SNNs) simulators are essential tools to prototype biologically inspired models and neuromorphic hardware architectures and predict their performance. For such a tool, ease of use and flexibility are critical, but so is simulation speed especially given the complexity inherent to simulating SNN. Here, we present SNNAX, a JAX-based framework for simulating and training such models with PyTorch-like intuitiveness and JAX-like execution speed. SNNAX models are easily extended and customized to fit the desired model specifications and target neuromorphic hardware. Additionally, SNNAX offers key features for optimizing the training and deployment of SNNs such as flexible automatic differentiation and just-in-time compilation. We evaluate and compare SNNAX to other commonly used machine learning (ML) frameworks used for programming SNNs. We provide key performance metrics, best practices, documented examples for simulating SNNs in SNNAX, and implement several benchmarks used in the literature. | | \u4f7f\u7528\u7c7b\u578b\u548c\u6807\u8bb0\u8bed\u8a00\u5efa\u6a21\u7684\u5386\u53f2\u5fb7\u8bed\u6587\u672c\u89c4\u8303\u5316 | \u5386\u53f2\u62fc\u5199\u7684\u53d8\u5316\u5bf9\u5168\u6587\u641c\u7d22\u6216\u5bf9\u5386\u53f2\u6570\u5b57\u5316\u6587\u672c\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6784\u6210\u4e86\u6311\u6218\u3002\u4e3a\u4e86\u7f29\u5c0f\u5386\u53f2\u6b63\u5b57\u6cd5\u4e0e\u73b0\u4ee3\u62fc\u5199\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u901a\u5e38\u4f1a\u8ffd\u6c42\u5bf9\u5386\u53f2\u6e90\u6750\u6599\u8fdb\u884c\u81ea\u52a8\u6b63\u5b57\u6cd5\u89c4\u8303\u5316\u3002\u672c\u62a5\u544a\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf91700\u5e74\u81f31900\u5e74\u95f4\u5fb7\u8bed\u6587\u5b66\u6587\u672c\u7684\u89c4\u8303\u5316\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u57fa\u4e8e\u5e73\u884c\u8bed\u6599\u5e93\u8fdb\u884c\u8bad\u7ec3\u3002\u6240\u63d0\u51fa\u7684\u7cfb\u7edf\u5229\u7528\u4e86\u57fa\u4e8eTransformer\u8bed\u8a00\u6a21\u578b\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\u6765\u89c4\u8303\u5316\u5355\u4e2a\u8bcd\u7c7b\uff0c\u5e76\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u56e0\u679c\u8bed\u8a00\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u4e2d\u8c03\u6574\u8fd9\u4e9b\u89c4\u8303\u5316\u3002\u5e7f\u6cdb\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\uff0c\u53ef\u4e0e\u4e00\u4e2a\u66f4\u5927\u89c4\u6a21\u7684\u7aef\u5230\u7aef\u53e5\u5b50\u7ea7\u89c4\u8303\u5316\u7cfb\u7edf\u76f8\u5ab2\u7f8e\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u5fae\u8c03\u9884\u8bad\u7ec3\u7684Transformer\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u3002\u7136\u800c\uff0c\u5386\u53f2\u6587\u672c\u7684\u89c4\u8303\u5316\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u56e0\u4e3a\u6a21\u578b\u96be\u4ee5\u6cdb\u5316\uff0c\u4e14\u7f3a\u4e4f\u5927\u91cf\u9ad8\u8d28\u91cf\u7684\u5e73\u884c\u6570\u636e\u3002 | Anton Ehrmanntraut | PDF | N/A | Historical German Text Normalization Using Type- and Token-Based Language Modeling | Historic variations of spelling poses a challenge for full-text search or natural language processing on historical digitized texts. To minimize the gap between the historic orthography and contemporary spelling, usually an automatic orthographic normalization of the historical source material is pursued. This report proposes a normalization system for German literary texts from c. 1700-1900, trained on a parallel corpus. The proposed system makes use of a machine learning approach using Transformer language models, combining an encoder-decoder model to normalize individual word types, and a pre-trained causal language model to adjust these normalizations within their context. An extensive evaluation shows that the proposed system provides state-of-the-art accuracy, comparable with a much larger fully end-to-end sentence-based normalization system, fine-tuning a pre-trained Transformer large language model. However, the normalization of historical text remains a challenge due to difficulties for models to generalize, and the lack of extensive high-quality parallel data. | | R2GQA\uff1a\u68c0\u7d22\u5668-\u9605\u8bfb\u5668-\u751f\u6210\u5668\u95ee\u7b54\u7cfb\u7edf\uff0c\u65e8\u5728\u5e2e\u52a9\u5b66\u751f\u7406\u89e3\u9ad8\u7b49\u6559\u80b2\u4e2d\u7684\u6cd5\u5f8b\u89c4\u7ae0 | \u5728\u8fd9\u7bc7\u6587\u7ae0\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86R2GQA\u7cfb\u7edf\uff0c\u8fd9\u662f\u4e00\u4e2a\u5305\u542b\u4e09\u4e2a\u4e3b\u8981\u7ec4\u4ef6\u7684\u68c0\u7d22\u5668-\u9605\u8bfb\u5668-\u751f\u6210\u5668\u95ee\u7b54\u7cfb\u7edf\uff1a\u6587\u6863\u68c0\u7d22\u5668\u3001\u673a\u5668\u9605\u8bfb\u5668\u548c\u7b54\u6848\u751f\u6210\u5668\u3002\u68c0\u7d22\u5668\u6a21\u5757\u91c7\u7528\u5148\u8fdb\u7684\u4fe1\u606f\u68c0\u7d22\u6280\u672f\uff0c\u4ece\u6cd5\u5f8b\u6cd5\u89c4\u6587\u6863\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u6587\u7ae0\u7684\u4e0a\u4e0b\u6587\u3002\u673a\u5668\u9605\u8bfb\u5668\u6a21\u5757\u5229\u7528\u6700\u5148\u8fdb\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u7b97\u6cd5\u6765\u7406\u89e3\u68c0\u7d22\u5230\u7684\u6587\u6863\u5e76\u63d0\u53d6\u7b54\u6848\u3002\u6700\u540e\uff0c\u751f\u6210\u5668\u6a21\u5757\u5c06\u63d0\u53d6\u7684\u7b54\u6848\u7efc\u5408\u6210\u7b80\u6d01\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u56de\u7b54\uff0c\u4ee5\u89e3\u7b54\u5b66\u751f\u5173\u4e8e\u6cd5\u5f8b\u6cd5\u89c4\u7684\u95ee\u9898\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5728\u5927\u5b66\u57f9\u8bad\u6cd5\u89c4\u9886\u57df\u6784\u5efa\u4e86ViRHE4QA\u6570\u636e\u96c6\uff0c\u5305\u542b9,758\u4e2a\u95ee\u9898-\u7b54\u6848\u5bf9\uff0c\u5e76\u7ecf\u8fc7\u4e86\u4e25\u683c\u7684\u6784\u5efa\u8fc7\u7a0b\u3002\u8fd9\u662f\u9ad8\u7b49\u6559\u80b2\u6cd5\u89c4\u9886\u57df\u4e2d\u9996\u4e2a\u5305\u542b\u591a\u79cd\u7c7b\u578b\u7b54\u6848\uff08\u5305\u62ec\u62bd\u53d6\u5f0f\u548c\u751f\u6210\u5f0f\uff09\u7684\u8d8a\u5357\u8bed\u6570\u636e\u96c6\u3002\u6b64\u5916\uff0cR2GQA\u7cfb\u7edf\u662f\u9996\u4e2a\u5728\u8d8a\u5357\u8bed\u4e2d\u63d0\u4f9b\u751f\u6210\u5f0f\u7b54\u6848\u7684\u7cfb\u7edf\u3002\u672c\u6587\u8ba8\u8bba\u4e86R2GQA\u7cfb\u7edf\u5728ViRHE4QA\u6570\u636e\u96c6\u4e0a\u7684\u6bcf\u4e2a\u6a21\u5757\u7684\u8bbe\u8ba1\u548c\u5b9e\u73b0\uff0c\u7a81\u51fa\u4e86\u5b83\u4eec\u7684\u529f\u80fd\u548c\u4ea4\u4e92\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5b9e\u9a8c\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7cfb\u7edf\u5728\u652f\u6301\u5b66\u751f\u7406\u89e3\u9ad8\u7b49\u6559\u80b2\u73af\u5883\u4e2d\u7684\u6cd5\u5f8b\u6cd5\u89c4\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002\u603b\u7684\u6765\u8bf4\uff0cR2GQA\u7cfb\u7edf\u548cViRHE4QA\u6570\u636e\u96c6\u6709\u671b\u5bf9\u76f8\u5173\u7814\u7a76\u505a\u51fa\u663e\u8457\u8d21\u732e\uff0c\u5e76\u5e2e\u52a9\u5b66\u751f\u5bfc\u822a\u590d\u6742\u7684\u6cd5\u5f8b\u6587\u4ef6\u548c\u6cd5\u89c4\uff0c\u4f7f\u4ed6\u4eec\u80fd\u591f\u505a\u51fa\u660e\u667a\u7684\u51b3\u7b56\u5e76\u6709\u6548\u9075\u5b88\u673a\u6784\u653f\u7b56\u3002\u6211\u4eec\u7684\u6570\u636e\u96c6\u53ef\u4f9b\u7814\u7a76\u4f7f\u7528\u3002 | Phuc-Tinh Pham Do | PDF | N/A | R2GQA: Retriever-Reader-Generator Question Answering System to Support Students Understanding Legal Regulations in Higher Education | In this article, we propose the R2GQA system, a Retriever-Reader-Generator Question Answering system, consisting of three main components: Document Retriever, Machine Reader, and Answer Generator. The Retriever module employs advanced information retrieval techniques to extract the context of articles from a dataset of legal regulation documents. The Machine Reader module utilizes state-of-the-art natural language understanding algorithms to comprehend the retrieved documents and extract answers. Finally, the Generator module synthesizes the extracted answers into concise and informative responses to questions of students regarding legal regulations. Furthermore, we built the ViRHE4QA dataset in the domain of university training regulations, comprising 9,758 question-answer pairs with a rigorous construction process. This is the first Vietnamese dataset in the higher regulations domain with various types of answers, both extractive and abstractive. In addition, the R2GQA system is the first system to offer abstractive answers in Vietnamese. This paper discusses the design and implementation of each module within the R2GQA system on the ViRHE4QA dataset, highlighting their functionalities and interactions. Furthermore, we present experimental results demonstrating the effectiveness and utility of the proposed system in supporting the comprehension of students of legal regulations in higher education settings. In general, the R2GQA system and the ViRHE4QA dataset promise to contribute significantly to related research and help students navigate complex legal documents and regulations, empowering them to make informed decisions and adhere to institutional policies effectively. Our dataset is available for research purposes. | | \u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5c0f\u6837\u672c\u5b66\u4e60\uff0c\u63a2\u7d22\u52a0\u5bc6\u8d27\u5e01\u8ba8\u8bba\u4e2d\u7684\u60c5\u611f\u52a8\u6001\u548c\u9884\u6d4b\u884c\u4e3a | \u672c\u7814\u7a76\u5229\u7528\u5148\u8fdb\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\uff0c\u5bf9\u52a0\u5bc6\u8d27\u5e01\u76f8\u5173\u8ba8\u8bba\u4e2d\u7684\u9884\u6d4b\u6027\u9648\u8ff0\u3001\u5e0c\u671b\u8a00\u8bba\u548c\u540e\u6094\u60c5\u7eea\u68c0\u6d4b\u884c\u4e3a\u8fdb\u884c\u4e86\u5206\u6790\u3002\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u9884\u6d4b\u6027\u9648\u8ff0\u201d\u7684\u65b0\u5206\u7c7b\u65b9\u6848\uff0c\u5c06\u8bc4\u8bba\u5206\u4e3a\u9884\u6d4b\u6027\u589e\u957f\u3001\u9884\u6d4b\u6027\u4e0b\u964d\u3001\u9884\u6d4b\u6027\u4e2d\u6027\u6216\u975e\u9884\u6d4b\u6027\u7c7b\u522b\u3002\u91c7\u7528\u5c16\u7aef\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578bGPT-4o\uff0c\u6211\u4eec\u63a2\u7d22\u4e86\u4e94\u79cd\u4e3b\u8981\u52a0\u5bc6\u8d27\u5e01\uff08Cardano\u3001Binance\u3001Matic\u3001Fantom\u548cRipple\uff09\u7684\u60c5\u611f\u52a8\u6001\u3002\u5206\u6790\u7ed3\u679c\u663e\u793a\uff0c\u9884\u6d4b\u6027\u60c5\u611f\u5448\u73b0\u51fa\u4e0d\u540c\u7684\u6a21\u5f0f\uff0c\u5176\u4e2dMatic\u8868\u73b0\u51fa\u663e\u8457\u66f4\u9ad8\u7684\u4e50\u89c2\u9884\u6d4b\u503e\u5411\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u7814\u7a76\u4e86\u5e0c\u671b\u548c\u540e\u6094\u60c5\u7eea\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u60c5\u611f\u4e0e\u9884\u6d4b\u884c\u4e3a\u4e4b\u95f4\u7684\u5fae\u5999\u4e92\u52a8\u3002\u5c3d\u7ba1\u5728\u6570\u636e\u91cf\u548c\u8d44\u6e90\u53ef\u7528\u6027\u65b9\u9762\u9047\u5230\u9650\u5236\uff0c\u6211\u4eec\u7684\u7814\u7a76\u4ecd\u62a5\u544a\u4e86\u5173\u4e8e\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u4e2d\u6295\u8d44\u8005\u884c\u4e3a\u548c\u60c5\u611f\u8d8b\u52bf\u7684\u5b9d\u8d35\u53d1\u73b0\uff0c\u4e3a\u6218\u7565\u51b3\u7b56\u548c\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u4fe1\u606f\u3002 | Moein Shahiki Tash | PDF | N/A | Exploring Sentiment Dynamics and Predictive Behaviors in Cryptocurrency Discussions by Few-Shot Learning with Large Language Models | This study performs analysis of Predictive statements, Hope speech, and Regret Detection behaviors within cryptocurrency-related discussions, leveraging advanced natural language processing techniques. We introduce a novel classification scheme named \"Prediction statements,\" categorizing comments into Predictive Incremental, Predictive Decremental, Predictive Neutral, or Non-Predictive categories. Employing GPT-4o, a cutting-edge large language model, we explore sentiment dynamics across five prominent cryptocurrencies: Cardano, Binance, Matic, Fantom, and Ripple. Our analysis reveals distinct patterns in predictive sentiments, with Matic demonstrating a notably higher propensity for optimistic predictions. Additionally, we investigate hope and regret sentiments, uncovering nuanced interplay between these emotions and predictive behaviors. Despite encountering limitations related to data volume and resource availability, our study reports valuable discoveries concerning investor behavior and sentiment trends within the cryptocurrency market, informing strategic decision-making and future research endeavors. | | CMM-Math\uff1a\u4e00\u4e2a\u4e2d\u6587\u591a\u6a21\u6001\u6570\u5b66\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u589e\u5f3a\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b | \u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u4ee4\u4eba\u77a9\u76ee\u7684\u6210\u679c\uff0c\u8fd9\u662f\u4eba\u7c7b\u667a\u80fd\u7684\u57fa\u7840\u6280\u80fd\u4e4b\u4e00\u3002\u5927\u591a\u6570\u5148\u524d\u7684\u7814\u7a76\u96c6\u4e2d\u5728\u57fa\u4e8e\u6587\u672c\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\uff08\u5982MATH\u3001GSM8K\uff09\u6539\u8fdb\u548c\u8861\u91cfLLMs\u7684\u6027\u80fd\u3002\u6700\u8fd1\uff0c\u4e00\u4e9b\u7814\u7a76\u8005\u53d1\u5e03\u4e86\u82f1\u8bed\u591a\u6a21\u6001\u6570\u5b66\u6570\u636e\u96c6\uff08\u5982MATHVISTA\u548cMATH-V\uff09\uff0c\u4ee5\u8bc4\u4f30\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u7684\u6709\u6548\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u53d1\u5e03\u4e86\u4e00\u4e2a\u4e2d\u6587\u591a\u6a21\u6001\u6570\u5b66\uff08CMM-Math\uff09\u6570\u636e\u96c6\uff0c\u5305\u62ec\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bad\u7ec3\u90e8\u5206\uff0c\u4ee5\u8bc4\u4f30\u548c\u63d0\u5347LMMs\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002CMM-Math\u5305\u542b\u8d85\u8fc728,000\u4e2a\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u6db5\u76d6\u4e86\u4ece\u5c0f\u5b66\u5230\u9ad8\u4e2d12\u4e2a\u5e74\u7ea7\u5404\u79cd\u95ee\u9898\u7c7b\u578b\uff08\u5982\u9009\u62e9\u9898\u3001\u586b\u7a7a\u9898\u7b49\uff09\uff0c\u5e76\u9644\u6709\u8be6\u7ec6\u7684\u89e3\u7b54\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u89c6\u89c9\u4e0a\u4e0b\u6587\u53ef\u80fd\u51fa\u73b0\u5728\u95ee\u9898\u6216\u89e3\u7b54\u4e2d\uff0c\u8fd9\u4f7f\u5f97\u8be5\u6570\u636e\u96c6\u66f4\u5177\u6311\u6218\u6027\u3002\u901a\u8fc7\u7efc\u5408\u5206\u6790\uff0c\u6211\u4eec\u53d1\u73b0CMM-Math\u6570\u636e\u96c6\u4e0a\u7684\u6700\u5148\u8fdbLMMs\u9762\u4e34\u6311\u6218\uff0c\u5f3a\u8c03\u4e86\u8fdb\u4e00\u6b65\u6539\u8fdbLMM\u5f00\u53d1\u7684\u5fc5\u8981\u6027\u3002\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u6570\u5b66LMM\uff08Math-LMM\uff09\uff0c\u7528\u4e8e\u5904\u7406\u5305\u542b\u591a\u4e2a\u56fe\u50cf\u548c\u6587\u672c\u7247\u6bb5\u7684\u6df7\u5408\u8f93\u5165\u95ee\u9898\u3002\u6211\u4eec\u901a\u8fc7\u4e09\u4e2a\u9636\u6bb5\u8bad\u7ec3\u6211\u4eec\u7684\u6a21\u578b\uff0c\u5305\u62ec\u57fa\u7840\u9884\u8bad\u7ec3\u3001\u57fa\u7840\u5fae\u8c03\u548c\u6570\u5b66\u5fae\u8c03\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7\u4e0e\u4e09\u4e2a\u591a\u6a21\u6001\u6570\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u6700\u5148\u8fdbLMMs\u8fdb\u884c\u6bd4\u8f83\uff0c\u6211\u4eec\u7684\u6a21\u578b\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u6570\u5b66\u63a8\u7406\u6027\u80fd\u3002 | Wentao Liu | PDF | N/A | CMM-Math: A Chinese Multimodal Math Dataset To Evaluate and Enhance the Mathematics Reasoning of Large Multimodal Models | Large language models (LLMs) have obtained promising results in mathematical reasoning, which is a foundational skill for human intelligence. Most previous studies focus on improving and measuring the performance of LLMs based on textual math reasoning datasets (e.g., MATH, GSM8K). Recently, a few researchers have released English multimodal math datasets (e.g., MATHVISTA and MATH-V) to evaluate the effectiveness of large multimodal models (LMMs). In this paper, we release a Chinese multimodal math (CMM-Math) dataset, including benchmark and training parts, to evaluate and enhance the mathematical reasoning of LMMs. CMM-Math contains over 28,000 high-quality samples, featuring a variety of problem types (e.g., multiple-choice, fill-in-the-blank, and so on) with detailed solutions across 12 grade levels from elementary to high school in China. Specifically, the visual context may be present in the questions or opinions, which makes this dataset more challenging. Through comprehensive analysis, we discover that state-of-the-art LMMs on the CMM-Math dataset face challenges, emphasizing the necessity for further improvements in LMM development. We also propose a Multimodal Mathematical LMM (Math-LMM) to handle the problems with mixed input of multiple images and text segments. We train our model using three stages, including foundational pre-training, foundational fine-tuning, and mathematical fine-tuning. The extensive experiments indicate that our model effectively improves math reasoning performance by comparing it with the SOTA LMMs over three multimodal mathematical datasets. | | \u9ed1\u66dc\u77f3\uff1a\u9488\u5bf9\u5b89\u5168\u673a\u5668\u5b66\u4e60\u52a0\u901f\u5668\u7684\u534f\u540c\u72b6\u6001\u7a7a\u95f4\u63a2\u7d22\u4ee5\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406 | \u53ef\u4fe1\u6267\u884c\u73af\u5883\uff08TEEs\uff09\u5bf9\u4e8e\u673a\u5668\u5b66\u4e60\u52a0\u901f\u5668\u7684\u6027\u80fd\u63d0\u5347\u5728\u5b89\u5168\u4e14\u9ad8\u6548\u7684\u673a\u5668\u5b66\u4e60\u63a8\u7406\u4e2d\u662f\u4e0d\u53ef\u6216\u7f3a\u7684\u3002\u901a\u8fc7\u72b6\u6001\u7a7a\u95f4\u63a2\u7d22\u5bf9\u52a0\u901f\u5668\u67b6\u6784\u8fdb\u884c\u4f18\u5316\uff0c\u53ef\u4ee5\u63d0\u5347\u6027\u80fd\u548c\u80fd\u8017\u8868\u73b0\u3002\u7136\u800c\uff0c\u7531\u4e8e\u641c\u7d22\u7a7a\u95f4\u5e9e\u5927\uff0c\u6b64\u7c7b\u63a2\u7d22\u65e2\u8017\u8d39\u8d44\u6e90\u53c8\u8017\u65f6\u3002\u5f53\u524d\u7684\u7814\u7a76\u4e0d\u5f97\u4e0d\u4f9d\u8d56\u5feb\u901f\u5206\u6790\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u820d\u5f03\u4e86\u5173\u952e\u7684\u786c\u4ef6\u7ec6\u8282\u4ee5\u53ca\u786c\u4ef6\u5b89\u5168\u539f\u8bed\u72ec\u6709\u7684\u8de8\u5c42\u673a\u4f1a\u3002\u5c3d\u7ba1\u5468\u671f\u7cbe\u786e\u6a21\u578b\u7406\u8bba\u4e0a\u80fd\u5b9e\u73b0\u66f4\u4f18\u7684\u8bbe\u8ba1\uff0c\u4f46\u5176\u9ad8\u6602\u7684\u8fd0\u884c\u6210\u672c\u9650\u5236\u4e86\u5b83\u4eec\u53ea\u80fd\u5728\u8f83\u5c0f\u7684\u72b6\u6001\u7a7a\u95f4\u5185\u5e94\u7528\u3002</p> <p>\u6211\u4eec\u63d0\u51fa\u4e86Obsidian\uff0c\u8fd9\u662f\u4e00\u4e2a\u4f18\u5316\u6846\u67b6\uff0c\u65e8\u5728\u4e3a\u673a\u5668\u5b66\u4e60\u5185\u6838\u5230\u5b89\u5168\u673a\u5668\u5b66\u4e60\u52a0\u901f\u5668\u7684\u6620\u5c04\u627e\u5230\u6700\u4f18\u89e3\u3002Obsidian\u901a\u8fc7\u534f\u540c\u4f7f\u7528\u5206\u6790\u6a21\u578b\u548c\u5468\u671f\u7cbe\u786e\u6a21\u578b\u6765\u63a2\u7d22\u72b6\u6001\u7a7a\u95f4\uff0c\u4ece\u800c\u5e94\u5bf9\u4e0a\u8ff0\u6311\u6218\u3002\u5176\u4e24\u5927\u4e3b\u8981\u63a2\u7d22\u7ec4\u4ef6\u5305\u62ec\uff1a(1) \u4e00\u4e2a\u5305\u542b\u5b89\u5168\u786c\u4ef6\u5f71\u54cd\u7684\u52a0\u901f\u5668\u5206\u6790\u6a21\u578b\uff0c\u5728\u904d\u5386\u5927\u89c4\u6a21\u6620\u5c04\u72b6\u6001\u7a7a\u95f4\u65f6\u751f\u6210\u6700\u4f73\u7684m\u4e2a\u6a21\u578b\u6620\u5c04\uff1b(2) \u5728\u5468\u671f\u7cbe\u786e\u6a21\u578b\u4e0a\u7684\u7f16\u8bd1\u5668\u5256\u6790\u6b65\u9aa4\uff0c\u6355\u6349\u8fd0\u884c\u65f6\u74f6\u9888\u4ee5\u8fdb\u4e00\u6b65\u4f18\u5316\u6267\u884c\u65f6\u95f4\u3001\u80fd\u8017\u548c\u8d44\u6e90\u5229\u7528\u7387\uff0c\u5e76\u627e\u5230\u6700\u4f18\u7684\u6a21\u578b\u6620\u5c04\u3002</p> <p>\u6211\u4eec\u5c06Obsidian\u7684\u7ed3\u679c\u4e0e\u4e00\u4e2a\u57fa\u7ebf\u5b89\u5168\u52a0\u901f\u5668\u8fdb\u884c\u4e86\u5bf9\u6bd4\uff0c\u8be5\u57fa\u7ebf\u52a0\u901f\u5668\u6574\u5408\u4e86\u4eceGuardNN [33] \u548c Sesame [11] \u83b7\u53d6\u7684\u6700\u65b0\u5b89\u5168\u65b9\u6848\u3002\u5206\u6790\u6a21\u578b\u5728\u4e91\u7aef\u90e8\u7f72\u4e2d\u5c06\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e\u4e8620.5%\uff0c\u5728\u8fb9\u7f18\u90e8\u7f72\u4e2d\u964d\u4f4e\u4e868.4%\uff0c\u540c\u65f6\u5206\u522b\u5b9e\u73b0\u4e8624%\u548c19%\u7684\u80fd\u8017\u6539\u8fdb\u3002\u5468\u671f\u7cbe\u786e\u6a21\u578b\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u8fdb\u4e00\u6b65\u5c06\u4e91\u7aef\u5ef6\u8fdf\u964d\u4f4e\u4e869.1%\uff0c\u8fb9\u7f18\u5ef6\u8fdf\u964d\u4f4e\u4e8612.2%\uff0c\u5e76\u5206\u522b\u5e26\u6765\u4e8613.8%\u548c13.1%\u7684\u80fd\u8017\u63d0\u5347\u3002 | Sarbartha Banerjee | PDF | N/A | Obsidian: Cooperative State-Space Exploration for Performant Inference on Secure ML Accelerators | Trusted execution environments (TEEs) for machine learning accelerators are indispensable in secure and efficient ML inference. Optimizing workloads through state-space exploration for the accelerator architectures improves performance and energy consumption. However, such explorations are expensive and slow due to the large search space. Current research has to use fast analytical models that forego critical hardware details and cross-layer opportunities unique to the hardware security primitives. While cycle-accurate models can theoretically reach better designs, their high runtime cost restricts them to a smaller state space.   We present Obsidian, an optimization framework for finding the optimal mapping from ML kernels to a secure ML accelerator. Obsidian addresses the above challenge by exploring the state space using analytical and cycle-accurate models cooperatively. The two main exploration components include: (1) A secure accelerator analytical model, that includes the effect of secure hardware while traversing the large mapping state space and produce the best m model mappings; (2) A compiler profiling step on a cycle-accurate model, that captures runtime bottlenecks to further improve execution runtime, energy and resource utilization and find the optimal model mapping.   We compare our results to a baseline secure accelerator, comprising of the state-of-the-art security schemes obtained from guardnn [ 33 ] and sesame [11]. The analytical model reduces the inference latency by 20.5% for a cloud and 8.4% for an edge deployment with an energy improvement of 24% and 19% respectively. The cycle-accurate model, further reduces the latency by 9.1% for a cloud and 12.2% for an edge with an energy improvement of 13.8% and 13.1%. | | MMMU-Pro\uff1a\u4e00\u4e2a\u66f4\u5f3a\u5927\u7684\u591a\u5b66\u79d1\u591a\u6a21\u6001\u7406\u89e3\u57fa\u51c6 | \u672c\u6587\u4ecb\u7ecd\u4e86MMMU-Pro\uff0c\u8fd9\u662f\u5927\u89c4\u6a21\u591a\u5b66\u79d1\u591a\u6a21\u6001\u7406\u89e3\u548c\u63a8\u7406\uff08MMMU\uff09\u57fa\u51c6\u7684\u4e00\u4e2a\u7a33\u5065\u7248\u672c\u3002MMMU-Pro\u901a\u8fc7\u57fa\u4e8eMMMU\u7684\u4e09\u6b65\u6d41\u7a0b\uff0c\u4e25\u683c\u8bc4\u4f30\u591a\u6a21\u6001\u6a21\u578b\u7684\u771f\u6b63\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\uff1a\uff081\uff09\u8fc7\u6ee4\u6389\u4ec5\u901a\u8fc7\u6587\u672c\u6a21\u578b\u53ef\u56de\u7b54\u7684\u95ee\u9898\uff0c\uff082\uff09\u589e\u52a0\u5019\u9009\u9009\u9879\uff0c\uff083\uff09\u5f15\u5165\u4ec5\u89c6\u89c9\u8f93\u5165\u8bbe\u7f6e\uff0c\u5176\u4e2d\u95ee\u9898\u5d4c\u5165\u5728\u56fe\u50cf\u4e2d\u3002\u8fd9\u79cd\u8bbe\u7f6e\u6311\u6218AI\u540c\u65f6\u201c\u770b\u201d\u548c\u201c\u8bfb\u201d\uff0c\u6d4b\u8bd5\u4e86\u65e0\u7f1d\u6574\u5408\u89c6\u89c9\u548c\u6587\u672c\u4fe1\u606f\u7684\u57fa\u672c\u4eba\u7c7b\u8ba4\u77e5\u6280\u80fd\u3002\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u5728MMMU-Pro\u4e0a\u7684\u8868\u73b0\u663e\u8457\u4f4e\u4e8e\u5728MMMU\u4e0a\u7684\u8868\u73b0\uff0c\u8de8\u6a21\u578b\u8303\u56f4\u4ece16.8%\u523026.9%\u3002\u6211\u4eec\u63a2\u8ba8\u4e86OCR\u63d0\u793a\u548c\u601d\u7ef4\u94fe\uff08CoT\uff09\u63a8\u7406\u7684\u5f71\u54cd\uff0c\u53d1\u73b0OCR\u63d0\u793a\u5f71\u54cd\u6700\u5c0f\uff0c\u800cCoT\u901a\u5e38\u80fd\u63d0\u9ad8\u6027\u80fd\u3002MMMU-Pro\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u4e25\u683c\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u7d27\u5bc6\u6a21\u62df\u73b0\u5b9e\u4e16\u754c\u573a\u666f\uff0c\u5e76\u4e3a\u591a\u6a21\u6001AI\u7684\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u65b9\u5411\u3002 | Xiang Yue | PDF | N/A | MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark | This paper introduces MMMU-Pro, a robust version of the Massive Multi-discipline Multimodal Understanding and Reasoning (MMMU) benchmark. MMMU-Pro rigorously assesses multimodal models' true understanding and reasoning capabilities through a three-step process based on MMMU: (1) filtering out questions answerable by text-only models, (2) augmenting candidate options, and (3) introducing a vision-only input setting where questions are embedded within images. This setting challenges AI to truly \"see\" and \"read\" simultaneously, testing a fundamental human cognitive skill of seamlessly integrating visual and textual information. Results show that model performance is substantially lower on MMMU-Pro than on MMMU, ranging from 16.8% to 26.9% across models. We explore the impact of OCR prompts and Chain of Thought (CoT) reasoning, finding that OCR prompts have minimal effect while CoT generally improves performance. MMMU-Pro provides a more rigorous evaluation tool, closely mimicking real-world scenarios and offering valuable directions for future research in multimodal AI. | | \u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4e2d\u8bc1\u4e66\u7684\u9c81\u68d2\u6027\uff1a\u9ad8\u6548\u81ea\u96c6\u6210\u65b9\u6cd5 | \u8fd1\u671f\uff0c\u65f6\u95f4\u5e8f\u5217\u9886\u57df\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u95ee\u9898\u5f15\u8d77\u4e86\u5e7f\u6cdb\u5173\u6ce8\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u9632\u5fa1\u673a\u5236\u4ecd\u7136\u6709\u9650\uff0c\u5bf9\u6297\u8bad\u7ec3\u662f\u4e3b\u8981\u7684\u65b9\u6cd5\uff0c\u5c3d\u7ba1\u5b83\u6ca1\u6709\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u3002\u968f\u673a\u5e73\u6ed1\uff08Randomized Smoothing\uff09\u56e0\u5176\u80fd\u591f\u5728 $\\ell_p$-ball \u653b\u51fb\u4e0b\u8bc1\u660e\u9c81\u68d2\u6027\u534a\u5f84\u7684\u53ef\u8bc1\u660e\u4e0b\u754c\u800c\u8131\u9896\u800c\u51fa\u3002\u9274\u4e8e\u5176\u6210\u529f\uff0c\u65f6\u95f4\u5e8f\u5217\u9886\u57df\u7684\u7814\u7a76\u5f00\u59cb\u5173\u6ce8\u8fd9\u4e9b\u65b9\u9762\u3002\u7136\u800c\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u6216\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\uff08TSC\uff09\u7684\u7edf\u8ba1\u7279\u5f81\u589e\u5f3a\u4e2d\u7684\u975e-$\\ell_p$ \u9c81\u68d2\u6027\u3002\u6211\u4eec\u7684\u7efc\u8ff0\u53d1\u73b0\uff0c\u968f\u673a\u5e73\u6ed1\u5728 TSC \u4e2d\u8868\u73b0\u4e00\u822c\uff0c\u96be\u4ee5\u5728\u9c81\u68d2\u6027\u8f83\u5dee\u7684\u6570\u636e\u96c6\u4e0a\u63d0\u4f9b\u6709\u6548\u7684\u4fdd\u8bc1\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u96c6\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u51cf\u5c11\u5206\u7c7b\u8fb9\u9645\u7684\u65b9\u5dee\u6765\u589e\u5f3a\u9884\u6d4b\u6807\u7b7e\u6982\u7387\u7f6e\u4fe1\u5ea6\u7684\u4e0b\u754c\uff0c\u4ece\u800c\u8bc1\u660e\u66f4\u5927\u7684\u534a\u5f84\u3002\u8be5\u65b9\u6cd5\u8fd8\u89e3\u51b3\u4e86\u6df1\u5ea6\u96c6\u6210\uff08DE\uff09\u7684\u8ba1\u7b97\u5f00\u9500\u95ee\u9898\uff0c\u540c\u65f6\u5728\u9c81\u68d2\u6027\u65b9\u9762\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u5e76\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8d85\u8d8a\u4e86\u5b83\u3002\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u7ed3\u679c\u90fd\u9a8c\u8bc1\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5728\u9c81\u68d2\u6027\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u80fd\u3002 | Chang Dong | PDF | N/A | Boosting Certificate Robustness for Time Series Classification with Efficient Self-Ensemble | Recently, the issue of adversarial robustness in the time series domain has garnered significant attention. However, the available defense mechanisms remain limited, with adversarial training being the predominant approach, though it does not provide theoretical guarantees. Randomized Smoothing has emerged as a standout method due to its ability to certify a provable lower bound on robustness radius under $\\ell_p$-ball attacks. Recognizing its success, research in the time series domain has started focusing on these aspects. However, existing research predominantly focuses on time series forecasting, or under the non-$\\ell_p$ robustness in statistic feature augmentation for time series classification~(TSC). Our review found that Randomized Smoothing performs modestly in TSC, struggling to provide effective assurances on datasets with poor robustness. Therefore, we propose a self-ensemble method to enhance the lower bound of the probability confidence of predicted labels by reducing the variance of classification margins, thereby certifying a larger radius. This approach also addresses the computational overhead issue of Deep Ensemble~(DE) while remaining competitive and, in some cases, outperforming it in terms of robustness. Both theoretical analysis and experimental results validate the effectiveness of our method, demonstrating superior performance in robustness testing compared to baseline approaches. | | \u8fc8\u5411\u5927\u8bed\u8a00\u6a21\u578b\u504f\u597d\u5b66\u4e60\u7684\u7edf\u4e00\u89c6\u89d2\uff1a\u4e00\u9879\u7efc\u8ff0 | \u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c55\u73b0\u51fa\u4e86\u6781\u5176\u5f3a\u5927\u7684\u80fd\u529b\u3002\u5b9e\u73b0\u6210\u529f\u7684\u5173\u952e\u56e0\u7d20\u4e4b\u4e00\u662f\u4f7fLLM\u7684\u8f93\u51fa\u4e0e\u4eba\u7c7b\u504f\u597d\u76f8\u4e00\u81f4\u3002\u8fd9\u4e00\u5bf9\u9f50\u8fc7\u7a0b\u901a\u5e38\u53ea\u9700\u8981\u5c11\u91cf\u7684\u6570\u636e\u5c31\u80fd\u6709\u6548\u5730\u63d0\u5347LLM\u7684\u6027\u80fd\u3002\u5c3d\u7ba1\u8fd9\u79cd\u65b9\u6cd5\u6548\u679c\u663e\u8457\uff0c\u4f46\u76f8\u5173\u7814\u7a76\u6d89\u53ca\u591a\u4e2a\u9886\u57df\uff0c\u6240\u6d89\u53ca\u7684\u65b9\u6cd5\u76f8\u5bf9\u590d\u6742\uff0c\u4e0d\u6613\u7406\u89e3\u3002\u4e0d\u540c\u65b9\u6cd5\u4e4b\u95f4\u7684\u5173\u7cfb\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u8fd9\u9650\u5236\u4e86\u504f\u597d\u5bf9\u9f50\u7684\u53d1\u5c55\u3002\u9274\u4e8e\u6b64\uff0c\u6211\u4eec\u5c06\u73b0\u6709\u7684\u6d41\u884c\u5bf9\u9f50\u7b56\u7565\u5206\u89e3\u4e3a\u4e0d\u540c\u7684\u7ec4\u6210\u90e8\u5206\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u7814\u7a76\u5f53\u524d\u7684\u5bf9\u9f50\u7b56\u7565\uff0c\u4ece\u800c\u5728\u8fd9\u4e9b\u7b56\u7565\u4e4b\u95f4\u5efa\u7acb\u8054\u7cfb\u3002\u5728\u672c\u7efc\u8ff0\u4e2d\uff0c\u6211\u4eec\u5c06\u504f\u597d\u5b66\u4e60\u4e2d\u7684\u6240\u6709\u7b56\u7565\u5206\u89e3\u4e3a\u56db\u4e2a\u7ec4\u6210\u90e8\u5206\uff1a\u6a21\u578b\u3001\u6570\u636e\u3001\u53cd\u9988\u548c\u7b97\u6cd5\u3002\u8fd9\u79cd\u7edf\u4e00\u7684\u89c6\u89d2\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u5bf9\u73b0\u6709\u5bf9\u9f50\u7b97\u6cd5\u7684\u6df1\u5165\u7406\u89e3\uff0c\u8fd8\u4e3a\u4e0d\u540c\u7b56\u7565\u7684\u4f18\u52bf\u7ed3\u5408\u5f00\u8f9f\u4e86\u53ef\u80fd\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u73b0\u6709\u6d41\u884c\u7b97\u6cd5\u7684\u8be6\u7ec6\u5de5\u4f5c\u793a\u4f8b\uff0c\u4ee5\u5e2e\u52a9\u8bfb\u8005\u5168\u9762\u7406\u89e3\u3002\u6700\u540e\uff0c\u57fa\u4e8e\u6211\u4eec\u7684\u7edf\u4e00\u89c6\u89d2\uff0c\u6211\u4eec\u63a2\u8ba8\u4e86\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u6240\u9762\u4e34\u7684\u6311\u6218\u548c\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002 | Bofei Gao | PDF | N/A | Towards a Unified View of Preference Learning for Large Language Models: A Survey | Large Language Models (LLMs) exhibit remarkably powerful capabilities. One of the crucial factors to achieve success is aligning the LLM's output with human preferences. This alignment process often requires only a small amount of data to efficiently enhance the LLM's performance. While effective, research in this area spans multiple domains, and the methods involved are relatively complex to understand. The relationships between different methods have been under-explored, limiting the development of the preference alignment. In light of this, we break down the existing popular alignment strategies into different components and provide a unified framework to study the current alignment strategies, thereby establishing connections among them. In this survey, we decompose all the strategies in preference learning into four components: model, data, feedback, and algorithm. This unified view offers an in-depth understanding of existing alignment algorithms and also opens up possibilities to synergize the strengths of different strategies. Furthermore, we present detailed working examples of prevalent existing algorithms to facilitate a comprehensive understanding for the readers. Finally, based on our unified perspective, we explore the challenges and future research directions for aligning large language models with human preferences. | | \u4ece\u7ecf\u9a8c\u4e2d\u201c\u53cd\u5b66\u4e60\u201d\u4ee5\u907f\u514d\u865a\u5047\u5173\u8054 | \u5c3d\u7ba1\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u8bb8\u591a\u4efb\u52a1\u4e2d\u80fd\u591f\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4f46\u8fd9\u4e9b\u6a21\u578b\u5b9e\u9645\u4e0a\u6bd4\u5b83\u4eec\u8868\u73b0\u51fa\u6765\u7684\u66f4\u4e3a\u8106\u5f31\u3002\u5b83\u4eec\u5bb9\u6613\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u5b66\u4e60\u5230\u865a\u5047\u7684\u76f8\u5173\u6027\uff0c\u4ece\u800c\u5bfc\u81f4\u4ee4\u4eba\u60ca\u8bb6\u7684\u5931\u8d25\u6848\u4f8b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u865a\u5047\u76f8\u5173\u6027\u7684\u95ee\u9898\uff1a\u4ece\u7ecf\u9a8c\u4e2d\u201c\u9057\u5fd8\u201d\uff08UnLearning from Experience\uff0c\u7b80\u79f0ULE\uff09\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u57fa\u4e8e\u4f7f\u7528\u4e24\u4e2a\u5e76\u884c\u8bad\u7ec3\u7684\u5206\u7c7b\u6a21\u578b\uff1a\u5b66\u751f\u6a21\u578b\u548c\u6559\u5e08\u6a21\u578b\u3002\u4e24\u4e2a\u6a21\u578b\u63a5\u6536\u76f8\u540c\u7684\u8bad\u7ec3\u6570\u636e\u6279\u6b21\u3002\u5b66\u751f\u6a21\u578b\u5728\u6ca1\u6709\u7ea6\u675f\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u8ffd\u6c42\u6570\u636e\u4e2d\u7684\u865a\u5047\u76f8\u5173\u6027\u3002\u6559\u5e08\u6a21\u578b\u5219\u88ab\u8bad\u7ec3\u6765\u89e3\u51b3\u76f8\u540c\u7684\u5206\u7c7b\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u5b66\u751f\u6a21\u578b\u7684\u9519\u8bef\u3002\u7531\u4e8e\u8bad\u7ec3\u662f\u5e76\u884c\u8fdb\u884c\u7684\uff0c\u5b66\u751f\u6a21\u578b\u5bf9\u865a\u5047\u76f8\u5173\u6027\u5b66\u5f97\u8d8a\u597d\uff0c\u6559\u5e08\u6a21\u578b\u5c31\u8d8a\u9c81\u68d2\u3002\u6559\u5e08\u6a21\u578b\u5229\u7528\u5b66\u751f\u8f93\u51fa\u76f8\u5bf9\u4e8e\u5176\u8f93\u5165\u7684\u68af\u5ea6\u6765\u201c\u9057\u5fd8\u201d\u5b66\u751f\u6240\u72af\u7684\u9519\u8bef\u3002\u6211\u4eec\u5728Waterbirds\u3001CelebA\u3001Spawrious\u548cUrbanCars\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002 | Jeff Mitchell | PDF | N/A | UnLearning from Experience to Avoid Spurious Correlations | While deep neural networks can achieve state-of-the-art performance in many tasks, these models are more fragile than they appear. They are prone to learning spurious correlations in their training data, leading to surprising failure cases. In this paper, we propose a new approach that addresses the issue of spurious correlations: UnLearning from Experience (ULE). Our method is based on using two classification models trained in parallel: student and teacher models. Both models receive the same batches of training data. The student model is trained with no constraints and pursues the spurious correlations in the data. The teacher model is trained to solve the same classification problem while avoiding the mistakes of the student model. As training is done in parallel, the better the student model learns the spurious correlations, the more robust the teacher model becomes. The teacher model uses the gradient of the student's output with respect to its input to unlearn mistakes made by the student. We show that our method is effective on the Waterbirds, CelebA, Spawrious and UrbanCars datasets. | | \u5177\u6709\u9886\u57df\u9002\u5e94\u6027\u7684\u6b63\u5219\u5316\u591a\u8f93\u51fa\u9ad8\u65af\u5377\u79ef\u8fc7\u7a0b | \u591a\u8f93\u51fa\u9ad8\u65af\u8fc7\u7a0b\uff08MGP\uff09\u4f5c\u4e3a\u4e00\u79cd\u5efa\u6a21\u591a\u4e2a\u8f93\u51fa\u7684\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u6b63\u53d7\u5230\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u6ce8\u3002\u5c3d\u7ba1MGP\u5177\u6709\u9ad8\u5ea6\u7684\u7075\u6d3b\u6027\u548c\u901a\u7528\u6027\uff0c\u4f46\u5728\u5e94\u7528\u4e8e\u8fc1\u79fb\u5b66\u4e60\u65f6\uff0c\u4ecd\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\u3002\u7b2c\u4e00\u4e2a\u6311\u6218\u662f\u8d1f\u8fc1\u79fb\uff0c\u5373\u5f53\u8f93\u51fa\u4e4b\u95f4\u4e0d\u5b58\u5728\u5171\u4eab\u4fe1\u606f\u65f6\u53d1\u751f\u7684\u60c5\u51b5\u3002\u7b2c\u4e8c\u4e2a\u6311\u6218\u662f\u8f93\u5165\u57df\u4e0d\u4e00\u81f4\uff0c\u8fd9\u5728\u8fc1\u79fb\u5b66\u4e60\u4e2d\u5e38\u89c1\uff0c\u4f46\u5728MGP\u4e2d\u5c1a\u672a\u5f97\u5230\u63a2\u8ba8\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e26\u6709\u57df\u9002\u5e94\u7684\u6b63\u5219\u5316MGP\u5efa\u6a21\u6846\u67b6\uff0c\u4ee5\u514b\u670d\u8fd9\u4e9b\u6311\u6218\u3002\u66f4\u5177\u4f53\u5730\u8bf4\uff0c\u901a\u8fc7\u4f7f\u7528\u5377\u79ef\u8fc7\u7a0b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7a00\u758f\u7684MGP\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u5176\u4e2d\u52a0\u5165\u4e86\u60e9\u7f5a\u9879\uff0c\u4ee5\u81ea\u9002\u5e94\u5730\u9009\u62e9\u6700\u5177\u4fe1\u606f\u91cf\u7684\u8f93\u51fa\u8fdb\u884c\u77e5\u8bc6\u8fc1\u79fb\u3002\u4e3a\u4e86\u5904\u7406\u57df\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fb9\u7f18\u5316\u4e0d\u4e00\u81f4\u7279\u5f81\u548c\u6269\u5c55\u7f3a\u5931\u7279\u5f81\u6765\u5bf9\u9f50\u4e0d\u540c\u8f93\u51fa\u4e4b\u95f4\u7684\u8f93\u5165\u57df\u3002\u63d0\u4f9b\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u4ee5\u4fdd\u8bc1\u5176\u5728\u5b9e\u9645\u5e94\u7528\u548c\u6e10\u8fd1\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u3002\u5728\u7efc\u5408\u6a21\u62df\u7814\u7a76\u548c\u9676\u74f7\u5236\u9020\u8fc7\u7a0b\u7684\u4e00\u4e2a\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u51c6\u65b9\u6cd5\u3002\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u5904\u7406\u8d1f\u8fc1\u79fb\u548c\u57df\u4e0d\u4e00\u81f4\u65b9\u9762\u5177\u6709\u6709\u6548\u6027\u3002 | Wang Xinming | PDF | N/A | Regularized Multi-output Gaussian Convolution Process with Domain Adaptation | Multi-output Gaussian process (MGP) has been attracting increasing attention as a transfer learning method to model multiple outputs. Despite its high flexibility and generality, MGP still faces two critical challenges when applied to transfer learning. The first one is negative transfer, which occurs when there exists no shared information among the outputs. The second challenge is the input domain inconsistency, which is commonly studied in transfer learning yet not explored in MGP. In this paper, we propose a regularized MGP modeling framework with domain adaptation to overcome these challenges. More specifically, a sparse covariance matrix of MGP is proposed by using convolution process, where penalization terms are added to adaptively select the most informative outputs for knowledge transfer. To deal with the domain inconsistency, a domain adaptation method is proposed by marginalizing inconsistent features and expanding missing features to align the input domains among different outputs. Statistical properties of the proposed method are provided to guarantee the performance practically and asymptotically. The proposed framework outperforms state-of-the-art benchmarks in comprehensive simulation studies and one real case study of a ceramic manufacturing process. The results demonstrate the effectiveness of our method in dealing with both the negative transfer and the domain inconsistency. | | \u5c06\u56e0\u679c\u8868\u5f81\u5b66\u4e60\u4e0e\u4e0d\u53d8\u6027\u539f\u5219\u7edf\u4e00\u8d77\u6765 | \u56e0\u679c\u8868\u793a\u5b66\u4e60\u65e8\u5728\u4ece\u9ad8\u7ef4\u89c2\u6d4b\u4e2d\u6062\u590d\u6f5c\u5728\u7684\u56e0\u679c\u53d8\u91cf\uff0c\u4ee5\u89e3\u51b3\u56e0\u679c\u4e0b\u6e38\u4efb\u52a1\uff0c\u4f8b\u5982\u9884\u6d4b\u65b0\u5e72\u9884\u63aa\u65bd\u7684\u6548\u679c\u6216\u8fdb\u884c\u66f4\u7a33\u5065\u7684\u5206\u7c7b\u3002\u5df2\u7ecf\u5f00\u53d1\u4e86\u5927\u91cf\u65b9\u6cd5\uff0c\u6bcf\u79cd\u65b9\u6cd5\u90fd\u9488\u5bf9\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u95ee\u9898\u8bbe\u7f6e\uff0c\u4ece\u800c\u5bfc\u81f4\u4e0d\u540c\u7c7b\u578b\u7684\u53ef\u8bc6\u522b\u6027\u3002\u6709\u4e00\u79cd\u666e\u904d\u7684\u770b\u6cd5\u662f\uff0c\u8fd9\u4e9b\u4e0d\u540c\u7684\u8bbe\u7f6e\u5f88\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u4eec\u901a\u5e38\u4e0ePearl\u56e0\u679c\u5c42\u6b21\u7ed3\u6784\u7684\u4e0d\u540c\u5c42\u6b21\u76f8\u5173\u8054\uff0c\u5c3d\u7ba1\u5e76\u975e\u6240\u6709\u90fd\u5b8c\u5168\u543b\u5408\u3002\u6211\u4eec\u7684\u4e3b\u8981\u8d21\u732e\u5728\u4e8e\u5c55\u793a\u4e86\u73b0\u6709\u8bb8\u591a\u56e0\u679c\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u5728\u65b9\u6cd5\u8bba\u4e0a\u5c06\u8868\u793a\u4e0e\u5df2\u77e5\u7684\u6570\u636e\u5bf9\u79f0\u6027\u5bf9\u9f50\u3002\u53d8\u91cf\u7684\u8bc6\u522b\u662f\u901a\u8fc7\u4e0d\u540c\u6570\u636e\u53e3\u888b\u4e4b\u95f4\u7684\u7b49\u4ef7\u7c7b\u6765\u6307\u5bfc\u7684\uff0c\u8fd9\u4e9b\u7b49\u4ef7\u7c7b\u4e0d\u4e00\u5b9a\u5177\u6709\u56e0\u679c\u6027\u3002\u8fd9\u4e00\u7ed3\u679c\u5177\u6709\u91cd\u8981\u7684\u610f\u4e49\uff0c\u4f7f\u6211\u4eec\u80fd\u591f\u5c06\u8bb8\u591a\u73b0\u6709\u65b9\u6cd5\u7edf\u4e00\u5728\u4e00\u4e2a\u5355\u4e00\u7684\u65b9\u6cd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u6839\u636e\u4e0e\u6211\u4eec\u5e94\u7528\u76f8\u5173\u7684\u6052\u5b9a\u6027\u6df7\u5408\u548c\u5339\u914d\u4e0d\u540c\u7684\u5047\u8bbe\uff0c\u5305\u62ec\u975e\u56e0\u679c\u6027\u7684\u5047\u8bbe\u3002\u8fd9\u8fd8\u5927\u5927\u63d0\u9ad8\u4e86\u9002\u7528\u6027\uff0c\u6211\u4eec\u901a\u8fc7\u6539\u8fdb\u73b0\u5b9e\u4e16\u754c\u9ad8\u7ef4\u751f\u6001\u6570\u636e\u4e0a\u7684\u6cbb\u7597\u6548\u679c\u4f30\u8ba1\u6765\u5c55\u793a\u8fd9\u4e00\u70b9\u3002\u603b\u7684\u6765\u8bf4\uff0c\u672c\u6587\u9610\u660e\u4e86\u56e0\u679c\u5047\u8bbe\u5728\u56e0\u679c\u53d8\u91cf\u53d1\u73b0\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u5c06\u91cd\u70b9\u8f6c\u79fb\u5230\u4fdd\u7559\u6570\u636e\u5bf9\u79f0\u6027\u4e0a\u3002 | Dingling Yao | PDF | N/A | Unifying Causal Representation Learning with the Invariance Principle | Causal representation learning aims at recovering latent causal variables from high-dimensional observations to solve causal downstream tasks, such as predicting the effect of new interventions or more robust classification. A plethora of methods have been developed, each tackling carefully crafted problem settings that lead to different types of identifiability. The folklore is that these different settings are important, as they are often linked to different rungs of Pearl's causal hierarchy, although not all neatly fit. Our main contribution is to show that many existing causal representation learning approaches methodologically align the representation to known data symmetries. Identification of the variables is guided by equivalence classes across different data pockets that are not necessarily causal. This result suggests important implications, allowing us to unify many existing approaches in a single method that can mix and match different assumptions, including non-causal ones, based on the invariances relevant to our application. It also significantly benefits applicability, which we demonstrate by improving treatment effect estimation on real-world high-dimensional ecological data. Overall, this paper clarifies the role of causality assumptions in the discovery of causal variables and shifts the focus to preserving data symmetries. | | \u9884\u8bad\u7ec3\u4e0e\u81ea\u8bad\u7ec3\u7684\u6bd4\u8f83\u7814\u7a76 | \u9884\u8bad\u7ec3\u548c\u81ea\u8bad\u7ec3\u662f\u4e24\u79cd\u534a\u76d1\u7763\u5b66\u4e60\u7684\u65b9\u6cd5\u3002\u5173\u4e8e\u9884\u8bad\u7ec3\u548c\u81ea\u8bad\u7ec3\u7684\u6bd4\u8f83\u5df2\u6709\u7814\u7a76\uff0c\u4f46\u4ee5\u5f80\u7684\u7814\u7a76\u7ed3\u679c\u4ee4\u4eba\u56f0\u60d1\uff1a\u5728\u67d0\u4e9b\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\uff0c\u81ea\u8bad\u7ec3\u4f18\u4e8e\u9884\u8bad\u7ec3\uff1b\u800c\u5728\u67d0\u4e9b\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\uff0c\u9884\u8bad\u7ec3\u5728\u4e0d\u53ef\u6bd4\u8f83\u7684\u8bbe\u7f6e\u6761\u4ef6\u4e0b\u4f18\u4e8e\u81ea\u8bad\u7ec3\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7efc\u5408\u6027\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u4ee5\u7ecf\u9a8c\u7814\u7a76\u6240\u6709\u53ef\u884c\u7684\u8bad\u7ec3\u8303\u5f0f\uff0c\u8fd9\u4e9b\u8303\u5f0f\u7ed3\u5408\u4e86\u9884\u8bad\u7ec3\u3001\u81ea\u8bad\u7ec3\u548c\u5fae\u8c03\uff0c\u5e76\u5728\u4e0e\u6570\u636e\u589e\u5f3a\u53ef\u6bd4\u7684\u57fa\u7840\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u3002\u6211\u4eec\u5728\u516d\u4e2a\u6570\u636e\u96c6\u3001\u56db\u79cd\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u4ee5\u53ca\u60c5\u611f\u5206\u6790\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\u7684\u4e0d\u5e73\u8861\u6570\u636e\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8bc1\u5b9e\uff0c\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u7684\u8303\u5f0f\u603b\u4f53\u8868\u73b0\u6700\u4f73\u3002\u6b64\u5916\uff0c\u5f53\u4e0e\u534a\u76d1\u7763\u9884\u8bad\u7ec3\u7ed3\u5408\u65f6\uff0c\u81ea\u8bad\u7ec3\u5e76\u672a\u5e26\u6765\u989d\u5916\u7684\u597d\u5904\u3002 | Yiheng Wang | PDF | N/A | A Comparative Study of Pre-training and Self-training | Pre-training and self-training are two approaches to semi-supervised learning. The comparison between pre-training and self-training has been explored. However, the previous works led to confusing findings: self-training outperforms pre-training experienced on some tasks in computer vision, and contrarily, pre-training outperforms self-training experienced on some tasks in natural language processing, under certain conditions of incomparable settings. We propose, comparatively and exhaustively, an ensemble method to empirical study all feasible training paradigms combining pre-training, self-training, and fine-tuning within consistent foundational settings comparable to data augmentation. We conduct experiments on six datasets, four data augmentation, and imbalanced data for sentiment analysis and natural language inference tasks. Our findings confirm that the pre-training and fine-tuning paradigm yields the best overall performances. Moreover, self-training offers no additional benefits when combined with semi-supervised pre-training. | | \u53ef\u5904\u7406\u7684\u6b63\u5219\u51b3\u7b56\u8fc7\u7a0b\u7684\u79bb\u7ebf\u5b66\u4e60 | \u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u79f0\u4e3a\u6b63\u5219\u51b3\u7b56\u8fc7\u7a0b\uff08RDPs\uff09\u7684\u4e00\u7c7b\u975e\u9a6c\u5c14\u53ef\u592b\u73af\u5883\u4e2d\u8fdb\u884c\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u95ee\u9898\u3002\u5728RDPs\u4e2d\uff0c\u672a\u6765\u89c2\u6d4b\u548c\u5956\u52b1\u5bf9\u8fc7\u53bb\u4ea4\u4e92\u7684\u672a\u77e5\u4f9d\u8d56\u6027\u53ef\u4ee5\u901a\u8fc7\u67d0\u4e2a\u9690\u85cf\u7684\u6709\u9650\u72b6\u6001\u81ea\u52a8\u673a\u6765\u6355\u6349\u3002\u56e0\u6b64\uff0c\u8bb8\u591aRDP\u7b97\u6cd5\u9996\u5148\u4f7f\u7528\u81ea\u52a8\u673a\u5b66\u4e60\u6280\u672f\u6765\u91cd\u5efa\u8fd9\u79cd\u672a\u77e5\u7684\u4f9d\u8d56\u5173\u7cfb\u3002\u672c\u6587\u8868\u660e\uff0c\u53ef\u4ee5\u901a\u8fc7\u5f15\u5165\u4e24\u79cd\u539f\u521b\u6280\u672f\u6765\u514b\u670d\u5148\u524dRDP\u79bb\u7ebfRL\u7b97\u6cd5\u7684\u4e24\u4e2a\u5f3a\u9650\u5236\uff0c\u7279\u522b\u662fRegORL\u3002\u8fd9\u4e9b\u6280\u672f\u5305\u62ec\uff1a\u57fa\u4e8e\u5f62\u5f0f\u8bed\u8a00\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u4f2a\u5ea6\u91cf\uff0c\u6d88\u9664\u4e86\u5bf9$L_\\infty^\\mathsf{p}$-\u53ef\u533a\u5206\u6027\u53c2\u6570\u7684\u4f9d\u8d56\u6027\u95ee\u9898\uff1b\u4ee5\u53ca\u91c7\u7528Count-Min-Sketch\uff08CMS\uff09\u800c\u975e\u7b80\u5355\u7684\u8ba1\u6570\u65b9\u6cd5\u3002\u524d\u8005\u51cf\u5c11\u4e86\u5728\u8bed\u8a00\u7406\u8bba\u672f\u8bed\u4e2d\u5177\u6709\u4f4e\u590d\u6742\u5ea6\u73af\u5883\u6240\u9700\u7684\u6837\u672c\u6570\u91cf\uff0c\u540e\u8005\u7f13\u89e3\u4e86\u957f\u89c4\u5212\u8303\u56f4\u7684\u5185\u5b58\u9700\u6c42\u3002\u6211\u4eec\u63a8\u5bfc\u4e86\u4e0e\u8fd9\u4e9b\u6280\u672f\u76f8\u5173\u7684PAC\u6837\u672c\u590d\u6742\u5ea6\u754c\u9650\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u3002 | Ahana Deb | PDF | N/A | Tractable Offline Learning of Regular Decision Processes | This work studies offline Reinforcement Learning (RL) in a class of non-Markovian environments called Regular Decision Processes (RDPs). In RDPs, the unknown dependency of future observations and rewards from the past interactions can be captured by some hidden finite-state automaton. For this reason, many RDP algorithms first reconstruct this unknown dependency using automata learning techniques. In this paper, we show that it is possible to overcome two strong limitations of previous offline RL algorithms for RDPs, notably RegORL. This can be accomplished via the introduction of two original techniques: the development of a new pseudometric based on formal languages, which removes a problematic dependency on $L_\\infty^\\mathsf{p}$-distinguishability parameters, and the adoption of Count-Min-Sketch (CMS), instead of naive counting. The former reduces the number of samples required in environments that are characterized by a low complexity in language-theoretic terms. The latter alleviates the memory requirements for long planning horizons. We derive the PAC sample complexity bounds associated to each of these techniques, and we validate the approach experimentally. | | \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7528\u4e8e\u81ea\u52a8\u5316\u5143\u80de\u81ea\u52a8\u673a\u5206\u7c7b | \u65f6\u7a7a\u56fe\u4e2d\u7684\u7ec6\u80de\u81ea\u52a8\u673a\uff08CA\uff09\u7684\u6d8c\u73b0\u52a8\u529b\u5b66\u901a\u5e38\u901a\u8fc7\u82e5\u5e72\u884c\u4e3a\u7c7b\u522b\u6765\u7ec4\u7ec7\u3002\u867d\u7136\u57fa\u672cCA\u7684\u5206\u7c7b\u662f\u53ef\u884c\u7684\u4e14\u5df2\u6709\u6df1\u5165\u7814\u7a76\uff0c\u4f46\u975e\u57fa\u672cCA\u901a\u5e38\u8fc7\u4e8e\u591a\u6837\u548c\u7e41\u591a\uff0c\u96be\u4ee5\u624b\u52a8\u8fdb\u884c\u8be6\u5c3d\u5206\u7c7b\u3002\u5728\u672c\u7ae0\u4e2d\uff0c\u6211\u4eec\u5c06\u65f6\u7a7a\u56fe\u89c6\u4e3a\u6570\u5b57\u56fe\u50cf\uff0c\u5e76\u5b9e\u65bd\u7b80\u5355\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6280\u672f\uff0c\u4ee5\u81ea\u52a8\u5c06\u57fa\u672c\u7ec6\u80de\u81ea\u52a8\u673a\u5206\u7c7b\u4e3a\u4e94\u4e2aLi-Packard\u7c7b\u522b\u3002\u7279\u522b\u662f\uff0c\u6211\u4eec\u5411\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u63d0\u51fa\u4e00\u4e2a\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\uff0c\u4f7f\u5176\u80fd\u591f\u63a8\u5e7f\u5230\u975e\u57fa\u672cCA\u3002\u5982\u679c\u6211\u4eec\u5e0c\u671b\u8fd9\u6837\u505a\uff0c\u6211\u4eec\u5fc5\u987b\u5c06\u7b97\u6cd5\u7684\u5173\u6ce8\u70b9\u4ece\u5e95\u5c42\u201c\u5fae\u89c2\u201d\u5c40\u90e8\u66f4\u65b0\u8f6c\u79fb\u5f00\u3002\u6211\u4eec\u9996\u5148\u5c55\u793a\uff0c\u5148\u524d\u5f00\u53d1\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5b9e\u9645\u4e0a\u5df2\u88ab\u8bad\u7ec3\u7528\u4e8e\u8bc6\u522b\u5c40\u90e8\u66f4\u65b0\u89c4\u5219\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u5173\u6ce8\u4e0e\u7279\u5b9a\u884c\u4e3a\u7c7b\u522b\u76f8\u5173\u7684\u4e2d\u89c2\u6a21\u5f0f\u3002\u901a\u8fc7\u5408\u7406\u8bbe\u8ba1\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4ee5\u53ca\u591a\u79cd\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u6211\u4eec\u968f\u540e\u63d0\u51fa\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u51e0\u4e4e\u5b8c\u7f8e\u5730\u8bc6\u522b\u884c\u4e3a\u7c7b\u522b\uff0c\u800c\u4e0d\u5fc5\u9996\u5148\u8bc6\u522b\u5e95\u5c42\u5fae\u89c2\u52a8\u529b\u5b66\u3002 | Michiel Rollier | PDF | N/A | Convolutional Neural Networks for Automated Cellular Automaton Classification | The emergent dynamics in spacetime diagrams of cellular automata (CAs) is often organised by means of a number of behavioural classes. Whilst classification of elementary CAs is feasible and well-studied, non-elementary CAs are generally too diverse and numerous to exhaustively classify manually. In this chapter we treat the spacetime diagram as a digital image, and implement simple computer vision techniques to perform an automated classification of elementary cellular automata into the five Li-Packard classes. In particular, we present a supervised learning task to a convolutional neural network, in such a way that it may be generalised to non-elementary CAs. If we want to do so, we must divert the algorithm's focus away from the underlying 'microscopic' local updates. We first show that previously developed deep learning approaches have in fact been trained to identify the local update rule, rather than directly focus on the mesoscopic patterns that are associated with the particular behavioural classes. By means of a well-argued neural network design, as well as a number of data augmentation techniques, we then present a convolutional neural network that performs nearly perfectly at identifying the behavioural class, without necessarily first identifying the underlying microscopic dynamics. | | \u5b8c\u6574\u4e14\u9ad8\u6548\u76843D\u70b9\u914d\u7f6e\u534f\u53d8\u91cf\u53ca\u5176\u5728\u5206\u5b50\u91cf\u5b50\u6027\u8d28\u5b66\u4e60\u4e2d\u7684\u5e94\u7528 | \u5728\u5229\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5316\u5206\u5b50\u7684\u7269\u7406\u6027\u8d28\u65f6\uff0c\u5f15\u5165$SO(3)$\u534f\u53d8\u6027\u662f\u53ef\u53d6\u7684\u3002\u5c3d\u7ba1\u57fa\u4e8e\u4f4e\u4f53\u9636\u7279\u5f81\u7684\u6b64\u7c7b\u6a21\u578b\u5e76\u4e0d\u5b8c\u5907\uff0c\u6211\u4eec\u4e3a\u9ad8\u9636\u65b9\u6cd5\u5236\u5b9a\u4e86\u5e76\u8bc1\u660e\u4e86\u666e\u904d\u7684\u5b8c\u5907\u6027\u6027\u8d28\uff0c\u5e76\u8868\u660e\u8fd9\u4e9b\u7279\u5f81\u4e2d\u7684$6k-5$\u4e2a\u8db3\u4ee5\u6db5\u76d6\u6700\u591a$k$\u4e2a\u539f\u5b50\u3002\u6211\u4eec\u8fd8\u53d1\u73b0\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4e2d\u5e38\u7528\u7684Clebsch--Gordan\u8fd0\u7b97\u53ef\u4ee5\u88ab\u77e9\u9635\u4e58\u6cd5\u6240\u53d6\u4ee3\uff0c\u800c\u4e0d\u4f1a\u727a\u7272\u5b8c\u5907\u6027\uff0c\u4ece\u800c\u5c06\u7279\u5f81\u5ea6\u6570\u7684\u7f29\u653e\u4ece$O(l^6)$\u964d\u4f4e\u5230$O(l^3)$\u3002\u6211\u4eec\u5c06\u6b64\u5e94\u7528\u4e8e\u91cf\u5b50\u5316\u5b66\uff0c\u4f46\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u666e\u904d\u9002\u7528\u4e8e\u6d89\u53ca\u4e09\u7ef4\u70b9\u914d\u7f6e\u7684\u95ee\u9898\u3002 | Hartmut Maennel | PDF | N/A | Complete and Efficient Covariants for 3D Point Configurations with Application to Learning Molecular Quantum Properties | When modeling physical properties of molecules with machine learning, it is desirable to incorporate $SO(3)$-covariance. While such models based on low body order features are not complete, we formulate and prove general completeness properties for higher order methods, and show that $6k-5$ of these features are enough for up to $k$ atoms. We also find that the Clebsch--Gordan operations commonly used in these methods can be replaced by matrix multiplications without sacrificing completeness, lowering the scaling from $O(l^6)$ to $O(l^3)$ in the degree of the features. We apply this to quantum chemistry, but the proposed methods are generally applicable for problems involving 3D point configurations. | | \u9762\u5411\u4efb\u52a1\u7684\u56fe\u6570\u636e\u901a\u4fe1\uff1a\u4e00\u79cd\u56fe\u4fe1\u606f\u74f6\u9888\u65b9\u6cd5 | \u56fe\u6570\u636e\u5728\u77e5\u8bc6\u8868\u793a\u548c\u793e\u4f1a\u7f51\u7edc\u7b49\u9886\u57df\u81f3\u5173\u91cd\u8981\uff0c\u901a\u5e38\u6d89\u53ca\u5177\u6709\u5927\u91cf\u8282\u70b9\u548c\u8fb9\u7684\u5e9e\u5927\u7f51\u7edc\u3002\u7531\u4e8e\u5176\u89c4\u6a21\u548c\u7279\u5b9a\u4efb\u52a1\u4e2d\u7684\u5197\u4f59\u6027\uff0c\u4f20\u8f93\u8fd9\u4e9b\u56fe\u6570\u636e\u53ef\u80fd\u6548\u7387\u6781\u4f4e\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u53d6\u4e00\u4e2a\u66f4\u5c0f\u3001\u4e13\u6ce8\u4e8e\u4efb\u52a1\u7684\u5b50\u56fe\uff0c\u8be5\u5b50\u56fe\u5728\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u7684\u540c\u65f6\u4fdd\u7559\u5173\u952e\u4fe1\u606f\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u548c\u56fe\u4fe1\u606f\u74f6\u9888\uff08GIB\uff09\u539f\u7406\uff0c\u521b\u5efa\u9002\u5408\u4f20\u8f93\u7684\u7d27\u51d1\u3001\u4fe1\u606f\u4e30\u5bcc\u4e14\u7a33\u5065\u7684\u56fe\u8868\u793a\u3002\u6311\u6218\u5728\u4e8e\u56fe\u6570\u636e\u7684\u4e0d\u89c4\u5219\u7ed3\u6784\uff0c\u4f7f\u5f97GIB\u4f18\u5316\u53d8\u5f97\u590d\u6742\u3002\u6211\u4eec\u901a\u8fc7\u63a8\u5bfc\u76ee\u6807\u51fd\u6570\u7684\u4e00\u4e2a\u53ef\u5904\u7406\u7684\u53d8\u5206\u4e0a\u754c\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63d0\u51fa\u4e86VQ-GIB\u673a\u5236\uff0c\u7ed3\u5408\u5411\u91cf\u91cf\u5316\uff08VQ\uff09\u5c06\u5b50\u56fe\u8868\u793a\u8f6c\u6362\u4e3a\u79bb\u6563\u7684\u7801\u672c\u5e8f\u5217\uff0c\u4e0e\u73b0\u6709\u7684\u6570\u5b57\u901a\u4fe1\u7cfb\u7edf\u517c\u5bb9\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u57fa\u4e8eGIB\u7684\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u901a\u4fe1\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u5173\u952e\u4fe1\u606f\u3002\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u901a\u4fe1\u4fe1\u9053\u4e0a\u8868\u73b0\u51fa\u7a33\u5065\u7684\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u8fde\u7eed\u548c\u79bb\u6563\u7cfb\u7edf\u3002 | Shujing Li | PDF | N/A | Task-Oriented Communication for Graph Data: A Graph Information Bottleneck Approach | Graph data, essential in fields like knowledge representation and social networks, often involves large networks with many nodes and edges. Transmitting these graphs can be highly inefficient due to their size and redundancy for specific tasks. This paper introduces a method to extract a smaller, task-focused subgraph that maintains key information while reducing communication overhead. Our approach utilizes graph neural networks (GNNs) and the graph information bottleneck (GIB) principle to create a compact, informative, and robust graph representation suitable for transmission. The challenge lies in the irregular structure of graph data, making GIB optimization complex. We address this by deriving a tractable variational upper bound for the objective function. Additionally, we propose the VQ-GIB mechanism, integrating vector quantization (VQ) to convert subgraph representations into a discrete codebook sequence, compatible with existing digital communication systems. Our experiments show that this GIB-based method significantly lowers communication costs while preserving essential task-related information. The approach demonstrates robust performance across various communication channels, suitable for both continuous and discrete systems. | | \u6c60\u5316\u548c\u6ce8\u610f\u529b\uff1a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5d4c\u5165\u6a21\u578b\u6709\u54ea\u4e9b\u6709\u6548\u8bbe\u8ba1\uff1f | \u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u663e\u8457\u8fdb\u5c55\uff0c\u50ac\u751f\u4e86\u5927\u91cf\u57fa\u4e8eLLM\u7684\u5d4c\u5165\u6a21\u578b\u7814\u7a76\u3002\u5c3d\u7ba1\u8fd9\u4e9b\u6a21\u578b\u901a\u8fc7\u91c7\u7528\u4e0d\u540c\u7684\u6c60\u5316\u548c\u6ce8\u610f\u529b\u7b56\u7565\uff0c\u5728\u516c\u5f00\u7684\u5d4c\u5165\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4f46\u5173\u4e8e\u4ec0\u4e48\u6784\u6210\u4e86\u6709\u6548\u7684LLM\u5d4c\u5165\u6a21\u578b\u8bbe\u8ba1\u7684\u7591\u95ee\u4f9d\u7136\u5b58\u5728\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6a21\u578b\u5f80\u5f80\u5728\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f7f\u7528\u4e0d\u540c\u7684LLM\u57fa\u7840\u6a21\u578b\u6216\u8bad\u7ec3\u8bbe\u7f6e\u3002\u6b64\u5916\uff0c\u516c\u5f00\u5d4c\u5165\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8bc4\u4f30\u5f80\u5f80\u672a\u80fd\u62a5\u544a\u7edf\u8ba1\u663e\u8457\u6027\uff0c\u8fd9\u4f7f\u5f97\u786e\u5b9a\u54ea\u4e9b\u8bbe\u8ba1\u771f\u6b63\u6709\u52a9\u4e8e\u6700\u7ec8\u6027\u80fd\u53d8\u5f97\u56f0\u96be\u3002\u8fd9\u7ed9\u5bfb\u6c42\u4f18\u5316LLM\u5d4c\u5165\u6a21\u578b\u8bad\u7ec3\u65b9\u6848\u7684\u4ece\u4e1a\u8005\u5e26\u6765\u4e86\u590d\u6742\u6027\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u4f7f\u7528\u76f8\u540c\u7684\u8bad\u7ec3\u6570\u636e\u548c\u57fa\u7840\u6a21\u578b\uff0c\u4f46\u91c7\u7528\u4e0d\u540c\u7684\u6c60\u5316\u548c\u6ce8\u610f\u529b\u7b56\u7565\uff0c\u8bad\u7ec3\u4e86\u4e00\u7cfb\u5217LLM\u5d4c\u5165\u6a21\u578b\uff0c\u8fdb\u884c\u4e86\u4e00\u6b21\u5927\u89c4\u6a21\u5b9e\u9a8c\u3002\u7ed3\u679c\u663e\u793a\uff0c\u6ca1\u6709\u4e00\u79cd\u7b56\u7565\u662f\u4e07\u80fd\u7684\uff1a\u5c3d\u7ba1\u53cc\u5411\u6ce8\u610f\u529b\u548c\u989d\u5916\u7684\u53ef\u8bad\u7ec3\u6c60\u5316\u5c42\u5728\u6587\u672c\u76f8\u4f3c\u6027\u548c\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u805a\u7c7b\u548c\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u5b83\u4eec\u5e76\u672a\u663e\u8457\u8d85\u8d8a\u50cfEOS-last token\u6c60\u5316\u548c\u9ed8\u8ba4\u56e0\u679c\u6ce8\u610f\u529b\u8fd9\u6837\u7684\u7b80\u5355\u8bbe\u8ba1\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6c60\u5316\u7b56\u7565\u2014\u2014\u591a\u5c42\u53ef\u8bad\u7ec3\u6c60\u5316\uff0c\u8be5\u7b56\u7565\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u7f51\u7edc\u8f6c\u6362\u6240\u6709\u9690\u85cf\u5c42\u7684\u8f93\u51fa\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u6700\u540e\u4e00\u5c42\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u6587\u672c\u76f8\u4f3c\u6027\u548c\u68c0\u7d22\u4efb\u52a1\u4e2d\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u7684\u6c60\u5316\u65b9\u6cd5\uff0c\u663e\u793a\u51fa\u7edf\u8ba1\u4e0a\u7684\u4f18\u8d8a\u6027\u3002\u603b\u4f53\u800c\u8a00\uff0c\u672c\u6587\u63ed\u793a\u4e86LLM\u5d4c\u5165\u6a21\u578b\u7684\u6709\u6548\u8bad\u7ec3\u7b56\u7565\u3002 | Yixuan Tang | PDF | N/A | Pooling And Attention: What Are Effective Designs For LLm-Based Embedding Models? | The significant advancements of Large Language Models (LLMs) in generative tasks have led to a growing body of work exploring LLM-based embedding models. While these models, employing different pooling and attention strategies, have achieved state-of-the-art performance on public embedding benchmarks, questions still arise about what constitutes an effective design for LLM-based embedding models. However, these models are often trained on different datasets, using different LLM base models or training settings. Moreover, evaluations on public embedding benchmarks often fail to report statistical significance, making it difficult to determine which designs truly contribute to final performance. This complicates the process for practitioners seeking optimal training recipes for LLM-based embedding models. In this study, we conduct a large-scale experiment by training a series of LLM-based embedding models using the same training data and base model but differing in their pooling and attention strategies. The results show that there is no one-size-fits-all solution: while bidirectional attention and an additional trainable pooling layer outperform in text similarity and information retrieval tasks, they do not significantly surpass simpler designs like EOS-last token pooling and default causal attention in clustering and classification tasks. Furthermore, we propose a new pooling strategy, Multi-Layers Trainable Pooling, which transforms the outputs of all hidden layers, rather than just the last layer, using a cross-attention network. This method proves to be statistically superior in text similarity and retrieval tasks compared to existing pooling methods. Overall, this paper sheds light on effective training strategies for LLM-based embedding models. | | \u5229\u7528\u671f\u520a\u5f71\u54cd\u6307\u6807\u8fdb\u884c\u751f\u7269\u533b\u5b66\u9886\u57df\u9002\u5e94\u7684\u9884\u8bad\u7ec3\u6570\u636e\u9009\u62e9 | \u9886\u57df\u9002\u5e94\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u7684\u8868\u73b0\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u751f\u7269\u533b\u5b66\u9886\u57df\u5c24\u4e3a\u5e38\u89c1\uff0c\u8be5\u9886\u57df\u5b9a\u671f\u53d1\u5e03\u5927\u91cf\u79d1\u5b66\u6587\u7ae0\u3002PubMed\u4f5c\u4e3a\u4e00\u4e2a\u91cd\u8981\u7684\u6587\u672c\u8bed\u6599\u5e93\uff0c\u5728\u751f\u7269\u533b\u5b66\u9886\u57df\u4e2d\u7ecf\u5e38\u88ab\u4f7f\u7528\u3002\u672c\u7814\u7a76\u7684\u4e3b\u8981\u76ee\u6807\u662f\u63a2\u8ba8\u901a\u8fc7\u4f7f\u7528\u7279\u5b9a\u7684\u8d28\u91cf\u6307\u6807\u5bf9\u9884\u8bad\u7ec3\u6570\u636e\u96c6\u8fdb\u884c\u4f18\u5316\uff0c\u662f\u5426\u80fd\u63d0\u5347\u6700\u7ec8\u6a21\u578b\u7684\u6027\u80fd\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u91c7\u7528\u4e86\u4e24\u79cd\u7b80\u5355\u7684\u671f\u520a\u5f71\u54cd\u6307\u6807\uff0c\u5e76\u901a\u8fc7\u5728PubMed\u8bad\u7ec3\u96c6\u7684\u4e0d\u540c\u5b50\u96c6\u4e0a\u6301\u7eed\u9884\u8bad\u7ec3BERT\uff0c\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u5b9e\u9a8c\u3002\u968f\u540e\uff0c\u6211\u4eec\u5728BLURB\u57fa\u51c6\u7684\u751f\u7269\u533b\u5b66\u8bed\u8a00\u7406\u89e3\u4efb\u52a1\u4e0a\u8bc4\u4f30\u4e86\u6240\u5f97\u6a21\u578b\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u671f\u520a\u5f71\u54cd\u6307\u6807\u8fdb\u884c\u526a\u679d\u5e76\u4e0d\u9ad8\u6548\u3002\u4f46\u6211\u4eec\u4e5f\u53d1\u73b0\uff0c\u4f7f\u7528\u8f83\u5c11\u7684\u6458\u8981\u8fdb\u884c\u9884\u8bad\u7ec3\uff08\u4f46\u4fdd\u6301\u76f8\u540c\u7684\u8bad\u7ec3\u6b65\u9aa4\uff09\u5e76\u4e0d\u4e00\u5b9a\u4f1a\u964d\u4f4e\u6700\u7ec8\u6a21\u578b\u7684\u6027\u80fd\u3002 | Mathieu La\u00ef-king | PDF | N/A | Pre-training data selection for biomedical domain adaptation using journal impact metrics | Domain adaptation is a widely used method in natural language processing (NLP) to improve the performance of a language model within a specific domain. This method is particularly common in the biomedical domain, which sees regular publication of numerous scientific articles. PubMed, a significant corpus of text, is frequently used in the biomedical domain. The primary objective of this study is to explore whether refining a pre-training dataset using specific quality metrics for scientific papers can enhance the performance of the resulting model. To accomplish this, we employ two straightforward journal impact metrics and conduct experiments by continually pre-training BERT on various subsets of the complete PubMed training set, we then evaluate the resulting models on biomedical language understanding tasks from the BLURB benchmark. Our results show that pruning using journal impact metrics is not efficient. But we also show that pre-training using fewer abstracts (but with the same number of training steps) does not necessarily decrease the resulting model's performance. | | \u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\u611f\u77e5\u6a21\u578b\u63d0\u53d6\u653b\u51fb | \u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u6a21\u578b\u63d0\u53d6\u653b\u51fb\uff08MEAs\uff09\u8fd1\u671f\u53d7\u5230\u4e86\u8d8a\u6765\u8d8a\u591a\u7684\u7814\u7a76\u5173\u6ce8\u3002\u73b0\u6709\u7684\u5bf9LLMs\u7684\u653b\u51fb\u65b9\u6cd5\u7ee7\u627f\u4e86\u4e3a\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNNs\uff09\u8bbe\u8ba1\u7684\u63d0\u53d6\u7b56\u7565\uff0c\u4f46\u5374\u5ffd\u7565\u4e86MEA\u4e0eLLMs\u5bf9\u9f50\u4efb\u52a1\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u4ece\u800c\u5bfc\u81f4\u653b\u51fb\u6548\u679c\u4e0d\u4f73\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u5c40\u90e8\u5f3a\u5316\u84b8\u998f\uff08Locality Reinforced Distillation, LoRD\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u4e13\u4e3aLLMs\u8bbe\u8ba1\u7684\u65b0\u578b\u6a21\u578b\u63d0\u53d6\u653b\u51fb\u7b97\u6cd5\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7b56\u7565\u68af\u5ea6\u98ce\u683c\u8bad\u7ec3\u4efb\u52a1\uff0c\u5229\u7528\u53d7\u5bb3\u6a21\u578b\u7684\u54cd\u5e94\u4f5c\u4e3a\u4fe1\u53f7\u6765\u6307\u5bfc\u5c40\u90e8\u6a21\u578b\u504f\u597d\u7684\u6784\u5efa\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\uff1ai) LoRD\u5728MEA\u4e2d\u7684\u6536\u655b\u8fc7\u7a0b\u4e0eLLMs\u7684\u5bf9\u9f50\u4e00\u81f4\uff1bii) LoRD\u901a\u8fc7\u57fa\u4e8e\u63a2\u7d22\u7684\u7a83\u53d6\uff0c\u80fd\u591f\u5728\u964d\u4f4e\u67e5\u8be2\u590d\u6742\u5ea6\u7684\u540c\u65f6\u7f13\u89e3\u6c34\u5370\u4fdd\u62a4\u3002\u5728\u7279\u5b9a\u9886\u57df\u7684\u63d0\u53d6\u5b9e\u9a8c\u4e2d\uff0c\u901a\u8fc7\u8003\u5bdf\u5bf9\u5404\u79cd\u6700\u5148\u8fdb\u7684\u5546\u4e1aLLMs\u7684\u63d0\u53d6\u6548\u679c\uff0c\u8bc1\u660e\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002 | Zi Liang | PDF | N/A | Alignment-Aware Model Extraction Attacks on Large Language Models | Model extraction attacks (MEAs) on large language models (LLMs) have received increasing research attention lately. Existing attack methods on LLMs inherit the extraction strategies from those designed for deep neural networks (DNNs) yet neglect the inconsistency of training tasks between MEA and LLMs' alignments. As such, they result in poor attack performances. To tackle this issue, we present Locality Reinforced Distillation (LoRD), a novel model extraction attack algorithm specifically for LLMs. In particular, we design a policy-gradient-style training task, which utilizes victim models' responses as a signal to guide the crafting of preference for the local model. Theoretical analysis has shown that i) LoRD's convergence procedure in MEAs is consistent with the alignments of LLMs, and ii) LoRD can reduce query complexity while mitigating watermark protection through exploration-based stealing. Extensive experiments on domain-specific extractions demonstrate the superiority of our method by examining the extraction of various state-of-the-art commercial LLMs. | | \u4e00\u79cd\u5229\u7528\u8de8\u8bed\u8a00\u53e5\u5b50\u8868\u793a\u63d0\u5347\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5 | \u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u7684\u673a\u5668\u7ffb\u8bd1\u9762\u4e34\u663e\u8457\u6311\u6218\uff0c\u4e3b\u8981\u6e90\u4e8e\u5e73\u884c\u8bed\u6599\u5e93\u548c\u8bed\u8a00\u8d44\u6e90\u7684\u532e\u4e4f\u3002\u672c\u7814\u7a76\u805a\u7126\u4e8e\u82f1\u8bed-\u9a6c\u62c9\u5730\u8bed\u5bf9\u7684\u6848\u4f8b\uff0c\u73b0\u6709\u6570\u636e\u96c6\u5b58\u5728\u663e\u8457\u566a\u97f3\uff0c\u4e25\u91cd\u5f71\u54cd\u4e86\u673a\u5668\u7ffb\u8bd1\u6a21\u578b\u7684\u6027\u80fd\u3002\u4e3a\u7f13\u89e3\u6570\u636e\u8d28\u91cf\u95ee\u9898\u7684\u5f71\u54cd\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8de8\u8bed\u8a00\u53e5\u5b50\u8868\u793a\u7684\u6570\u636e\u8fc7\u6ee4\u65b9\u6cd5\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5229\u7528\u591a\u8bed\u8a00SBERT\u6a21\u578b\u6765\u7b5b\u9009\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u95ee\u9898\u7ffb\u8bd1\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u91c7\u7528IndicSBERT\u76f8\u4f3c\u6027\u6a21\u578b\u8bc4\u4f30\u539f\u59cb\u53e5\u5b50\u548c\u7ffb\u8bd1\u53e5\u5b50\u4e4b\u95f4\u7684\u8bed\u4e49\u7b49\u4ef7\u6027\uff0c\u4ece\u800c\u4fdd\u7559\u8bed\u8a00\u4e0a\u6b63\u786e\u7684\u7ffb\u8bd1\uff0c\u540c\u65f6\u5254\u9664\u5b58\u5728\u91cd\u5927\u504f\u5dee\u7684\u5b9e\u4f8b\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528IndicSBERT\u8fdb\u884c\u8fc7\u6ee4\u540e\uff0c\u7ffb\u8bd1\u8d28\u91cf\u76f8\u8f83\u4e8e\u57fa\u7ebf\u6709\u663e\u8457\u63d0\u5347\u3002\u8fd9\u5c55\u793a\u4e86\u8de8\u8bed\u8a00\u53e5\u5b50\u8868\u793a\u5982\u4f55\u5728\u8d44\u6e90\u6709\u9650\u7684\u673a\u5668\u7ffb\u8bd1\u573a\u666f\u4e2d\u51cf\u5c11\u9519\u8bef\u3002\u901a\u8fc7\u5c06\u591a\u8bed\u8a00\u53e5\u5b50BERT\u6a21\u578b\u6574\u5408\u5230\u7ffb\u8bd1\u6d41\u7a0b\u4e2d\uff0c\u672c\u7814\u7a76\u63a8\u52a8\u4e86\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u673a\u5668\u7ffb\u8bd1\u6280\u672f\u7684\u8fdb\u6b65\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u89e3\u51b3\u4e86\u82f1\u8bed-\u9a6c\u62c9\u5730\u8bed\u5bf9\u7684\u6311\u6218\uff0c\u8fd8\u4e3a\u5176\u4ed6\u4f4e\u8d44\u6e90\u8bed\u8a00\u7ffb\u8bd1\u4efb\u52a1\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u6846\u67b6\u3002 | Nidhi Kowtal | PDF | N/A | A Data Selection Approach for Enhancing Low Resource Machine Translation Using Cross-Lingual Sentence Representations | Machine translation in low-resource language pairs faces significant challenges due to the scarcity of parallel corpora and linguistic resources. This study focuses on the case of English-Marathi language pairs, where existing datasets are notably noisy, impeding the performance of machine translation models. To mitigate the impact of data quality issues, we propose a data filtering approach based on cross-lingual sentence representations. Our methodology leverages a multilingual SBERT model to filter out problematic translations in the training data. Specifically, we employ an IndicSBERT similarity model to assess the semantic equivalence between original and translated sentences, allowing us to retain linguistically correct translations while discarding instances with substantial deviations. The results demonstrate a significant improvement in translation quality over the baseline post-filtering with IndicSBERT. This illustrates how cross-lingual sentence representations can reduce errors in machine translation scenarios with limited resources. By integrating multilingual sentence BERT models into the translation pipeline, this research contributes to advancing machine translation techniques in low-resource environments. The proposed method not only addresses the challenges in English-Marathi language pairs but also provides a valuable framework for enhancing translation quality in other low-resource language translation tasks. | | \u5c11\u6837\u672c\u591a\u4efb\u52a1\u5b66\u4e60\u7ebf\u6027\u4e0d\u53d8\u7279\u5f81\u4e0e\u5143\u5b50\u7a7a\u95f4\u8ffd\u8e2a | \u6570\u636e\u7a00\u7f3a\u5bf9\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u548c\u4eba\u5de5\u667a\u80fd\u6784\u6210\u4e86\u4e25\u91cd\u5a01\u80c1\uff0c\u56e0\u4e3a\u5b83\u4eec\u7684\u5b9e\u9645\u6210\u529f\u901a\u5e38\u4f9d\u8d56\u4e8e\u5927\u6570\u636e\u96c6\u7684\u53ef\u7528\u6027\u3002\u7f13\u89e3\u6570\u636e\u4e0d\u8db3\u95ee\u9898\u7684\u4e00\u4e2a\u6709\u6548\u7b56\u7565\u662f\uff0c\u9996\u5148\u5728\u7814\u7a76\u8bbe\u8ba1\u9636\u6bb5\u5229\u7528\u6765\u81ea\u5176\u4ed6\u5728\u7814\u7a76\u8bbe\u8ba1\u4e0a\u5177\u6709\u4e00\u5b9a\u76f8\u4f3c\u6027\u7684\u6570\u636e\u6e90\u7684\u4fe1\u606f\uff0c\u7136\u540e\u5728\u5206\u6790\u9636\u6bb5\u91c7\u7528\u591a\u4efb\u52a1\u6216\u5143\u5b66\u4e60\u6846\u67b6\u3002\u672c\u6587\u91cd\u70b9\u7814\u7a76\u4e86\u591a\u4efb\u52a1\uff08\u6216\u591a\u6e90\uff09\u7ebf\u6027\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u7684\u7cfb\u6570\u5728\u4e0d\u540c\u4efb\u52a1\u4e4b\u95f4\u5171\u4eab\u4e00\u4e2a\u4e0d\u53d8\u7684\u4f4e\u79e9\u5206\u91cf\uff0c\u8fd9\u662f\u8fd1\u671f\u591a\u4efb\u52a1\u6216\u5143\u5b66\u4e60\u6587\u732e\u4e2d\u8003\u8651\u7684\u4e00\u79cd\u6d41\u884c\u7ed3\u6784\u5047\u8bbe\u3002\u5728\u6b64\u5047\u8bbe\u4e0b\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\uff0c\u79f0\u4e3a\u5143\u5b50\u7a7a\u95f4\u8ffd\u8e2a\uff08\u7b80\u79f0Meta-SP\uff09\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u8bc1\u660e\u6027\u5730\u5b66\u4e60\u4e0d\u540c\u4efb\u52a1\u5171\u4eab\u7684\u4e0d\u53d8\u5b50\u7a7a\u95f4\u3002\u5728\u591a\u4efb\u52a1\u6216\u5143\u5b66\u4e60\u7684\u8fd9\u79cd\u7406\u60f3\u5316\u8bbe\u7f6e\u4e0b\uff0c\u6211\u4eec\u5efa\u7acb\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u7b97\u6cd5\u548c\u7edf\u8ba1\u4fdd\u8bc1\u3002\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u6570\u503c\u5b9e\u9a8c\uff0c\u5c06Meta-SP\u4e0e\u51e0\u79cd\u7ade\u4e89\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5305\u62ec\u6d41\u884c\u7684\u3001\u73b0\u6210\u7684\u6a21\u578b\u4e0d\u53ef\u77e5\u5143\u5b66\u4e60\u7b97\u6cd5\uff0c\u5982ANIL\u3002\u8fd9\u4e9b\u5b9e\u9a8c\u8868\u660e\uff0cMeta-SP\u5728\u5404\u4e2a\u65b9\u9762\u90fd\u4f18\u4e8e\u7ade\u4e89\u65b9\u6cd5\u3002 | Chaozhi Zhang | PDF | N/A | Few-shot Multi-Task Learning of Linear Invariant Features with Meta Subspace Pursuit | Data scarcity poses a serious threat to modern machine learning and artificial intelligence, as their practical success typically relies on the availability of big datasets. One effective strategy to mitigate the issue of insufficient data is to first harness information from other data sources possessing certain similarities in the study design stage, and then employ the multi-task or meta learning framework in the analysis stage. In this paper, we focus on multi-task (or multi-source) linear models whose coefficients across tasks share an invariant low-rank component, a popular structural assumption considered in the recent multi-task or meta learning literature. Under this assumption, we propose a new algorithm, called Meta Subspace Pursuit (abbreviated as Meta-SP), that provably learns this invariant subspace shared by different tasks. Under this stylized setup for multi-task or meta learning, we establish both the algorithmic and statistical guarantees of the proposed method. Extensive numerical experiments are conducted, comparing Meta-SP against several competing methods, including popular, off-the-shelf model-agnostic meta learning algorithms such as ANIL. These experiments demonstrate that Meta-SP achieves superior performance over the competing methods in various aspects. | | \u7528\u4e8e\u589e\u5f3a\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u95ee\u9898\u4e2d\u795e\u7ecf\u5c40\u90e8\u641c\u7d22\u7684\u51b3\u7b56\u53d8\u6362\u5668 | \u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u95ee\u9898\uff08JSSP\uff09\u53ca\u5176\u6c42\u89e3\u7b97\u6cd5\u591a\u5e74\u6765\u5728\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u4e00\u76f4\u5907\u53d7\u5173\u6ce8\u3002\u8fd1\u5e74\u6765\uff0c\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u5728\u63a8\u8fdb\u73b0\u6709\u548c\u6784\u5efa\u65b0\u7684JSSP\u542f\u53d1\u5f0f\u89e3\u51b3\u65b9\u6848\u65b9\u9762\u53d1\u6325\u7740\u8d8a\u6765\u8d8a\u91cd\u8981\u7684\u4f5c\u7528\uff0c\u65e8\u5728\u5728\u66f4\u77ed\u7684\u8ba1\u7b97\u65f6\u95f4\u5185\u627e\u5230\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u57fa\u4e8e\u4e00\u79cd\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u4ee3\u7406\uff0c\u79f0\u4e3a\u795e\u7ecf\u5c40\u90e8\u641c\u7d22\uff08NLS\uff09\uff0c\u8be5\u4ee3\u7406\u80fd\u591f\u9ad8\u6548\u4e14\u6709\u6548\u5730\u63a7\u5236JSSP\u4e0a\u7684\u5927\u89c4\u6a21\u5c40\u90e8\u90bb\u57df\u641c\u7d22\u3002\u7279\u522b\u5730\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3\u6709\u7d20\u7684NLS\u4ee3\u7406\u6240\u91c7\u53d6\u7684\u641c\u7d22\u8f68\u8ff9\u6765\u8bad\u7ec3\u51b3\u7b56\u8f6c\u6362\u5668\uff08DT\uff09\u7b97\u6cd5\uff0c\u4ee5\u8fdb\u4e00\u6b65\u6539\u8fdb\u6240\u5b66\u5230\u7684\u51b3\u7b56\u5e8f\u5217\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDT\u6210\u529f\u5730\u5b66\u4e60\u4e86\u4e0eNLS\u4ee3\u7406\u4e0d\u540c\u7684\u5c40\u90e8\u641c\u7d22\u7b56\u7565\uff0c\u5e76\u4e14\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e9b\u7b56\u7565\u66f4\u4e3a\u6709\u6548\u3002\u5728\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u53ef\u63a5\u53d7\u7684\u641c\u7d22\u6240\u9700\u8ba1\u7b97\u65f6\u95f4\u4e4b\u95f4\u7684\u6743\u8861\u65b9\u9762\uff0cDT\u5728\u5141\u8bb8\u66f4\u957f\u8ba1\u7b97\u65f6\u95f4\u7684\u5e94\u7528\u573a\u666f\u4e2d\u8868\u73b0\u5c24\u4e3a\u4f18\u8d8a\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u5b83\u901a\u8fc7\u6bcf\u4e00\u6b65\u66f4\u597d\u7684\u51b3\u7b56\u8d28\u91cf\u5f25\u8865\u4e86\u6bcf\u4e2a\u641c\u7d22\u6b65\u9aa4\u6240\u9700\u66f4\u957f\u7684\u63a8\u7406\u65f6\u95f4\uff0c\u8fd9\u662f\u7531\u4e8e\u66f4\u5927\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u6240\u5bfc\u81f4\u7684\u3002\u56e0\u6b64\uff0cDT\u5728ML\u589e\u5f3a\u641c\u7d22\u7684JSSP\u6c42\u89e3\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002 | Constantin Waubert de Puiseau | PDF | N/A | Decision Transformer for Enhancing Neural Local Search on the Job Shop Scheduling Problem | The job shop scheduling problem (JSSP) and its solution algorithms have been of enduring interest in both academia and industry for decades. In recent years, machine learning (ML) is playing an increasingly important role in advancing existing and building new heuristic solutions for the JSSP, aiming to find better solutions in shorter computation times. In this paper we build on top of a state-of-the-art deep reinforcement learning (DRL) agent, called Neural Local Search (NLS), which can efficiently and effectively control a large local neighborhood search on the JSSP. In particular, we develop a method for training the decision transformer (DT) algorithm on search trajectories taken by a trained NLS agent to further improve upon the learned decision-making sequences. Our experiments show that the DT successfully learns local search strategies that are different and, in many cases, more effective than those of the NLS agent itself. In terms of the tradeoff between solution quality and acceptable computational time needed for the search, the DT is particularly superior in application scenarios where longer computational times are acceptable. In this case, it makes up for the longer inference times required per search step, which are caused by the larger neural network architecture, through better quality decisions per step. Thereby, the DT achieves state-of-the-art results for solving the JSSP with ML-enhanced search. | | \u68c0\u6d4b\u591a\u6a21\u6001\u5185\u5bb9\u4e2d\u7684\u884c\u52a8\u547c\u5401\uff1a\u5bf92021\u5e74\u5fb7\u56fd\u8054\u90a6\u9009\u4e3e\u5728Instagram\u4e0a\u7684\u7ade\u9009\u6d3b\u52a8\u5206\u6790 | \u672c\u7814\u7a76\u63a2\u8ba8\u4e862021\u5e74\u5fb7\u56fdInstagram\u9009\u4e3e\u6d3b\u52a8\u4e2d\u884c\u52a8\u53f7\u53ec\uff08CTAs\uff09\u7684\u81ea\u52a8\u5316\u5206\u7c7b\uff0c\u4ee5\u589e\u8fdb\u5bf9\u793e\u4ea4\u5a92\u4f53\u52a8\u5458\u7b56\u7565\u7684\u7406\u89e3\u3002\u6211\u4eec\u4f7f\u7528\u7ecf\u8fc7\u5fae\u8c03\u7684BERT\u6a21\u578b\u548cOpenAI\u7684GPT-4\u6a21\u578b\uff0c\u5206\u6790\u4e86\u8d85\u8fc72,208\u4e2aInstagram\u6545\u4e8b\u548c712\u7bc7\u5e16\u5b50\u3002\u7ecf\u8fc7\u5408\u6210\u8bad\u7ec3\u6570\u636e\u5fae\u8c03\u7684BERT\u6a21\u578b\u8fbe\u5230\u4e860.93\u7684\u5b8f\u89c2F1\u5206\u6570\uff0c\u663e\u793a\u51fa\u5f3a\u5927\u7684\u5206\u7c7b\u6027\u80fd\u3002\u5206\u6790\u7ed3\u679c\u663e\u793a\uff0c49.58%\u7684Instagram\u5e16\u5b50\u548c10.64%\u7684\u6545\u4e8b\u5305\u542bCTAs\uff0c\u7a81\u663e\u4e86\u8fd9\u4e24\u79cd\u5185\u5bb9\u7c7b\u578b\u5728\u52a8\u5458\u7b56\u7565\u4e0a\u7684\u663e\u8457\u5dee\u5f02\u3002\u6b64\u5916\uff0c\u6211\u4eec\u53d1\u73b0FDP\u548c\u7eff\u515a\u5728\u5e16\u5b50\u4e2dCTAs\u7684\u666e\u904d\u6027\u6700\u9ad8\uff0c\u800cCDU\u548cCSU\u5219\u5728\u6545\u4e8b\u4e2d\u7684CTAs\u5360\u6bd4\u9886\u5148\u3002 | Michael Achmann-Denkler | PDF | N/A | Detecting Calls to Action in Multimodal Content: Analysis of the 2021 German Federal Election Campaign on Instagram | This study investigates the automated classification of Calls to Action (CTAs) within the 2021 German Instagram election campaign to advance the understanding of mobilization in social media contexts. We analyzed over 2,208 Instagram stories and 712 posts using fine-tuned BERT models and OpenAI's GPT-4 models. The fine-tuned BERT model incorporating synthetic training data achieved a macro F1 score of 0.93, demonstrating a robust classification performance. Our analysis revealed that 49.58% of Instagram posts and 10.64% of stories contained CTAs, highlighting significant differences in mobilization strategies between these content types. Additionally, we found that FDP and the Greens had the highest prevalence of CTAs in posts, whereas CDU and CSU led in story CTAs. | | \u53bb\u6df7\u6dc6\u56e0\u679c\u611f\u77e5\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u4ee5\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b | \u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6839\u636e\u4eba\u7c7b\u6307\u4ee4\u5904\u7406\u5404\u79cd\u4efb\u52a1\u65b9\u9762\u5c55\u793a\u4e86\u663e\u8457\u7684\u6548\u7387\uff0c\u4f46\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u6d89\u53ca\u63a8\u7406\u7684\u95ee\u9898\u4e0a\uff0c\u5982\u6570\u5b66\u6216\u7269\u7406\u95ee\u9898\uff0c\u5f80\u5f80\u65e0\u6cd5\u53d6\u5f97\u4ee4\u4eba\u6ee1\u610f\u7684\u7ed3\u679c\u3002\u8fd9\u79cd\u73b0\u8c61\u901a\u5e38\u5f52\u56e0\u4e8e\u8fd9\u4e9b\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u4e86\u5d4c\u5165\u5728\u6587\u672c\u4e2d\u7684\u77e5\u8bc6\uff0c\u8fd8\u662f\u4ec5\u4ec5\u5b66\u4f1a\u4e86\u590d\u5236\u4ee4\u724c\u5206\u5e03\u800c\u6ca1\u6709\u771f\u6b63\u7406\u89e3\u5185\u5bb9\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u6df1\u5165\u63a2\u8ba8\u4e86\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u65e8\u5728\u63d0\u5347LLMs\u7684\u63a8\u7406\u80fd\u529b\u3002\u9996\u5148\uff0c\u6211\u4eec\u901a\u8fc7\u5728\u6ce8\u610f\u529b\u548c\u8868\u793a\u5c42\u9762\u53ef\u89c6\u5316\u6587\u672c\u751f\u6210\u8fc7\u7a0b\uff0c\u6765\u63a2\u7a76\u6a21\u578b\u662f\u5426\u5177\u6709\u771f\u6b63\u7684\u63a8\u7406\u80fd\u529b\u3002\u63a5\u7740\uff0c\u6211\u4eec\u5c06LLMs\u7684\u63a8\u7406\u8fc7\u7a0b\u5f62\u5f0f\u5316\u4e3a\u4e00\u4e2a\u56e0\u679c\u6846\u67b6\uff0c\u4e3a\u6211\u4eec\u5728\u53ef\u89c6\u5316\u4e2d\u89c2\u5bdf\u5230\u7684\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6b63\u5f0f\u7684\u89e3\u91ca\u3002\u6700\u540e\uff0c\u57fa\u4e8e\u8fd9\u4e2a\u56e0\u679c\u6846\u67b6\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u53bb\u6df7\u6dc6\u56e0\u679c\u9002\u5e94\uff08Deconfounded Causal Adaptation, DCA\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u9f13\u52b1\u6a21\u578b\u63d0\u53d6\u4e00\u822c\u7684\u95ee\u9898\u89e3\u51b3\u6280\u80fd\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u4e0d\u540c\u95ee\u9898\uff0c\u6765\u589e\u5f3a\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5e76\u4e14\u4ec5\u75281.2M\u53ef\u8c03\u53c2\u6570\uff0c\u6211\u4eec\u5c31\u80fd\u53d6\u5f97\u4f18\u4e8e\u6216\u4e0e\u5176\u4ed6\u5fae\u8c03\u65b9\u6cd5\u76f8\u5f53\u7684\u7ed3\u679c\u3002\u8fd9\u8bc1\u660e\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u63d0\u9ad8LLMs\u6574\u4f53\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002 | Ruoyu Wang | PDF | N/A | Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs | Large Language Models (LLMs) have demonstrated remarkable efficiency in tackling various tasks based on human instructions, but recent studies reveal that these models often fail to achieve satisfactory results on questions involving reasoning, such as mathematics or physics questions. This phenomenon is usually attributed to the uncertainty regarding whether these models could genuinely comprehend the knowledge embedded in the text or merely learn to replicate the token distribution without a true understanding of the content. In this paper, we delve into this problem and aim to enhance the reasoning capabilities of LLMs. First, we investigate if the model has genuine reasoning capabilities by visualizing the text generation process at the attention and representation level. Then, we formulate the reasoning process of LLMs into a causal framework, which provides a formal explanation of the problems we observe in the visualization. Finally, building upon this causal framework, we propose Deconfounded Causal Adaptation (DCA), a novel parameter-efficient fine-tuning (PEFT) method to enhance the model's reasoning capabilities by encouraging the model to extract the general problem-solving skills and apply these skills to different questions. Experiments show that our method outperforms the baseline consistently across multiple benchmarks, and with only 1.2M tunable parameters, we achieve better or comparable results to other fine-tuning methods. This demonstrates the effectiveness and efficiency of our method in improving the overall accuracy and reliability of LLMs. | | \u4ece\u8ba1\u7b97\u89d2\u5ea6\u770b\u795e\u7ecf\u65f6\u95f4\u5c3a\u5ea6 | \u795e\u7ecf\u6d3b\u52a8\u7684\u65f6\u95f4\u5c3a\u5ea6\u5728\u4e0d\u540c\u8111\u533a\u548c\u540c\u4e00\u8111\u533a\u5185\u90e8\u90fd\u8868\u73b0\u51fa\u591a\u6837\u6027\uff0c\u5b9e\u9a8c\u89c2\u5bdf\u8868\u660e\u795e\u7ecf\u65f6\u95f4\u5c3a\u5ea6\u53cd\u6620\u4e86\u52a8\u6001\u73af\u5883\u4e2d\u7684\u4fe1\u606f\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u89c2\u5bdf\u5e76\u672a\u660e\u786e\u6307\u51fa\u795e\u7ecf\u65f6\u95f4\u5c3a\u5ea6\u662f\u5982\u4f55\u5f62\u6210\u7684\uff0c\u4e5f\u6ca1\u6709\u8bf4\u660e\u7279\u5b9a\u7684\u65f6\u95f4\u5c3a\u5ea6\u662f\u5426\u5bf9\u795e\u7ecf\u8ba1\u7b97\u548c\u8111\u529f\u80fd\u662f\u5fc5\u8981\u7684\u3002\u5728\u6b64\uff0c\u6211\u4eec\u4ece\u4e00\u4e2a\u4e92\u8865\u7684\u89d2\u5ea6\u51fa\u53d1\uff0c\u7efc\u5408\u4e86\u8ba1\u7b97\u65b9\u6cd5\u7684\u4e09\u4e2a\u65b9\u5411\uff0c\u5c06\u5e7f\u6cdb\u7684\u7ecf\u9a8c\u89c2\u5bdf\u63d0\u70bc\u6210\u5b9a\u91cf\u4e14\u53ef\u9a8c\u8bc1\u7684\u7406\u8bba\uff1a\u6211\u4eec\u56de\u987e\u4e86\uff08i\uff09\u6570\u636e\u5206\u6790\u65b9\u6cd5\u5982\u4f55\u8ba9\u6211\u4eec\u6355\u6349\u4e0d\u540c\u8bb0\u5f55\u6a21\u5f0f\u4e0b\u795e\u7ecf\u52a8\u529b\u5b66\u7684\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\uff0c\uff08ii\uff09\u8ba1\u7b97\u6a21\u578b\u5982\u4f55\u4e3a\u591a\u6837\u65f6\u95f4\u5c3a\u5ea6\u7684\u51fa\u73b0\u63d0\u4f9b\u673a\u5236\u6027\u89e3\u91ca\uff0c\u4ee5\u53ca\uff08iii\uff09\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u4efb\u52a1\u4f18\u5316\u6a21\u578b\u5982\u4f55\u63ed\u793a\u795e\u7ecf\u65f6\u95f4\u5c3a\u5ea6\u7684\u529f\u80fd\u76f8\u5173\u6027\u3002\u8fd9\u79cd\u7efc\u5408\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u7ed3\u5408\u5b9e\u8bc1\u53d1\u73b0\uff0c\u5c06\u63d0\u4f9b\u4e00\u4e2a\u66f4\u5168\u9762\u7684\u7406\u89e3\uff0c\u5373\u795e\u7ecf\u65f6\u95f4\u5c3a\u5ea6\u5982\u4f55\u6355\u6349\u8111\u7ed3\u6784\u3001\u52a8\u6001\u548c\u884c\u4e3a\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 | Roxana Zeraati | PDF | N/A | Neural timescales from a computational perspective | Timescales of neural activity are diverse across and within brain areas, and experimental observations suggest that neural timescales reflect information in dynamic environments. However, these observations do not specify how neural timescales are shaped, nor whether particular timescales are necessary for neural computations and brain function. Here, we take a complementary perspective and synthesize three directions where computational methods can distill the broad set of empirical observations into quantitative and testable theories: We review (i) how data analysis methods allow us to capture different timescales of neural dynamics across different recording modalities, (ii) how computational models provide a mechanistic explanation for the emergence of diverse timescales, and (iii) how task-optimized models in machine learning uncover the functional relevance of neural timescales. This integrative computational approach, combined with empirical findings, would provide a more holistic understanding of how neural timescales capture the relationship between brain structure, dynamics, and behavior. | | \u4f7f\u7528LSTM\u548cGRU\u795e\u7ecf\u7f51\u7edc\u5728\u4e9a\u9a6c\u900a\u5730\u533a\u5efa\u6a21\u6d3b\u8dc3\u706b\u707e | \u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7efc\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u5efa\u6a21\u548c\u9884\u6d4b\u5df4\u897f\u4e9a\u9a6c\u900a\u5730\u533a\u7531AQUA_M-T\u536b\u661f\u68c0\u6d4b\u5230\u7684\u706b\u70b9\u5386\u53f2\u65f6\u95f4\u5e8f\u5217\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u6df7\u5408\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08RNN\uff09\u6a21\u578b\uff0c\u7ed3\u5408\u957f\u77ed\u671f\u8bb0\u5fc6\uff08LSTM\uff09\u548c\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08GRU\uff09\u67b6\u6784\uff0c\u4ee5\u9884\u6d4b\u6bcf\u65e5\u68c0\u6d4b\u5230\u7684\u706b\u70b9\u7684\u6708\u5ea6\u7d2f\u79ef\u91cf\u3002\u6570\u636e\u6982\u8ff0\u663e\u793a\uff0c\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\uff0c\u5b58\u5728\u4e00\u81f4\u7684\u5b63\u8282\u6027\uff0c\u6bcf\u5e74\u7684\u706b\u70b9\u6700\u5927\u503c\u548c\u6700\u5c0f\u503c\u5f80\u5f80\u5728\u540c\u4e00\u65f6\u671f\u91cd\u590d\u51fa\u73b0\u3002\u4e3b\u8981\u76ee\u6807\u662f\u9a8c\u8bc1\u9884\u6d4b\u662f\u5426\u901a\u8fc7\u4e25\u683c\u7684\u7edf\u8ba1\u5206\u6790\u6355\u6349\u5230\u8fd9\u79cd\u56fa\u6709\u7684\u5b63\u8282\u6027\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\u4ed4\u7ec6\u7684\u6570\u636e\u51c6\u5907\u3001\u6a21\u578b\u914d\u7f6e\u548c\u4f7f\u7528\u4e24\u4e2a\u79cd\u5b50\u7684\u4ea4\u53c9\u9a8c\u8bc1\u8fdb\u884c\u8bad\u7ec3\uff0c\u786e\u4fdd\u6570\u636e\u80fd\u591f\u5f88\u597d\u5730\u6cdb\u5316\u5230\u6d4b\u8bd5\u548c\u9a8c\u8bc1\u96c6\uff0c\u5e76\u786e\u8ba4\u6a21\u578b\u53c2\u6570\u7684\u6536\u655b\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u6df7\u5408LSTM\u548cGRU\u6a21\u578b\u5728\u63d0\u524d12\u4e2a\u6708\u7684\u9884\u6d4b\u4e2d\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u6355\u6349\u590d\u6742\u65f6\u95f4\u6a21\u5f0f\u548c\u5efa\u6a21\u89c2\u6d4b\u65f6\u95f4\u5e8f\u5217\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u8fd9\u9879\u7814\u7a76\u663e\u8457\u4fc3\u8fdb\u4e86\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5728\u73af\u5883\u76d1\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u5728\u706b\u70b9\u9884\u6d4b\u65b9\u9762\u3002\u9664\u4e86\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u5916\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u8fd8\u7a81\u663e\u4e86\u9002\u5e94\u5176\u4ed6\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6311\u6218\u7684\u6f5c\u529b\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u548c\u81ea\u7136\u73b0\u8c61\u9884\u6d4b\u7684\u7814\u7a76\u548c\u5f00\u53d1\u5f00\u8f9f\u4e86\u65b0\u7684\u9014\u5f84\u3002\u5173\u952e\u8bcd\uff1a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u6df1\u5ea6\u5b66\u4e60\u3002 | Ramon Tavares | PDF | N/A | Neural Networks with LSTM and GRU in Modeling Active Fires in the Amazon | This study presents a comprehensive methodology for modeling and forecasting the historical time series of fire spots detected by the AQUA_M-T satellite in the Amazon, Brazil. The approach utilizes a mixed Recurrent Neural Network (RNN) model, combining Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) architectures to predict monthly accumulations of daily detected fire spots. A summary of the data revealed a consistent seasonality over time, with annual maximum and minimum fire spot values tending to repeat at the same periods each year. The primary objective is to verify whether the forecasts capture this inherent seasonality through rigorous statistical analysis. The methodology involved careful data preparation, model configuration, and training using cross-validation with two seeds, ensuring that the data generalizes well to the test and validation sets, and confirming the convergence of the model parameters. The results indicate that the mixed LSTM and GRU model offers improved accuracy in forecasting 12 months ahead, demonstrating its effectiveness in capturing complex temporal patterns and modeling the observed time series. This research significantly contributes to the application of deep learning techniques in environmental monitoring, specifically in fire spot forecasting. In addition to improving forecast accuracy, the proposed approach highlights the potential for adaptation to other time series forecasting challenges, opening new avenues for research and development in machine learning and natural phenomenon prediction. Keywords: Time Series Forecasting, Recurrent Neural Networks, Deep Learning. | | \u57fa\u4e8e\u8d85\u58f0\u4f20\u611f\u5668\u548c\u901f\u7387\u7f16\u7801\u7684\u4f4e\u6210\u672c\u5b9e\u65f6\u5c16\u5cf0\u969c\u788d\u7269\u68c0\u6d4b\u7cfb\u7edf | \u81ea\u79fb\u52a8\u673a\u5668\u4eba\u95ee\u4e16\u4ee5\u6765\uff0c\u969c\u788d\u7269\u68c0\u6d4b\u4e00\u76f4\u662f\u4e00\u4e2a\u5907\u53d7\u5173\u6ce8\u7684\u8bfe\u9898\u3002\u5728\u795e\u7ecf\u79d1\u5b66\u9886\u57df\uff0c\u969c\u788d\u7269\u68c0\u6d4b\u4e5f\u662f\u4e00\u4e2a\u7814\u7a76\u5bf9\u8c61\uff0c\u5176\u4e2d\u98de\u884c\u7684\u6606\u866b\u548c\u8759\u8760\u5206\u522b\u88ab\u8ba4\u4e3a\u662f\u57fa\u4e8e\u89c6\u89c9\u548c\u57fa\u4e8e\u58f0\u97f3\u7684\u969c\u788d\u7269\u68c0\u6d4b\u673a\u5236\u4e2d\u6700\u6709\u8da3\u7684\u4e24\u4e2a\u6848\u4f8b\u3002\u76ee\u524d\uff0c\u8bb8\u591a\u7814\u7a76\u96c6\u4e2d\u5728\u57fa\u4e8e\u89c6\u89c9\u7684\u969c\u788d\u7269\u68c0\u6d4b\u4e0a\uff0c\u4f46\u5173\u4e8e\u57fa\u4e8e\u58f0\u97f3\u7684\u969c\u788d\u7269\u68c0\u6d4b\u7684\u7814\u7a76\u5374\u4e0d\u591a\u89c1\u3002\u672c\u7814\u7a76\u4e13\u6ce8\u4e8e\u540e\u8005\uff0c\u5e76\u5229\u7528\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u6765\u53d1\u6325\u8fd9\u4e9b\u67b6\u6784\u7684\u4f18\u52bf\uff0c\u5b9e\u73b0\u66f4\u63a5\u8fd1\u751f\u7269\u5b66\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u4e00\u7cfb\u5217\u5b9e\u9a8c\u6d4b\u8bd5\u4e86\u6574\u4e2a\u7cfb\u7edf\uff0c\u786e\u8ba4\u4e86\u8109\u51b2\u67b6\u6784\u5728\u969c\u788d\u7269\u68c0\u6d4b\u4e2d\u7684\u6709\u6548\u6027\u3002\u5b9e\u8bc1\u8868\u660e\uff0c\u5f53\u673a\u5668\u4eba\u4e0e\u969c\u788d\u7269\u4e4b\u95f4\u7684\u8ddd\u79bb\u51cf\u5c0f\u65f6\uff0c\u7cfb\u7edf\u7684\u8f93\u51fa\u653e\u7535\u7387\u5982\u9884\u671f\u822c\u589e\u52a0\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\u56e0\u6b64\uff0c\u8fd9\u4e24\u8005\u4e4b\u95f4\u5b58\u5728\u76f4\u63a5\u5173\u7cfb\u3002\u6b64\u5916\uff0c\u672c\u7814\u7a76\u8fd8\u5b9e\u8bc1\u6d4b\u91cf\u4e86\u53ef\u68c0\u6d4b\u4e0e\u4e0d\u53ef\u68c0\u6d4b\u7269\u4f53\u4e4b\u95f4\u7684\u8ddd\u79bb\u9608\u503c\u3002\u5bf9\u57fa\u4e8e\u8109\u51b2\u95f4\u95f4\u9694\u6982\u5ff5\u7684\u4f4e\u5c42\u6b21\u7cfb\u7edf\u5de5\u4f5c\u539f\u7406\u8fdb\u884c\u4e86\u6df1\u5165\u7814\u7a76\uff0c\u8fd9\u53ef\u80fd\u5bf9\u672a\u6765\u57fa\u4e8e\u8109\u51b2\u6ee4\u6ce2\u5668\u7684\u5e94\u7528\u5f00\u53d1\u6709\u6240\u5e2e\u52a9\u3002 | Alvaro Ayuso-Martinez | PDF | N/A | A Low-Cost Real-Time Spiking System for Obstacle Detection based on Ultrasonic Sensors and Rate Coding | Since the advent of mobile robots, obstacle detection has been a topic of great interest. It has also been a subject of study in neuroscience, where flying insects and bats could be considered two of the most interesting cases in terms of vision-based and sound-based mechanisms for obstacle detection, respectively. Currently, many studies focus on vision-based obstacle detection, but not many can be found regarding sound-based obstacle detection. This work focuses on the latter approach, which also makes use of a Spiking Neural Network to exploit the advantages of these architectures and achieve an approach closer to biology. The complete system was tested through a series of experiments that confirm the validity of the spiking architecture for obstacle detection. It is empirically demonstrated that, when the distance between the robot and the obstacle decreases, the output firing rate of the system increases in response as expected, and vice versa. Therefore, there is a direct relation between the two. Furthermore, there is a distance threshold between detectable and undetectable objects which is also empirically measured in this work. An in-depth study on how this system works at low level based on the Inter-Spike Interval concept was performed, which may be useful in the future development of applications based on spiking filters. | | \u4ece\u8ba4\u8bc6\u8bba\u89d2\u5ea6\u63a2\u8ba8\u72ec\u7acb\u7ea6\u675f\u4e0b\u7684\u89e3\u8026\u8868\u793a\u5b66\u4e60 | \u89e3\u8026\u8868\u793a\u5b66\u4e60\u65e8\u5728\u901a\u8fc7\u8bad\u7ec3\u6570\u636e\u7f16\u7801\u5668\u6765\u63d0\u9ad8\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u8be5\u7f16\u7801\u5668\u80fd\u591f\u8bc6\u522b\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u4e2d\u5177\u6709\u8bed\u4e49\u610f\u4e49\u7684\u6f5c\u5728\u53d8\u91cf\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u89e3\u8026\u8868\u793a\u5b66\u4e60\u7684\u76ee\u6807\uff0c\u76ee\u524d\u5c1a\u65e0\u666e\u904d\u63a5\u53d7\u7684\u5b9a\u4e49\u3002\u7279\u522b\u662f\uff0c\u5173\u4e8e\u6f5c\u5728\u53d8\u91cf\u662f\u5426\u5e94\u76f8\u4e92\u72ec\u7acb\u7684\u8ba8\u8bba\u76f8\u5f53\u591a\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u9996\u5148\u901a\u8fc7\u5728\u8ba4\u8bc6\u8bba\u4e0e\u89e3\u8026\u8868\u793a\u5b66\u4e60\u4e4b\u95f4\u5efa\u7acb\u6982\u5ff5\u6865\u6881\uff0c\u63a2\u8ba8\u4e86\u6f5c\u5728\u53d8\u91cf\u4e4b\u95f4\u76f8\u4e92\u5173\u7cfb\u7684\u8fd9\u4e9b\u8bba\u70b9\u3002\u7136\u540e\uff0c\u53d7\u8fd9\u4e9b\u8de8\u5b66\u79d1\u6982\u5ff5\u7684\u542f\u53d1\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u53cc\u5c42\u6f5c\u5728\u7a7a\u95f4\u6846\u67b6\uff0c\u4e3a\u5148\u524d\u5173\u4e8e\u6b64\u95ee\u9898\u7684\u4e89\u8bba\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002\u6700\u540e\uff0c\u6211\u4eec\u5728\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u6846\u67b6\u5185\u7ed3\u5408\u4e92\u4fe1\u606f\u7ea6\u675f\u548c\u72ec\u7acb\u6027\u7ea6\u675f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u8026\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u5e38\u7528\u6307\u6807\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u80fd\u529b\u6765\u89e3\u8026\u5404\u79cd\u8bed\u4e49\u56e0\u7d20\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u53ef\u63a7\u751f\u6210\u7684\u8d28\u91cf\uff0c\u8fdb\u800c\u589e\u5f3a\u4e86\u7b97\u6cd5\u7684\u53ef\u89e3\u91ca\u6027\u3002 | Ruoyu Wang | PDF | N/A | Independence Constrained Disentangled Representation Learning from Epistemological Perspective | Disentangled Representation Learning aims to improve the explainability of deep learning methods by training a data encoder that identifies semantically meaningful latent variables in the data generation process. Nevertheless, there is no consensus regarding a universally accepted definition for the objective of disentangled representation learning. In particular, there is a considerable amount of discourse regarding whether should the latent variables be mutually independent or not. In this paper, we first investigate these arguments on the interrelationships between latent variables by establishing a conceptual bridge between Epistemology and Disentangled Representation Learning. Then, inspired by these interdisciplinary concepts, we introduce a two-level latent space framework to provide a general solution to the prior arguments on this issue. Finally, we propose a novel method for disentangled representation learning by employing an integration of mutual information constraint and independence constraint within the Generative Adversarial Network (GAN) framework. Experimental results demonstrate that our proposed method consistently outperforms baseline approaches in both quantitative and qualitative evaluations. The method exhibits strong performance across multiple commonly used metrics and demonstrates a great capability in disentangling various semantic factors, leading to an improved quality of controllable generation, which consequently benefits the explainability of the algorithm. | | \u56e0\u679c\u611f\u77e5\u578bTransformer\u7f51\u7edc\u5728\u673a\u5668\u4eba\u5bfc\u822a\u4e2d\u7684\u5e94\u7528 | \u8fd1\u671f\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u8fdb\u5c55\u5f15\u53d1\u4e86\u5f00\u53d1\u591a\u529f\u80fd\u5177\u8eab\u667a\u80fd\u7cfb\u7edf\u7684\u65e5\u76ca\u589e\u957f\u7684\u5173\u6ce8\u3002\u7136\u800c\uff0c\u5f53\u524d\u8be5\u9886\u57df\u7684\u7814\u7a76\u63ed\u793a\u4e86\u6539\u8fdb\u7684\u673a\u4f1a\u3002\u9996\u5148\uff0c\u76f4\u63a5\u91c7\u7528RNN\u548cTransformer\u5f80\u5f80\u5ffd\u89c6\u4e86\u5177\u8eab\u667a\u80fd\u4e0e\u4f20\u7edf\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u4e4b\u95f4\u7684\u5177\u4f53\u5dee\u5f02\uff0c\u8fd9\u53ef\u80fd\u9650\u5236\u5176\u5728\u5177\u8eab\u667a\u80fd\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u5176\u6b21\uff0c\u4f9d\u8d56\u4e8e\u4efb\u52a1\u7279\u5b9a\u7684\u914d\u7f6e\uff0c\u5982\u9884\u8bad\u7ec3\u6a21\u5757\u548c\u6570\u636e\u96c6\u7279\u5b9a\u7684\u903b\u8f91\uff0c\u635f\u5bb3\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u901a\u7528\u6027\u3002\u6211\u4eec\u901a\u8fc7\u9996\u5148\u4ece\u56e0\u679c\u5173\u7cfb\u7684\u89d2\u5ea6\u63a2\u8ba8\u5177\u8eab\u667a\u80fd\u4efb\u52a1\u4e0e\u5176\u4ed6\u5e8f\u5217\u6570\u636e\u4efb\u52a1\u7684\u72ec\u7279\u5dee\u5f02\uff0c\u6765\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u56e0\u679c\u6846\u67b6\u4ee5\u9610\u660e\u4f20\u7edf\u5e8f\u5217\u65b9\u6cd5\u5728\u5177\u8eab\u667a\u80fd\u4e2d\u7684\u4e0d\u8db3\u3002\u901a\u8fc7\u5229\u7528\u8fd9\u79cd\u56e0\u679c\u89c6\u89d2\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u7528\u4e8e\u5bfc\u822a\u7684\u56e0\u679c\u611f\u77e5Transformer\uff08CAT\uff09\u7f51\u7edc\uff0c\u5176\u7279\u70b9\u662f\u56e0\u679c\u7406\u89e3\u6a21\u5757\uff0c\u4ee5\u589e\u5f3a\u6a21\u578b\u7684\u73af\u5883\u7406\u89e3\u80fd\u529b\u3002\u540c\u65f6\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u4e0d\u5305\u542b\u4efb\u52a1\u7279\u5b9a\u7684\u5f52\u7eb3\u504f\u5dee\uff0c\u5e76\u4e14\u53ef\u4ee5\u4ee5\u7aef\u5230\u7aef\u7684\u65b9\u5f0f\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fd9\u589e\u5f3a\u4e86\u65b9\u6cd5\u5728\u5404\u79cd\u60c5\u5883\u4e0b\u7684\u901a\u7528\u6027\u3002\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u5404\u79cd\u8bbe\u7f6e\u3001\u4efb\u52a1\u548c\u6a21\u62df\u73af\u5883\u4e2d\u59cb\u7ec8\u8d85\u8d8a\u57fa\u51c6\u6027\u80fd\u3002\u5e7f\u6cdb\u7684\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u6027\u80fd\u63d0\u5347\u53ef\u5f52\u56e0\u4e8e\u56e0\u679c\u7406\u89e3\u6a21\u5757\uff0c\u8be5\u6a21\u5757\u5728\u5f3a\u5316\u5b66\u4e60\u548c\u76d1\u7763\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u5747\u8868\u73b0\u51fa\u6709\u6548\u6027\u548c\u6548\u7387\u3002 | Ruoyu Wang | PDF | N/A | Causality-Aware Transformer Networks for Robotic Navigation | Recent advances in machine learning algorithms have garnered growing interest in developing versatile Embodied AI systems. However, current research in this domain reveals opportunities for improvement. First, the direct adoption of RNNs and Transformers often overlooks the specific differences between Embodied AI and traditional sequential data modelling, potentially limiting its performance in Embodied AI tasks. Second, the reliance on task-specific configurations, such as pre-trained modules and dataset-specific logic, compromises the generalizability of these methods. We address these constraints by initially exploring the unique differences between Embodied AI tasks and other sequential data tasks through the lens of Causality, presenting a causal framework to elucidate the inadequacies of conventional sequential methods for Embodied AI. By leveraging this causal perspective, we propose Causality-Aware Transformer (CAT) Networks for Navigation, featuring a Causal Understanding Module to enhance the models's Environmental Understanding capability. Meanwhile, our method is devoid of task-specific inductive biases and can be trained in an End-to-End manner, which enhances the method's generalizability across various contexts. Empirical evaluations demonstrate that our methodology consistently surpasses benchmark performances across a spectrum of settings, tasks and simulation environments. Extensive ablation studies reveal that the performance gains can be attributed to the Causal Understanding Module, which demonstrates effectiveness and efficiency in both Reinforcement Learning and Supervised Learning settings. | | \u673a\u5668\u5b66\u4e60\u7b80\u4ecb | \u8fd9\u672c\u4e66\u4ecb\u7ecd\u4e86\u6570\u5b66\u57fa\u7840\u548c\u6280\u5de7\uff0c\u8fd9\u4e9b\u57fa\u7840\u548c\u6280\u5de7\u5bfc\u81f4\u4e86\u673a\u5668\u5b66\u4e60\u4e2d\u4f7f\u7528\u7684\u8bb8\u591a\u7b97\u6cd5\u7684\u5f00\u53d1\u548c\u5206\u6790\u3002\u5b83\u4ece\u4e00\u4e2a\u4ecb\u7ecd\u6027\u7684\u7ae0\u8282\u5f00\u59cb\uff0c\u63cf\u8ff0\u4e86\u8d2f\u7a7f\u5168\u4e66\u7684\u7b26\u53f7\uff0c\u5e76\u4f5c\u4e3a\u5bf9\u5fae\u79ef\u5206\u3001\u7ebf\u6027\u4ee3\u6570\u548c\u6982\u7387\u8bba\u4e2d\u57fa\u672c\u6982\u5ff5\u7684\u63d0\u9192\uff0c\u540c\u65f6\u4e5f\u4ecb\u7ecd\u4e86\u4e00\u4e9b\u6d4b\u5ea6\u8bba\u672f\u8bed\uff0c\u8fd9\u4e9b\u672f\u8bed\u53ef\u4ee5\u4f5c\u4e3a\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\u7684\u7ae0\u8282\u7684\u9605\u8bfb\u6307\u5357\u3002\u4ecb\u7ecd\u6027\u7ae0\u8282\u8fd8\u63d0\u4f9b\u4e86\u77e9\u9635\u5206\u6790\u548c\u4f18\u5316\u7684\u80cc\u666f\u6750\u6599\u3002\u540e\u9762\u7684\u7ae0\u8282\u4e3a\u4e66\u4e2d\u4f7f\u7528\u7684\u8bb8\u591a\u7b97\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5305\u62ec\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u3001\u8fd1\u7aef\u65b9\u6cd5\u7b49\u3002\u5728\u8ba8\u8bba\u4e86\u7edf\u8ba1\u9884\u6d4b\u7684\u57fa\u672c\u6982\u5ff5\u4e4b\u540e\uff0c\u672c\u4e66\u4ecb\u7ecd\u4e86\u518d\u751f\u6838\u7406\u8bba\u548c\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u6280\u672f\uff0c\u8fd9\u4e9b\u6280\u672f\u5728\u8bb8\u591a\u5730\u65b9\u90fd\u6709\u5e94\u7528\uff0c\u7136\u540e\u4ecb\u7ecd\u4e86\u5404\u79cd\u76d1\u7763\u7edf\u8ba1\u5b66\u4e60\u7b97\u6cd5\u7684\u63cf\u8ff0\uff0c\u5305\u62ec\u7ebf\u6027\u65b9\u6cd5\u3001\u652f\u6301\u5411\u91cf\u673a\u3001\u51b3\u7b56\u6811\u3001\u63d0\u5347\u6cd5\u6216\u795e\u7ecf\u7f51\u7edc\u3002\u4e3b\u9898\u968f\u540e\u8f6c\u5411\u751f\u6210\u65b9\u6cd5\uff0c\u4ece\u4ecb\u7ecd\u91c7\u6837\u65b9\u6cd5\u548c\u9a6c\u5c14\u53ef\u592b\u94fe\u7406\u8bba\u7684\u7ae0\u8282\u5f00\u59cb\u3002\u63a5\u4e0b\u6765\u7684\u7ae0\u8282\u63cf\u8ff0\u4e86\u56fe\u5f62\u6a21\u578b\u7684\u7406\u8bba\uff0c\u6f5c\u5728\u53d8\u91cf\u6a21\u578b\u7684\u53d8\u5206\u65b9\u6cd5\u4ecb\u7ecd\uff0c\u4ee5\u53ca\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u751f\u6210\u6a21\u578b\u3002\u63a5\u4e0b\u6765\u7684\u7ae0\u8282\u4e13\u6ce8\u4e8e\u65e0\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u805a\u7c7b\u3001\u56e0\u5b50\u5206\u6790\u548c\u6d41\u5f62\u5b66\u4e60\u3002\u672c\u4e66\u7684\u6700\u540e\u4e00\u7ae0\u662f\u7406\u8bba\u5bfc\u5411\u7684\uff0c\u8ba8\u8bba\u4e86\u96c6\u4e2d\u4e0d\u7b49\u5f0f\u548c\u6cdb\u5316\u754c\u9650\u3002 | Laurent Younes | PDF | N/A | Introduction to Machine Learning | This book introduces the mathematical foundations and techniques that lead to the development and analysis of many of the algorithms that are used in machine learning. It starts with an introductory chapter that describes notation used throughout the book and serve at a reminder of basic concepts in calculus, linear algebra and probability and also introduces some measure theoretic terminology, which can be used as a reading guide for the sections that use these tools. The introductory chapters also provide background material on matrix analysis and optimization. The latter chapter provides theoretical support to many algorithms that are used in the book, including stochastic gradient descent, proximal methods, etc. After discussing basic concepts for statistical prediction, the book includes an introduction to reproducing kernel theory and Hilbert space techniques, which are used in many places, before addressing the description of various algorithms for supervised statistical learning, including linear methods, support vector machines, decision trees, boosting, or neural networks. The subject then switches to generative methods, starting with a chapter that presents sampling methods and an introduction to the theory of Markov chains. The following chapter describe the theory of graphical models, an introduction to variational methods for models with latent variables, and to deep-learning based generative models. The next chapters focus on unsupervised learning methods, for clustering, factor analysis and manifold learning. The final chapter of the book is theory-oriented and discusses concentration inequalities and generalization bounds. | | \u521b\u5efa\u7279\u5b9a\u9886\u57df\u7684\u7ffb\u8bd1\u8bb0\u5fc6\u4ee5\u8fdb\u884c\u673a\u5668\u7ffb\u8bd1\u5fae\u8c03\uff1aTRENCARD\u53cc\u8bed\u5fc3\u810f\u75c5\u5b66\u8bed\u6599\u5e93 | \u672c\u6587\u63a2\u8ba8\u4e86\u8bd1\u8005\u6216\u5176\u4ed6\u8bed\u8a00\u4e13\u4e1a\u4eba\u58eb\u5982\u4f55\u521b\u5efa\u7ffb\u8bd1\u8bb0\u5fc6\uff08TM\uff09\uff0c\u4ee5\u7f16\u8bd1\u7279\u5b9a\u9886\u57df\u7684\u5e73\u884c\u8bed\u6599\u5e93\uff0c\u8fd9\u4e9b\u8bed\u6599\u5e93\u53ef\u7528\u4e8e\u4e0d\u540c\u573a\u666f\uff0c\u5982\u673a\u5668\u7ffb\u8bd1\u8bad\u7ec3\u548c\u5fae\u8c03\u3001TM\u5229\u7528\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u3002\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u534a\u81ea\u52a8\u5316\u7684TM\u51c6\u5907\u65b9\u6cd5\uff0c\u4e3b\u8981\u5229\u7528\u8bd1\u8005\u5e38\u7528\u7684\u7ffb\u8bd1\u5de5\u5177\uff0c\u4ee5\u786e\u4fdd\u6570\u636e\u8d28\u91cf\u548c\u8bd1\u8005\u7684\u63a7\u5236\u3002\u968f\u540e\uff0c\u8be5\u534a\u81ea\u52a8\u5316\u65b9\u6cd5\u88ab\u7528\u4e8e\u6784\u5efa\u57fa\u4e8e\u5fc3\u810f\u75c5\u5b66\u7684\u571f\u8033\u5176\u8bed\u5230\u82f1\u8bed\u8bed\u6599\u5e93\uff0c\u8be5\u8bed\u6599\u5e93\u6765\u81ea\u571f\u8033\u5176\u5fc3\u810f\u75c5\u5b66\u671f\u520a\u7684\u53cc\u8bed\u6458\u8981\u3002\u6700\u7ec8\u5f62\u6210\u7684\u8bed\u6599\u5e93\u540d\u4e3aTRENCARD Corpus\uff0c\u5305\u542b\u7ea680\u4e07\u4e2a\u6e90\u8bcd\u548c5\u4e07\u4e2a\u53e5\u5b50\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\uff0c\u8bd1\u8005\u53ef\u4ee5\u5728\u5408\u7406\u65f6\u95f4\u5185\u6784\u5efa\u81ea\u5b9a\u4e49TM\uff0c\u5e76\u5728\u9700\u8981\u53cc\u8bed\u6570\u636e\u7684\u4efb\u52a1\u4e2d\u4f7f\u7528\u5b83\u4eec\u3002 | Gokhan Dogru | PDF | N/A | Creating Domain-Specific Translation Memories for Machine Translation Fine-tuning: The TRENCARD Bilingual Cardiology Corpus | This article investigates how translation memories (TM) can be created by translators or other language professionals in order to compile domain-specific parallel corpora , which can then be used in different scenarios, such as machine translation training and fine-tuning, TM leveraging, and/or large language model fine-tuning. The article introduces a semi-automatic TM preparation methodology leveraging primarily translation tools used by translators in favor of data quality and control by the translators. This semi-automatic methodology is then used to build a cardiology-based Turkish -&gt; English corpus from bilingual abstracts of Turkish cardiology journals. The resulting corpus called TRENCARD Corpus has approximately 800,000 source words and 50,000 sentences. Using this methodology, translators can build their custom TMs in a reasonable time and use them in their bilingual data requiring tasks. | | OpenFact \u5728 CheckThat! 2024\uff1a\u7ed3\u5408\u591a\u79cd\u653b\u51fb\u65b9\u6cd5\u5b9e\u73b0\u6709\u6548\u7684\u5bf9\u6297\u6027\u6587\u672c\u751f\u6210 | \u672c\u6587\u4ecb\u7ecd\u4e86\u5728CLEF 2024\u4efb\u52a16\uff1a\u5bf9\u6297\u6837\u672c\u4e0b\u7684\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u9c81\u68d2\u6027\uff08InCrediblAE\uff09\u4e2dCheckThat!\u5b9e\u9a8c\u5ba4\u7684\u5b9e\u9a8c\u548c\u7ed3\u679c\u3002\u8be5\u4efb\u52a1\u7684\u4e3b\u8981\u76ee\u6807\u662f\u751f\u6210\u4e94\u4e2a\u95ee\u9898\u9886\u57df\u7684\u5bf9\u6297\u6837\u672c\uff0c\u4ee5\u8bc4\u4f30\u5e7f\u6cdb\u4f7f\u7528\u7684\u6587\u672c\u5206\u7c7b\u65b9\u6cd5\uff08\u5fae\u8c03\u7684BERT\u3001BiLSTM\u548cRoBERTa\uff09\u5728\u5e94\u7528\u4e8e\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u95ee\u9898\u65f6\u7684\u9c81\u68d2\u6027\u3002\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5c06\u96c6\u6210\u5b66\u4e60\u5e94\u7528\u4e8e\u589e\u5f3a\u5bf9\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u6a21\u578b\u7684\u5bf9\u6297\u653b\u51fb\u3002\u6211\u4eec\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u7cfb\u7edf\u5730\u6d4b\u8bd5\u548c\u4f18\u5316\u4e86\u51e0\u79cd\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u5305\u62ecBERT-Attack\u3001\u9057\u4f20\u7b97\u6cd5\u3001TextFooler\u548cCLARE\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u6d89\u53ca\u5404\u79cd\u9519\u8bef\u4fe1\u606f\u4efb\u52a1\u3002\u901a\u8fc7\u5f00\u53d1BERT-Attack\u7684\u6539\u8fdb\u7248\u672c\u548c\u6df7\u5408\u65b9\u6cd5\uff0c\u6211\u4eec\u5728\u653b\u51fb\u6548\u679c\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002\u6211\u4eec\u7684\u7ed3\u679c\u5c55\u793a\u4e86\u901a\u8fc7\u4fee\u6539\u548c\u7ed3\u5408\u591a\u79cd\u65b9\u6cd5\u6765\u521b\u5efa\u66f4\u590d\u6742\u548c\u6709\u6548\u7684\u5bf9\u6297\u653b\u51fb\u7b56\u7565\u7684\u6f5c\u529b\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u9c81\u68d2\u548c\u5b89\u5168\u7684\u7cfb\u7edf\u3002 | W\u0142odzimierz Lewoniewski | PDF | N/A | OpenFact at CheckThat! 2024: Combining Multiple Attack Methods for Effective Adversarial Text Generation | This paper presents the experiments and results for the CheckThat! Lab at CLEF 2024 Task 6: Robustness of Credibility Assessment with Adversarial Examples (InCrediblAE). The primary objective of this task was to generate adversarial examples in five problem domains in order to evaluate the robustness of widely used text classification methods (fine-tuned BERT, BiLSTM, and RoBERTa) when applied to credibility assessment issues.   This study explores the application of ensemble learning to enhance adversarial attacks on natural language processing (NLP) models. We systematically tested and refined several adversarial attack methods, including BERT-Attack, Genetic algorithms, TextFooler, and CLARE, on five datasets across various misinformation tasks. By developing modified versions of BERT-Attack and hybrid methods, we achieved significant improvements in attack effectiveness. Our results demonstrate the potential of modification and combining multiple methods to create more sophisticated and effective adversarial attack strategies, contributing to the development of more robust and secure systems. | | \u57fa\u4e8e\u5b66\u4e60\u7684\u5148\u8fdb\u8f66\u8f86\u4eea\u8868\u96c6\u7fa4\u6e32\u67d3\u9519\u8bef\u68c0\u6d4b\u7cfb\u7edf | \u6c7d\u8f66\u884c\u4e1a\u6b63\u5728\u901a\u8fc7\u6bcf\u4e00\u6b3e\u65b0\u4e0a\u5e02\u7684\u8f66\u578b\u4e0d\u65ad\u6269\u5c55\u6570\u5b57\u663e\u793a\u9009\u9879\u3002\u8fd9\u4e0d\u4ec5\u6d89\u53ca\u5c3a\u5bf8\u3001\u5206\u8fa8\u7387\u548c\u5b9a\u5236\u9009\u62e9\u7684\u6269\u5c55\uff0c\u8fd8\u5305\u62ec\u5728\u7ec4\u88c5\u663e\u793a\u96c6\u7fa4\u5185\u5bb9\u65f6\u91c7\u7528\u65b0\u9896\u7684\u663e\u793a\u6548\u679c\uff0c\u5982\u53e0\u52a0\u3002\u9057\u61be\u7684\u662f\uff0c\u8fd9\u4e5f\u5e26\u6765\u4e86\u5bf9\u9002\u5f53\u76d1\u63a7\u7cfb\u7edf\u7684\u9700\u6c42\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u80fd\u591f\u5728\u68c0\u6d4b\u5230\u6e32\u67d3\u9519\u8bef\u65f6\u53ca\u65f6\u91c7\u53d6\u9002\u5f53\u7684\u5e94\u5bf9\u63aa\u65bd\u3002\u4f20\u7edf\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5982\u5faa\u73af\u5197\u4f59\u6821\u9a8c\uff08CRC\uff09\uff0c\u5f88\u5feb\u5c06\u4e0d\u518d\u9002\u7528\uff0c\u56e0\u4e3a\u4efb\u4f55\u5f62\u5f0f\u7684\u963f\u5c14\u6cd5\u6df7\u5408\u3001\u5185\u5bb9\u626d\u66f2\u6216\u7f29\u653e\u90fd\u53ef\u80fd\u5bfc\u81f4\u4e0d\u5fc5\u8981\u7684CRC\u8fdd\u89c4\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u76d1\u63a7\u65b9\u6cd5\uff0c\u4f7f\u7528\u6307\u793a\u706f\uff08\u4f8b\u5982\u8b66\u544a\u6807\u5fd7\uff09\u4f5c\u4e3a\u793a\u4f8b\uff0c\u6765\u9a8c\u8bc1\u663e\u793a\u5185\u5bb9\u7684\u6b63\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u5f0f\uff0c\u533a\u5206\u201c\u826f\u597d\u201d\u7684\u6307\u793a\u706f\uff0c\u5373\u4eba\u7c7b\u9a7e\u9a76\u5458\u80fd\u591f\u6b63\u786e\u7406\u89e3\u7684\u6307\u793a\u706f\uff0c\u4ee5\u53ca\u201c\u635f\u574f\u201d\u7684\u6307\u793a\u706f\uff0c\u5373\u90a3\u4e9b\u65e0\u6cd5\u6b63\u786e\u663e\u793a\u6216\u88ab\u6b63\u786e\u611f\u77e5\u7684\u6307\u793a\u706f\u3002\u56e0\u6b64\uff0c\u5b83\u5177\u6709\u5bf9\u5355\u4e2a\u50cf\u7d20\u9519\u8bef\u7684\u5185\u5728\u6297\u6027\uff0c\u5e76\u9690\u542b\u5730\u652f\u6301\u80cc\u666f\u53d8\u5316\u3001\u53e0\u52a0\u6216\u7f29\u653e\u6548\u679c\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u7814\u7a76\u8868\u660e\uff0c\u6240\u6709\u201c\u635f\u574f\u201d\u7684\u6d4b\u8bd5\u6a21\u5f0f\u90fd\u88ab\u6b63\u786e\u5206\u7c7b\uff0c\u540c\u65f6\u6ca1\u6709\u89e6\u53d1\u4efb\u4f55\u8bef\u62a5\uff0c\u8fd9\u8fdb\u4e00\u6b65\u5f3a\u8c03\u4e86\u5176\u6709\u6548\u6027\u3002 | Cornelius B\u00fcrkle | PDF | N/A | Learning-Based Error Detection System for Advanced Vehicle Instrument Cluster Rendering | The automotive industry is currently expanding digital display options with every new model that comes onto the market. This entails not just an expansion in dimensions, resolution, and customization choices, but also the capability to employ novel display effects like overlays while assembling the content of the display cluster. Unfortunately, this raises the need for appropriate monitoring systems that can detect rendering errors and apply appropriate countermeasures when required. Classical solutions such as Cyclic Redundancy Checks (CRC) will soon be no longer viable as any sort of alpha blending, warping of scaling of content can cause unwanted CRC violations. Therefore, we propose a novel monitoring approach to verify correctness of displayed content using telltales (e.g. warning signs) as example. It uses a learning-based approach to separate \"good\" telltales, i.e. those that a human driver will understand correctly, and \"corrupted\" telltales, i.e. those that will not be visible or perceived correctly. As a result, it possesses inherent resilience against individual pixel errors and implicitly supports changing backgrounds, overlay or scaling effects. This is underlined by our experimental study where all \"corrupted\" test patterns were correctly classified, while no false alarms were triggered. | | \u5173\u4e8e\u65b0\u5174\u8bed\u8a00\u7684\u8c03\u67e5 | \u65b0\u5174\u8bed\u8a00\u9886\u57df\u4ee3\u8868\u4e86\u4eba\u5de5\u667a\u80fd\u9886\u57df\u5185\u7684\u4e00\u4e2a\u65b0\u9896\u7814\u7a76\u65b9\u5411\uff0c\u7279\u522b\u662f\u5728\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u80cc\u666f\u4e0b\u3002\u5c3d\u7ba1\u7814\u7a76\u8bed\u8a00\u51fa\u73b0\u7684\u6982\u5ff5\u5e76\u4e0d\u65b0\u9c9c\uff0c\u4f46\u65e9\u671f\u7684\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u89e3\u91ca\u4eba\u7c7b\u8bed\u8a00\u7684\u5f62\u6210\uff0c\u5bf9\u5176\u5728\u4eba\u5de5\u4ee3\u7406\u4e2d\u7684\u6f5c\u5728\u7528\u9014\u8003\u8651\u8f83\u5c11\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u51fa\u4e0e\u4eba\u7c7b\u8bed\u8a00\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u7684\u4ee3\u7406\u901a\u4fe1\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u5b83\u4eec\u8d85\u8d8a\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\u4e2d\u5e38\u89c1\u7684\u5b66\u4e60\u7edf\u8ba1\u8868\u793a\u3002\u8fd9\u5f15\u53d1\u4e86\u4e00\u7cfb\u5217\u57fa\u672c\u95ee\u9898\uff0c\u4ece\u8bed\u8a00\u51fa\u73b0\u7684\u5148\u51b3\u6761\u4ef6\u5230\u8861\u91cf\u5176\u6210\u529f\u7684\u6807\u51c6\u3002\u672c\u6587\u901a\u8fc7\u5168\u9762\u7efc\u8ff0181\u7bc7\u5173\u4e8e\u4eba\u5de5\u667a\u80fd\u4e2d\u65b0\u5174\u8bed\u8a00\u7684\u79d1\u5b66\u51fa\u7248\u7269\u6765\u56de\u7b54\u8fd9\u4e9b\u95ee\u9898\u3002\u5176\u76ee\u7684\u662f\u4e3a\u5bf9\u8be5\u9886\u57df\u611f\u5174\u8da3\u6216\u7cbe\u901a\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u53c2\u8003\u3002\u56e0\u6b64\uff0c\u4e3b\u8981\u8d21\u732e\u5305\u62ec\u5bf9\u6d41\u884c\u672f\u8bed\u7684\u5b9a\u4e49\u548c\u6982\u8ff0\u3001\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u548c\u6307\u6807\u7684\u5206\u6790\uff0c\u4ee5\u53ca\u6240\u8bc6\u522b\u7814\u7a76\u7a7a\u767d\u7684\u63cf\u8ff0\u3002 | Jannik Peters | PDF | N/A | A Survey on Emergent Language | The field of emergent language represents a novel area of research within the domain of artificial intelligence, particularly within the context of multi-agent reinforcement learning. Although the concept of studying language emergence is not new, early approaches were primarily concerned with explaining human language formation, with little consideration given to its potential utility for artificial agents. In contrast, studies based on reinforcement learning aim to develop communicative capabilities in agents that are comparable to or even superior to human language. Thus, they extend beyond the learned statistical representations that are common in natural language processing research. This gives rise to a number of fundamental questions, from the prerequisites for language emergence to the criteria for measuring its success. This paper addresses these questions by providing a comprehensive review of 181 scientific publications on emergent language in artificial intelligence. Its objective is to serve as a reference for researchers interested in or proficient in the field. Consequently, the main contributions are the definition and overview of the prevailing terminology, the analysis of existing evaluation methods and metrics, and the description of the identified research gaps. | | \u52a8\u6001\u751f\u7269\u7cfb\u7edf\u4e2d\u7684\u5171\u5f62\u9884\u6d4b | \u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u662f\u6307\u7cfb\u7edf\u6027\u5730\u786e\u5b9a\u548c\u8868\u5f81\u8ba1\u7b97\u6a21\u578b\u9884\u6d4b\u4e2d\u7f6e\u4fe1\u5ea6\u7684\u8fc7\u7a0b\u3002\u5728\u7cfb\u7edf\u751f\u7269\u5b66\u9886\u57df\uff0c\u5c24\u5176\u662f\u52a8\u6001\u6a21\u578b\u4e2d\uff0cUQ\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u89e3\u51b3\u4e86\u7531\u975e\u7ebf\u6027\u548c\u53c2\u6570\u654f\u611f\u6027\u5e26\u6765\u7684\u6311\u6218\uff0c\u4f7f\u6211\u4eec\u80fd\u591f\u6b63\u786e\u7406\u89e3\u548c\u63a8\u65ad\u590d\u6742\u751f\u7269\u7cfb\u7edf\u7684\u884c\u4e3a\u3002\u5728\u6b64\uff0c\u6211\u4eec\u4e13\u6ce8\u4e8e\u7531\u786e\u5b9a\u6027\u975e\u7ebf\u6027\u5e38\u5fae\u5206\u65b9\u7a0b\u8868\u793a\u7684\u52a8\u6001\u6a21\u578b\u3002\u5f53\u524d\u8bb8\u591aUQ\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u8d1d\u53f6\u65af\u7edf\u8ba1\u65b9\u6cd5\uff0c\u5c3d\u7ba1\u8fd9\u4e9b\u65b9\u6cd5\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u9700\u8981\u5f3a\u5148\u9a8c\u5047\u8bbe\uff0c\u5e76\u505a\u51fa\u53ef\u80fd\u4e0d\u9002\u7528\u4e8e\u751f\u7269\u7cfb\u7edf\u7684\u53c2\u6570\u5047\u8bbe\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728\u6837\u672c\u91cf\u6709\u9650\u4e14\u7edf\u8ba1\u63a8\u65ad\u53d7\u5230\u9650\u5236\u7684\u9886\u57df\u9762\u4e34\u6311\u6218\uff0c\u8ba1\u7b97\u901f\u5ea6\u6210\u4e3a\u5927\u578b\u751f\u7269\u7cfb\u7edf\u6a21\u578b\u4e2d\u7684\u74f6\u9888\u3002\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\uff0c\u6211\u4eec\u63d0\u51fa\u4f7f\u7528\u4fdd\u5f62\u63a8\u65ad\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u4e24\u79cd\u65b0\u7b97\u6cd5\uff0c\u8fd9\u4e9b\u7b97\u6cd5\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u63d0\u4f9b\u4e86\u975e\u6e10\u8fd1\u4fdd\u8bc1\uff0c\u589e\u5f3a\u4e86\u5728\u5404\u79cd\u5e94\u7528\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002\u6211\u4eec\u901a\u8fc7\u591a\u4e2a\u573a\u666f\u5c55\u793a\u4e86\u6240\u63d0\u51fa\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u7a81\u663e\u4e86\u5b83\u4eec\u76f8\u5bf9\u4e8e\u4f20\u7edf\u8d1d\u53f6\u65af\u65b9\u6cd5\u7684\u4f18\u52bf\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u6837\u5316\u7684\u751f\u7269\u6570\u636e\u7ed3\u6784\u548c\u573a\u666f\u4e2d\u663e\u793a\u51fa\u6709\u524d\u666f\u7684\u7ed3\u679c\uff0c\u4e3a\u751f\u7269\u7cfb\u7edf\u52a8\u6001\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u7684\u8f6f\u4ef6\u53ca\u7ed3\u679c\u590d\u73b0\u4ee3\u7801\u53ef\u5728https://zenodo.org/doi/10.5281/zenodo.13644870\u83b7\u53d6\u3002 | Alberto Portela | PDF | N/A | Conformal Prediction in Dynamic Biological Systems | Uncertainty quantification (UQ) is the process of systematically determining and characterizing the degree of confidence in computational model predictions. In the context of systems biology, especially with dynamic models, UQ is crucial because it addresses the challenges posed by nonlinearity and parameter sensitivity, allowing us to properly understand and extrapolate the behavior of complex biological systems. Here, we focus on dynamic models represented by deterministic nonlinear ordinary differential equations. Many current UQ approaches in this field rely on Bayesian statistical methods. While powerful, these methods often require strong prior specifications and make parametric assumptions that may not always hold in biological systems. Additionally, these methods face challenges in domains where sample sizes are limited, and statistical inference becomes constrained, with computational speed being a bottleneck in large models of biological systems. As an alternative, we propose the use of conformal inference methods, introducing two novel algorithms that, in some instances, offer non-asymptotic guarantees, enhancing robustness and scalability across various applications. We demonstrate the efficacy of our proposed algorithms through several scenarios, highlighting their advantages over traditional Bayesian approaches. The proposed methods show promising results for diverse biological data structures and scenarios, offering a general framework to quantify uncertainty for dynamic models of biological systems.The software for the methodology and the reproduction of the results is available at https://zenodo.org/doi/10.5281/zenodo.13644870. | | AdvSecureNet\uff1a\u4e00\u4e2a\u7528\u4e8e\u5bf9\u6297\u673a\u5668\u5b66\u4e60\u7684Python\u5de5\u5177\u5305 | \u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u653b\u51fb\u3002\u867d\u7136\u5df2\u7ecf\u5f00\u53d1\u4e86\u591a\u79cd\u5de5\u5177\u6765\u7814\u7a76\u8fd9\u4e9b\u6f0f\u6d1e\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u7f3a\u4e4f\u5168\u9762\u7684\u529f\u80fd\u548c\u7075\u6d3b\u6027\u3002\u6211\u4eec\u5f15\u5165\u4e86AdvSecureNet\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8ePyTorch\u7684\u5bf9\u6297\u673a\u5668\u5b66\u4e60\u5de5\u5177\u5305\uff0c\u9996\u6b21\u539f\u751f\u652f\u6301\u591aGPU\u8bbe\u7f6e\u7528\u4e8e\u653b\u51fb\u3001\u9632\u5fa1\u548c\u8bc4\u4f30\u3002\u5b83\u4e5f\u662f\u9996\u4e2a\u540c\u65f6\u652f\u6301CLI\u548cAPI\u63a5\u53e3\u4ee5\u53ca\u5916\u90e8YAML\u914d\u7f6e\u6587\u4ef6\u7684\u5de5\u5177\u5305\uff0c\u4ee5\u589e\u5f3a\u591a\u529f\u80fd\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002\u8be5\u5de5\u5177\u5305\u5305\u542b\u591a\u79cd\u653b\u51fb\u3001\u9632\u5fa1\u548c\u8bc4\u4f30\u6307\u6807\u3002\u9075\u5faa\u4e25\u683c\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\uff0c\u4ee5\u786e\u4fdd\u9ad8\u4ee3\u7801\u8d28\u91cf\u548c\u53ef\u7ef4\u62a4\u6027\u3002\u8be5\u9879\u76ee\u4f5c\u4e3a\u5f00\u6e90\u9879\u76ee\u5728GitHub\u4e0a\u63d0\u4f9b\uff0c\u5730\u5740\u4e3ahttps://github.com/melihcatal/advsecurenet\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7PyPI\u5b89\u88c5\u3002 | Melih Catal | PDF | N/A | AdvSecureNet: A Python Toolkit for Adversarial Machine Learning | Machine learning models are vulnerable to adversarial attacks. Several tools have been developed to research these vulnerabilities, but they often lack comprehensive features and flexibility. We introduce AdvSecureNet, a PyTorch based toolkit for adversarial machine learning that is the first to natively support multi-GPU setups for attacks, defenses, and evaluation. It is the first toolkit that supports both CLI and API interfaces and external YAML configuration files to enhance versatility and reproducibility. The toolkit includes multiple attacks, defenses and evaluation metrics. Rigiorous software engineering practices are followed to ensure high code quality and maintainability. The project is available as an open-source project on GitHub at https://github.com/melihcatal/advsecurenet and installable via PyPI. | | \uff08\u9690\u5f0f\uff09\u96c6\u6210\u4e2d\u7684\u96c6\u6210\uff1a\u5927\u578b\u6a21\u578b\u4e2d\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u5d29\u6e83 | \u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u5bf9\u5b89\u5168\u5173\u952e\u578b\u5e94\u7528\u548c\u5206\u5e03\u5916\u68c0\u6d4b\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u6211\u4eec\u5728\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u53d1\u73b0\u4e86\u4e00\u4e2a\u77db\u76fe\u73b0\u8c61\uff1a\u968f\u7740\u6a21\u578b\u590d\u6742\u6027\u7684\u589e\u52a0\uff0c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u51fa\u73b0\u4e86\u5d29\u6e83\uff0c\u8fd9\u6311\u6218\u4e86\u66f4\u5927\u6a21\u578b\u5fc5\u7136\u63d0\u4f9b\u66f4\u597d\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u5047\u8bbe\u3002\u6211\u4eec\u8ba4\u4e3a\uff0c\u8fd9\u662f\u7531\u4e8e\u5927\u578b\u6a21\u578b\u5185\u90e8\u7684\u9690\u5f0f\u96c6\u6210\u6240\u5bfc\u81f4\u7684\u3002\u4e3a\u4e86\u652f\u6301\u8fd9\u4e00\u5047\u8bbe\uff0c\u6211\u4eec\u5728\u591a\u79cd\u67b6\u6784\u4e0a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u6f14\u793a\uff0c\u4ece\u663e\u5f0f\u96c6\u6210\u548c\u7b80\u5355\u591a\u5c42\u611f\u77e5\u5668\u5230\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u6a21\u578b\uff0c\u5305\u62ecResNet\u548cVision Transformers\u3002\u5bf9\u4e8e\u540e\u8005\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u9690\u5f0f\u96c6\u6210\u63d0\u53d6\uff0c\u5e76\u5c06\u5927\u578b\u6a21\u578b\u5206\u89e3\u4e3a\u591a\u6837\u5316\u7684\u5b50\u6a21\u578b\uff0c\u4ece\u800c\u6062\u590d\u4e86\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u3002\u6211\u4eec\u4e3a\u8fd9\u4e9b\u73b0\u8c61\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u5e76\u63a2\u8ba8\u4e86\u5b83\u4eec\u5bf9\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u5f71\u54cd\u3002 | Andreas Kirsch | PDF | N/A | (Implicit) Ensembles of Ensembles: Epistemic Uncertainty Collapse in Large Models | Epistemic uncertainty is crucial for safety-critical applications and out-of-distribution detection tasks. Yet, we uncover a paradoxical phenomenon in deep learning models: an epistemic uncertainty collapse as model complexity increases, challenging the assumption that larger models invariably offer better uncertainty quantification. We propose that this stems from implicit ensembling within large models. To support this hypothesis, we demonstrate epistemic uncertainty collapse empirically across various architectures, from explicit ensembles of ensembles and simple MLPs to state-of-the-art vision models, including ResNets and Vision Transformers -- for the latter, we examine implicit ensemble extraction and decompose larger models into diverse sub-models, recovering epistemic uncertainty. We provide theoretical justification for these phenomena and explore their implications for uncertainty estimation. |</p>"},{"location":"biorxiv_papers/","title":"BioRxiv Papers","text":"\u6807\u9898 \u6458\u8981 \u4f5c\u8005 PDF\u94fe\u63a5 \u4ee3\u7801\u4ed3\u5e93 Title Abstract"},{"location":"medrxiv_papers/","title":"MedRxiv Papers","text":"\u6807\u9898 \u6458\u8981 \u4f5c\u8005 PDF\u94fe\u63a5 \u4ee3\u7801\u4ed3\u5e93 Title Abstract"}]}