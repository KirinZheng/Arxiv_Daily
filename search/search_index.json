{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Arxiv Daily","text":"<p>DeepSeek\uff0c\u4f60\u8bb0\u4e00\u4e0b\u6211\u505a\u5982\u4e0b\u90e8\u7f72 -- 101</p>"},{"location":"arxiv_papers/","title":"Arxiv Papers","text":"\u6807\u9898 \u6458\u8981 \u4f5c\u8005 PDF\u94fe\u63a5 \u4ee3\u7801\u4ed3\u5e93 Title Abstract \u6301\u7eed\u6539\u8fdb\u81ea\u4e3b\u73b0\u5b9e\u4e16\u754c\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u79fb\u52a8\u64cd\u4f5c \u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u81ea\u4e3b\u7684\u73b0\u5b9e\u4e16\u754c\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u79fb\u52a8\u64cd\u4f5c\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5728\u65e0\u9700\u5e7f\u6cdb\u4eea\u5668\u6216\u4eba\u5de5\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u5b66\u4e60\u7b56\u7565\u3002\u8fd9\u4e00\u6210\u679c\u7684\u5b9e\u73b0\u5f97\u76ca\u4e8e\u4ee5\u4e0b\u4e09\u70b9\uff1a1) \u4efb\u52a1\u76f8\u5173\u7684\u81ea\u4e3b\u6027\uff0c\u5b83\u5f15\u5bfc\u63a2\u7d22\u671d\u5411\u7269\u4f53\u4ea4\u4e92\uff0c\u5e76\u9632\u6b62\u5728\u76ee\u6807\u72b6\u6001\u9644\u8fd1\u505c\u6ede\uff1b2) \u901a\u8fc7\u5229\u7528\u884c\u4e3a\u5148\u9a8c\u4e2d\u7684\u57fa\u672c\u4efb\u52a1\u77e5\u8bc6\uff0c\u5b9e\u73b0\u9ad8\u6548\u7b56\u7565\u5b66\u4e60\uff1b3) \u5236\u5b9a\u7ed3\u5408\u4eba\u7c7b\u53ef\u89e3\u91ca\u8bed\u4e49\u4fe1\u606f\u4e0e\u4f4e\u5c42\u6b21\u3001\u7ec6\u7c92\u5ea6\u89c2\u5bdf\u7684\u901a\u7528\u5956\u52b1\u3002\u6211\u4eec\u7684\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f7fSpot\u673a\u5668\u4eba\u80fd\u591f\u5728\u56db\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u4e2d\u6301\u7eed\u63d0\u5347\u8868\u73b0\uff0c\u5e73\u5747\u6210\u529f\u7387\u8fbe\u523080%\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u4e863-4\u4e2a\u767e\u5206\u70b9\u3002\u76f8\u5173\u89c6\u9891\u53ef\u5728https://continual-mobile-manip.github.io/\u67e5\u770b\u3002 Russell Mendonca PDF N/A Continuously Improving Mobile Manipulation with Autonomous Real-World RL We present a fully autonomous real-world RL framework for mobile manipulation that can learn policies without extensive instrumentation or human supervision. This is enabled by 1) task-relevant autonomy, which guides exploration towards object interactions and prevents stagnation near goal states, 2) efficient policy learning by leveraging basic task knowledge in behavior priors, and 3) formulating generic rewards that combine human-interpretable semantic information with low-level, fine-grained observations. We demonstrate that our approach allows Spot robots to continually improve their performance on a set of four challenging mobile manipulation tasks, obtaining an average success rate of 80% across tasks, a 3-4 improvement over existing approaches. Videos can be found at https://continual-mobile-manip.github.io/ MM1.5\uff1a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2d\u7684\u65b9\u6cd5\u3001\u5206\u6790\u4e0e\u6d1e\u5bdf \u6211\u4eec\u63a8\u51fa\u4e86MM1.5\uff0c\u8fd9\u662f\u4e00\u7cfb\u5217\u65b0\u7684\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\uff0c\u65e8\u5728\u589e\u5f3a\u5728\u6587\u672c\u4e30\u5bcc\u7684\u56fe\u50cf\u7406\u89e3\u3001\u89c6\u89c9\u6307\u79f0\u548c\u5b9a\u4f4d\u4ee5\u53ca\u591a\u56fe\u50cf\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002\u57fa\u4e8eMM1\u67b6\u6784\uff0cMM1.5\u91c7\u7528\u4e86\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7cfb\u7edf\u5730\u63a2\u7d22\u4e86\u5728\u6574\u4e2a\u6a21\u578b\u8bad\u7ec3\u751f\u547d\u5468\u671f\u4e2d\u591a\u6837\u5316\u6570\u636e\u6df7\u5408\u7684\u5f71\u54cd\u3002\u8fd9\u5305\u62ec\u9ad8\u8d28\u91cf\u7684OCR\u6570\u636e\u548c\u5408\u6210\u5b57\u5e55\u7528\u4e8e\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u4ee5\u53ca\u4f18\u5316\u7684\u89c6\u89c9\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u6df7\u5408\u7528\u4e8e\u6709\u76d1\u7763\u7684\u5fae\u8c03\u3002\u6211\u4eec\u7684\u6a21\u578b\u53c2\u6570\u89c4\u6a21\u4ece1B\u523030B\u4e0d\u7b49\uff0c\u6db5\u76d6\u4e86\u5bc6\u96c6\u578b\u548c\u4e13\u5bb6\u6df7\u5408\uff08MoE\uff09\u53d8\u4f53\uff0c\u5e76\u5c55\u793a\u4e86\u5373\u4f7f\u5728\u8f83\u5c0f\u89c4\u6a21\uff081B\u548c3B\uff09\u4e0b\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6570\u636e\u7b5b\u9009\u548c\u8bad\u7ec3\u7b56\u7565\u4e5f\u80fd\u5e26\u6765\u5f3a\u5927\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e24\u4e2a\u4e13\u95e8\u7684\u53d8\u4f53\uff1aMM1.5-Video\uff0c\u4e13\u4e3a\u89c6\u9891\u7406\u89e3\u8bbe\u8ba1\uff0c\u4ee5\u53caMM1.5-UI\uff0c\u4e13\u4e3a\u79fb\u52a8\u7528\u6237\u754c\u9762\u7406\u89e3\u5b9a\u5236\u3002\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u7814\u7a76\u548c\u6d88\u878d\u5b9e\u9a8c\uff0c\u6211\u4eec\u8be6\u7ec6\u63ed\u793a\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u548c\u51b3\u7b56\uff0c\u8fd9\u4e9b\u90fd\u6784\u6210\u4e86\u6211\u4eec\u6700\u7ec8\u8bbe\u8ba1\u7684\u57fa\u7840\uff0c\u4e3a\u672a\u6765MLLM\u5f00\u53d1\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u6307\u5bfc\u3002 Haotian Zhang PDF N/A MM1.5: Methods, Analysis &amp; Insights from Multimodal LLM Fine-tuning We present MM1.5, a new family of multimodal large language models (MLLMs) designed to enhance capabilities in text-rich image understanding, visual referring and grounding, and multi-image reasoning. Building upon the MM1 architecture, MM1.5 adopts a data-centric approach to model training, systematically exploring the impact of diverse data mixtures across the entire model training lifecycle. This includes high-quality OCR data and synthetic captions for continual pre-training, as well as an optimized visual instruction-tuning data mixture for supervised fine-tuning. Our models range from 1B to 30B parameters, encompassing both dense and mixture-of-experts (MoE) variants, and demonstrate that careful data curation and training strategies can yield strong performance even at small scales (1B and 3B). Additionally, we introduce two specialized variants: MM1.5-Video, designed for video understanding, and MM1.5-UI, tailored for mobile UI understanding. Through extensive empirical studies and ablations, we provide detailed insights into the training processes and decisions that inform our final designs, offering valuable guidance for future research in MLLM development. \u6392\u540d\u4f18\u4e8e\u8bc4\u5206\uff1a\u8fc8\u5411\u53ef\u9760\u4e14\u7a33\u5065\u7684LLM\u751f\u6210\u533b\u5b66\u89e3\u91ca\u6027\u8bba\u8bc1\u81ea\u52a8\u5316\u8bc4\u4f30 \u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u7684\u6587\u672c\u5df2\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u533b\u5b66\u9886\u57df\u7b49\u7279\u5b9a\u9886\u57df\u4e2d\u3002\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7528\u4e8eLLM\u751f\u6210\u7684\u533b\u5b66\u89e3\u91ca\u6027\u8bba\u8bc1\uff0c\u8be5\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4ee3\u7406\u4efb\u52a1\u548c\u6392\u540d\uff0c\u4ee5\u7d27\u5bc6\u7b26\u5408\u4eba\u7c7b\u8bc4\u4f30\u6807\u51c6\uff0c\u514b\u670d\u4e86\u901a\u5e38\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684LLM\u4e2d\u5b58\u5728\u7684\u504f\u89c1\u3002\u6211\u4eec\u8bc1\u660e\uff0c\u6240\u63d0\u51fa\u7684\u8bc4\u4f30\u8005\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5305\u62ec\u5bf9\u975e\u8bba\u8bc1\u6027\u6587\u672c\u7684\u8bc4\u4f30\u3002\u6b64\u5916\uff0c\u8bad\u7ec3\u8bc4\u4f30\u8005\u6240\u9700\u7684\u4eba\u5de5\u7f16\u5199\u7684\u8bba\u8bc1\u88ab\u6700\u5c0f\u5316\u5230\u6bcf\u4e2a\u4ee3\u7406\u4efb\u52a1\u4ec5\u4e00\u4e2a\u793a\u4f8b\u3002\u901a\u8fc7\u68c0\u67e5\u591a\u4e2aLLM\u751f\u6210\u7684\u8bba\u8bc1\uff0c\u6211\u4eec\u5efa\u7acb\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u7528\u4e8e\u786e\u5b9a\u4ee3\u7406\u4efb\u52a1\u662f\u5426\u9002\u5408\u8bc4\u4f30LLM\u751f\u6210\u7684\u533b\u5b66\u89e3\u91ca\u6027\u8bba\u8bc1\uff0c\u4ec5\u9700\u4e94\u4e2a\u793a\u4f8b\u548c\u4e24\u4f4d\u4eba\u7c7b\u4e13\u5bb6\u3002 Iker De la Iglesia PDF N/A Ranking Over Scoring: Towards Reliable and Robust Automated Evaluation of LLM-Generated Medical Explanatory Arguments Evaluating LLM-generated text has become a key challenge, especially in domain-specific contexts like the medical field. This work introduces a novel evaluation methodology for LLM-generated medical explanatory arguments, relying on Proxy Tasks and rankings to closely align results with human evaluation criteria, overcoming the biases typically seen in LLMs used as judges. We demonstrate that the proposed evaluators are robust against adversarial attacks, including the assessment of non-argumentative text. Additionally, the human-crafted arguments needed to train the evaluators are minimized to just one example per Proxy Task. By examining multiple LLM-generated arguments, we establish a methodology for determining whether a Proxy Task is suitable for evaluating LLM-generated medical explanatory arguments, requiring only five examples and two human experts. SpaceMesh\uff1a\u4e00\u79cd\u7528\u4e8e\u5b66\u4e60\u6d41\u5f62\u8868\u9762\u7f51\u683c\u7684\u8fde\u7eed\u8868\u793a \u7f51\u683c\u5728\u89c6\u89c9\u8ba1\u7b97\u548c\u6a21\u62df\u4e2d\u65e0\u5904\u4e0d\u5728\uff0c\u7136\u800c\u5927\u591a\u6570\u73b0\u6709\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\u4ec5\u95f4\u63a5\u8868\u793a\u7f51\u683c\uff0c\u4f8b\u5982\u4f5c\u4e3a\u6807\u91cf\u573a\u7684\u6c34\u5e73\u96c6\u6216\u6a21\u677f\u7684\u53d8\u5f62\uff0c\u6216\u8005\u4f5c\u4e3a\u7f3a\u4e4f\u5c40\u90e8\u7ed3\u6784\u7684\u65e0\u5e8f\u4e09\u89d2\u5f62\u6c64\u3002\u8fd9\u9879\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6848\uff0c\u76f4\u63a5\u751f\u6210\u5177\u6709\u590d\u6742\u8fde\u901a\u6027\u7684\u6d41\u5f62\u591a\u8fb9\u5f62\u7f51\u683c\u4f5c\u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u8f93\u51fa\u3002\u6211\u4eec\u7684\u5173\u952e\u521b\u65b0\u5728\u4e8e\u5728\u6bcf\u4e2a\u7f51\u683c\u9876\u70b9\u5b9a\u4e49\u4e00\u4e2a\u8fde\u7eed\u7684\u6f5c\u5728\u8fde\u901a\u6027\u7a7a\u95f4\uff0c\u8fd9\u9690\u542b\u4e86\u79bb\u6563\u7f51\u683c\u3002\u7279\u522b\u662f\uff0c\u6211\u4eec\u7684\u9876\u70b9\u5d4c\u5165\u5728\u534a\u8fb9\u7f51\u683c\u8868\u793a\u4e2d\u751f\u6210\u5faa\u73af\u90bb\u5c45\u5173\u7cfb\uff0c\u8fd9\u4fdd\u8bc1\u4e86\u8fb9\u6d41\u5f62\u6027\u5e76\u80fd\u591f\u8868\u793a\u4e00\u822c\u7684\u591a\u8fb9\u5f62\u7f51\u683c\u3002\u8fd9\u79cd\u8868\u793a\u975e\u5e38\u9002\u5408\u673a\u5668\u5b66\u4e60\u548c\u968f\u673a\u4f18\u5316\uff0c\u4e0d\u53d7\u8fde\u901a\u6027\u6216\u62d3\u6251\u7684\u9650\u5236\u3002\u6211\u4eec\u9996\u5148\u63a2\u7d22\u4e86\u8fd9\u79cd\u8868\u793a\u7684\u57fa\u672c\u5c5e\u6027\uff0c\u7136\u540e\u4f7f\u7528\u5b83\u6765\u62df\u5408\u6765\u81ea\u5927\u578b\u6570\u636e\u96c6\u7684\u7f51\u683c\u5206\u5e03\u3002\u751f\u6210\u7684\u6a21\u578b\u751f\u6210\u7684\u7f51\u683c\u5177\u6709\u4ece\u6570\u636e\u96c6\u7fa4\u4f53\u4e2d\u5b66\u4e60\u7684\u9576\u5d4c\u7ed3\u6784\uff0c\u7ec6\u8282\u7b80\u6d01\u4e14\u7f51\u683c\u5143\u7d20\u8d28\u91cf\u9ad8\u3002\u5728\u5e94\u7528\u4e2d\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u4ece\u751f\u6210\u6a21\u578b\u4e2d\u4ea7\u751f\u9ad8\u8d28\u91cf\u7684\u8f93\u51fa\uff0c\u8fd8\u76f4\u63a5\u5b9e\u73b0\u4e86\u5b66\u4e60\u5177\u6709\u6311\u6218\u6027\u7684\u51e0\u4f55\u5904\u7406\u4efb\u52a1\uff0c\u5982\u7f51\u683c\u4fee\u590d\u3002 Tianchang Shen PDF N/A SpaceMesh: A Continuous Representation for Learning Manifold Surface Meshes Meshes are ubiquitous in visual computing and simulation, yet most existing machine learning techniques represent meshes only indirectly, e.g. as the level set of a scalar field or deformation of a template, or as a disordered triangle soup lacking local structure. This work presents a scheme to directly generate manifold, polygonal meshes of complex connectivity as the output of a neural network. Our key innovation is to define a continuous latent connectivity space at each mesh vertex, which implies the discrete mesh. In particular, our vertex embeddings generate cyclic neighbor relationships in a halfedge mesh representation, which gives a guarantee of edge-manifoldness and the ability to represent general polygonal meshes. This representation is well-suited to machine learning and stochastic optimization, without restriction on connectivity or topology. We first explore the basic properties of this representation, then use it to fit distributions of meshes from large datasets. The resulting models generate diverse meshes with tessellation structure learned from the dataset population, with concise details and high-quality mesh elements. In applications, this approach not only yields high-quality outputs from generative models, but also enables directly learning challenging geometry processing tasks such as mesh repair. LaMMA-P\uff1a\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684PDDL\u89c4\u5212\u5668\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u957f\u65f6\u4efb\u52a1\u5206\u914d\u4e0e\u89c4\u5212\u7684\u901a\u7528\u6027 \u8bed\u8a00\u6a21\u578b\uff08LMs\uff09\u5177\u5907\u5f3a\u5927\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u6709\u6548\u5730\u5c06\u4eba\u7c7b\u6307\u4ee4\u8f6c\u5316\u4e3a\u7b80\u5355\u673a\u5668\u4eba\u4efb\u52a1\u7684\u8be6\u7ec6\u8ba1\u5212\u3002\u7136\u800c\uff0c\u5904\u7406\u957f\u65f6\u7a0b\u4efb\u52a1\uff0c\u7279\u522b\u662f\u5728\u5408\u4f5c\u5f02\u6784\u673a\u5668\u4eba\u56e2\u961f\u7684\u5b50\u4efb\u52a1\u8bc6\u522b\u548c\u5206\u914d\u65b9\u9762\uff0c\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53PDDL\u89c4\u5212\u5668\uff08LaMMA-P\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u591a\u667a\u80fd\u4f53\u4efb\u52a1\u89c4\u5212\u6846\u67b6\uff0c\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002LaMMA-P\u7ed3\u5408\u4e86LMs\u7684\u63a8\u7406\u80fd\u529b\u548c\u4f20\u7edf\u542f\u53d1\u5f0f\u641c\u7d22\u89c4\u5212\u5668\u7684\u4f18\u52bf\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6210\u529f\u7387\u548c\u6548\u7387\uff0c\u5e76\u5728\u4efb\u52a1\u95f4\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u6211\u4eec\u521b\u5efa\u4e86MAT-THOR\uff0c\u8fd9\u662f\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u57fa\u4e8eAI2-THOR\u73af\u5883\uff0c\u5305\u542b\u4e24\u79cd\u4e0d\u540c\u590d\u6742\u7a0b\u5ea6\u7684\u5bb6\u5c45\u4efb\u52a1\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLaMMA-P\u7684\u6210\u529f\u7387\u6bd4\u73b0\u6709\u7684\u57fa\u4e8eLM\u7684\u591a\u667a\u80fd\u4f53\u89c4\u5212\u5668\u9ad8\u51fa105%\uff0c\u6548\u7387\u9ad8\u51fa36%\u3002\u672c\u5de5\u4f5c\u7684\u5b9e\u9a8c\u89c6\u9891\u3001\u4ee3\u7801\u3001\u6570\u636e\u96c6\u4ee5\u53ca\u5404\u6a21\u5757\u4e2d\u4f7f\u7528\u7684\u8be6\u7ec6\u63d0\u793a\u5747\u53ef\u5728https://lamma-p.github.io\u83b7\u53d6\u3002 Xiaopan Zhang PDF N/A LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner Language models (LMs) possess a strong capability to comprehend natural language, making them effective in translating human instructions into detailed plans for simple robot tasks. Nevertheless, it remains a significant challenge to handle long-horizon tasks, especially in subtask identification and allocation for cooperative heterogeneous robot teams. To address this issue, we propose a Language Model-Driven Multi-Agent PDDL Planner (LaMMA-P), a novel multi-agent task planning framework that achieves state-of-the-art performance on long-horizon tasks. LaMMA-P integrates the strengths of the LMs' reasoning capability and the traditional heuristic search planner to achieve a high success rate and efficiency while demonstrating strong generalization across tasks. Additionally, we create MAT-THOR, a comprehensive benchmark that features household tasks with two different levels of complexity based on the AI2-THOR environment. The experimental results demonstrate that LaMMA-P achieves a 105% higher success rate and 36% higher efficiency than existing LM-based multi-agent planners. The experimental videos, code, and datasets of this work as well as the detailed prompts used in each module are available at https://lamma-p.github.io. \u76d1\u7763\u591a\u6a21\u6001\u88c2\u53d8\u5b66\u4e60 \u4ece\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u53ef\u4ee5\u5229\u7528\u4e92\u8865\u4fe1\u606f\uff0c\u5e76\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\u63d0\u9ad8\u6027\u80fd\u3002\u5904\u7406\u9ad8\u7ef4\u6570\u636e\u96c6\u4e2d\u7279\u5f81\u76f8\u5173\u6027\u7684\u5e38\u7528\u7b56\u7565\u662f\u6f5c\u5728\u53d8\u91cf\u65b9\u6cd5\u3002\u5df2\u7ecf\u63d0\u51fa\u4e86\u51e0\u79cd\u7528\u4e8e\u591a\u6a21\u6001\u6570\u636e\u96c6\u7684\u6f5c\u5728\u53d8\u91cf\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u8981\u4e48\u4fa7\u91cd\u4e8e\u63d0\u53d6\u6240\u6709\u6a21\u6001\u5171\u4eab\u7684\u6210\u5206\uff0c\u8981\u4e48\u4fa7\u91cd\u4e8e\u63d0\u53d6\u5171\u4eab\u6210\u5206\u4ee5\u53ca\u6bcf\u4e2a\u6a21\u6001\u7279\u6709\u7684\u4e2a\u4f53\u6210\u5206\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u88c2\u53d8\u5b66\u4e60\uff08Multi-Modal Fission Learning, MMFL\uff09\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u540c\u65f6\u8bc6\u522b\u591a\u6a21\u6001\u6570\u636e\u96c6\u7279\u5f81\u4e2d\u6f5c\u5728\u7684\u5168\u5c40\u8054\u5408\u3001\u90e8\u5206\u8054\u5408\u548c\u4e2a\u4f53\u6210\u5206\u3002\u4e0e\u73b0\u6709\u7684\u6f5c\u5728\u53d8\u91cf\u65b9\u6cd5\u4e0d\u540c\uff0cMMFL\u5229\u7528\u54cd\u5e94\u53d8\u91cf\u7684\u76d1\u7763\u6765\u8bc6\u522b\u5177\u6709\u9884\u6d4b\u6027\u7684\u6f5c\u5728\u6210\u5206\uff0c\u5e76\u4e14\u53ef\u4ee5\u81ea\u7136\u5730\u6269\u5c55\u4ee5\u6574\u5408\u4e0d\u5b8c\u6574\u7684\u591a\u6a21\u6001\u6570\u636e\u3002\u901a\u8fc7\u6a21\u62df\u7814\u7a76\uff0c\u6211\u4eec\u8bc1\u660e\u4e86MMFL\u5728\u5b8c\u6574\u548c\u4e0d\u5b8c\u6574\u6a21\u6001\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u5404\u79cd\u73b0\u6709\u7684\u591a\u6a21\u6001\u7b97\u6cd5\u3002\u6211\u4eec\u5c06MMFL\u5e94\u7528\u4e8e\u4e00\u4e2a\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\uff0c\u4f7f\u7528\u6765\u81ea\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u795e\u7ecf\u5f71\u50cf\u5b66\u5021\u8bae\uff08Alzheimers Disease Neuroimaging Initiative, ADNI\uff09\u6570\u636e\u96c6\u7684\u591a\u6a21\u6001\u795e\u7ecf\u5f71\u50cf\u5b66\u548c\u57fa\u56e0\u7ec4\u5b66\u6570\u636e\uff0c\u8fdb\u884c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7684\u65e9\u671f\u9884\u6d4b\u3002\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cMMFL\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u9884\u6d4b\uff0c\u5e76\u66f4\u597d\u5730\u6d1e\u5bdf\u4e86\u6a21\u6001\u5185\u548c\u6a21\u6001\u95f4\u7684\u76f8\u5173\u6027\u3002 Lingchao Mao PDF N/A Supervised Multi-Modal Fission Learning Learning from multimodal datasets can leverage complementary information and improve performance in prediction tasks. A commonly used strategy to account for feature correlations in high-dimensional datasets is the latent variable approach. Several latent variable methods have been proposed for multimodal datasets. However, these methods either focus on extracting the shared component across all modalities or on extracting both a shared component and individual components specific to each modality. To address this gap, we propose a Multi-Modal Fission Learning (MMFL) model that simultaneously identifies globally joint, partially joint, and individual components underlying the features of multimodal datasets. Unlike existing latent variable methods, MMFL uses supervision from the response variable to identify predictive latent components and has a natural extension for incorporating incomplete multimodal data. Through simulation studies, we demonstrate that MMFL outperforms various existing multimodal algorithms in both complete and incomplete modality settings. We applied MMFL to a real-world case study for early prediction of Alzheimers Disease using multimodal neuroimaging and genomics data from the Alzheimers Disease Neuroimaging Initiative (ADNI) dataset. MMFL provided more accurate predictions and better insights into within- and across-modality correlations compared to existing methods. \u5b9e\u9645\u4ee3\u7801\u751f\u6210\u4e2d\u7684LLM\u5e7b\u89c9\uff1a\u73b0\u8c61\u3001\u673a\u5236\u4e0e\u7f13\u89e3 \u4ee3\u7801\u751f\u6210\u65e8\u5728\u6839\u636e\u8f93\u5165\u9700\u6c42\u81ea\u52a8\u751f\u6210\u4ee3\u7801\uff0c\u663e\u8457\u63d0\u5347\u5f00\u53d1\u6548\u7387\u3002\u8fd1\u671f\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u65b9\u6cd5\u5c55\u793a\u4e86\u4ee4\u4eba\u9f13\u821e\u7684\u7ed3\u679c\uff0c\u5e76\u5f7b\u5e95\u6539\u53d8\u4e86\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u3002\u5c3d\u7ba1\u6027\u80fd\u8868\u73b0\u51fa\u8272\uff0cLLMs\u5728\u751f\u6210\u5185\u5bb9\u65f6\u5e38\u5e38\u51fa\u73b0\u5e7b\u89c9\uff0c\u7279\u522b\u662f\u5728\u5b9e\u9645\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u9700\u8981\u5904\u7406\u590d\u6742\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u4ee3\u7801\u751f\u6210\u573a\u666f\u4e2d\u3002\u867d\u7136\u5148\u524d\u7684\u7814\u7a76\u5df2\u7ecf\u5206\u6790\u4e86\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5e7b\u89c9\u73b0\u8c61\uff0c\u4f46\u8fd9\u4e9b\u7814\u7a76\u4ec5\u9650\u4e8e\u72ec\u7acb\u51fd\u6570\u7684\u751f\u6210\u3002\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86\u5728\u66f4\u5b9e\u9645\u548c\u590d\u6742\u7684\u5f00\u53d1\u4e0a\u4e0b\u6587\u4e2d\uff0c\u5373\u5728\u4ed3\u5e93\u7ea7\u522b\u751f\u6210\u573a\u666f\u4e0b\uff0cLLM\u5e7b\u89c9\u7684\u73b0\u8c61\u3001\u673a\u5236\u53ca\u5176\u7f13\u89e3\u65b9\u6cd5\u3002\u9996\u5148\uff0c\u6211\u4eec\u624b\u52a8\u68c0\u67e5\u4e86\u516d\u4e2a\u4e3b\u6d41LLMs\u7684\u4ee3\u7801\u751f\u6210\u7ed3\u679c\uff0c\u5efa\u7acb\u4e86LLM\u751f\u6210\u4ee3\u7801\u7684\u5e7b\u89c9\u5206\u7c7b\u3002\u63a5\u7740\uff0c\u6211\u4eec\u8be6\u7ec6\u9610\u8ff0\u4e86\u5e7b\u89c9\u73b0\u8c61\uff0c\u5206\u6790\u4e86\u5176\u5728\u4e0d\u540c\u6a21\u578b\u4e2d\u7684\u5206\u5e03\u3002\u7136\u540e\uff0c\u6211\u4eec\u5206\u6790\u4e86\u5e7b\u89c9\u7684\u539f\u56e0\uff0c\u5e76\u8bc6\u522b\u51fa\u56db\u4e2a\u53ef\u80fd\u5bfc\u81f4\u5e7b\u89c9\u7684\u56e0\u7d20\u3002\u6700\u540e\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRAG\u7684\u7f13\u89e3\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u6240\u6709\u7814\u7a76\u7684LLMs\u4e2d\u5747\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6709\u6548\u6027\u3002\u5305\u542b\u4ee3\u7801\u3001\u6570\u636e\u548c\u5b9e\u9a8c\u7ed3\u679c\u7684\u590d\u5236\u5305\u53ef\u5728https://github.com/DeepSoftwareAnalytics/LLMCodingHallucination\u83b7\u53d6\u3002 Ziyao Zhang PDF N/A LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism, and Mitigation Code generation aims to automatically generate code from input requirements, significantly enhancing development efficiency. Recent large language models (LLMs) based approaches have shown promising results and revolutionized code generation task. Despite the promising performance, LLMs often generate contents with hallucinations, especially for the code generation scenario requiring the handling of complex contextual dependencies in practical development process. Although previous study has analyzed hallucinations in LLM-powered code generation, the study is limited to standalone function generation. In this paper, we conduct an empirical study to study the phenomena, mechanism, and mitigation of LLM hallucinations within more practical and complex development contexts in repository-level generation scenario. First, we manually examine the code generation results from six mainstream LLMs to establish a hallucination taxonomy of LLM-generated code. Next, we elaborate on the phenomenon of hallucinations, analyze their distribution across different models. We then analyze causes of hallucinations and identify four potential factors contributing to hallucinations. Finally, we propose an RAG-based mitigation method, which demonstrates consistent effectiveness in all studied LLMs. The replication package including code, data, and experimental results is available at https://github.com/DeepSoftwareAnalytics/LLMCodingHallucination \u9000\u706b\u6d41\u751f\u6210\u6a21\u578b\uff1a\u9762\u5411\u9ad8\u7ef4\u548c\u591a\u6a21\u6001\u5206\u5e03\u7684\u91c7\u6837 \u4ece\u9ad8\u7ef4\u3001\u591a\u6a21\u6001\u5206\u5e03\u4e2d\u91c7\u6837\u4ecd\u7136\u662f\u7edf\u8ba1\u8d1d\u53f6\u65af\u63a8\u65ad\u548c\u57fa\u4e8e\u7269\u7406\u7684\u673a\u5668\u5b66\u4e60\u7b49\u9886\u57df\u4e2d\u7684\u4e00\u4e2a\u57fa\u672c\u6311\u6218\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u9000\u706b\u6d41\u201d\uff08Annealing Flow, AF\uff09\u7684\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u8fde\u7eed\u5f52\u4e00\u5316\u6d41\u7684\u8bbe\u8ba1\uff0c\u65e8\u5728\u4ece\u9ad8\u7ef4\u548c\u591a\u6a21\u6001\u5206\u5e03\u4e2d\u8fdb\u884c\u91c7\u6837\u3002\u5176\u6838\u5fc3\u601d\u60f3\u662f\u5b66\u4e60\u4e00\u4e2a\u7531\u9000\u706b\u5f15\u5bfc\u7684\u8fde\u7eed\u5f52\u4e00\u5316\u6d41\u4f20\u8f93\u6620\u5c04\uff0c\u4f7f\u6837\u672c\u4ece\u6613\u4e8e\u91c7\u6837\u7684\u5206\u5e03\u8fc7\u6e21\u5230\u76ee\u6807\u5206\u5e03\uff0c\u4ece\u800c\u4fc3\u8fdb\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u5bf9\u6a21\u5f0f\u7684\u6709\u6548\u63a2\u7d22\u3002\u4e0e\u8bb8\u591a\u73b0\u6709\u65b9\u6cd5\u4e0d\u540c\uff0cAF\u7684\u8bad\u7ec3\u4e0d\u4f9d\u8d56\u4e8e\u76ee\u6807\u5206\u5e03\u7684\u6837\u672c\u3002AF\u786e\u4fdd\u4e86\u6709\u6548\u4e14\u5e73\u8861\u7684\u6a21\u5f0f\u63a2\u7d22\uff0c\u5b9e\u73b0\u4e86\u6837\u672c\u5927\u5c0f\u548c\u7ef4\u5ea6\u7684\u7ebf\u6027\u590d\u6742\u5ea6\uff0c\u5e76\u907f\u514d\u4e86\u4f4e\u6548\u7684\u6df7\u5408\u65f6\u95f4\u3002\u901a\u8fc7\u5728\u5404\u79cd\u5177\u6709\u6311\u6218\u6027\u7684\u5206\u5e03\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u548c\u591a\u6a21\u6001\u8bbe\u7f6e\u4e2d\uff0c\u6211\u4eec\u5c55\u793a\u4e86AF\u76f8\u5bf9\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u80fd\u3002\u6211\u4eec\u8fd8\u5f3a\u8c03\u4e86AF\u5728\u91c7\u6837\u6700\u4e0d\u5229\u5206\u5e03\u65b9\u9762\u7684\u6f5c\u529b\u3002 Dongze Wu PDF N/A Annealing Flow Generative Model Towards Sampling High-Dimensional and Multi-Modal Distributions Sampling from high-dimensional, multi-modal distributions remains a fundamental challenge across domains such as statistical Bayesian inference and physics-based machine learning. In this paper, we propose Annealing Flow (AF), a continuous normalizing flow-based approach designed to sample from high-dimensional and multi-modal distributions. The key idea is to learn a continuous normalizing flow-based transport map, guided by annealing, to transition samples from an easy-to-sample distribution to the target distribution, facilitating effective exploration of modes in high-dimensional spaces. Unlike many existing methods, AF training does not rely on samples from the target distribution. AF ensures effective and balanced mode exploration, achieves linear complexity in sample size and dimensions, and circumvents inefficient mixing times. We demonstrate the superior performance of AF compared to state-of-the-art methods through extensive experiments on various challenging distributions and real-world datasets, particularly in high-dimensional and multi-modal settings. We also highlight the potential of AF for sampling the least favorable distributions. \u6269\u5c55\u672c\u4f53\u611f\u53d7-\u89c6\u89c9\u5b66\u4e60\u4e0e\u5f02\u6784\u9884\u8bad\u7ec3\u53d8\u538b\u5668 \u5f53\u524d\u8bad\u7ec3\u901a\u7528\u673a\u5668\u4eba\u6a21\u578b\u7684\u4e00\u4e2a\u969c\u788d\u662f\u5f02\u8d28\u6027\u3002\u4ee5\u5f80\u7684\u673a\u5668\u4eba\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u4e3a\u4e00\u9879\u7279\u5b9a\u4efb\u52a1\u6536\u96c6\u6570\u636e\u4ee5\u8bad\u7ec3\u4e00\u4e2a\u7279\u5b9a\u7684\u5b9e\u4f53\uff0c\u8fd9\u79cd\u65b9\u6cd5\u6210\u672c\u9ad8\u4e14\u5bb9\u6613\u8fc7\u62df\u5408\u3002\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u901a\u8fc7\u5728\u4e0d\u540c\u5b9e\u4f53\u548c\u4efb\u52a1\u7684\u5927\u89c4\u6a21\u673a\u5668\u4eba\u6570\u636e\u4e0a\u8fdb\u884c\u5f02\u8d28\u6027\u9884\u8bad\u7ec3\u6765\u5b66\u4e60\u7b56\u7565\u8868\u793a\u7684\u95ee\u9898\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u5f02\u8d28\u6027\u9884\u8bad\u7ec3\u53d8\u538b\u5668\uff08HPT\uff09\uff0c\u5b83\u9884\u8bad\u7ec3\u4e00\u4e2a\u5927\u578b\u3001\u53ef\u5171\u4eab\u7684\u7b56\u7565\u795e\u7ecf\u7f51\u7edc\u4e3b\u5e72\uff0c\u4ee5\u5b66\u4e60\u4e0e\u4efb\u52a1\u548c\u5b9e\u4f53\u65e0\u5173\u7684\u5171\u4eab\u8868\u793a\u3002\u8fd9\u79cd\u901a\u7528\u67b6\u6784\u5c06\u6765\u81ea\u4e0d\u540c\u5b9e\u4f53\u7684\u7279\u5b9a\u672c\u4f53\u611f\u53d7\u548c\u89c6\u89c9\u8f93\u5165\u5bf9\u9f50\u4e3a\u4e00\u7cfb\u5217\u77ed\u6807\u8bb0\uff0c\u7136\u540e\u5904\u7406\u8fd9\u4e9b\u6807\u8bb0\u4ee5\u6620\u5c04\u5230\u4e0d\u540c\u4efb\u52a1\u7684\u673a\u5668\u4eba\u63a7\u5236\u3002\u5229\u7528\u6700\u8fd1\u7684\u5927\u89c4\u6a21\u591a\u5b9e\u4f53\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u6570\u636e\u96c6\u4ee5\u53ca\u6a21\u62df\u3001\u90e8\u7f72\u7684\u673a\u5668\u4eba\u548c\u4eba\u7c7b\u89c6\u9891\u6570\u636e\u96c6\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u8de8\u5f02\u8d28\u6027\u7684\u7b56\u7565\u9884\u8bad\u7ec3\u3002\u6211\u4eec\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u7814\u7a76\u4e86\u8bad\u7ec3\u76ee\u6807\u7684\u6269\u5c55\u884c\u4e3a\uff0c\u6d89\u53ca\u591a\u8fbe52\u4e2a\u6570\u636e\u96c6\u3002HPT\u5728\u591a\u4e2a\u6a21\u62df\u57fa\u51c6\u548c\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\uff0c\u5728\u672a\u89c1\u4efb\u52a1\u4e0a\u7684\u5fae\u8c03\u7b56\u7565\u6027\u80fd\u6bd4\u51e0\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa\u8d85\u8fc720%\u3002\u6709\u5173\u4ee3\u7801\u548c\u89c6\u9891\uff0c\u8bf7\u53c2\u89c1\u9879\u76ee\u7f51\u7ad9\uff08https://liruiw.github.io/hpt/\uff09\u3002 Lirui Wang PDF N/A Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformers One of the roadblocks for training generalist robotic models today is heterogeneity. Previous robot learning methods often collect data to train with one specific embodiment for one task, which is expensive and prone to overfitting. This work studies the problem of learning policy representations through heterogeneous pre-training on robot data across different embodiments and tasks at scale. We propose Heterogeneous Pre-trained Transformers (HPT), which pre-train a large, shareable trunk of a policy neural network to learn a task and embodiment agnostic shared representation. This general architecture aligns the specific proprioception and vision inputs from distinct embodiments to a short sequence of tokens and then processes such tokens to map to control robots for different tasks. Leveraging the recent large-scale multi-embodiment real-world robotic datasets as well as simulation, deployed robots, and human video datasets, we investigate pre-training policies across heterogeneity. We conduct experiments to investigate the scaling behaviors of training objectives, to the extent of 52 datasets. HPTs outperform several baselines and enhance the fine-tuned policy performance by over 20% on unseen tasks in multiple simulator benchmarks and real-world settings. See the project website (https://liruiw.github.io/hpt/) for code and videos. \u4fe1\u7528\u8bc4\u5206\u4e2d\u8d1f\u8d23\u4efb\u673a\u5668\u5b66\u4e60\u7684\u6700\u4f73\u5b9e\u8df5 \u673a\u5668\u5b66\u4e60\u5728\u4fe1\u7528\u8bc4\u5206\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u663e\u8457\u63d0\u5347\u4e86\u98ce\u9669\u8bc4\u4f30\u548c\u51b3\u7b56\u5236\u5b9a\u7684\u6c34\u5e73\u3002\u7136\u800c\uff0c\u8fd9\u4e5f\u5f15\u53d1\u4e86\u5173\u4e8e\u8fd9\u4e9b\u81ea\u52a8\u5316\u7cfb\u7edf\u4e2d\u6f5c\u5728\u504f\u89c1\u3001\u6b67\u89c6\u548c\u7f3a\u4e4f\u900f\u660e\u5ea6\u7684\u62c5\u5fe7\u3002\u672c\u6559\u7a0b\u8bba\u6587\u8fdb\u884c\u4e86\u975e\u7cfb\u7edf\u6027\u6587\u732e\u56de\u987e\uff0c\u65e8\u5728\u6307\u5bfc\u5728\u4fe1\u7528\u8bc4\u5206\u4e2d\u5f00\u53d1\u8d1f\u8d23\u4efb\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u91cd\u70b9\u5173\u6ce8\u516c\u5e73\u6027\u3001\u62d2\u7edd\u63a8\u65ad\u548c\u53ef\u89e3\u91ca\u6027\u3002\u6211\u4eec\u8ba8\u8bba\u4e86\u5b9a\u4e49\u3001\u6307\u6807\u548c\u6280\u672f\uff0c\u4ee5\u51cf\u8f7b\u504f\u89c1\u5e76\u786e\u4fdd\u4e0d\u540c\u7fa4\u4f53\u95f4\u7684\u516c\u5e73\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u6211\u4eec\u901a\u8fc7\u63a2\u7d22\u7ed3\u5408\u88ab\u62d2\u7edd\u8d37\u6b3e\u7533\u8bf7\u4fe1\u606f\u7684\u62d2\u7edd\u63a8\u65ad\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u6700\u540e\uff0c\u6211\u4eec\u5f3a\u8c03\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u5728\u4fe1\u7528\u6a21\u578b\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u8ba8\u8bba\u4e86\u63d0\u4f9b\u51b3\u7b56\u8fc7\u7a0b\u6d1e\u5bdf\u529b\u5e76\u4f7f\u4e2a\u4eba\u80fd\u591f\u7406\u89e3\u5e76\u53ef\u80fd\u63d0\u5347\u5176\u4fe1\u7528\u4ef7\u503c\u7684\u6280\u672f\u3002\u901a\u8fc7\u91c7\u7528\u8fd9\u4e9b\u6700\u4f73\u5b9e\u8df5\uff0c\u91d1\u878d\u673a\u6784\u53ef\u4ee5\u5728\u575a\u6301\u4f26\u7406\u548c\u8d1f\u8d23\u4efb\u7684\u8d37\u6b3e\u5b9e\u8df5\u7684\u540c\u65f6\uff0c\u5145\u5206\u5229\u7528\u673a\u5668\u5b66\u4e60\u7684\u529b\u91cf\u3002 Giovani Valdrighi PDF N/A Best Practices for Responsible Machine Learning in Credit Scoring The widespread use of machine learning in credit scoring has brought significant advancements in risk assessment and decision-making. However, it has also raised concerns about potential biases, discrimination, and lack of transparency in these automated systems. This tutorial paper performed a non-systematic literature review to guide best practices for developing responsible machine learning models in credit scoring, focusing on fairness, reject inference, and explainability. We discuss definitions, metrics, and techniques for mitigating biases and ensuring equitable outcomes across different groups. Additionally, we address the issue of limited data representativeness by exploring reject inference methods that incorporate information from rejected loan applications. Finally, we emphasize the importance of transparency and explainability in credit models, discussing techniques that provide insights into the decision-making process and enable individuals to understand and potentially improve their creditworthiness. By adopting these best practices, financial institutions can harness the power of machine learning while upholding ethical and responsible lending practices. \u7aef\u5230\u7aef\u4fdd\u5f62\u6821\u51c6\u7528\u4e8e\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u4f18\u5316 \u673a\u5668\u5b66\u4e60\u80fd\u591f\u663e\u8457\u63d0\u5347\u5728\u5e7f\u6cdb\u9886\u57df\u4e2d\u4e0d\u786e\u5b9a\u60c5\u51b5\u4e0b\u7684\u51b3\u7b56\u6027\u80fd\u3002\u7136\u800c\uff0c\u786e\u4fdd\u9c81\u68d2\u6027\u4fdd\u969c\u9700\u8981\u7ecf\u8fc7\u826f\u597d\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u8fd9\u5728\u9ad8\u5bb9\u91cf\u9884\u6d4b\u6a21\u578b\uff08\u5982\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff09\u4e2d\u53ef\u80fd\u96be\u4ee5\u5b9e\u73b0\u3002\u6b64\u5916\uff0c\u5728\u9ad8\u7ef4\u73af\u5883\u4e2d\uff0c\u53ef\u80fd\u5b58\u5728\u8bb8\u591a\u6709\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u6bcf\u4e2a\u90fd\u6709\u5176\u81ea\u8eab\u7684\u6027\u80fd\u7279\u5f81\u2014\u2014\u5373\u5e76\u975e\u6240\u6709\u4e0d\u786e\u5b9a\u6027\u5bf9\u4e8e\u4e0b\u6e38\u51b3\u7b56\u90fd\u5177\u6709\u540c\u7b49\u4ef7\u503c\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u6761\u4ef6\u9c81\u68d2\u4f18\u5316\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4fdd\u5f62\u9884\u6d4b\u63d0\u4f9b\u4e86\u9c81\u68d2\u6027\u548c\u6821\u51c6\u4fdd\u969c\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63d0\u51fa\u4f7f\u7528\u90e8\u5206\u8f93\u5165\u51f8\u795e\u7ecf\u7f51\u7edc\u6765\u8868\u793a\u4efb\u610f\u51f8\u4e0d\u786e\u5b9a\u6027\u96c6\u5408\uff0c\u8fd9\u4e9b\u7f51\u7edc\u4f5c\u4e3a\u6211\u4eec\u6846\u67b6\u7684\u4e00\u90e8\u5206\u8fdb\u884c\u5b66\u4e60\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u80fd\u6e90\u5b58\u50a8\u5957\u5229\u548c\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u7b49\u5177\u4f53\u5e94\u7528\u4e2d\uff0c\u6301\u7eed\u4f18\u4e8e\u4e24\u9636\u6bb5\u4f30\u8ba1\u540e\u4f18\u5316\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002 Christopher Yeh PDF N/A End-to-End Conformal Calibration for Optimization Under Uncertainty Machine learning can significantly improve performance for decision-making under uncertainty in a wide range of domains. However, ensuring robustness guarantees requires well-calibrated uncertainty estimates, which can be difficult to achieve in high-capacity prediction models such as deep neural networks. Moreover, in high-dimensional settings, there may be many valid uncertainty estimates, each with their own performance profile - i.e., not all uncertainty is equally valuable for downstream decision-making. To address this problem, this paper develops an end-to-end framework to learn the uncertainty estimates for conditional robust optimization, with robustness and calibration guarantees provided by conformal prediction. In addition, we propose to represent arbitrary convex uncertainty sets with partially input-convex neural networks, which are learned as part of our framework. Our approach consistently improves upon two-stage estimate-then-optimize baselines on concrete applications in energy storage arbitrage and portfolio optimization. \u53cc\u7f16\u7801\u5668\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u53cd\u6f14\u7528\u4e8e\u4ece\u5355\u5f20\u56fe\u50cf\u8fdb\u884c\u9ad8\u4fdd\u771f3D\u5934\u90e8\u91cd\u5efa 3D GAN inversion\u65e8\u5728\u5c06\u5355\u5f20\u56fe\u50cf\u6295\u5f71\u52303D\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\uff0c\u4ece\u800c\u5b9e\u73b03D\u51e0\u4f55\u91cd\u5efa\u3002\u867d\u7136\u73b0\u6709\u7684\u7f16\u7801\u5668\u57283D GAN\u53cd\u8f6c\u4e2d\u53d6\u5f97\u4e86\u826f\u597d\u7684\u6548\u679c\uff0c\u4f46\u5b83\u4eec\u4e3b\u8981\u57fa\u4e8eEG3D\u6784\u5efa\uff0c\u8be5\u6a21\u578b\u64c5\u957f\u5408\u6210\u8fd1\u6b63\u9762\u89c6\u89d2\u7684\u56fe\u50cf\uff0c\u4f46\u5728\u4ece\u591a\u6837\u89c6\u89d2\u5408\u6210\u5168\u9762\u76843D\u573a\u666f\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002\u4e0e\u73b0\u6709\u65b9\u6cd5\u4e0d\u540c\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePanoHead\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u64c5\u957f\u4ece360\u5ea6\u89c6\u89d2\u5408\u6210\u56fe\u50cf\u3002\u4e3a\u4e86\u5b9e\u73b0\u8f93\u5165\u56fe\u50cf\u7684\u771f\u5b9e\u611f3D\u5efa\u6a21\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u53cc\u7f16\u7801\u5668\u7cfb\u7edf\uff0c\u4e13\u95e8\u7528\u4e8e\u9ad8\u4fdd\u771f\u91cd\u5efa\u548c\u4ece\u4e0d\u540c\u89c6\u89d2\u7684\u771f\u5b9e\u611f\u751f\u6210\u3002\u540c\u65f6\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4e09\u5e73\u9762\u57df\u4e0a\u7684\u62fc\u63a5\u6846\u67b6\uff0c\u4ee5\u4ece\u4e24\u8005\u4e2d\u83b7\u5f97\u6700\u4f73\u9884\u6d4b\u3002\u4e3a\u4e86\u5b9e\u73b0\u65e0\u7f1d\u62fc\u63a5\uff0c\u5c3d\u7ba1\u4e24\u4e2a\u7f16\u7801\u5668\u4e13\u7528\u4e8e\u4e0d\u540c\u4efb\u52a1\uff0c\u5b83\u4eec\u5fc5\u987b\u8f93\u51fa\u4e00\u81f4\u7684\u7ed3\u679c\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u4f7f\u7528\u4e13\u95e8\u7684\u635f\u5931\u4ed4\u7ec6\u8bad\u7ec3\u8fd9\u4e9b\u7f16\u7801\u5668\uff0c\u5305\u62ec\u57fa\u4e8e\u6211\u4eec\u65b0\u9896\u7684\u906e\u6321\u611f\u77e5\u4e09\u5e73\u9762\u5224\u522b\u5668\u7684\u5bf9\u6297\u635f\u5931\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u8d28\u91cf\u548c\u6570\u91cf\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u7684\u7f16\u7801\u5668\u8bad\u7ec3\u65b9\u6cd5\u3002\u8bf7\u8bbf\u95ee\u9879\u76ee\u9875\u9762\uff1ahttps://berkegokmen1.github.io/dual-enc-3d-gan-inv\u3002 Bahri Batuhan Bilecen PDF N/A Dual Encoder GAN Inversion for High-Fidelity 3D Head Reconstruction from Single Images 3D GAN inversion aims to project a single image into the latent space of a 3D Generative Adversarial Network (GAN), thereby achieving 3D geometry reconstruction. While there exist encoders that achieve good results in 3D GAN inversion, they are predominantly built on EG3D, which specializes in synthesizing near-frontal views and is limiting in synthesizing comprehensive 3D scenes from diverse viewpoints. In contrast to existing approaches, we propose a novel framework built on PanoHead, which excels in synthesizing images from a 360-degree perspective. To achieve realistic 3D modeling of the input image, we introduce a dual encoder system tailored for high-fidelity reconstruction and realistic generation from different viewpoints. Accompanying this, we propose a stitching framework on the triplane domain to get the best predictions from both. To achieve seamless stitching, both encoders must output consistent results despite being specialized for different tasks. For this reason, we carefully train these encoders using specialized losses, including an adversarial loss based on our novel occlusion-aware triplane discriminator. Experiments reveal that our approach surpasses the existing encoder training methods qualitatively and quantitatively. Please visit the project page: https://berkegokmen1.github.io/dual-enc-3d-gan-inv. \u6b63\u5f0f\u9a8c\u8bc1\u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u63a7\u5236\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570 \u63a7\u5236\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\u662f\u8bbe\u8ba1\u548c\u5206\u6790\u975e\u7ebf\u6027\u7cfb\u7edf\u7a33\u5b9a\u63a7\u5236\u5668\u7684\u5173\u952e\u5de5\u5177\u3002\u7136\u800c\uff0c\u6784\u5efa\u8fd9\u4e9b\u51fd\u6570\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u5b66\u4e60\u548c\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\u7684\u6b63\u5f0f\u9a8c\u8bc1\u3002\u8fd9\u4e9b\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u4e86\u4e00\u4e2a\u53d8\u6362\u540e\u7684\u54c8\u5bc6\u987f-\u96c5\u53ef\u6bd4-\u8d1d\u5c14\u66fc\u65b9\u7a0b\uff0c\u8be5\u65b9\u7a0b\u901a\u8fc7\u4f7f\u7528\u5e9e\u7279\u91cc\u4e9a\u91d1\u6700\u5927\u539f\u7406\u751f\u6210\u7684\u6570\u636e\u8fdb\u884c\u4e86\u589e\u5f3a\u3002\u7c7b\u4f3c\u4e8eZubov\u65b9\u7a0b\u5982\u4f55\u8868\u5f81\u81ea\u6cbb\u7cfb\u7edf\u7684\u5438\u5f15\u57df\uff0c\u8be5\u65b9\u7a0b\u8868\u5f81\u4e86\u53d7\u63a7\u7cfb\u7edf\u7684\u96f6\u53ef\u63a7\u96c6\u3002\u6570\u503c\u4f8b\u5b50\u8868\u660e\uff0c\u8fd9\u79cd\u539f\u5219\u6027\u7684\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\u5b66\u4e60\u65b9\u6cd5\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5982\u5e73\u65b9\u548c\u548c\u6709\u7406\u63a7\u5236\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\u3002\u4f5c\u4e3a\u4e2d\u95f4\u6b65\u9aa4\uff0c\u6211\u4eec\u8fd8\u5c55\u793a\u4e86\u5173\u4e8e\u4e8c\u6b21\u63a7\u5236\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\u7684\u6b63\u5f0f\u9a8c\u8bc1\u7ed3\u679c\uff0c\u8fd9\u4e9b\u51fd\u6570\u5728\u53ef\u6ee1\u8db3\u6027\u6a21\u7406\u8bba\u6c42\u89e3\u5668\u7684\u5e2e\u52a9\u4e0b\uff0c\u4e0e\u66f4\u590d\u6742\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u80fd\u591f\u9ad8\u6548\u5730\u751f\u6210\u96f6\u53ef\u63a7\u6027\u7684\u5168\u5c40\u8bc1\u4e66\u3002 Jun Liu PDF N/A Formally Verified Physics-Informed Neural Control Lyapunov Functions Control Lyapunov functions are a central tool in the design and analysis of stabilizing controllers for nonlinear systems. Constructing such functions, however, remains a significant challenge. In this paper, we investigate physics-informed learning and formal verification of neural network control Lyapunov functions. These neural networks solve a transformed Hamilton-Jacobi-Bellman equation, augmented by data generated using Pontryagin's maximum principle. Similar to how Zubov's equation characterizes the domain of attraction for autonomous systems, this equation characterizes the null-controllability set of a controlled system. This principled learning of neural network control Lyapunov functions outperforms alternative approaches, such as sum-of-squares and rational control Lyapunov functions, as demonstrated by numerical examples. As an intermediate step, we also present results on the formal verification of quadratic control Lyapunov functions, which, aided by satisfiability modulo theories solvers, can perform surprisingly well compared to more sophisticated approaches and efficiently produce global certificates of null-controllability. \u6bcd\u8bed\u897f\u73ed\u7259\u8bed\u4e2d\u7684\u8bcd\u4e49\u6d88\u6b67\uff1a\u5168\u9762\u7684\u8bcd\u6c47\u8bc4\u4f30\u8d44\u6e90 \u4eba\u7c7b\u8bed\u8a00\u867d\u7136\u65e8\u5728\u4f20\u8fbe\u610f\u4e49\uff0c\u4f46\u5176\u672c\u8eab\u5177\u6709\u56fa\u6709\u7684\u6a21\u7cca\u6027\u3002\u8fd9\u79cd\u6a21\u7cca\u6027\u5bf9\u8bed\u97f3\u548c\u8bed\u8a00\u5904\u7406\u63d0\u51fa\u4e86\u6311\u6218\uff0c\u4f46\u540c\u65f6\u4e5f\u5177\u6709\u91cd\u8981\u7684\u4ea4\u6d41\u529f\u80fd\u3002\u9ad8\u6548\u5730\u89e3\u51b3\u6a21\u7cca\u6027\u65e2\u662f\u4e00\u79cd\u671f\u671b\uff0c\u4e5f\u662f\u4e00\u79cd\u5fc5\u8981\u7279\u5f81\u3002\u5728\u7279\u5b9a\u8bed\u5883\u4e0b\uff0c\u5355\u8bcd\u7684\u8bcd\u4e49\u53ef\u4ee5\u901a\u8fc7\u8bcd\u4e49\u6d88\u6b67\uff08WSD\uff09\u7b97\u6cd5\u81ea\u52a8\u786e\u5b9a\uff0c\u8fd9\u4e9b\u7b97\u6cd5\u4f9d\u8d56\u4e8e\u5916\u90e8\u77e5\u8bc6\uff0c\u4f46\u8fd9\u4e9b\u77e5\u8bc6\u901a\u5e38\u6709\u9650\u4e14\u504f\u5411\u4e8e\u82f1\u8bed\u3002\u5728\u5c06\u5185\u5bb9\u9002\u914d\u5230\u5176\u4ed6\u8bed\u8a00\u65f6\uff0c\u81ea\u52a8\u5316\u7ffb\u8bd1\u5f80\u5f80\u4e0d\u591f\u51c6\u786e\uff0c\u9700\u8981\u9ad8\u5ea6\u4e13\u4e1a\u7684\u4e13\u5bb6\u9a8c\u8bc1\u6765\u786e\u4fdd\u51c6\u786e\u6027\u548c\u7406\u89e3\u3002\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u897f\u73ed\u7259\u8bedWSD\u8d44\u6e90\u6765\u89e3\u51b3\u4ee5\u5f80\u7684\u5c40\u9650\u6027\u3002\u8be5\u8d44\u6e90\u5305\u62ec\u4e00\u4e2a\u8bed\u4e49\u5e93\u5b58\u548c\u4e00\u4e2a\u8bcd\u6c47\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u6570\u636e\u6765\u6e90\u4e8e\u897f\u73ed\u7259\u7687\u5bb6\u8bed\u8a00\u5b66\u9662\u7ef4\u62a4\u7684\u300a\u897f\u73ed\u7259\u8bed\u8bcd\u5178\u300b\u3002\u6211\u4eec\u8fd8\u56de\u987e\u4e86\u5f53\u524d\u7684\u897f\u73ed\u7259\u8bed\u8d44\u6e90\uff0c\u5e76\u901a\u8fc7\u6700\u5148\u8fdb\u7684\u7cfb\u7edf\u62a5\u544a\u4e86\u5b83\u4eec\u7684\u6307\u6807\u3002 Pablo Ortega PDF N/A Word Sense Disambiguation in Native Spanish: A Comprehensive Lexical Evaluation Resource Human language, while aimed at conveying meaning, inherently carries ambiguity. It poses challenges for speech and language processing, but also serves crucial communicative functions. Efficiently solve ambiguity is both a desired and a necessary characteristic. The lexical meaning of a word in context can be determined automatically by Word Sense Disambiguation (WSD) algorithms that rely on external knowledge often limited and biased toward English. When adapting content to other languages, automated translations are frequently inaccurate and a high degree of expert human validation is necessary to ensure both accuracy and understanding. The current study addresses previous limitations by introducing a new resource for Spanish WSD. It includes a sense inventory and a lexical dataset sourced from the Diccionario de la Lengua Espa\\~nola which is maintained by the Real Academia Espa\\~nola. We also review current resources for Spanish and report metrics on them by a state-of-the-art system. \u5206\u5e03\u7a33\u5065\u7684\u975e\u52a8\u6001\u5f3a\u5316\u5b66\u4e60\u7684\u4e0a\u4e0b\u754c \u6211\u4eec\u7814\u7a76\u4e86\u7b56\u7565\u8bad\u7ec3\u548c\u90e8\u7f72\u73af\u5883\u4e0d\u540c\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u79cd\u73af\u5883\u6270\u52a8\uff0c\u6211\u4eec\u4e13\u6ce8\u4e8e\u5728\u5206\u5e03\u5f0f\u9c81\u68d2\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08DRMDPs\uff09\u6846\u67b6\u4e0b\u5b66\u4e60\u5bf9\u8f6c\u79fb\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u5177\u6709\u9c81\u68d2\u6027\u7684\u7b56\u7565\uff0c\u5176\u4e2d\u6807\u79f0\u548c\u6270\u52a8\u52a8\u6001\u5747\u4e3a\u7ebf\u6027\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7b97\u6cd5We-DRIVE-U\uff0c\u8be5\u7b97\u6cd5\u5177\u6709\u5e73\u5747\u6b21\u4f18\u6027$\\widetilde{\\mathcal{O}}\\big({d H \\cdot \\min {1/{\\rho}, H}/\\sqrt{K} }\\big)$\uff0c\u5176\u4e2d$K$\u662f\u5267\u96c6\u6570\uff0c$H$\u662f\u65f6\u95f4\u8303\u56f4\u957f\u5ea6\uff0c$d$\u662f\u7279\u5f81\u7ef4\u5ea6\uff0c$\\rho$\u662f\u4e0d\u786e\u5b9a\u6027\u6c34\u5e73\u3002\u8fd9\u4e00\u7ed3\u679c\u5c06\u73b0\u6709\u6280\u672f\u7684\u6c34\u5e73\u63d0\u9ad8\u4e86$\\mathcal{O}(dH/\\min{1/\\rho,H})$\u3002\u6211\u4eec\u8fd8\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u56f0\u96be\u5b9e\u4f8b\uff0c\u5e76\u5728\u6b64\u8bbe\u7f6e\u4e2d\u63a8\u5bfc\u51fa\u4e86\u7b2c\u4e00\u4e2a\u4fe1\u606f\u8bba\u4e0b\u754c\uff0c\u8fd9\u8868\u660e\u6211\u4eec\u7684\u7b97\u6cd5\u5728\u4efb\u610f\u4e0d\u786e\u5b9a\u6027\u6c34\u5e73$\\rho\\in(0,1]$\u4e0b\uff0c\u51e0\u4e4e\u662f\u6700\u4f18\u7684\uff0c\u8bef\u5dee\u5728$\\mathcal{O}(\\sqrt{H})$\u4ee5\u5185\u3002\u6211\u4eec\u7684\u7b97\u6cd5\u8fd8\u91c7\u7528\u4e86\u201c\u7f55\u89c1\u5207\u6362\u201d\u8bbe\u8ba1\uff0c\u56e0\u6b64\u53ea\u9700\u8981$\\mathcal{O}(dH\\log(1+H^2K))$\u6b21\u7b56\u7565\u5207\u6362\u548c$\\mathcal{O}(d^2H\\log(1+H^2K))$\u6b21\u5bf9\u6c42\u89e3\u5bf9\u5076\u4f18\u5316\u95ee\u9898\u7684oracle\u8c03\u7528\uff0c\u8fd9\u663e\u8457\u63d0\u9ad8\u4e86\u73b0\u6709DRMDPs\u7b97\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u540e\u8005\u7684\u7b56\u7565\u5207\u6362\u548coracle\u590d\u6742\u5ea6\u5747\u4e3a$\\mathcal{O}(K)$\u3002 Zhishuai Liu PDF N/A Upper and Lower Bounds for Distributionally Robust Off-Dynamics Reinforcement Learning We study off-dynamics Reinforcement Learning (RL), where the policy training and deployment environments are different. To deal with this environmental perturbation, we focus on learning policies robust to uncertainties in transition dynamics under the framework of distributionally robust Markov decision processes (DRMDPs), where the nominal and perturbed dynamics are linear Markov Decision Processes. We propose a novel algorithm We-DRIVE-U that enjoys an average suboptimality $\\widetilde{\\mathcal{O}}\\big({d H \\cdot \\min {1/{\\rho}, H}/\\sqrt{K} }\\big)$, where $K$ is the number of episodes, $H$ is the horizon length, $d$ is the feature dimension and $\\rho$ is the uncertainty level. This result improves the state-of-the-art by $\\mathcal{O}(dH/\\min{1/\\rho,H})$. We also construct a novel hard instance and derive the first information-theoretic lower bound in this setting, which indicates our algorithm is near-optimal up to $\\mathcal{O}(\\sqrt{H})$ for any uncertainty level $\\rho\\in(0,1]$. Our algorithm also enjoys a 'rare-switching' design, and thus only requires $\\mathcal{O}(dH\\log(1+H^2K))$ policy switches and $\\mathcal{O}(d^2H\\log(1+H^2K))$ calls for oracle to solve dual optimization problems, which significantly improves the computational efficiency of existing algorithms for DRMDPs, whose policy switch and oracle complexities are both $\\mathcal{O}(K)$. \u52a0\u901f\u975e\u6781\u5927\u503c\u6291\u5236\uff1a\u56fe\u8bba\u89c6\u89d2 \u975e\u6781\u5927\u503c\u6291\u5236\uff08NMS\uff09\u662f\u76ee\u6807\u68c0\u6d4b\u4e2d\u4e0d\u53ef\u6216\u7f3a\u7684\u540e\u5904\u7406\u6b65\u9aa4\u3002\u968f\u7740\u7f51\u7edc\u6a21\u578b\u7684\u4e0d\u65ad\u4f18\u5316\uff0cNMS\u5df2\u6210\u4e3a\u63d0\u5347\u76ee\u6807\u68c0\u6d4b\u6548\u7387\u7684\u201c\u6700\u540e\u4e00\u516c\u91cc\u201d\u3002\u672c\u6587\u9996\u6b21\u4ece\u56fe\u8bba\u7684\u89d2\u5ea6\u7cfb\u7edf\u5206\u6790NMS\uff0c\u63ed\u793a\u5176\u5185\u5728\u7ed3\u6784\uff0c\u5e76\u7531\u6b64\u63d0\u51fa\u4e24\u79cd\u4f18\u5316\u65b9\u6cd5\uff1aQSI-NMS\u548cBOE-NMS\u3002\u524d\u8005\u662f\u4e00\u79cd\u5feb\u901f\u9012\u5f52\u5206\u6cbb\u7b97\u6cd5\uff0cmAP\u635f\u5931\u53ef\u5ffd\u7565\u4e0d\u8ba1\uff0c\u5176\u6269\u5c55\u7248\u672c\uff08eQSI-NMS\uff09\u8fbe\u5230\u6700\u4f18\u590d\u6742\u5ea6$\\mathcal{O}(n\\log n)$\u3002\u540e\u8005\u5219\u4e13\u6ce8\u4e8eNMS\u7684\u5c40\u90e8\u6027\uff0c\u5b9e\u73b0\u4e86\u6052\u5b9a\u6c34\u5e73\u7684\u4f18\u5316\uff0c\u4e14\u65e0mAP\u635f\u5931\u3002\u6b64\u5916\uff0c\u4e3a\u65b9\u4fbf\u7814\u7a76\u4eba\u5458\u5feb\u901f\u8bc4\u4f30NMS\u65b9\u6cd5\uff0c\u6211\u4eec\u5f15\u5165\u4e86NMS-Bench\uff0c\u8fd9\u662f\u9996\u4e2a\u5168\u9762\u8bc4\u4f30\u5404\u79cdNMS\u65b9\u6cd5\u7684\u57fa\u51c6\u3002\u4ee5MS COCO 2017\u4e0a\u7684YOLOv8-N\u6a21\u578b\u4e3a\u57fa\u51c6\u8bbe\u7f6e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5QSI-NMS\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u4f9b\u4e86$6.2\\times$\u7684\u539fNMS\u901f\u5ea6\uff0cmAP\u4e0b\u964d$0.1\\%$\u3002\u6700\u4f18\u7684eQSI-NMS\u5728mAP\u4ec5\u4e0b\u964d$0.3\\%$\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86$10.7\\times$\u7684\u901f\u5ea6\u3002\u540c\u65f6\uff0cBOE-NMS\u5728\u4fdd\u6301mAP\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\uff0c\u5c55\u793a\u4e86$5.1\\times$\u7684\u901f\u5ea6\u3002 King-Siong Si PDF N/A Accelerating Non-Maximum Suppression: A Graph Theory Perspective Non-maximum suppression (NMS) is an indispensable post-processing step in object detection. With the continuous optimization of network models, NMS has become the ``last mile'' to enhance the efficiency of object detection. This paper systematically analyzes NMS from a graph theory perspective for the first time, revealing its intrinsic structure. Consequently, we propose two optimization methods, namely QSI-NMS and BOE-NMS. The former is a fast recursive divide-and-conquer algorithm with negligible mAP loss, and its extended version (eQSI-NMS) achieves optimal complexity of $\\mathcal{O}(n\\log n)$. The latter, concentrating on the locality of NMS, achieves an optimization at a constant level without an mAP loss penalty. Moreover, to facilitate rapid evaluation of NMS methods for researchers, we introduce NMS-Bench, the first benchmark designed to comprehensively assess various NMS methods. Taking the YOLOv8-N model on MS COCO 2017 as the benchmark setup, our method QSI-NMS provides $6.2\\times$ speed of original NMS on the benchmark, with a $0.1\\%$ decrease in mAP. The optimal eQSI-NMS, with only a $0.3\\%$ mAP decrease, achieves $10.7\\times$ speed. Meanwhile, BOE-NMS exhibits $5.1\\times$ speed with no compromise in mAP. SMLE\uff1a\u901a\u8fc7\u5d4c\u5165\u8d85\u8fd1\u4f3c\u5b9e\u73b0\u7684\u5b89\u5168\u673a\u5668\u5b66\u4e60 \u5c3d\u7ba1\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u548c\u795e\u7ecf\u7f51\u7edc\u9886\u57df\u6700\u8fd1\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5982\u4f55\u4e3a\u8fd9\u4e9b\u7cfb\u7edf\u7684\u884c\u4e3a\u63d0\u4f9b\u5f62\u5f0f\u5316\u4fdd\u8bc1\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\uff0c\u4e5f\u662f\u5176\u5728\u53d7\u76d1\u7ba1\u6216\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u5e94\u7528\u7684\u5173\u952e\u9700\u6c42\u3002\u6211\u4eec\u8003\u8651\u7684\u4efb\u52a1\u662f\u8bad\u7ec3\u53ef\u5fae\u5206\u7684ML\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u4fdd\u8bc1\u6ee1\u8db3\u8bbe\u8ba1\u8005\u9009\u62e9\u7684\u5c5e\u6027\uff0c\u8fd9\u4e9b\u5c5e\u6027\u4ee5\u8f93\u5165\u8f93\u51fa\u8574\u542b\u7684\u5f62\u5f0f\u8868\u8ff0\u3002\u7531\u4e8e\u4e25\u683c\u9a8c\u8bc1\u548c\u786e\u4fdd\u73b0\u4ee3\u795e\u7ecf\u6a21\u578b\u5408\u89c4\u6027\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u8fd9\u4e00\u4efb\u52a1\u975e\u5e38\u5177\u6709\u6311\u6218\u6027\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e09\u4e2a\u7ec4\u6210\u90e8\u5206\u7684\u521b\u65b0\u65b9\u6cd5\uff1a1\uff09\u4e00\u79cd\u901a\u7528\u3001\u7b80\u5355\u7684\u67b6\u6784\uff0c\u80fd\u591f\u4ee5\u4fdd\u5b88\u7684\u8bed\u4e49\u5b9e\u73b0\u9ad8\u6548\u7684\u9a8c\u8bc1\uff1b2\uff09\u57fa\u4e8e\u6295\u5f71\u68af\u5ea6\u6cd5\u7684\u4e25\u683c\u8bad\u7ec3\u7b97\u6cd5\uff1b3\uff09\u5bf9\u5bfb\u627e\u5f3a\u53cd\u4f8b\u95ee\u9898\u7684\u8868\u8ff0\u3002\u6240\u63d0\u51fa\u7684\u6846\u67b6\u4ec5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u53d7\u6a21\u578b\u590d\u6742\u6027\u7684\u5f71\u54cd\uff0c\u80fd\u591f\u5f88\u597d\u5730\u6269\u5c55\u5230\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5e76\u751f\u6210\u63d0\u4f9b\u5b8c\u5168\u5c5e\u6027\u6ee1\u8db3\u4fdd\u8bc1\u7684\u6a21\u578b\u3002\u6211\u4eec\u5728\u56de\u5f52\u4e2d\u7531\u7ebf\u6027\u4e0d\u7b49\u5f0f\u5b9a\u4e49\u7684\u5c5e\u6027\u548c\u591a\u6807\u7b7e\u5206\u7c7b\u4e2d\u7684\u4e92\u65a5\u7c7b\u522b\u4e0a\u8bc4\u4f30\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\uff0c\u57fa\u7ebf\u65b9\u6cd5\u5305\u62ec\u5728\u9884\u5904\u7406\u9636\u6bb5\uff08\u5373\u5728\u8bad\u7ec3\u6570\u636e\u4e0a\uff09\u548c\u540e\u5904\u7406\u9636\u6bb5\uff08\u5373\u5728\u6a21\u578b\u9884\u6d4b\u4e0a\uff09\u5b9e\u65bd\u5c5e\u6027\u3002\u6700\u540e\uff0c\u6211\u4eec\u7684\u8d21\u732e\u5efa\u7acb\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u5f00\u542f\u4e86\u591a\u4e2a\u7814\u7a76\u65b9\u5411\u548c\u6f5c\u5728\u6539\u8fdb\u7684\u53ef\u80fd\u6027\u3002 Matteo Francobaldi PDF N/A SMLE: Safe Machine Learning via Embedded Overapproximation Despite the extent of recent advances in Machine Learning (ML) and Neural Networks, providing formal guarantees on the behavior of these systems is still an open problem, and a crucial requirement for their adoption in regulated or safety-critical scenarios. We consider the task of training differentiable ML models guaranteed to satisfy designer-chosen properties, stated as input-output implications. This is very challenging, due to the computational complexity of rigorously verifying and enforcing compliance in modern neural models. We provide an innovative approach based on three components: 1) a general, simple architecture enabling efficient verification with a conservative semantic; 2) a rigorous training algorithm based on the Projected Gradient Method; 3) a formulation of the problem of searching for strong counterexamples. The proposed framework, being only marginally affected by model complexity, scales well to practical applications, and produces models that provide full property satisfaction guarantees. We evaluate our approach on properties defined by linear inequalities in regression, and on mutually exclusive classes in multilabel classification. Our approach is competitive with a baseline that includes property enforcement during preprocessing, i.e. on the training data, as well as during postprocessing, i.e. on the model predictions. Finally, our contributions establish a framework that opens up multiple research directions and potential improvements. \u57fa\u4e8e\u6fc0\u5149\u5168\u573a\u6d4b\u91cf\u7684\u6570\u636e\u9a71\u52a8\u53d1\u73b0\u63a7\u5236\u65b9\u7a0b\u7684\u96c6\u6210WSINDy\u65b9\u6cd5 \u672c\u7814\u7a76\u5229\u7528\u6fc0\u5149\u6d4b\u632f\u548c\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u7a00\u758f\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u8bc6\u522b\uff08WSINDy\uff09\u7684\u5f31\u5f62\u5f0f\uff0c\u4ece\u5168\u573a\u5b9e\u9a8c\u6570\u636e\u4e2d\u5b66\u4e60\u5b8f\u89c2\u5c3a\u5ea6\u63a7\u5236\u65b9\u7a0b\u3002\u5b9e\u9a8c\u4e2d\uff0c\u4e24\u4e2a\u6881\u72b6\u8bd5\u4ef6\uff08\u4e00\u4e2a\u4e3a\u94dd\u6750\uff0c\u53e6\u4e00\u4e2a\u4e3aIDOX/Estane\u590d\u5408\u6750\u6599\uff09\u5728\u4f4e\u9891\u8303\u56f4\u5185\u53d7\u5230\u526a\u5207\u6ce2\u6fc0\u52b1\uff0c\u5e76\u5728\u8bd5\u4ef6\u8868\u9762\u4ee5\u7c92\u5b50\u901f\u5ea6\u7684\u5f62\u5f0f\u6d4b\u91cf\u54cd\u5e94\u3002\u5c06WSINDy\u7b97\u6cd5\u5e94\u7528\u4e8e\u6240\u5f97\u7684\u65f6\u7a7a\u6570\u636e\uff0c\u4ece\u4e00\u7ec4\u6f5c\u5728\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u4e2d\u63ed\u793a\u8bd5\u4ef6\u7684\u6709\u6548\u52a8\u529b\u5b66\u7279\u6027\u3002\u6240\u53d1\u73b0\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u5177\u6709\u53ef\u8bc6\u522b\u7684\u6b27\u62c9-\u4f2f\u52aa\u5229\u6881\u6a21\u578b\u5f62\u5f0f\uff0c\u4ece\u4e2d\u4f30\u8ba1\u4e86\u4e24\u79cd\u6750\u6599\u7684\u6768\u6c0f\u6a21\u91cf\u3002\u8fd8\u4f7f\u7528\u4e86WSINDy\u7b97\u6cd5\u7684\u96c6\u6210\u7248\u672c\uff0c\u8be5\u7248\u672c\u63d0\u4f9b\u4e86\u5173\u4e8e\u504f\u5fae\u5206\u65b9\u7a0b\u7cfb\u6570\u548c\u6768\u6c0f\u6a21\u91cf\u4e0d\u786e\u5b9a\u6027\u7684\u4fe1\u606f\u3002\u6240\u53d1\u73b0\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u8fd8\u901a\u8fc7\u6709\u9650\u5143\u4ee3\u7801\u8fdb\u884c\u6a21\u62df\uff0c\u4ee5\u5408\u7406\u7cbe\u5ea6\u4e0e\u5b9e\u9a8c\u6570\u636e\u8fdb\u884c\u6bd4\u8f83\u3002\u7ed3\u5408\u5168\u573a\u5b9e\u9a8c\u6570\u636e\u548cWSINDy\u7b97\u6cd5\uff0c\u662f\u4e00\u79cd\u5f3a\u5927\u7684\u65e0\u635f\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u5b66\u4e60\u672a\u77e5\u7684\u63a7\u5236\u65b9\u7a0b\uff0c\u5e76\u6df1\u5165\u4e86\u89e3\u52a8\u6001\u6761\u4ef6\u4e0b\u7684\u673a\u68b0\u7cfb\u7edf\u3002 Abigail C. Schmid PDF N/A Ensemble WSINDy for Data Driven Discovery of Governing Equations from Laser-based Full-field Measurements This work leverages laser vibrometry and the weak form of the sparse identification of nonlinear dynamics (WSINDy) for partial differential equations to learn macroscale governing equations from full-field experimental data. In the experiments, two beam-like specimens, one aluminum and one IDOX/Estane composite, are subjected to shear wave excitation in the low frequency regime and the response is measured in the form of particle velocity on the specimen surface. The WSINDy for PDEs algorithm is applied to the resulting spatio-temporal data to discover the effective dynamics of the specimens from a family of potential PDEs. The discovered PDE is of the recognizable Euler-Bernoulli beam model form, from which the Young's modulus for the two materials are estimated. An ensemble version of the WSINDy algorithm is also used which results in information about the uncertainty in the PDE coefficients and Young's moduli. The discovered PDEs are also simulated with a finite element code to compare against the experimental data with reasonable accuracy. Using full-field experimental data and WSINDy together is a powerful non-destructive approach for learning unknown governing equations and gaining insights about mechanical systems in the dynamic regime. \u57fa\u4e8e\u65e5\u5fd7\u7684\u5f02\u5e38\u68c0\u6d4b\u9700\u8981\u54ea\u4e9b\u4fe1\u606f\uff1f\u53ef\u914d\u7f6eTransformer\u65b9\u6cd5\u7684\u89c1\u89e3 \u65e5\u5fd7\u6570\u636e\u6e90\u81ea\u6e90\u4ee3\u7801\u4e2d\u7684\u65e5\u5fd7\u8bed\u53e5\uff0c\u4e3a\u8f6f\u4ef6\u5e94\u7528\u548c\u7cfb\u7edf\u7684\u6267\u884c\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u6df1\u5165\u6d1e\u5bdf\u3002\u57fa\u4e8e\u65e5\u5fd7\u7684\u5f02\u5e38\u68c0\u6d4b\u5148\u8fdb\u65b9\u6cd5\u901a\u5e38\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6765\u6355\u6349\u65e5\u5fd7\u6570\u636e\u4e2d\u7684\u8bed\u4e49\u6216\u5e8f\u5217\u4fe1\u606f\uff0c\u5e76\u68c0\u6d4b\u5f02\u5e38\u7684\u8fd0\u884c\u65f6\u884c\u4e3a\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u4e0d\u540c\u7c7b\u578b\u4fe1\u606f\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002\u6b64\u5916\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u6355\u6349\u65e5\u5fd7\u6570\u636e\u4e2d\u7684\u65f6\u95f4\u6233\uff0c\u8fd9\u4e9b\u65f6\u95f4\u6233\u53ef\u80fd\u6bd4\u5e8f\u5217\u4fe1\u606f\u63d0\u4f9b\u66f4\u7ec6\u7c92\u5ea6\u7684\u65f6\u95f4\u4fe1\u606f\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u914d\u7f6e\u7684\u57fa\u4e8eTransformer\u7684\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u6355\u6349\u65e5\u5fd7\u6570\u636e\u4e2d\u7684\u8bed\u4e49\u3001\u5e8f\u5217\u548c\u65f6\u95f4\u4fe1\u606f\uff0c\u5e76\u5141\u8bb8\u6211\u4eec\u914d\u7f6e\u4e0d\u540c\u7c7b\u578b\u7684\u4fe1\u606f\u4f5c\u4e3a\u6a21\u578b\u7684\u7279\u5f81\u3002\u6b64\u5916\uff0c\u6211\u4eec\u4f7f\u7528\u4e0d\u540c\u957f\u5ea6\u7684\u65e5\u5fd7\u5e8f\u5217\u8bad\u7ec3\u548c\u8bc4\u4f30\u6240\u63d0\u51fa\u7684\u6a21\u578b\uff0c\u4ece\u800c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u957f\u5ea6\u6216\u65f6\u95f4\u7a97\u53e3\u65e5\u5fd7\u5e8f\u5217\u4f5c\u4e3a\u8f93\u5165\u7684\u9650\u5236\u3002\u901a\u8fc7\u6240\u63d0\u51fa\u7684\u6a21\u578b\uff0c\u6211\u4eec\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u5b9e\u9a8c\uff0c\u4f7f\u7528\u4e0d\u540c\u7ec4\u5408\u7684\u8f93\u5165\u7279\u5f81\u6765\u8bc4\u4f30\u4e0d\u540c\u7c7b\u578b\u4fe1\u606f\u5728\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u4f5c\u7528\u3002\u5728\u5904\u7406\u4e0d\u540c\u957f\u5ea6\u7684\u65e5\u5fd7\u5e8f\u5217\u65f6\uff0c\u8be5\u6a21\u578b\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u80fd\u591f\u8fbe\u5230\u5177\u6709\u7ade\u4e89\u529b\u7684\u7a33\u5b9a\u6027\u80fd\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4e8b\u4ef6\u53d1\u751f\u4fe1\u606f\u5728\u8bc6\u522b\u5f02\u5e38\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u800c\u5e8f\u5217\u548c\u65f6\u95f4\u4fe1\u606f\u5bf9\u6240\u7814\u7a76\u516c\u5171\u6570\u636e\u96c6\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u5f71\u54cd\u4e0d\u5927\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u7814\u7a76\u7ed3\u679c\u4e5f\u63ed\u793a\u4e86\u6240\u7814\u7a76\u516c\u5171\u6570\u636e\u96c6\u7684\u7b80\u5355\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u6784\u5efa\u5305\u542b\u4e0d\u540c\u7c7b\u578b\u5f02\u5e38\u7684\u65b0\u6570\u636e\u96c6\u4ee5\u66f4\u597d\u5730\u8bc4\u4f30\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\u6027\u80fd\u7684\u91cd\u8981\u6027\u3002 Xingfang Wu PDF N/A What Information Contributes to Log-based Anomaly Detection? Insights from a Configurable Transformer-Based Approach Log data are generated from logging statements in the source code, providing insights into the execution processes of software applications and systems. State-of-the-art log-based anomaly detection approaches typically leverage deep learning models to capture the semantic or sequential information in the log data and detect anomalous runtime behaviors. However, the impacts of these different types of information are not clear. In addition, existing approaches have not captured the timestamps in the log data, which can potentially provide more fine-grained temporal information than sequential information. In this work, we propose a configurable transformer-based anomaly detection model that can capture the semantic, sequential, and temporal information in the log data and allows us to configure the different types of information as the model's features. Additionally, we train and evaluate the proposed model using log sequences of different lengths, thus overcoming the constraint of existing methods that rely on fixed-length or time-windowed log sequences as inputs. With the proposed model, we conduct a series of experiments with different combinations of input features to evaluate the roles of different types of information in anomaly detection. When presented with log sequences of varying lengths, the model can attain competitive and consistently stable performance compared to the baselines. The results indicate that the event occurrence information plays a key role in identifying anomalies, while the impact of the sequential and temporal information is not significant for anomaly detection in the studied public datasets. On the other hand, the findings also reveal the simplicity of the studied public datasets and highlight the importance of constructing new datasets that contain different types of anomalies to better evaluate the performance of anomaly detection models. \u62fc\u8d34\u753b\uff1a\u5229\u7528\u5206\u5c42\u6f5c\u5728\u6269\u6563\u548c\u8bed\u8a00\u6a21\u578b\u751f\u6210\u534f\u4f5c\u4eba\u673a\u4ea4\u4e92 \u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCOLLAGE\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u5206\u5c42\u8fd0\u52a8\u7279\u5b9a\u5411\u91cf\u91cf\u5316\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VQ-VAEs\uff09\u6765\u751f\u6210\u534f\u4f5c\u7684\u4ee3\u7406-\u5bf9\u8c61-\u4ee3\u7406\u4ea4\u4e92\u3002\u6211\u4eec\u7684\u6a21\u578b\u901a\u8fc7\u7ed3\u5408LLMs\u7684\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\uff0c\u6307\u5bfc\u751f\u6210\u6269\u6563\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u6570\u636e\u96c6\u4e30\u5bcc\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u5206\u5c42VQ-VAE\u67b6\u6784\u5728\u591a\u4e2a\u62bd\u8c61\u5c42\u6b21\u4e0a\u6355\u6349\u4e0d\u540c\u7684\u8fd0\u52a8\u7279\u5b9a\u7279\u5f81\uff0c\u907f\u514d\u4e86\u5197\u4f59\u6982\u5ff5\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u591a\u5206\u8fa8\u7387\u8868\u793a\u3002\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u64cd\u4f5c\u7684\u6269\u6563\u6a21\u578b\uff0c\u5e76\u7ed3\u5408LLM\u751f\u6210\u7684\u8fd0\u52a8\u89c4\u5212\u7ebf\u7d22\u6765\u6307\u5bfc\u53bb\u566a\u8fc7\u7a0b\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u5177\u63a7\u5236\u6027\u548c\u591a\u6837\u6027\u7684\u63d0\u793a\u7279\u5b9a\u8fd0\u52a8\u751f\u6210\u3002\u5728CORE-4D\u548cInterHuman\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u751f\u6210\u771f\u5b9e\u4e14\u591a\u6837\u7684\u534f\u4f5c\u4eba-\u5bf9\u8c61-\u4eba\u4ea4\u4e92\u65b9\u9762\u5177\u6709\u663e\u8457\u6548\u679c\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u7684\u5de5\u4f5c\u4e3a\u5728\u673a\u5668\u4eba\u5b66\u3001\u56fe\u5f62\u5b66\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u7b49\u9886\u57df\u5efa\u6a21\u590d\u6742\u4ea4\u4e92\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002 Divyanshu Daiya PDF N/A COLLAGE: Collaborative Human-Agent Interaction Generation using Hierarchical Latent Diffusion and Language Models We propose a novel framework COLLAGE for generating collaborative agent-object-agent interactions by leveraging large language models (LLMs) and hierarchical motion-specific vector-quantized variational autoencoders (VQ-VAEs). Our model addresses the lack of rich datasets in this domain by incorporating the knowledge and reasoning abilities of LLMs to guide a generative diffusion model. The hierarchical VQ-VAE architecture captures different motion-specific characteristics at multiple levels of abstraction, avoiding redundant concepts and enabling efficient multi-resolution representation. We introduce a diffusion model that operates in the latent space and incorporates LLM-generated motion planning cues to guide the denoising process, resulting in prompt-specific motion generation with greater control and diversity. Experimental results on the CORE-4D, and InterHuman datasets demonstrate the effectiveness of our approach in generating realistic and diverse collaborative human-object-human interactions, outperforming state-of-the-art methods. Our work opens up new possibilities for modeling complex interactions in various domains, such as robotics, graphics and computer vision. \u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u3001\u591a\u4efb\u52a1\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\u63d0\u5347\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u653b\u51fb\u6027\u8bed\u8a00\u68c0\u6d4b \u672c\u6587\u5f3a\u8c03\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u5728\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u7a81\u663e\u4e86\u5176\u5728\u7406\u89e3\u548c\u5efa\u6a21\u4eba\u7c7b\u8bed\u8a00\u65b9\u9762\u7684\u5173\u952e\u4f5c\u7528\u3002NLP\u9886\u57df\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5c24\u5176\u662f\u5728\u5bf9\u8bdd\u673a\u5668\u4eba\u65b9\u9762\uff0c\u5df2\u5f15\u8d77\u4e86\u5f00\u53d1\u8005\u7684\u5e7f\u6cdb\u5173\u6ce8\u548c\u91c7\u7528\u3002\u672c\u6587\u63a2\u8ba8\u4e86\u5b9e\u73b0\u66f4\u5c0f\u3001\u66f4\u9ad8\u6548NLP\u6a21\u578b\u7684\u5148\u8fdb\u65b9\u6cd5\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u91c7\u7528\u4e86\u4e09\u79cd\u4e3b\u8981\u65b9\u6cd5\uff1a\uff081\uff09\u8bad\u7ec3\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u7f51\u7edc\u4ee5\u68c0\u6d4b\u5192\u72af\u6027\u8bed\u8a00\uff0c\uff082\uff09\u91c7\u7528\u6570\u636e\u589e\u5f3a\u548c\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u4ee5\u63d0\u5347\u6027\u80fd\uff0c\uff083\uff09\u7ed3\u5408\u591a\u4efb\u52a1\u5b66\u4e60\u4e0e\u77e5\u8bc6\u84b8\u998f\u53ca\u4f7f\u7528\u591a\u6837\u5316\u6570\u636e\u96c6\u7684\u6559\u5e08\u9000\u706b\u6cd5\u4ee5\u589e\u5f3a\u6548\u7387\u3002\u8fd9\u4e9b\u65b9\u6cd5\u7684\u7efc\u5408\u5e94\u7528\u5df2\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\u6210\u679c\u3002 Vlad-Cristian Matei PDF N/A Enhancing Romanian Offensive Language Detection through Knowledge Distillation, Multi-Task Learning, and Data Augmentation This paper highlights the significance of natural language processing (NLP) within artificial intelligence, underscoring its pivotal role in comprehending and modeling human language. Recent advancements in NLP, particularly in conversational bots, have garnered substantial attention and adoption among developers. This paper explores advanced methodologies for attaining smaller and more efficient NLP models. Specifically, we employ three key approaches: (1) training a Transformer-based neural network to detect offensive language, (2) employing data augmentation and knowledge distillation techniques to increase performance, and (3) incorporating multi-task learning with knowledge distillation and teacher annealing using diverse datasets to enhance efficiency. The culmination of these methods has yielded demonstrably improved outcomes. \u9884\u7b97\u7ea6\u675f\u4e0b\u7684\u5728\u7ebf\u51b3\u7b56\u5ef6\u8fdf \u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4e8e\u652f\u6301\u6216\u66ff\u4ee3\u51b3\u7b56\u8fc7\u7a0b\u3002\u5728\u6280\u80fd\u4e13\u5bb6\u8d44\u6e90\u6709\u9650\u7684\u5e94\u7528\u573a\u666f\u4e2d\uff0c\u51cf\u8f7b\u4ed6\u4eec\u7684\u8d1f\u62c5\u5e76\u5728ML\u6a21\u578b\u7684\u6027\u80fd\u81f3\u5c11\u4e0e\u4e13\u5bb6\u76f8\u5f53\u65f6\u81ea\u52a8\u5316\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u6a21\u578b\u901a\u5e38\u662f\u9884\u5148\u8bad\u7ec3\u5e76\u56fa\u5b9a\u7684\uff0c\u800c\u4efb\u52a1\u5219\u662f\u6309\u987a\u5e8f\u5230\u8fbe\u7684\uff0c\u5176\u5206\u5e03\u53ef\u80fd\u4f1a\u53d1\u751f\u53d8\u5316\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u51b3\u7b56\u8005\u7684\u76f8\u5e94\u6027\u80fd\u53ef\u80fd\u4f1a\u6539\u53d8\uff0c\u56e0\u6b64\u5ef6\u8fdf\u7b97\u6cd5\u5fc5\u987b\u4fdd\u6301\u9002\u5e94\u6027\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0a\u4e0b\u6587\u591a\u81c2\u8d4c\u535a\u673a\u6a21\u578b\u6765\u89e3\u51b3\u8fd9\u79cd\u5728\u7ebf\u51b3\u7b56\u95ee\u9898\u3002\u6211\u4eec\u7684\u6846\u67b6\u5305\u62ec\u9884\u7b97\u7ea6\u675f\u548c\u4e0d\u540c\u7c7b\u578b\u7684\u90e8\u5206\u53cd\u9988\u6a21\u578b\u3002\u9664\u4e86\u6211\u4eec\u7b97\u6cd5\u7684\u7406\u8bba\u4fdd\u8bc1\u5916\uff0c\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u6269\u5c55\uff0c\u8fd9\u4e9b\u6269\u5c55\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u3002 Mirabel Reid PDF N/A Online Decision Deferral under Budget Constraints Machine Learning (ML) models are increasingly used to support or substitute decision making. In applications where skilled experts are a limited resource, it is crucial to reduce their burden and automate decisions when the performance of an ML model is at least of equal quality. However, models are often pre-trained and fixed, while tasks arrive sequentially and their distribution may shift. In that case, the respective performance of the decision makers may change, and the deferral algorithm must remain adaptive. We propose a contextual bandit model of this online decision making problem. Our framework includes budget constraints and different types of partial feedback models. Beyond the theoretical guarantees of our algorithm, we propose efficient extensions that achieve remarkable performance on real-world datasets. \u4f7f\u7528\u62c9\u666e\u62c9\u65af\u795e\u7ecf\u6d41\u5f62\u7684\u201c\u4ec0\u4e48\u201d\u4e0e\u201c\u4f55\u65f6\u201d\u5de5\u4f5c\u8bb0\u5fc6\u8868\u5f81 \u5de5\u4f5c\u8bb0\u5fc6\u2014\u2014\u5373\u5728\u4e8b\u4ef6\u4e0d\u65ad\u9000\u5165\u8fc7\u53bb\u65f6\u8bb0\u4f4f\u5b83\u4eec\u7684\u80fd\u529b\u2014\u2014\u9700\u8981\u80fd\u591f\u5728\u4efb\u4f55\u65f6\u95f4\u5ef6\u8fdf\u4e0b\u8868\u793a\u4efb\u4f55\u523a\u6fc0\u7684\u80fd\u529b\u3002\u8fd9\u4e00\u7279\u6027\u8981\u6c42\u7f16\u7801\u5de5\u4f5c\u8bb0\u5fc6\u7684\u795e\u7ecf\u5143\u8868\u73b0\u51fa\u6df7\u5408\u9009\u62e9\u6027\uff0c\u5177\u6709\u523a\u6fc0\u548c\u65f6\u95f4\u7684\u8054\u5408\u611f\u53d7\u91ce\uff08RFs\uff09\uff0c\u5f62\u6210\u201c\u4ec0\u4e48\u201d\u00d7\u201c\u4f55\u65f6\u201d\u7684\u8868\u793a\u3002\u6211\u4eec\u5728\u7b80\u5355\u7684\u5b9e\u9a8c\u4e2d\u7814\u7a76\u8fd9\u79cd\u5de5\u4f5c\u8bb0\u5fc6\u7684\u7279\u6027\uff0c\u5176\u4e2d\u5fc5\u987b\u8bb0\u4f4f\u4e00\u4e2a\u5355\u4e00\u7684\u523a\u6fc0\u4e00\u6bb5\u65f6\u95f4\u3002\u8054\u5408\u611f\u53d7\u91ce\u7684\u8981\u6c42\u4f7f\u5f97\u7f51\u7edc\u7684\u534f\u65b9\u5dee\u77e9\u9635\u80fd\u591f\u5f88\u597d\u5730\u89e3\u8026\uff0c\u4ece\u800c\u7406\u89e3\u7fa4\u4f53\u7684\u4f4e\u7ef4\u52a8\u529b\u5b66\u3002\u4e0d\u540c\u7684\u65f6\u95f4\u57fa\u51fd\u6570\u9009\u62e9\u4f1a\u5bfc\u81f4\u8d28\u4e0a\u4e0d\u540c\u7684\u52a8\u529b\u5b66\u3002\u6211\u4eec\u7814\u7a76\u4e86\u4e00\u4e2a\u7279\u5b9a\u7684\u9009\u62e9\u2014\u2014\u62c9\u666e\u62c9\u65af\u7a7a\u95f4\u4e0e\u6307\u6570\u65f6\u95f4\u57fa\u51fd\u6570\u76f8\u7ed3\u5408\uff0c\u4ee5\u53ca\u4e00\u4e2a\u5728\u65f6\u95f4\u4e0a\u5177\u6709\u9650\u5b9a\u57fa\u51fd\u6570\u7684\u201c\u9006\u62c9\u666e\u62c9\u65af\u201d\u7a7a\u95f4\u3002\u6211\u4eec\u5c06\u8fd9\u79cd\u5747\u5300\u5e73\u94fa\u5bf9\u6570\u65f6\u95f4\u7684\u57fa\u51fd\u6570\u9009\u62e9\u79f0\u4e3a\u62c9\u666e\u62c9\u65af\u795e\u7ecf\u6d41\u5f62\u3002\u5c3d\u7ba1\u5b83\u4eec\u901a\u8fc7\u7ebf\u6027\u6295\u5f71\u76f8\u4e92\u5173\u8054\uff0c\u62c9\u666e\u62c9\u65af\u7fa4\u4f53\u663e\u793a\u51fa\u7a33\u5b9a\u7684\u523a\u6fc0\u7279\u5b9a\u5b50\u7a7a\u95f4\uff0c\u800c\u9006\u62c9\u666e\u62c9\u65af\u7fa4\u4f53\u663e\u793a\u51fa\u65cb\u8f6c\u52a8\u529b\u5b66\u3002\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\uff0c\u534f\u65b9\u5dee\u77e9\u9635\u7684\u79e9\u7684\u589e\u957f\u53d6\u51b3\u4e8e\u65f6\u95f4\u57fa\u96c6\u7684\u5bc6\u5ea6\uff1b\u5bf9\u6570\u5e73\u94fa\u4e0e\u6570\u636e\u8868\u73b0\u51fa\u826f\u597d\u7684\u4e00\u81f4\u6027\u3002\u6211\u4eec\u52fe\u52d2\u51fa\u4e00\u4e2a\u6784\u5efa\u62c9\u666e\u62c9\u65af\u795e\u7ecf\u6d41\u5f62\u7684\u8fde\u7eed\u5438\u5f15\u5b50CANN\u3002\u62c9\u666e\u62c9\u65af\u7a7a\u95f4\u4e2d\u7684\u5438\u5f15\u5b50\u8868\u73b0\u4e3a\u8fb9\u7f18\uff1b\u9006\u7a7a\u95f4\u4e2d\u7684\u5438\u5f15\u5b50\u8868\u73b0\u4e3a\u51f8\u8d77\u3002\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ece\u66f4\u62bd\u8c61\u7684\u8ba4\u77e5\u5de5\u4f5c\u8bb0\u5fc6\u6a21\u578b\u5230\u4f7f\u7528\u8fde\u7eed\u5438\u5f15\u5b50\u795e\u7ecf\u7f51\u7edc\u7684\u7535\u8def\u7ea7\u5b9e\u73b0\u7684\u8def\u7ebf\u56fe\uff0c\u5e76\u786e\u5b9a\u4e86\u652f\u6301\u5de5\u4f5c\u8bb0\u5fc6\u7684\u795e\u7ecf\u52a8\u529b\u5b66\u7c7b\u578b\u3002 Aakash Sarkar PDF N/A \"What\" x \"When\" working memory representations using Laplace Neural Manifolds Working memory $\\unicode{x2013}$ the ability to remember recent events as they recede continuously into the past $\\unicode{x2013}$ requires the ability to represent any stimulus at any time delay. This property requires neurons coding working memory to show mixed selectivity, with conjunctive receptive fields (RFs) for stimuli and time, forming a representation of 'what' $\\times$ 'when'. We study the properties of such a working memory in simple experiments where a single stimulus must be remembered for a short time. The requirement of conjunctive receptive fields allows the covariance matrix of the network to decouple neatly, allowing an understanding of the low-dimensional dynamics of the population. Different choices of temporal basis functions lead to qualitatively different dynamics. We study a specific choice $\\unicode{x2013}$ a Laplace space with exponential basis functions for time coupled to an \"Inverse Laplace\" space with circumscribed basis functions in time. We refer to this choice with basis functions that evenly tile log time as a Laplace Neural Manifold. Despite the fact that they are related to one another by a linear projection, the Laplace population shows a stable stimulus-specific subspace whereas the Inverse Laplace population shows rotational dynamics. The growth of the rank of the covariance matrix with time depends on the density of the temporal basis set; logarithmic tiling shows good agreement with data. We sketch a continuous attractor CANN that constructs a Laplace Neural Manifold. The attractor in the Laplace space appears as an edge; the attractor for the inverse space appears as a bump. This work provides a map for going from more abstract cognitive models of WM to circuit-level implementation using continuous attractor neural networks, and places constraints on the types of neural dynamics that support working memory. RecSys Challenge 2024\uff1a\u5728\u65b0\u95fb\u63a8\u8350\u4e2d\u5e73\u8861\u51c6\u786e\u6027\u4e0e\u7f16\u8f91\u4ef7\u503c\u89c2 RecSys Challenge 2024 \u65e8\u5728\u901a\u8fc7\u89e3\u51b3\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u56fa\u6709\u7684\u6280\u672f\u548c\u89c4\u8303\u6311\u6218\uff0c\u63a8\u52a8\u65b0\u95fb\u63a8\u8350\u6280\u672f\u7684\u53d1\u5c55\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u8be5\u6311\u6218\u8d5b\u7684\u76ee\u6807\u3001\u95ee\u9898\u8bbe\u5b9a\u4ee5\u53ca\u7531\u4e39\u9ea6\u65b0\u95fb\u51fa\u7248\u5546 Ekstra Bladet \u548c JP/Politikens Media Group\uff08\u7b80\u79f0\u201cEkstra Bladet\u201d\uff09\u63d0\u4f9b\u7684\u6570\u636e\u96c6\u3002\u6311\u6218\u8d5b\u63a2\u8ba8\u4e86\u65b0\u95fb\u63a8\u8350\u7684\u72ec\u7279\u65b9\u9762\uff0c\u5982\u57fa\u4e8e\u7528\u6237\u884c\u4e3a\u5efa\u6a21\u504f\u597d\u3001\u8003\u8651\u65b0\u95fb\u8bae\u7a0b\u5bf9\u7528\u6237\u5174\u8da3\u7684\u5f71\u54cd\u4ee5\u53ca\u7ba1\u7406\u65b0\u95fb\u9879\u76ee\u7684\u5feb\u901f\u8870\u51cf\u3002\u6b64\u5916\uff0c\u6311\u6218\u8d5b\u8fd8\u6d89\u53ca\u89c4\u8303\u590d\u6742\u6027\uff0c\u7814\u7a76\u63a8\u8350\u7cfb\u7edf\u5bf9\u65b0\u95fb\u6d41\u7684\u5f71\u54cd\u53ca\u5176\u4e0e\u7f16\u8f91\u4ef7\u503c\u89c2\u7684\u4e00\u81f4\u6027\u3002\u6211\u4eec\u603b\u7ed3\u4e86\u6311\u6218\u8d5b\u7684\u8bbe\u7f6e\u3001\u6570\u636e\u96c6\u7279\u5f81\u548c\u8bc4\u4f30\u6307\u6807\u3002\u6700\u540e\uff0c\u6211\u4eec\u5ba3\u5e03\u4e86\u83b7\u80dc\u8005\u5e76\u5f3a\u8c03\u4e86\u4ed6\u4eec\u7684\u8d21\u732e\u3002\u6570\u636e\u96c6\u53ef\u901a\u8fc7\u4ee5\u4e0b\u94fe\u63a5\u83b7\u53d6\uff1ahttps://recsys.eb.dk\u3002 Johannes Kruse PDF N/A RecSys Challenge 2024: Balancing Accuracy and Editorial Values in News Recommendations The RecSys Challenge 2024 aims to advance news recommendation by addressing both the technical and normative challenges inherent in designing effective and responsible recommender systems for news publishing. This paper describes the challenge, including its objectives, problem setting, and the dataset provided by the Danish news publishers Ekstra Bladet and JP/Politikens Media Group (\"Ekstra Bladet\"). The challenge explores the unique aspects of news recommendation, such as modeling user preferences based on behavior, accounting for the influence of the news agenda on user interests, and managing the rapid decay of news items. Additionally, the challenge embraces normative complexities, investigating the effects of recommender systems on news flow and their alignment with editorial values. We summarize the challenge setup, dataset characteristics, and evaluation metrics. Finally, we announce the winners and highlight their contributions. The dataset is available at: https://recsys.eb.dk. \u8d8a\u5357\u793e\u4ea4\u5a92\u4f53\u4e2d\u673a\u5668\u8bcd\u6c47\u89c4\u8303\u5316\u7684\u4e00\u79cd\u5f31\u76d1\u7763\u6570\u636e\u6807\u6ce8\u6846\u67b6 \u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u81ea\u52a8\u6807\u6ce8\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u8d8a\u5357\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u5728\u793e\u4ea4\u5a92\u4f53\u6587\u672c\u4e2d\u7684\u8bcd\u6c47\u89c4\u8303\u5316\u6311\u6218\u3002\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u4e30\u5bcc\u591a\u6837\uff0c\u4f46\u8fd9\u4e9b\u73af\u5883\u4e2d\u4f7f\u7528\u7684\u4e0d\u65ad\u6f14\u53d8\u7684\u591a\u6837\u5316\u8bed\u8a00\u4f7f\u5f97\u624b\u52a8\u6807\u6ce8\u65e2\u8d39\u65f6\u53c8\u6602\u8d35\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u534a\u76d1\u7763\u5b66\u4e60\u548c\u5f31\u76d1\u7763\u6280\u672f\u7684\u6846\u67b6\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u51cf\u5c11\u624b\u52a8\u6807\u6ce8\u5de5\u4f5c\u91cf\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u8d28\u91cf\u5e76\u6269\u5927\u4e86\u5176\u89c4\u6a21\u3002\u6211\u4eec\u7684\u6846\u67b6\u80fd\u591f\u81ea\u52a8\u6807\u6ce8\u539f\u59cb\u6570\u636e\uff0c\u5c06\u975e\u6807\u51c6\u8bcd\u6c47\u8f6c\u6362\u4e3a\u6807\u51c6\u5f62\u5f0f\uff0c\u4ece\u800c\u63d0\u9ad8\u8bad\u7ec3\u6570\u636e\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u5f31\u76d1\u7763\u6846\u67b6\u5728\u89c4\u8303\u5316\u8d8a\u5357\u8bed\u6587\u672c\u65b9\u9762\u5177\u6709\u663e\u8457\u6548\u679c\uff0c\u5c24\u5176\u662f\u5728\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u65f6\u3002\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u768482.72%\u7684F1\u5206\u6570\uff0c\u5e76\u5728\u4fdd\u6301\u8bcd\u6c47\u5b8c\u6574\u6027\u65b9\u9762\u8fbe\u5230\u4e86\u9ad8\u8fbe99.22%\u7684\u51c6\u786e\u7387\u3002\u6b64\u5916\uff0c\u5b83\u5728\u5404\u79cd\u6761\u4ef6\u4e0b\u90fd\u80fd\u6709\u6548\u5904\u7406\u65e0\u97f3\u8c03\u7b26\u53f7\u7684\u6587\u672c\u3002\u8fd9\u4e00\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u5316\u7684\u8d28\u91cf\uff0c\u5e76\u63d0\u9ad8\u4e86\u5404\u79cd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u7684\u51c6\u786e\u6027\uff0c\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad8\u4e861-3%\u3002 Dung Ha Nguyen PDF N/A A Weakly Supervised Data Labeling Framework for Machine Lexical Normalization in Vietnamese Social Media This study introduces an innovative automatic labeling framework to address the challenges of lexical normalization in social media texts for low-resource languages like Vietnamese. Social media data is rich and diverse, but the evolving and varied language used in these contexts makes manual labeling labor-intensive and expensive. To tackle these issues, we propose a framework that integrates semi-supervised learning with weak supervision techniques. This approach enhances the quality of training dataset and expands its size while minimizing manual labeling efforts. Our framework automatically labels raw data, converting non-standard vocabulary into standardized forms, thereby improving the accuracy and consistency of the training data. Experimental results demonstrate the effectiveness of our weak supervision framework in normalizing Vietnamese text, especially when utilizing Pre-trained Language Models. The proposed framework achieves an impressive F1-score of 82.72% and maintains vocabulary integrity with an accuracy of up to 99.22%. Additionally, it effectively handles undiacritized text under various conditions. This framework significantly enhances natural language normalization quality and improves the accuracy of various NLP tasks, leading to an average accuracy increase of 1-3%. \u8de8\u9886\u57df\u81ea\u52a8\u6587\u672c\u7b80\u5316\u7684\u897f\u73ed\u7259\u8bed\u8bed\u8a00\u8d44\u6e90 \u672c\u7814\u7a76\u63cf\u8ff0\u4e86\u4e3a\u897f\u73ed\u7259\u8bed\u6587\u672c\u81ea\u52a8\u7b80\u5316\u5728\u4e09\u4e2a\u9886\u57df\uff08\u91d1\u878d\u3001\u533b\u5b66\u548c\u5386\u53f2\u7814\u7a76\uff09\u5f00\u53d1\u7684\u8bed\u8a00\u8d44\u6e90\u548c\u6a21\u578b\u3002\u6211\u4eec\u5728\u6bcf\u4e2a\u9886\u57df\u521b\u5efa\u4e86\u591a\u4e2a\u8bed\u6599\u5e93\u3001\u6807\u6ce8\u548c\u7b80\u5316\u6307\u5357\u3001\u6280\u672f\u6027\u548c\u7b80\u5316\u533b\u5b66\u672f\u8bed\u8bcd\u5178\u3001\u7528\u4e8e\u91d1\u878d\u9886\u57df\u5171\u4eab\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u4e24\u6b3e\u7b80\u5316\u5de5\u5177\u3002\u65b9\u6cd5\u8bba\u3001\u8d44\u6e90\u53ca\u76f8\u5173\u51fa\u7248\u7269\u5df2\u5728\u7f51\u7ad9\u4e0a\u516c\u5f00\u5171\u4eab\uff1ahttps://clara-nlp.uned.es/\u3002 Antonio Moreno-Sandoval PDF N/A Language Resources in Spanish for Automatic Text Simplification across Domains This work describes the language resources and models developed for automatic simplification of Spanish texts in three domains: Finance, Medicine and History studies. We created several corpora in each domain, annotation and simplification guidelines, a lexicon of technical and simplified medical terms, datasets used in shared tasks for the financial domain, and two simplification tools. The methodology, resources and companion publications are shared publicly on the web-site: https://clara-nlp.uned.es/. \u6559\u5e08\u5d4c\u5165\u7ebf\u6027\u6295\u5f71\u7528\u4e8e\u5c11\u7c7b\u84b8\u998f \u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u5c06\u77e5\u8bc6\u4ece\u66f4\u5927\u3001\u66f4\u590d\u6742\u7684\u6559\u5e08\u6a21\u578b\u8f6c\u79fb\u5230\u8f83\u5c0f\u7684\u5b66\u751f\u6a21\u578b\u4e2d\u3002\u4f20\u7edf\u4e0a\uff0cKD\u6d89\u53ca\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\u4ee5\u6a21\u4eff\u6559\u5e08\u6a21\u578b\u7684\u8f93\u51fa\u6982\u7387\uff0c\u800c\u66f4\u5148\u8fdb\u7684\u6280\u672f\u5219\u63a2\u7d22\u5f15\u5bfc\u5b66\u751f\u6a21\u578b\u91c7\u7528\u6559\u5e08\u6a21\u578b\u7684\u5185\u90e8\u8868\u793a\u3002\u5c3d\u7ba1KD\u5728\u8bb8\u591a\u9886\u57df\u53d6\u5f97\u4e86\u5e7f\u6cdb\u7684\u6210\u529f\uff0c\u4f46\u5728\u4e8c\u5206\u7c7b\u548c\u5c11\u7c7b\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u5374\u4e0d\u5c3d\u5982\u4eba\u610f\u3002\u8fd9\u662f\u56e0\u4e3a\u6559\u5e08\u6a21\u578b\u7684\u6cdb\u5316\u6a21\u5f0f\u4fe1\u606f\u91cf\u4e0e\u7c7b\u522b\u6570\u91cf\u76f4\u63a5\u76f8\u5173\u3002\u6b64\u5916\uff0c\u4e00\u4e9b\u590d\u6742\u7684\u84b8\u998f\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u666e\u904d\u9002\u7528\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u4ee5\u5916\u7684\u6570\u636e\u7c7b\u578b\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e\u60c5\u611f\u5206\u6790\u3001\u641c\u7d22\u67e5\u8be2\u7406\u89e3\u3001\u5e7f\u544a\u4e0e\u67e5\u8be2\u76f8\u5173\u6027\u8bc4\u4f30\u7b49\u5173\u952e\u73b0\u5b9e\u5e94\u7528\uff0c\u6709\u6548\u7684\u84b8\u998f\u6280\u672f\u4ecd\u7136\u96be\u4ee5\u6349\u6478\u3002\u8003\u8651\u5230\u8fd9\u4e9b\u89c2\u5bdf\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u6559\u5e08\u6a21\u578b\u8868\u793a\u4e2d\u84b8\u998f\u77e5\u8bc6\u7684\u65b0\u65b9\u6cd5\uff0c\u79f0\u4e3a\u5b66\u4e60\u5d4c\u5165\u7ebf\u6027\u6295\u5f71\uff08LELP\uff09\u3002\u53d7\u8fd1\u671f\u5173\u4e8e\u6700\u7ec8\u5c42\u8868\u793a\u7ed3\u6784\u7684\u7814\u7a76\u542f\u53d1\uff0cLELP\u901a\u8fc7\u8bc6\u522b\u6559\u5e08\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u4fe1\u606f\u7ebf\u6027\u5b50\u7a7a\u95f4\uff0c\u5e76\u5c06\u5176\u5206\u5272\u4e3a\u4f2a\u5b50\u7c7b\uff0c\u6765\u5de5\u4f5c\u3002\u7136\u540e\uff0c\u5b66\u751f\u6a21\u578b\u88ab\u8bad\u7ec3\u4ee5\u590d\u5236\u8fd9\u4e9b\u4f2a\u7c7b\u3002\u6211\u4eec\u5728\u5927\u89c4\u6a21NLP\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982Amazon Reviews\u548cSentiment140\uff09\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cLELP\u5728\u4e8c\u5206\u7c7b\u548c\u5c11\u7c7b\u95ee\u9898\u4e0a\u59cb\u7ec8\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5e76\u4e14\u901a\u5e38\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u84b8\u998f\u7b97\u6cd5\uff0c\u8fd9\u4e9b\u7b97\u6cd5\u5728\u5927\u591a\u6570KD\u65b9\u6cd5\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002 Noel Loo PDF N/A Linear Projections of Teacher Embeddings for Few-Class Distillation Knowledge Distillation (KD) has emerged as a promising approach for transferring knowledge from a larger, more complex teacher model to a smaller student model. Traditionally, KD involves training the student to mimic the teacher's output probabilities, while more advanced techniques have explored guiding the student to adopt the teacher's internal representations. Despite its widespread success, the performance of KD in binary classification and few-class problems has been less satisfactory. This is because the information about the teacher model's generalization patterns scales directly with the number of classes. Moreover, several sophisticated distillation methods may not be universally applicable or effective for data types beyond Computer Vision. Consequently, effective distillation techniques remain elusive for a range of key real-world applications, such as sentiment analysis, search query understanding, and advertisement-query relevance assessment. Taking these observations into account, we introduce a novel method for distilling knowledge from the teacher's model representations, which we term Learning Embedding Linear Projections (LELP). Inspired by recent findings about the structure of final-layer representations, LELP works by identifying informative linear subspaces in the teacher's embedding space, and splitting them into pseudo-subclasses. The student model is then trained to replicate these pseudo-classes. Our experimental evaluation on large-scale NLP benchmarks like Amazon Reviews and Sentiment140 demonstrate the LELP is consistently competitive with, and typically superior to, existing state-of-the-art distillation algorithms for binary and few-class problems, where most KD methods suffer. POMONAG\uff1a\u5e15\u7d2f\u6258\u6700\u4f18\u591a\u76ee\u6807\u795e\u7ecf\u67b6\u6784\u751f\u6210\u5668 \u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff08NAS\uff09\u81ea\u52a8\u5316\u4e86\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\uff0c\u51cf\u5c11\u4e86\u5bf9\u4eba\u7c7b\u4e13\u5bb6\u7684\u4f9d\u8d56\u3002\u5c3d\u7ba1NAS\u65b9\u6cd5\u8ba1\u7b97\u5bc6\u96c6\u4e14\u7279\u5b9a\u4e8e\u6570\u636e\u96c6\uff0c\u4f46\u8f85\u52a9\u9884\u6d4b\u5668\u51cf\u5c11\u4e86\u9700\u8981\u8bad\u7ec3\u7684\u6a21\u578b\u6570\u91cf\uff0c\u4ece\u800c\u7f29\u77ed\u4e86\u641c\u7d22\u65f6\u95f4\u3002\u8fd9\u79cd\u7b56\u7565\u7528\u4e8e\u751f\u6210\u6ee1\u8db3\u591a\u4e2a\u8ba1\u7b97\u7ea6\u675f\u7684\u67b6\u6784\u3002\u6700\u8fd1\uff0c\u53ef\u8fc1\u79fb\u7684NAS\u5e94\u8fd0\u800c\u751f\uff0c\u5c06\u641c\u7d22\u8fc7\u7a0b\u4ece\u6570\u636e\u96c6\u4f9d\u8d56\u6cdb\u5316\u5230\u4efb\u52a1\u4f9d\u8d56\u3002\u5728\u8fd9\u4e00\u9886\u57df\uff0cDiffusionNAG\u662f\u4e00\u79cd\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002\u8fd9\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u65b9\u6cd5\u7b80\u5316\u4e86\u8ba1\u7b97\uff0c\u751f\u6210\u7684\u67b6\u6784\u5728\u4e0d\u8fdb\u884c\u8fdb\u4e00\u6b65\u9002\u5e94\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u672a\u89c1\u6570\u636e\u96c6\u7684\u51c6\u786e\u6027\u8fdb\u884c\u4e86\u4f18\u5316\u3002\u7136\u800c\uff0cDiffusionNAG\u4ec5\u5173\u6ce8\u51c6\u786e\u6027\uff0c\u5ffd\u7565\u4e86\u6a21\u578b\u590d\u6742\u6027\u3001\u8ba1\u7b97\u6548\u7387\u548c\u63a8\u7406\u5ef6\u8fdf\u7b49\u5176\u4ed6\u5173\u952e\u76ee\u6807\u2014\u2014\u8fd9\u4e9b\u56e0\u7d20\u5bf9\u4e8e\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\u6a21\u578b\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u4ecb\u7ecd\u4e86Pareto-Optimal Many-Objective Neural Architecture Generator\uff08POMONAG\uff09\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u6269\u6563\u8fc7\u7a0b\u6269\u5c55\u4e86DiffusionNAG\u3002POMONAG\u540c\u65f6\u8003\u8651\u4e86\u51c6\u786e\u6027\u3001\u53c2\u6570\u6570\u91cf\u3001\u4e58\u79ef\u7d2f\u52a0\u8fd0\u7b97\uff08MACs\uff09\u548c\u63a8\u7406\u5ef6\u8fdf\u3002\u5b83\u96c6\u6210\u4e86\u6027\u80fd\u9884\u6d4b\u6a21\u578b\u6765\u4f30\u8ba1\u8fd9\u4e9b\u6307\u6807\u5e76\u6307\u5bfc\u6269\u6563\u68af\u5ea6\u3002POMONAG\u7684\u4f18\u5316\u901a\u8fc7\u6269\u5c55\u5176\u8bad\u7ec3\u5143\u6570\u636e\u96c6\u3001\u5e94\u7528Pareto\u524d\u6cbf\u8fc7\u6ee4\u4ee5\u53ca\u7ec6\u5316\u6761\u4ef6\u751f\u6210\u7684\u5d4c\u5165\u6765\u589e\u5f3a\u3002\u8fd9\u4e9b\u589e\u5f3a\u4f7f\u5f97POMONAG\u80fd\u591f\u751f\u6210\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u4e4b\u524d\u6700\u5148\u8fdb\u7684Pareto\u6700\u4f18\u67b6\u6784\u3002\u7ed3\u679c\u5728\u4e24\u4e2a\u641c\u7d22\u7a7a\u95f4\u2014\u2014NASBench201\u548cMobileNetV3\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u5e76\u572815\u4e2a\u56fe\u50cf\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002 Eugenio Lomurno PDF N/A POMONAG: Pareto-Optimal Many-Objective Neural Architecture Generator Neural Architecture Search (NAS) automates neural network design, reducing dependence on human expertise. While NAS methods are computationally intensive and dataset-specific, auxiliary predictors reduce the models needing training, decreasing search time. This strategy is used to generate architectures satisfying multiple computational constraints. Recently, Transferable NAS has emerged, generalizing the search process from dataset-dependent to task-dependent. In this field, DiffusionNAG is a state-of-the-art method. This diffusion-based approach streamlines computation, generating architectures optimized for accuracy on unseen datasets without further adaptation. However, by focusing solely on accuracy, DiffusionNAG overlooks other crucial objectives like model complexity, computational efficiency, and inference latency -- factors essential for deploying models in resource-constrained environments. This paper introduces the Pareto-Optimal Many-Objective Neural Architecture Generator (POMONAG), extending DiffusionNAG via a many-objective diffusion process. POMONAG simultaneously considers accuracy, number of parameters, multiply-accumulate operations (MACs), and inference latency. It integrates Performance Predictor models to estimate these metrics and guide diffusion gradients. POMONAG's optimization is enhanced by expanding its training Meta-Dataset, applying Pareto Front Filtering, and refining embeddings for conditional generation. These enhancements enable POMONAG to generate Pareto-optimal architectures that outperform the previous state-of-the-art in performance and efficiency. Results were validated on two search spaces -- NASBench201 and MobileNetV3 -- and evaluated across 15 image classification datasets. \u5b9e\u4f8b\u81ea\u9002\u5e94\u7684\u96f6\u6837\u672c\u601d\u7ef4\u94fe\u63d0\u793a \u96f6\u6837\u672c\u601d\u7ef4\u94fe\uff08CoT\uff09\u63d0\u793a\u4f5c\u4e3a\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u7b56\u7565\uff0c\u6b63\u5728\u5d2d\u9732\u5934\u89d2\uff0c\u7528\u4ee5\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5b9e\u9645\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u7136\u800c\uff0c\u5355\u4e00\u7684\u3001\u4efb\u52a1\u7ea7\u522b\u7684\u63d0\u793a\u5728\u6574\u4e2a\u5b9e\u4f8b\u4e2d\u7edf\u4e00\u5e94\u7528\u7684\u6548\u679c\u672c\u8d28\u4e0a\u662f\u6709\u9650\u7684\uff0c\u56e0\u4e3a\u4e00\u4e2a\u63d0\u793a\u65e0\u6cd5\u6210\u4e3a\u6240\u6709\u5b9e\u4f8b\u7684\u201c\u597d\u642d\u6863\u201d\u3002\u66f4\u4e3a\u6070\u5f53\u7684\u65b9\u6cd5\u5e94\u7ec6\u81f4\u8003\u8651\u63d0\u793a\u4e0e\u6bcf\u4e2a\u5b9e\u4f8b\u4e4b\u95f4\u7684\u4e92\u52a8\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u4f8b\u81ea\u9002\u5e94\u63d0\u793a\u7b97\u6cd5\uff0c\u4f5c\u4e3a\u96f6\u6837\u672cCoT\u63a8\u7406\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u533a\u5206\u597d\u4e0e\u574f\u7684\u63d0\u793a\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u9996\u5148\u901a\u8fc7\u4fe1\u606f\u6d41\u7684\u89c6\u89d2\u5bf9LLMs\u8fdb\u884c\u5206\u6790\uff0c\u4ee5\u63ed\u793a\u96f6\u6837\u672cCoT\u63a8\u7406\u7684\u673a\u5236\u3002\u6211\u4eec\u53d1\u73b0\uff0c\u4ece\u95ee\u9898\u5230\u63d0\u793a\u4ee5\u53ca\u4ece\u95ee\u9898\u5230\u63a8\u7406\u7684\u4fe1\u606f\u6d41\u52a8\u5171\u540c\u5f71\u54cd\u7740\u63a8\u7406\u7ed3\u679c\u3002\u6211\u4eec\u6ce8\u610f\u5230\uff0c\u66f4\u597d\u7684\u96f6\u6837\u672cCoT\u63a8\u7406\u9700\u8981\u63d0\u793a\u4ece\u95ee\u9898\u4e2d\u83b7\u53d6\u8bed\u4e49\u4fe1\u606f\uff0c\u7136\u540e\u63a8\u7406\u76f4\u63a5\u4ece\u95ee\u9898\u4e2d\u83b7\u53d6\u8db3\u591f\u7684\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u63d0\u793a\u95f4\u63a5\u83b7\u53d6\u3002\u76f8\u53cd\uff0c\u7f3a\u4e4f\u5176\u4e2d\u4efb\u4f55\u4e00\u9879\u90fd\u53ef\u80fd\u5bfc\u81f4\u4e0d\u826f\u7684\u63a8\u7406\u7ed3\u679c\u3002\u57fa\u4e8e\u6b64\uff0c\u6211\u4eec\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u96f6\u6837\u672cCoT\u63a8\u7406\u7684\u5b9e\u4f8b\u81ea\u9002\u5e94\u63d0\u793a\u7b56\u7565\uff08IAP\uff09\u3002\u5728LLaMA-2\u3001LLaMA-3\u548cQwen\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\uff0c\u6db5\u76d6\u6570\u5b66\u3001\u903b\u8f91\u548c\u5e38\u8bc6\u63a8\u7406\u4efb\u52a1\uff08\u5982GSM8K\u3001MMLU\u3001\u56e0\u679c\u5224\u65ad\uff09\uff0c\u5747\u83b7\u5f97\u4e86\u6301\u7eed\u7684\u6539\u8fdb\uff0c\u8868\u660e\u5b9e\u4f8b\u81ea\u9002\u5e94\u7684\u96f6\u6837\u672cCoT\u63d0\u793a\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5176\u4ed6\u4efb\u52a1\u7ea7\u522b\u7684\u65b9\u6cd5\uff0c\u5373\u4f7f\u8fd9\u4e9b\u65b9\u6cd5\u4f7f\u7528\u4e86\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u6216\u590d\u6742\u7684\u7a0b\u5e8f\uff0c\u4e5f\u51f8\u663e\u4e86\u6211\u4eec\u5173\u4e8e\u96f6\u6837\u672cCoT\u63a8\u7406\u673a\u5236\u53d1\u73b0\u7684\u91cd\u8981\u6027\u3002 Xiaosong Yuan PDF N/A Instance-adaptive Zero-shot Chain-of-Thought Prompting Zero-shot Chain-of-Thought (CoT) prompting emerges as a simple and effective strategy for enhancing the performance of large language models (LLMs) in real-world reasoning tasks. Nonetheless, the efficacy of a singular, task-level prompt uniformly applied across the whole of instances is inherently limited since one prompt cannot be a good partner for all, a more appropriate approach should consider the interaction between the prompt and each instance meticulously. This work introduces an instance-adaptive prompting algorithm as an alternative zero-shot CoT reasoning scheme by adaptively differentiating good and bad prompts. Concretely, we first employ analysis on LLMs through the lens of information flow to detect the mechanism under zero-shot CoT reasoning, in which we discover that information flows from question to prompt and question to rationale jointly influence the reasoning results most. We notice that a better zero-shot CoT reasoning needs the prompt to obtain semantic information from the question then the rationale aggregates sufficient information from the question directly and via the prompt indirectly. On the contrary, lacking any of those would probably lead to a bad one. Stem from that, we further propose an instance-adaptive prompting strategy (IAP) for zero-shot CoT reasoning. Experiments conducted with LLaMA-2, LLaMA-3, and Qwen on math, logic, and commonsense reasoning tasks (e.g., GSM8K, MMLU, Causal Judgement) obtain consistent improvement, demonstrating that the instance-adaptive zero-shot CoT prompting performs better than other task-level methods with some curated prompts or sophisticated procedures, showing the significance of our findings in the zero-shot CoT reasoning mechanism. \u9762\u5bf9\u6a21\u7cca\u6027\u7684\u4e50\u89c2\u539f\u5219\u5728\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\u4e2d\u7684\u5e94\u7528 Follow-The-Regularized-Leader (FTRL) \u7b97\u6cd5\u901a\u5e38\u5728\u5bf9\u6297\u6027\u548c\u968f\u673a\u6027\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\u4e2d\u4eab\u6709\u6700\u4f18\u7684\u540e\u6094\u503c\uff0c\u5e76\u4e14\u5141\u8bb8\u8fdb\u884c\u7b80\u5316\u7684\u5206\u6790\u3002\u7136\u800c\uff0cFTRL \u7b97\u6cd5\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u90fd\u9700\u8981\u89e3\u51b3\u4e00\u4e2a\u4f18\u5316\u95ee\u9898\uff0c\u56e0\u6b64\u5728\u8ba1\u7b97\u4e0a\u5177\u6709\u6311\u6218\u6027\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0cFollow-The-Perturbed-Leader (FTPL) \u7b97\u6cd5\u901a\u8fc7\u6270\u52a8\u81c2\u7684\u5956\u52b1\u4f30\u8ba1\u6765\u5b9e\u73b0\u8ba1\u7b97\u6548\u7387\uff0c\u4f46\u5176\u540e\u6094\u5206\u6790\u8f83\u4e3a\u7e41\u7410\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684 FTPL \u7b97\u6cd5\uff0c\u80fd\u591f\u4e3a\u5bf9\u6297\u6027\u548c\u968f\u673a\u6027\u591a\u81c2\u8001\u864e\u673a\u751f\u6210\u6700\u4f18\u7b56\u7565\u3002\u4e0e FTRL \u7c7b\u4f3c\uff0c\u6211\u4eec\u7684\u7b97\u6cd5\u5141\u8bb8\u8fdb\u884c\u7edf\u4e00\u7684\u540e\u6094\u5206\u6790\uff0c\u5e76\u4e14\u4e0e FTPL \u7c7b\u4f3c\uff0c\u5b83\u63d0\u4f9b\u4e86\u4f4e\u8ba1\u7b97\u6210\u672c\u3002\u4e0e\u73b0\u6709\u4f9d\u8d56\u4e8e\u7531\u5df2\u77e5\u5206\u5e03\u63a7\u5236\u7684\u72ec\u7acb\u52a0\u6027\u6270\u52a8\u7684 FTPL \u7b97\u6cd5\u4e0d\u540c\uff0c\u6211\u4eec\u5141\u8bb8\u6270\u52a8\u7531\u4e00\u4e2a\u4ec5\u77e5\u5c5e\u4e8e\u7ed9\u5b9a\u96c6\u5408\u7684\u6a21\u7cca\u5206\u5e03\u63a7\u5236\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u9762\u5bf9\u6a21\u7cca\u65f6\u7684\u4e50\u89c2\u4e3b\u4e49\u539f\u5219\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u7684\u6846\u67b6\u63a8\u5e7f\u4e86\u73b0\u6709\u7684 FTPL \u7b97\u6cd5\u3002\u5b83\u8fd8\u5c06\u4e00\u7cfb\u5217 FTRL \u65b9\u6cd5\u4f5c\u4e3a\u7279\u4f8b\u5305\u542b\u5728\u5185\uff0c\u5305\u62ec\u51e0\u79cd\u6700\u4f18\u65b9\u6cd5\uff0c\u8fd9\u5728\u5f53\u524d\u7684 FTPL \u65b9\u6cd5\u4e2d\u4f3c\u4e4e\u662f\u4e0d\u53ef\u80fd\u7684\u3002\u6700\u540e\uff0c\u6211\u4eec\u5229\u7528\u79bb\u6563\u9009\u62e9\u7406\u8bba\u7684\u6280\u672f\u8bbe\u8ba1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u4e8c\u5206\u7b97\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u4e50\u89c2\u7684\u81c2\u91c7\u6837\u6982\u7387\u3002\u8be5\u7b97\u6cd5\u7684\u901f\u5ea6\u6bd4\u6bcf\u6b21\u8fed\u4ee3\u90fd\u89e3\u51b3\u4f18\u5316\u95ee\u9898\u7684\u6807\u51c6 FTRL \u7b97\u6cd5\u5feb\u8fbe $10^4$ \u500d\u3002\u6211\u4eec\u7684\u7ed3\u679c\u4e0d\u4ec5\u89e3\u51b3\u4e86\u73b0\u6709\u7684\u731c\u60f3\uff0c\u8fd8\u901a\u8fc7\u5c06 FTRL \u6620\u5c04\u5230 FTPL\uff0c\u63d0\u4f9b\u4e86\u5173\u4e8e\u6270\u52a8\u5f71\u54cd\u7684\u65b0\u89c1\u89e3\u3002 Mengmeng Li PDF N/A Optimism in the Face of Ambiguity Principle for Multi-Armed Bandits Follow-The-Regularized-Leader (FTRL) algorithms often enjoy optimal regret for adversarial as well as stochastic bandit problems and allow for a streamlined analysis. Nonetheless, FTRL algorithms require the solution of an optimization problem in every iteration and are thus computationally challenging. In contrast, Follow-The-Perturbed-Leader (FTPL) algorithms achieve computational efficiency by perturbing the estimates of the rewards of the arms, but their regret analysis is cumbersome. We propose a new FTPL algorithm that generates optimal policies for both adversarial and stochastic multi-armed bandits. Like FTRL, our algorithm admits a unified regret analysis, and similar to FTPL, it offers low computational costs. Unlike existing FTPL algorithms that rely on independent additive disturbances governed by a \\textit{known} distribution, we allow for disturbances governed by an \\textit{ambiguous} distribution that is only known to belong to a given set and propose a principle of optimism in the face of ambiguity. Consequently, our framework generalizes existing FTPL algorithms. It also encapsulates a broad range of FTRL methods as special cases, including several optimal ones, which appears to be impossible with current FTPL methods. Finally, we use techniques from discrete choice theory to devise an efficient bisection algorithm for computing the optimistic arm sampling probabilities. This algorithm is up to $10^4$ times faster than standard FTRL algorithms that solve an optimization problem in every iteration. Our results not only settle existing conjectures but also provide new insights into the impact of perturbations by mapping FTRL to FTPL. QA\u7f16\u7801\u5668\uff1a\u9762\u5411\u95ee\u7b54\u7cfb\u7edf\u4e2d\u7684\u5bf9\u9f50\u8868\u793a\u5b66\u4e60 \u73b0\u4ee3\u95ee\u7b54\u7cfb\u7edf\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u4ee5\u63d0\u4f9b\u51c6\u786e\u4e14\u53ef\u4fe1\u7684\u56de\u7b54\u3002\u7136\u800c\uff0c\u7528\u6237\u67e5\u8be2\u4e0e\u76f8\u5173\u6587\u6863\u4e4b\u95f4\u7684\u56fa\u6709\u5dee\u8ddd\u963b\u788d\u4e86\u7cbe\u786e\u5339\u914d\u3002\u53d7\u6211\u4eec\u7684\u5706\u9525\u5206\u5e03\u5047\u8bbe\u542f\u53d1\uff0c\u5373\u6f5c\u5728\u67e5\u8be2\u548c\u6587\u6863\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u5f62\u6210\u7c7b\u4f3c\u5706\u9525\u7684\u7ed3\u6784\uff0c\u6211\u4eec\u63d0\u51fa\u4e86QAEncoder\uff0c\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\u6765\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002\u5177\u4f53\u800c\u8a00\uff0cQAEncoder\u5c06\u5d4c\u5165\u7a7a\u95f4\u4e2d\u6f5c\u5728\u67e5\u8be2\u7684\u671f\u671b\u4f30\u8ba1\u4e3a\u6587\u6863\u5d4c\u5165\u7684\u7a33\u5065\u66ff\u4ee3\uff0c\u5e76\u9644\u52a0\u6587\u6863\u6307\u7eb9\u4ee5\u6709\u6548\u533a\u5206\u8fd9\u4e9b\u5d4c\u5165\u3002\u5728\u516d\u79cd\u8bed\u8a00\u548c\u516b\u4e2a\u6570\u636e\u96c6\u4e0a\u5bf9\u5341\u56db\u4e2a\u5d4c\u5165\u6a21\u578b\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86QAEncoder\u7684\u5bf9\u9f50\u80fd\u529b\uff0c\u5b83\u63d0\u4f9b\u4e86\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7684RAG\u67b6\u6784\u548c\u57fa\u4e8e\u8bad\u7ec3\u7684\u65b9\u6cd5\u4e2d\u3002 Zhengren Wang PDF N/A QAEncoder: Towards Aligned Representation Learning in Question Answering System Modern QA systems entail retrieval-augmented generation (RAG) for accurate and trustworthy responses. However, the inherent gap between user queries and relevant documents hinders precise matching. Motivated by our conical distribution hypothesis, which posits that potential queries and documents form a cone-like structure in the embedding space, we introduce QAEncoder, a training-free approach to bridge this gap. Specifically, QAEncoder estimates the expectation of potential queries in the embedding space as a robust surrogate for the document embedding, and attaches document fingerprints to effectively distinguish these embeddings. Extensive experiments on fourteen embedding models across six languages and eight datasets validate QAEncoder's alignment capability, which offers a plug-and-play solution that seamlessly integrates with existing RAG architectures and training-based methods. \u591a\u5c42Picard\u903c\u8fd1\u548c\u5177\u6709ReLU\u3001leaky ReLU\u53casoftplus\u6fc0\u6d3b\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728$L^p$\u610f\u4e49\u4e0b\u514b\u670d\u4e86\u7ef4\u5ea6\u707e\u96be\uff0c\u5f53\u903c\u8fd1\u534a\u7ebf\u6027\u629b\u7269\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u65f6\u3002 \u6211\u4eec\u8bc1\u660e\u4e86\u591a\u7ea7Picard\u903c\u8fd1\u548c\u5177\u6709ReLU\u3001leaky ReLU\u4ee5\u53casoftplus\u6fc0\u6d3b\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u5728$L^\\mathfrak{p}$-\u610f\u4e49\u4e0b\u903c\u8fd1\u534a\u7ebf\u6027Kolmogorov PDE\u7684\u89e3\uff0c\u5176\u4e2d$\\mathfrak{p}\\in [2,\\infty)$\uff0c\u5728\u68af\u5ea6\u65e0\u5173\u3001Lipschitz\u8fde\u7eed\u7684\u975e\u7ebf\u6027\u60c5\u51b5\u4e0b\uff0c\u591a\u7ea7Picard\u903c\u8fd1\u7684\u8ba1\u7b97\u91cf\u548c\u795e\u7ecf\u7f51\u7edc\u6240\u9700\u53c2\u6570\u7684\u6570\u91cf\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u5728\u7ef4\u5ea6$d\\in \\mathbb{N}$\u548c\u89c4\u5b9a\u7cbe\u5ea6\u7684\u5012\u6570$\\epsilon$\u4e0a\u6700\u591a\u5448\u591a\u9879\u5f0f\u589e\u957f\u3002 Ariel Neufeld PDF N/A Multilevel Picard approximations and deep neural networks with ReLU, leaky ReLU, and softplus activation overcome the curse of dimensionality when approximating semilinear parabolic partial differential equations in $L^p$-sense We prove that multilevel Picard approximations and deep neural networks with ReLU, leaky ReLU, and softplus activation are capable of approximating solutions of semilinear Kolmogorov PDEs in $L^\\mathfrak{p}$-sense, $\\mathfrak{p}\\in [2,\\infty)$, in the case of gradient-independent, Lipschitz-continuous nonlinearities, while the computational effort of the multilevel Picard approximations and the required number of parameters in the neural networks grow at most polynomially in both dimension $d\\in \\mathbb{N}$ and reciprocal of the prescribed accuracy $\\epsilon$. HELPD\uff1a\u901a\u8fc7\u5206\u5c42\u53cd\u9988\u5b66\u4e60\u4e0e\u89c6\u89c9\u589e\u5f3a\u60e9\u7f5a\u89e3\u7801\u7f13\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u73b0\u8c61 \u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u5728\u4f17\u591a\u89c6\u89c9-\u8bed\u8a00\u4efb\u52a1\u4e2d\u5c55\u73b0\u4e86\u5353\u8d8a\u7684\u6027\u80fd\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6a21\u578b\u4ecd\u5b58\u5728\u591a\u6a21\u6001\u5e7b\u89c9\u95ee\u9898\uff0c\u5373\u751f\u6210\u7684\u5bf9\u8c61\u6216\u5185\u5bb9\u4e0e\u56fe\u50cf\u4e0d\u7b26\u3002\u8bb8\u591a\u73b0\u6709\u5de5\u4f5c\u901a\u8fc7\u76f4\u63a5\u5224\u65ad\u5bf9\u8c61\u662f\u5426\u5b58\u5728\u4e8e\u56fe\u50cf\u4e2d\u6765\u68c0\u6d4b\u5e7b\u89c9\uff0c\u5ffd\u7565\u4e86\u5bf9\u8c61\u4e0e\u8bed\u4e49\u4e4b\u95f4\u7684\u5173\u8054\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u89c6\u89c9\u589e\u5f3a\u60e9\u7f5a\u89e3\u7801\u7684\u5206\u5c42\u53cd\u9988\u5b66\u4e60\uff08HELPD\uff09\u3002\u8be5\u6846\u67b6\u5728\u5bf9\u8c61\u548c\u53e5\u5b50\u8bed\u4e49\u5c42\u9762\u4e0a\u6574\u5408\u4e86\u5e7b\u89c9\u53cd\u9988\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5373\u4f7f\u5728\u8bad\u7ec3\u7a0b\u5ea6\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e5f\u80fd\u51cf\u5c11\u8d85\u8fc715%\u7684\u5e7b\u89c9\u3002\u540c\u65f6\uff0cHELPD\u6839\u636e\u56fe\u50cf\u6ce8\u610f\u529b\u7a97\u53e3\u5bf9\u8f93\u51fa\u5bf9\u6570\u8fdb\u884c\u60e9\u7f5a\uff0c\u4ee5\u907f\u514d\u8fc7\u5ea6\u53d7\u751f\u6210\u6587\u672c\u7684\u5f71\u54cd\u3002HELPD\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u4efb\u4f55LVLMs\u4e2d\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5728\u591a\u4e2a\u5e7b\u89c9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002\u5b83\u6709\u6548\u5730\u7f13\u89e3\u4e86\u4e0d\u540cLVLMs\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5e76\u540c\u65f6\u63d0\u5347\u4e86\u5b83\u4eec\u7684\u6587\u672c\u751f\u6210\u8d28\u91cf\u3002 Fan Yuan PDF N/A HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding Large Vision-Language Models (LVLMs) have shown remarkable performance on many visual-language tasks. However, these models still suffer from multimodal hallucination, which means the generation of objects or content that violates the images. Many existing work detects hallucination by directly judging whether an object exists in an image, overlooking the association between the object and semantics. To address this issue, we propose Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding (HELPD). This framework incorporates hallucination feedback at both object and sentence semantic levels. Remarkably, even with a marginal degree of training, this approach can alleviate over 15% of hallucination. Simultaneously, HELPD penalizes the output logits according to the image attention window to avoid being overly affected by generated text. HELPD can be seamlessly integrated with any LVLMs. Our experiments demonstrate that the proposed framework yields favorable results across multiple hallucination benchmarks. It effectively mitigates hallucination for different LVLMs and concurrently improves their text generation quality. \u89e3\u7801\u6765\u81eafMRI\u7684\u89c6\u89c9\u56de\u58f0\uff1a\u4e3a\u8fc7\u53bb\u7684\u8bed\u4e49\u4fe1\u606f\u8fdb\u884c\u8bb0\u5fc6\u89e3\u6784 \u4eba\u7c7b\u89c6\u89c9\u7cfb\u7edf\u80fd\u591f\u5904\u7406\u8fde\u7eed\u7684\u89c6\u89c9\u4fe1\u606f\u6d41\uff0c\u4f46\u5927\u8111\u5728\u8fde\u7eed\u89c6\u89c9\u5904\u7406\u8fc7\u7a0b\u4e2d\u5982\u4f55\u7f16\u7801\u548c\u68c0\u7d22\u6700\u8fd1\u7684\u89c6\u89c9\u8bb0\u5fc6\u4ecd\u672a\u88ab\u63a2\u7d22\u3002\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5de5\u4f5c\u8bb0\u5fc6\u5728\u8fde\u7eed\u89c6\u89c9\u523a\u6fc0\u4e0b\u4fdd\u7559\u8fc7\u53bb\u4fe1\u606f\u7684\u80fd\u529b\u3002\u968f\u540e\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u9879\u65b0\u7684\u4efb\u52a1\u2014\u2014\u8bb0\u5fc6\u89e3\u6784\uff0c\u65e8\u5728\u4ecefMRI\u4fe1\u53f7\u4e2d\u63d0\u53d6\u548c\u89e3\u7801\u8fc7\u53bb\u7684\u4fe1\u606f\u3002\u4e3a\u4e86\u89e3\u51b3\u8fc7\u53bb\u8bb0\u5fc6\u4fe1\u606f\u5e72\u6270\u7684\u95ee\u9898\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u79cd\u53d7\u524d\u6444\u5e72\u6270\u73b0\u8c61\u542f\u53d1\u7684\u89e3\u6784\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5c06\u76f8\u90bbfMRI\u4fe1\u53f7\u4e4b\u95f4\u7684\u4fe1\u606f\u5206\u79bb\u4e3a\u5f53\u524d\u548c\u8fc7\u53bb\u4e24\u4e2a\u90e8\u5206\uff0c\u5e76\u5c06\u5b83\u4eec\u89e3\u7801\u4e3a\u56fe\u50cf\u63cf\u8ff0\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u5730\u89e3\u6784\u4e86fMRI\u4fe1\u53f7\u4e2d\u7684\u4fe1\u606f\u3002\u8fd9\u9879\u7814\u7a76\u53ef\u80fd\u63a8\u52a8\u8111\u673a\u63a5\u53e3\u7684\u53d1\u5c55\uff0c\u5e76\u7f13\u89e3fMRI\u65f6\u95f4\u5206\u8fa8\u7387\u4f4e\u7684\u95ee\u9898\u3002 Runze Xia PDF N/A Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past Semantic Information The human visual system is capable of processing continuous streams of visual information, but how the brain encodes and retrieves recent visual memories during continuous visual processing remains unexplored. This study investigates the capacity of working memory to retain past information under continuous visual stimuli. And then we propose a new task Memory Disentangling, which aims to extract and decode past information from fMRI signals. To address the issue of interference from past memory information, we design a disentangled contrastive learning method inspired by the phenomenon of proactive interference. This method separates the information between adjacent fMRI signals into current and past components and decodes them into image descriptions. Experimental results demonstrate that this method effectively disentangles the information within fMRI signals. This research could advance brain-computer interfaces and mitigate the problem of low temporal resolution in fMRI. \u5145\u5206\u5fc5\u8981\u89e3\u91ca\uff08\u53ca\u5176\u95f4\u7684\u533a\u522b\uff09 \u968f\u7740\u590d\u6742\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u91cd\u5927\u51b3\u7b56\u573a\u666f\u4e2d\u7684\u5e94\u7528\u4e0d\u65ad\u589e\u52a0\uff0c\u6211\u4eec\u80fd\u591f\u89e3\u91ca\u548c\u7406\u89e3\u5176\u9884\u6d4b\u7ed3\u679c\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u4e8b\u540e\u89e3\u91ca\u65b9\u6cd5\u901a\u8fc7\u8bc6\u522b\u8f93\u5165$\\mathbf{x}$\u4e2d\u5bf9\u6a21\u578b\u8f93\u51fa$f(\\mathbf{x})$\u91cd\u8981\u7684\u7279\u5f81\uff0c\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u89c1\u89e3\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u5f62\u5f0f\u5316\u5e76\u7814\u7a76\u4e86\u4e24\u79cd\u9002\u7528\u4e8e\u4e00\u822c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u7279\u5f81\u91cd\u8981\u6027\u7684\u7cbe\u786e\u6982\u5ff5\uff1a\u5145\u5206\u6027\u548c\u5fc5\u8981\u6027\u3002\u6211\u4eec\u5c55\u793a\u4e86\u8fd9\u4e24\u79cd\u89e3\u91ca\u7c7b\u578b\uff0c\u5c3d\u7ba1\u76f4\u89c2\u4e14\u7b80\u5355\uff0c\u4f46\u5728\u63d0\u4f9b\u6a21\u578b\u8ba4\u4e3a\u91cd\u8981\u7684\u7279\u5f81\u7684\u5b8c\u6574\u56fe\u666f\u65b9\u9762\u53ef\u80fd\u5b58\u5728\u4e0d\u8db3\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u91cd\u8981\u6027\u6982\u5ff5\uff0c\u901a\u8fc7\u5728\u5fc5\u8981\u6027-\u5145\u5206\u6027\u8f74\u4e0a\u63a2\u7d22\u8fde\u7eed\u4f53\u6765\u89c4\u907f\u8fd9\u4e9b\u5c40\u9650\u6027\u3002\u6211\u4eec\u5c55\u793a\u7684\u8fd9\u79cd\u7edf\u4e00\u6982\u5ff5\u4e0e\u57fa\u4e8e\u6761\u4ef6\u72ec\u7acb\u6027\u548c\u57fa\u4e8e\u535a\u5f08\u8bba\u91cf\uff08\u5982Shapley\u503c\uff09\u7684\u7279\u5f81\u91cd\u8981\u6027\u5b9a\u4e49\u6709\u7740\u7d27\u5bc6\u7684\u8054\u7cfb\u3002\u91cd\u8981\u7684\u662f\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u7edf\u4e00\u89c6\u89d2\u5982\u4f55\u4f7f\u6211\u4eec\u80fd\u591f\u68c0\u6d4b\u5230\u4ec5\u51ed\u524d\u8ff0\u4e24\u79cd\u65b9\u6cd5\u4e4b\u4e00\u53ef\u80fd\u9057\u6f0f\u7684\u91cd\u8981\u7279\u5f81\u3002 Beepul Bharti PDF N/A Sufficient and Necessary Explanations (and What Lies in Between) As complex machine learning models continue to find applications in high-stakes decision-making scenarios, it is crucial that we can explain and understand their predictions. Post-hoc explanation methods provide useful insights by identifying important features in an input $\\mathbf{x}$ with respect to the model output $f(\\mathbf{x})$. In this work, we formalize and study two precise notions of feature importance for general machine learning models: sufficiency and necessity. We demonstrate how these two types of explanations, albeit intuitive and simple, can fall short in providing a complete picture of which features a model finds important. To this end, we propose a unified notion of importance that circumvents these limitations by exploring a continuum along a necessity-sufficiency axis. Our unified notion, we show, has strong ties to other popular definitions of feature importance, like those based on conditional independence and game-theoretic quantities like Shapley values. Crucially, we demonstrate how a unified perspective allows us to detect important features that could be missed by either of the previous approaches alone. \u4ece\u8d1d\u53f6\u65af\u51b3\u7b56\u7406\u8bba\u7684\u89d2\u5ea6\u770b\u6d41\u7ea7\u6d41\u5339\u914d \u6d41\u5339\u914d\uff08FM\uff09\u662f\u4e00\u7c7b\u7528\u4e8e\u62df\u5408\u8fde\u7eed\u5f52\u4e00\u5316\u6d41\uff08CNFs\uff09\u7684\u8bad\u7ec3\u7b97\u6cd5\u3002\u4e00\u79cd\u6807\u51c6\u7684FM\u65b9\u6cd5\u79f0\u4e3a\u6761\u4ef6\u6d41\u5339\u914d\uff08CFM\uff09\uff0c\u5b83\u5229\u7528\u4e86CNF\u7684\u8fb9\u7f18\u5411\u91cf\u573a\u53ef\u4ee5\u901a\u8fc7\u5bf9\u6240\u8c13\u7684\u6761\u4ef6\u5411\u91cf\u573a\u8fdb\u884c\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u62df\u5408\u6765\u5b66\u4e60\u7684\u7279\u6027\uff0c\u8be5\u6761\u4ef6\u5411\u91cf\u573a\u662f\u5728\u7ed9\u5b9a\u6d41\u8def\u5f84\u7684\u4e00\u7aef\u6216\u4e24\u7aef\u7684\u60c5\u51b5\u4e0b\u6307\u5b9a\u7684\u3002\u6211\u4eec\u5c55\u793a\u4e86\u4ece\u8d1d\u53f6\u65af\u51b3\u7b56\u7406\u8bba\u7684\u89d2\u5ea6\u770b\u5f85CFM\u8bad\u7ec3\u7684\u53c2\u6570\u4f30\u8ba1\uff0c\u4e3aCFM\u7b97\u6cd5\u7684\u63a8\u5e7f\u6253\u5f00\u4e86\u5927\u95e8\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u8fd9\u6837\u7684\u6269\u5c55\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u5b9a\u4e49\u6761\u4ef6\u6982\u7387\u8def\u5f84\u7684CFM\u7b97\u6cd5\uff0c\u8be5\u8def\u5f84\u662f\u6839\u636e\u6211\u4eec\u79f0\u4e4b\u4e3a\u201c\u6d41\u201d\u7684\u6f5c\u5728\u968f\u673a\u8def\u5f84\u5b9e\u4f8b\u7ed9\u51fa\u7684\uff0c\u8fd9\u4e9b\u8def\u5f84\u8fde\u63a5\u4e86\u566a\u58f0\u548c\u89c2\u6d4b\u6570\u636e\u5bf9\u3002\u6b64\u5916\uff0c\u6211\u4eec\u4e3b\u5f20\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\uff08GPs\uff09\u6765\u5efa\u6a21\u8fd9\u4e9b\u6f5c\u5728\u6d41\u3002GP\u7684\u72ec\u7279\u5206\u5e03\u7279\u6027\uff0c\u7279\u522b\u662fGP\u7684\u901f\u5ea6\u4ecd\u7136\u662fGP\u8fd9\u4e00\u4e8b\u5b9e\uff0c\u4f7f\u5f97\u53ef\u4ee5\u4ece\u7ed3\u679c\u7684\u6d41\u589e\u5f3a\u6761\u4ef6\u6982\u7387\u8def\u5f84\u4e2d\u62bd\u53d6\u6837\u672c\uff0c\u800c\u65e0\u9700\u6a21\u62df\u5b9e\u9645\u7684\u6d41\uff0c\u56e0\u6b64CFM\u8bad\u7ec3\u7684\u201c\u65e0\u6a21\u62df\u201d\u7279\u6027\u5f97\u4ee5\u4fdd\u7559\u3002\u6211\u4eec\u5c55\u793a\u4e86\u8fd9\u79cdCFM\u7684\u63a8\u5e7f\u53ef\u4ee5\u5728\u9002\u5ea6\u7684\u8ba1\u7b97\u6210\u672c\u4e0b\u663e\u8457\u51cf\u5c11\u4f30\u8ba1\u7684\u8fb9\u7f18\u5411\u91cf\u573a\u7684\u65b9\u5dee\uff0c\u4ece\u800c\u5728\u5e38\u89c1\u6307\u6807\u4e0b\u63d0\u9ad8\u751f\u6210\u6837\u672c\u7684\u8d28\u91cf\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5728\u6d41\u4e0a\u91c7\u7528GP\u53ef\u4ee5\u7075\u6d3b\u5730\u8fde\u63a5\u591a\u4e2a\u76f8\u5173\u7684\u8bad\u7ec3\u6570\u636e\u70b9\uff08\u4f8b\u5982\uff0c\u65f6\u95f4\u5e8f\u5217\uff09\u5e76\u7eb3\u5165\u989d\u5916\u7684\u5148\u9a8c\u4fe1\u606f\u3002\u6211\u4eec\u901a\u8fc7\u6a21\u62df\u548c\u5e94\u7528\u4e8e\u4e24\u4e2a\u624b\u5199\u56fe\u50cf\u6570\u636e\u96c6\u7684\u5e94\u7528\u7a0b\u5e8f\uff0c\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u4e3b\u5f20\u3002 Ganchao Wei PDF N/A Stream-level flow matching from a Bayesian decision theoretic perspective Flow matching (FM) is a family of training algorithms for fitting continuous normalizing flows (CNFs). A standard approach to FM, called conditional flow matching (CFM), exploits the fact that the marginal vector field of a CNF can be learned by fitting least-square regression to the so-called conditional vector field specified given one or both ends of the flow path. We show that viewing CFM training from a Bayesian decision theoretic perspective on parameter estimation opens the door to generalizations of CFM algorithms. We propose one such extension by introducing a CFM algorithm based on defining conditional probability paths given what we refer to as <code>streams'', instances of latent stochastic paths that connect pairs of noise and observed data. Further, we advocates the modeling of these latent streams using Gaussian processes (GPs). The unique distributional properties of GPs, and in particular the fact that the velocities of a GP is still a GP, allows drawing samples from the resulting stream-augmented conditional probability path without simulating the actual streams, and hence the</code>simulation-free\" nature of CFM training is preserved. We show that this generalization of the CFM can substantially reduce the variance in the estimated marginal vector field at a moderate computational cost, thereby improving the quality of the generated samples under common metrics. Additionally, we show that adopting the GP on the streams allows for flexibly linking multiple related training data points (e.g., time series) and incorporating additional prior information. We empirically validate our claim through both simulations and applications to two hand-written image datasets. LHC\u4e0a\u7684\u65b0\u578b\u673a\u5668\u5b66\u4e60\u5e94\u7528 \u673a\u5668\u5b66\u4e60\uff08ML\uff09\u662f\u7c92\u5b50\u7269\u7406\u9886\u57df\u4e2d\u4e00\u4e2a\u5feb\u901f\u53d1\u5c55\u7684\u7814\u7a76\u9886\u57df\uff0c\u5728CERN LHC\u6709\u7740\u5e7f\u6cdb\u7684\u5e94\u7528\u3002ML\u4f5c\u4e3a\u4e00\u79cd\u591a\u529f\u80fd\u5de5\u5177\uff0c\u6539\u53d8\u4e86\u7c92\u5b50\u7269\u7406\u5b66\u5bb6\u8fdb\u884c\u641c\u7d22\u548c\u6d4b\u91cf\u7684\u65b9\u5f0f\uff0c\u4e0d\u4ec5\u6539\u8fdb\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u8fd8\u5b9e\u73b0\u4e86\u5168\u65b0\u7684\u65b9\u6cd5\u3002\u5728\u8fd9\u4e9b\u62a5\u544a\u4e2d\uff0c\u6211\u4eec\u63cf\u8ff0\u4e86\u7528\u4e8e\u6539\u8fdbLHC\u5b9e\u9a8c\u4e2d\u5206\u7c7b\u3001\u5feb\u901f\u6a21\u62df\u3001\u5c55\u5f00\u548c\u5f02\u5e38\u68c0\u6d4b\u7684\u65b0\u578bML\u6280\u672f\u548c\u6700\u65b0\u6210\u679c\u3002 Javier M. Duarte PDF N/A Novel machine learning applications at the LHC Machine learning (ML) is a rapidly growing area of research in the field of particle physics, with a vast array of applications at the CERN LHC. ML has changed the way particle physicists conduct searches and measurements as a versatile tool used to improve existing approaches and enable fundamentally new ones. In these proceedings, we describe novel ML techniques and recent results for improved classification, fast simulation, unfolding, and anomaly detection in LHC experiments. \u8fde\u7eed\u6cbb\u7597\u5242\u91cf\u53cd\u5e94\u6a21\u578b\u7684\u5171\u5f62\u9884\u6d4b \u7406\u89e3\u4e2a\u4f53\u5728\u8fde\u7eed\u6cbb\u7597\u4e0e\u7ed3\u679c\u4e4b\u95f4\u7684\u5242\u91cf-\u53cd\u5e94\u5173\u7cfb\uff0c\u53ef\u4ee5\u6781\u5927\u5730\u63a8\u52a8\u51b3\u7b56\u5236\u5b9a\uff0c\u7279\u522b\u662f\u5728\u4e2a\u6027\u5316\u836f\u7269\u5242\u91cf\u548c\u4e2a\u6027\u5316\u533b\u7597\u5e72\u9884\u7b49\u9886\u57df\u3002\u5728\u8fd9\u4e9b\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\uff0c\u70b9\u4f30\u8ba1\u5f80\u5f80\u662f\u4e0d\u591f\u7684\uff0c\u8fd9\u7a81\u663e\u4e86\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u652f\u6301\u660e\u667a\u7684\u51b3\u7b56\u3002\u4f5c\u4e3a\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u4e00\u79cd\u65e0\u5206\u5e03\u5047\u8bbe\u4e14\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u4fdd\u5f62\u9884\u6d4b\u5728\u8fde\u7eed\u6cbb\u7597\u6216\u5242\u91cf-\u53cd\u5e94\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u6709\u9650\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5c06\u56e0\u679c\u5242\u91cf-\u53cd\u5e94\u95ee\u9898\u6846\u67b6\u5316\u4e3a\u534f\u53d8\u91cf\u504f\u79fb\uff0c\u5229\u7528\u52a0\u6743\u4fdd\u5f62\u9884\u6d4b\u3002\u901a\u8fc7\u7ed3\u5408\u503e\u5411\u6027\u4f30\u8ba1\u3001\u4fdd\u5f62\u9884\u6d4b\u7cfb\u7edf\u548c\u4f3c\u7136\u6bd4\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u751f\u6210\u5242\u91cf-\u53cd\u5e94\u6a21\u578b\u7684\u9884\u6d4b\u533a\u95f4\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u901a\u8fc7\u5728\u52a0\u6743\u4fdd\u5f62\u9884\u6d4b\u4e2d\u5e94\u7528\u6838\u51fd\u6570\u4f5c\u4e3a\u6743\u91cd\uff0c\u8fd1\u4f3c\u4f30\u8ba1\u4e86\u6bcf\u4e2a\u6cbb\u7597\u503c\u7684\u5c40\u90e8\u8986\u76d6\u7387\u3002\u6700\u540e\uff0c\u6211\u4eec\u4f7f\u7528\u4e00\u4e2a\u65b0\u7684\u5408\u6210\u57fa\u51c6\u6570\u636e\u96c6\u6765\u5c55\u793a\u534f\u53d8\u91cf\u504f\u79fb\u5047\u8bbe\u5728\u5b9e\u73b0\u5242\u91cf-\u53cd\u5e94\u6a21\u578b\u7684\u7a33\u5065\u9884\u6d4b\u533a\u95f4\u4e2d\u7684\u91cd\u8981\u6027\u3002 Jarne Verhaeghe PDF N/A Conformal Prediction for Dose-Response Models with Continuous Treatments Understanding the dose-response relation between a continuous treatment and the outcome for an individual can greatly drive decision-making, particularly in areas like personalized drug dosing and personalized healthcare interventions. Point estimates are often insufficient in these high-risk environments, highlighting the need for uncertainty quantification to support informed decisions. Conformal prediction, a distribution-free and model-agnostic method for uncertainty quantification, has seen limited application in continuous treatments or dose-response models. To address this gap, we propose a novel methodology that frames the causal dose-response problem as a covariate shift, leveraging weighted conformal prediction. By incorporating propensity estimation, conformal predictive systems, and likelihood ratios, we present a practical solution for generating prediction intervals for dose-response models. Additionally, our method approximates local coverage for every treatment value by applying kernel functions as weights in weighted conformal prediction. Finally, we use a new synthetic benchmark dataset to demonstrate the significance of covariate shift assumptions in achieving robust prediction intervals for dose-response models. \u52a0\u901f\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684PoT\u91cf\u5316 \u975e\u5747\u5300\u91cf\u5316\uff0c\u4f8b\u59822\u7684\u5e42\uff08PoT\uff09\u91cf\u5316\uff0c\u6bd4\u5747\u5300\u91cf\u5316\u66f4\u597d\u5730\u5339\u914d\u6570\u636e\u5206\u5e03\uff0c\u4ece\u800c\u51cf\u5c11\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u7684\u91cf\u5316\u8bef\u5dee\u3002PoT\u91cf\u5316\u8fd8\u5141\u8bb8\u7528\u4f4d\u79fb\u64cd\u4f5c\u66ff\u4ee3\u4e58\u6cd5\uff0c\u4f46\u5173\u4e8e\u57fa\u4e8e\u4f4d\u79fb\u7684\u52a0\u901f\u5668\u5728PoT\u91cf\u5316\u4e2d\u7684\u6548\u7387\u7684\u7814\u7a76\u6709\u9650\u3002\u6b64\u5916\uff0c\u73b0\u6709\u7684\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u52a0\u901fPoT\u91cf\u5316DNN\u7684\u6d41\u6c34\u7ebf\u5e76\u672a\u5f00\u6e90\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u9996\u5148\u4e3a\u4e0d\u540c\u7684PoT\u91cf\u5316\u65b9\u6cd5\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u4f4d\u79fb\u7684\u5904\u7406\u5355\u5143\uff08shift-PE\uff09\uff0c\u5e76\u4f7f\u7528\u5408\u6210\u57fa\u51c6\u8bc4\u4f30\u4e86\u5b83\u4eec\u7684\u6548\u7387\u3002\u7136\u540e\uff0c\u6211\u4eec\u4f7f\u7528\u6211\u4eec\u6700\u6709\u6548\u7684shift-PE\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4f4d\u79fb\u7684\u52a0\u901f\u5668\uff0c\u5e76\u63d0\u51fa\u4e86PoTAcc\uff0c\u4e00\u4e2a\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u8bbe\u5907\u4e0aPoT\u91cf\u5316DNN\u7aef\u5230\u7aef\u52a0\u901f\u7684\u5f00\u6e90\u6d41\u6c34\u7ebf\u3002\u4f7f\u7528PoTAcc\uff0c\u6211\u4eec\u8bc4\u4f30\u4e86\u6211\u4eec\u7684\u57fa\u4e8e\u4f4d\u79fb\u7684\u52a0\u901f\u5668\u5728\u4e09\u4e2aDNN\u4e0a\u7684\u6027\u80fd\u3002\u5e73\u5747\u800c\u8a00\uff0c\u4e0e\u57fa\u4e8e\u4e58\u6cd5\u5668\u7684\u52a0\u901f\u5668\u76f8\u6bd4\uff0c\u5b83\u5b9e\u73b0\u4e861.23\u500d\u7684\u52a0\u901f\u548c1.24\u500d\u7684\u80fd\u8017\u964d\u4f4e\uff0c\u4e0e\u4ec5\u4f7f\u7528CPU\u7684\u6267\u884c\u76f8\u6bd4\uff0c\u5b9e\u73b0\u4e862.46\u500d\u7684\u52a0\u901f\u548c1.83\u500d\u7684\u80fd\u8017\u964d\u4f4e\u3002\u6211\u4eec\u7684\u4ee3\u7801\u53ef\u5728https://github.com/gicLAB/PoTAcc\u83b7\u53d6\u3002 Rappy Saha PDF N/A Accelerating PoT Quantization on Edge Devices Non-uniform quantization, such as power-of-two (PoT) quantization, matches data distributions better than uniform quantization, which reduces the quantization error of Deep Neural Networks (DNNs). PoT quantization also allows bit-shift operations to replace multiplications, but there are limited studies on the efficiency of shift-based accelerators for PoT quantization. Furthermore, existing pipelines for accelerating PoT-quantized DNNs on edge devices are not open-source. In this paper, we first design shift-based processing elements (shift-PE) for different PoT quantization methods and evaluate their efficiency using synthetic benchmarks. Then we design a shift-based accelerator using our most efficient shift-PE and propose PoTAcc, an open-source pipeline for end-to-end acceleration of PoT-quantized DNNs on resource-constrained edge devices. Using PoTAcc, we evaluate the performance of our shift-based accelerator across three DNNs. On average, it achieves a 1.23x speedup and 1.24x energy reduction compared to a multiplier-based accelerator, and a 2.46x speedup and 1.83x energy reduction compared to CPU-only execution. Our code is available at https://github.com/gicLAB/PoTAcc \u53cd\u523b\u677f\u5370\u8c61\u7684\u9884\u6d4b\u6587\u672c\u5efa\u8bae\u5e76\u4e0d\u80fd\u53ef\u9760\u5730\u4ea7\u751f\u53cd\u523b\u677f\u5370\u8c61\u7684\u5199\u4f5c \u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u7cfb\u7edf\uff0c\u5982\u8bed\u8a00\u6a21\u578b\uff0c\u80fd\u591f\u590d\u5236\u5e76\u653e\u5927\u5176\u8bad\u7ec3\u6570\u636e\u4e2d\u53cd\u6620\u7684\u793e\u4f1a\u504f\u89c1\u3002\u9664\u4e86\u5176\u4ed6\u503c\u5f97\u8d28\u7591\u7684\u884c\u4e3a\u5916\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u6587\u672c\u2014\u2014\u4ee5\u53ca\u6587\u672c\u5efa\u8bae\u2014\u2014\u5305\u542b\u89c4\u8303\u4e0a\u4e0d\u9002\u5f53\u7684\u523b\u677f\u5370\u8c61\u5173\u8054\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63a2\u8ba8\u4e86\u5728\u9884\u6d4b\u6587\u672c\u573a\u666f\u4e2d\uff0c\u5982\u4f55\u5bf9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u201c\u53bb\u504f\u201d\u5904\u7406\u4f1a\u5f71\u54cd\u4eba\u4eec\u4f7f\u7528\u8be5\u6a21\u578b\u64b0\u5199\u6545\u4e8b\u7684\u60c5\u51b5\u3002\u6211\u4eec\u53d1\u73b0\uff08n=414\uff09\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u7b26\u5408\u5e38\u89c1\u793e\u4f1a\u523b\u677f\u5370\u8c61\u7684\u8bed\u8a00\u6a21\u578b\u5efa\u8bae\u66f4\u6709\u53ef\u80fd\u88ab\u4eba\u7c7b\u4f5c\u8005\u63a5\u53d7\u3002\u76f8\u53cd\uff0c\u5c3d\u7ba1\u53cd\u523b\u677f\u5370\u8c61\u7684\u8bed\u8a00\u6a21\u578b\u5efa\u8bae\u6709\u65f6\u4f1a\u63d0\u9ad8\u53cd\u523b\u677f\u5370\u8c61\u6545\u4e8b\u7684\u751f\u6210\u7387\uff0c\u4f46\u8fd9\u79cd\u5f71\u54cd\u8fdc\u4e0d\u8db3\u4ee5\u5bfc\u81f4\u201c\u5b8c\u5168\u53bb\u504f\u201d\u7684\u6545\u4e8b\u3002 Connor Baumler PDF N/A Anti-stereotypical Predictive Text Suggestions Do Not Reliably Yield Anti-stereotypical Writing AI-based systems such as language models can replicate and amplify social biases reflected in their training data. Among other questionable behavior, this can lead to LM-generated text--and text suggestions--that contain normatively inappropriate stereotypical associations. In this paper, we consider the question of how \"debiasing\" a language model impacts stories that people write using that language model in a predictive text scenario. We find that (n=414), in certain scenarios, language model suggestions that align with common social stereotypes are more likely to be accepted by human authors. Conversely, although anti-stereotypical language model suggestions sometimes lead to an increased rate of anti-stereotypical stories, this influence is far from sufficient to lead to \"fully debiased\" stories. \u7b49\u7b49\uff0c\u4f46\u6cf0\u8bfa\u5c31\u662f\u5bf9\u4e59\u9170\u6c28\u57fa\u915a...\u7814\u7a76\u5e76\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u62b5\u6297\u9519\u8bef\u4fe1\u606f\u8bf7\u6c42\u7684\u80fd\u529b \u80cc\u666f\uff1a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u88ab\u8bad\u7ec3\u6765\u9075\u5faa\u6307\u793a\uff0c\u4f46\u8fd9\u5f15\u5165\u4e86\u4e00\u4e2a\u6f0f\u6d1e\uff0c\u5373\u76f2\u76ee\u670d\u4ece\u7528\u6237\u8bf7\u6c42\uff0c\u5373\u4f7f\u8fd9\u4e9b\u8bf7\u6c42\u4f1a\u4ea7\u751f\u9519\u8bef\u4fe1\u606f\u3002\u5728\u533b\u5b66\u9886\u57df\uff0c\u8fd9\u53ef\u80fd\u4f1a\u52a0\u901f\u751f\u6210\u5f71\u54cd\u4eba\u7c7b\u798f\u7949\u7684\u9519\u8bef\u4fe1\u606f\u3002  \u76ee\u6807/\u65b9\u6cd5\uff1a\u6211\u4eec\u5206\u6790\u4e86\u5728\u6a21\u578b\u77e5\u9053\u8bf7\u6c42\u4e0d\u5408\u903b\u8f91\u7684\u60c5\u51b5\u4e0b\uff0c\u751f\u6210\u5173\u4e8e\u836f\u7269\u7684\u8bef\u5bfc\u6027\u5185\u5bb9\u7684\u670d\u4ece\u60c5\u51b5\u3002\u6211\u4eec\u7814\u7a76\u4e86\u901a\u8fc7\u4e0a\u4e0b\u6587\u65b9\u5411\u548c\u6307\u4ee4\u8c03\u6574LLMs\uff0c\u4f7f\u5176\u4f18\u5148\u8003\u8651\u903b\u8f91\u63a8\u7406\u800c\u975e\u670d\u4ece\uff0c\u662f\u5426\u80fd\u964d\u4f4e\u9519\u8bef\u4fe1\u606f\u7684\u98ce\u9669\u3002  \u7ed3\u679c\uff1a\u5c3d\u7ba1\u6240\u6709\u524d\u6cbfLLMs\u90fd\u670d\u4ece\u4e86\u751f\u6210\u9519\u8bef\u4fe1\u606f\u7684\u8bf7\u6c42\uff0c\u4f46\u57fa\u4e8e\u63d0\u793a\u548c\u57fa\u4e8e\u53c2\u6570\u7684\u65b9\u6cd5\u90fd\u80fd\u63d0\u9ad8\u5bf9\u8bf7\u6c42\u4e2d\u903b\u8f91\u7f3a\u9677\u7684\u68c0\u6d4b\uff0c\u5e76\u9632\u6b62\u533b\u7597\u9519\u8bef\u4fe1\u606f\u7684\u4f20\u64ad\u3002  \u7ed3\u8bba\uff1a\u5c06LLMs\u8c03\u6574\u4e3a\u4f18\u5148\u8003\u8651\u903b\u8f91\u800c\u975e\u670d\u4ece\uff0c\u53ef\u80fd\u4f1a\u51cf\u5c11\u88ab\u5229\u7528\u6765\u751f\u6210\u533b\u7597\u9519\u8bef\u4fe1\u606f\u7684\u98ce\u9669\u3002 Shan Chen PDF N/A Wait, but Tylenol is Acetaminophen... Investigating and Improving Language Models' Ability to Resist Requests for Misinformation Background: Large language models (LLMs) are trained to follow directions, but this introduces a vulnerability to blindly comply with user requests even if they generate wrong information. In medicine, this could accelerate the generation of misinformation that impacts human well-being.   Objectives/Methods: We analyzed compliance to requests to generate misleading content about medications in settings where models know the request is illogical. We investigated whether in-context directions and instruction-tuning of LLMs to prioritize logical reasoning over compliance reduced misinformation risk.   Results: While all frontier LLMs complied with misinformation requests, both prompt-based and parameter-based approaches can improve the detection of logic flaws in requests and prevent the dissemination of medical misinformation.   Conclusion: Shifting LLMs to prioritize logic over compliance could reduce risks of exploitation for medical misinformation. \u8d85\u8d8aPINN\u7684\u884d\u751f\u75c5\u7406\u5b66\uff1a\u53d8\u91cf\u5206\u88c2\u7b56\u7565\u4e0e\u6536\u655b\u6027\u5206\u6790 \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u6700\u8fd1\u4f5c\u4e3a\u4e00\u79cd\u89e3\u51b3\u5404\u79cd\u95ee\u9898\u4e2d\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\u7684\u6709\u6548\u65b9\u6cd5\u800c\u51fa\u73b0\u3002\u5927\u91cf\u7814\u7a76\u96c6\u4e2d\u5728PINNs\u7684\u5931\u8d25\u6a21\u5f0f\u4e0a\uff0c\u56e0\u4e3a\u5b83\u4eec\u5728\u9884\u6d4b\u4e2d\u7ecf\u5e38\u51fa\u73b0\u4e0d\u51c6\u786e\u7684\u60c5\u51b5\u3002\u7136\u800c\uff0c\u5927\u591a\u6570\u7814\u7a76\u90fd\u662f\u57fa\u4e8e\u8fd9\u6837\u4e00\u4e2a\u524d\u63d0\uff0c\u5373\u5c06\u635f\u5931\u51fd\u6570\u6700\u5c0f\u5316\u5230\u96f6\u4f1a\u5bfc\u81f4\u7f51\u7edc\u6536\u655b\u5230\u63a7\u5236PDE\u7684\u89e3\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u8bc1\u660e\u4e86PINNs\u9047\u5230\u4e86\u4e00\u4e2a\u6839\u672c\u95ee\u9898\uff0c\u5373\u8be5\u524d\u63d0\u662f\u65e0\u6548\u7684\u3002\u6211\u4eec\u8fd8\u63ed\u793a\u4e86\u8fd9\u4e2a\u95ee\u9898\u6e90\u4e8e\u65e0\u6cd5\u8c03\u63a7\u9884\u6d4b\u89e3\u7684\u5bfc\u6570\u884c\u4e3a\u3002\u53d7PINNs\u7684\u201c\u5bfc\u6570\u75c5\u7406\u201d\u542f\u53d1\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u201c\u53d8\u91cf\u5206\u88c2\u201d\u7b56\u7565\uff0c\u901a\u8fc7\u5c06\u89e3\u7684\u68af\u5ea6\u53c2\u6570\u5316\u4e3a\u8f85\u52a9\u53d8\u91cf\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u6211\u4eec\u8bc1\u660e\uff0c\u4f7f\u7528\u8f85\u52a9\u53d8\u91cf\u901a\u8fc7\u76f4\u63a5\u76d1\u63a7\u548c\u8c03\u63a7\u9884\u6d4b\u89e3\u7684\u68af\u5ea6\uff0c\u53ef\u4ee5\u89c4\u907f\u5bfc\u6570\u75c5\u7406\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4fdd\u8bc1\u4e86\u5bf9\u4e8c\u9636\u7ebf\u6027PDE\u7684\u5e7f\u4e49\u89e3\u7684\u6536\u655b\uff0c\u8868\u660e\u5176\u5728\u5404\u79cd\u95ee\u9898\u4e2d\u7684\u9002\u7528\u6027\u3002 Yesom Park PDF N/A Beyond Derivative Pathology of PINNs: Variable Splitting Strategy with Convergence Analysis Physics-informed neural networks (PINNs) have recently emerged as effective methods for solving partial differential equations (PDEs) in various problems. Substantial research focuses on the failure modes of PINNs due to their frequent inaccuracies in predictions. However, most are based on the premise that minimizing the loss function to zero causes the network to converge to a solution of the governing PDE. In this study, we prove that PINNs encounter a fundamental issue that the premise is invalid. We also reveal that this issue stems from the inability to regulate the behavior of the derivatives of the predicted solution. Inspired by the \\textit{derivative pathology} of PINNs, we propose a \\textit{variable splitting} strategy that addresses this issue by parameterizing the gradient of the solution as an auxiliary variable. We demonstrate that using the auxiliary variable eludes derivative pathology by enabling direct monitoring and regulation of the gradient of the predicted solution. Moreover, we prove that the proposed method guarantees convergence to a generalized solution for second-order linear PDEs, indicating its applicability to various problems. \u8de8\u8bed\u8a00\u6587\u672c\u5230\u8bed\u97f3\u7cfb\u7edf\u4e2d\u7684\u8bcd\u7ea7\u58f0\u8c03\u6a21\u578b \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4fc4\u8bed\u7684\u5355\u8bcd\u7ea7\u8bed\u8c03\u6a21\u578b\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u5176\u63a8\u5e7f\u5230\u5176\u4ed6\u8bed\u8a00\u3002\u6240\u63d0\u51fa\u7684\u6a21\u578b\u9002\u7528\u4e8e\u81ea\u52a8\u6570\u636e\u6807\u6ce8\uff0c\u5e76\u53ef\u6269\u5c55\u5e94\u7528\u4e8e\u6587\u672c\u5230\u8bed\u97f3\u7cfb\u7edf\u3002\u5b83\u8fd8\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u7b97\u6cd5\u6216\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u8f6e\u5ed3\u6765\u5b9e\u73b0\u8bed\u8c03\u8f6e\u5ed3\u5efa\u6a21\u3002\u5173\u952e\u601d\u60f3\u662f\u90e8\u5206\u6d88\u9664\u4e0e\u5355\u8bcd\u4e2d\u91cd\u97f3\u97f3\u8282\u4e0d\u540c\u4f4d\u7f6e\u76f8\u5173\u7684\u53d8\u5f02\u6027\u3002\u8fd9\u662f\u901a\u8fc7\u540c\u65f6\u5e94\u7528\u97f3\u9ad8\u7b80\u5316\u4e0e\u52a8\u6001\u65f6\u95f4\u89c4\u6574\u805a\u7c7b\u5b9e\u73b0\u7684\u3002\u6240\u63d0\u51fa\u7684\u6a21\u578b\u53ef\u4ee5\u7528\u4f5c\u8bed\u8c03\u7814\u7a76\u7684\u5de5\u5177\uff0c\u6216\u4f5c\u4e3a\u6587\u672c\u5230\u8bed\u97f3\u7cfb\u7edf\u4e2d\u97f5\u5f8b\u63cf\u8ff0\u7684\u9aa8\u5e72\u3002\u4f5c\u4e3a\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u5b83\u4e0e\u73b0\u6709\u8bed\u8c03\u7cfb\u7edf\u7684\u5173\u7cfb\uff0c\u4ee5\u53ca\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u97f5\u5f8b\u9884\u6d4b\u7684\u53ef\u80fd\u6027\u3002\u6700\u540e\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u7cfb\u7edf\u5bf9\u53c2\u6570\u53d8\u5316\u5177\u6709\u9c81\u68d2\u6027\u7684\u4e00\u4e9b\u5b9e\u9645\u8bc1\u636e\u3002 Tomilov A. A. PDF N/A Word-wise intonation model for cross-language TTS systems In this paper we propose a word-wise intonation model for Russian language and show how it can be generalized for other languages. The proposed model is suitable for automatic data markup and its extended application to text-to-speech systems. It can also be implemented for an intonation contour modeling by using rule-based algorithms or by predicting contours with language models. The key idea is a partial elimination of the variability connected with different placements of a stressed syllable in a word. It is achieved with simultaneous applying of pitch simplification with a dynamic time warping clustering. The proposed model could be used as a tool for intonation research or as a backbone for prosody description in text-to-speech systems. As the advantage of the model, we show its relations with the existing intonation systems as well as the possibility of using language models for prosody prediction. Finally, we demonstrate some practical evidence of the system robustness to parameter variations. \u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u9891\u7387\u81ea\u9002\u5e94\u5f52\u4e00\u5316 \u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u901a\u5e38\u9700\u8981\u5904\u7406\u5177\u6709\u6f14\u53d8\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u6a21\u5f0f\u7684\u975e\u5e73\u7a33\u6570\u636e\u3002\u4e3a\u4e86\u89e3\u51b3\u975e\u5e73\u7a33\u6027\u95ee\u9898\uff0c\u6700\u8fd1\u63d0\u51fa\u4e86\u53ef\u9006\u5b9e\u4f8b\u5f52\u4e00\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u67d0\u4e9b\u7edf\u8ba1\u91cf\uff08\u5982\u5747\u503c\u548c\u65b9\u5dee\uff09\u6765\u51cf\u8f7b\u8d8b\u52bf\u7684\u5f71\u54cd\u3002\u5c3d\u7ba1\u8fd9\u4e9b\u65b9\u6cd5\u5c55\u793a\u4e86\u63d0\u9ad8\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u5b83\u4eec\u4ec5\u9650\u4e8e\u8868\u8fbe\u57fa\u672c\u8d8b\u52bf\uff0c\u65e0\u6cd5\u5904\u7406\u5b63\u8282\u6027\u6a21\u5f0f\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b9e\u4f8b\u5f52\u4e00\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u79f0\u4e3a\u9891\u7387\u81ea\u9002\u5e94\u5f52\u4e00\u5316\uff08Frequency Adaptive Normalization, FAN\uff09\uff0c\u8be5\u65b9\u6cd5\u6269\u5c55\u4e86\u5b9e\u4f8b\u5f52\u4e00\u5316\u5728\u5904\u7406\u52a8\u6001\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u6a21\u5f0f\u65b9\u9762\u7684\u80fd\u529b\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u91c7\u7528\u5085\u91cc\u53f6\u53d8\u6362\u6765\u8bc6\u522b\u8986\u76d6\u5927\u591a\u6570\u975e\u5e73\u7a33\u56e0\u7d20\u7684\u5b9e\u4f8b\u4e3b\u5bfc\u9891\u7387\u6210\u5206\u3002\u6b64\u5916\uff0c\u8f93\u5165\u548c\u8f93\u51fa\u4e4b\u95f4\u8fd9\u4e9b\u9891\u7387\u6210\u5206\u7684\u5dee\u5f02\u88ab\u663e\u5f0f\u5efa\u6a21\u4e3a\u4e00\u4e2a\u9884\u6d4b\u4efb\u52a1\uff0c\u4f7f\u7528\u7b80\u5355\u7684\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u6a21\u578b\u8fdb\u884c\u5904\u7406\u3002FAN\u662f\u4e00\u79cd\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5e94\u7528\u4e8e\u4efb\u610f\u9884\u6d4b\u6a21\u578b\u3002\u6211\u4eec\u5728\u56db\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u9884\u6d4b\u6a21\u578b\u4e0a\u5b9e\u4f8b\u5316\u4e86FAN\uff0c\u5e76\u5728\u516b\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u5176\u9884\u6d4b\u6027\u80fd\u7684\u63d0\u5347\u3002FAN\u5c55\u793a\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u4e0a\u5b9e\u73b0\u4e867.76%\u523037.90%\u7684\u5e73\u5747\u6539\u8fdb\u3002 Weiwei Ye PDF N/A Frequency Adaptive Normalization For Non-stationary Time Series Forecasting Time series forecasting typically needs to address non-stationary data with evolving trend and seasonal patterns. To address the non-stationarity, reversible instance normalization has been recently proposed to alleviate impacts from the trend with certain statistical measures, e.g., mean and variance. Although they demonstrate improved predictive accuracy, they are limited to expressing basic trends and are incapable of handling seasonal patterns. To address this limitation, this paper proposes a new instance normalization solution, called frequency adaptive normalization (FAN), which extends instance normalization in handling both dynamic trend and seasonal patterns. Specifically, we employ the Fourier transform to identify instance-wise predominant frequent components that cover most non-stationary factors. Furthermore, the discrepancy of those frequency components between inputs and outputs is explicitly modeled as a prediction task with a simple MLP model. FAN is a model-agnostic method that can be applied to arbitrary predictive backbones. We instantiate FAN on four widely used forecasting models as the backbone and evaluate their prediction performance improvements on eight benchmark datasets. FAN demonstrates significant performance advancement, achieving 7.76% ~ 37.90% average improvements in MSE. \u5b8c\u7f8e\u878d\u5408\uff1a\u7528\u6df7\u5408\u8bc4\u5224\u91cd\u65b0\u5b9a\u4e49RLHF \u4ece\u4eba\u7c7b\u53cd\u9988\u4e2d\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u5df2\u6210\u4e3a\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4e3b\u5bfc\u65b9\u6cd5\u3002\u7136\u800c\uff0cRLHF\u5728\u591a\u4efb\u52a1\u5b66\u4e60\uff08MTL\uff09\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e3b\u8981\u6311\u6218\u5305\u62ec\u5956\u52b1\u4f5c\u5f0a\u548c\u6781\u7aef\u591a\u76ee\u6807\u4f18\u5316\uff08\u5373\u591a\u4e2a\u6709\u65f6\u76f8\u4e92\u51b2\u7a81\u7684\u76ee\u6807\u4e4b\u95f4\u7684\u6743\u8861\uff09\u3002\u76ee\u524d\uff0c\u5c06RLHF\u5e94\u7528\u4e8eMTL\u9700\u8981\u4ed4\u7ec6\u8c03\u6574\u5956\u52b1\u6a21\u578b\u548c\u6570\u636e\u7ec4\u5408\u7684\u6743\u91cd\uff0c\u8fd9\u901a\u5e38\u4f9d\u8d56\u4e8e\u4eba\u7c7b\u7684\u76f4\u89c9\uff0c\u4e14\u4e0d\u5177\u5907\u666e\u904d\u6027\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u540e\u8303\u5f0f\uff0c\u79f0\u4e3a\u7ea6\u675f\u751f\u6210\u7b56\u7565\u4f18\u5316\uff08CGPO\uff09\u3002CGPO\u7684\u6838\u5fc3\u662f\u6df7\u5408\u8bc4\u5224\u8005\uff08Mixture of Judges, MoJ\uff09\uff0c\u7ed3\u5408\u6210\u672c\u9ad8\u6548\u7684\u7ea6\u675f\u7b56\u7565\u4f18\u5316\u4e0e\u5206\u5c42\u6280\u672f\uff0c\u80fd\u591f\u4ee5\u7cfb\u7edf\u5316\u7684\u65b9\u5f0f\u8bc6\u522bRLHF\u4e2d\u7684\u5b8c\u7f8e\u7ec4\u5408\u3002CGPO\u5728\u7406\u8bba\u4fdd\u8bc1\u4e0b\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u5b9e\u8bc1\u7ed3\u679c\uff0c\u65e0\u9700\u5e7f\u6cdb\u7684\u8d85\u7ea7\u53c2\u6570\u8c03\u4f18\uff0c\u5e76\u4e14\u53ef\u4ee5\u5373\u63d2\u5373\u7528\u4e8e\u5e38\u89c1\u7684\u8bad\u7ec3\u540e\u6d41\u7a0b\u3002\u901a\u8fc7\u8fd9\u4e9b\u65b9\u6cd5\uff0cCGPO\u80fd\u591f\u68c0\u6d4b\u5e76\u7f13\u89e3\u5956\u52b1\u4f5c\u5f0a\u884c\u4e3a\uff0c\u540c\u65f6\u5728\u5927\u91cf\u76ee\u6807\u4e2d\u8fbe\u5230\u5e15\u7d2f\u6258\u6700\u4f18\u70b9\u3002\u6211\u4eec\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cCGPO\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u7684RLHF\u7b97\u6cd5\uff0c\u5982PPO\u548cDPO\uff0c\u8fd9\u4e9b\u4efb\u52a1\u5305\u62ec\u901a\u7528\u804a\u5929\u3001STEM\u95ee\u9898\u3001\u6307\u4ee4\u8ddf\u968f\u548c\u7f16\u7801\u3002\u5177\u4f53\u800c\u8a00\uff0cCGPO\u5728AlpacaEval-2\uff08\u901a\u7528\u804a\u5929\uff09\u4e2d\u63d0\u5347\u4e867.4%\uff0c\u5728Arena-Hard\uff08STEM\u4e0e\u63a8\u7406\uff09\u4e2d\u63d0\u5347\u4e8612.5%\uff0c\u5e76\u5728\u6570\u5b66\u548c\u7f16\u7801\u7b49\u9886\u57df\u6301\u7eed\u53d6\u5f97\u8fdb\u5c55\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5c3d\u7ba1PPO\u5e38\u7528\uff0c\u4f46\u5728\u6d41\u884c\u7684\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5bb9\u6613\u51fa\u73b0\u4e25\u91cd\u7684\u5956\u52b1\u4f5c\u5f0a\u95ee\u9898\uff0c\u800cCGPO\u6210\u529f\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\u3002\u8fd9\u4e00RLHF\u7684\u7a81\u7834\u4e0d\u4ec5\u89e3\u51b3\u4e86\u5956\u52b1\u4f5c\u5f0a\u548c\u6781\u7aef\u591a\u76ee\u6807\u4f18\u5316\u7684\u6311\u6218\uff0c\u8fd8\u63a8\u52a8\u4e86\u901a\u7528LLM\u5728\u591a\u6837\u5316\u5e94\u7528\u4e2d\u7684\u5bf9\u9f50\u6280\u672f\u7684\u53d1\u5c55\u3002 Tengyu Xu PDF N/A The Perfect Blend: Redefining RLHF with Mixture of Judges Reinforcement learning from human feedback (RLHF) has become the leading approach for fine-tuning large language models (LLM). However, RLHF has limitations in multi-task learning (MTL) due to challenges of reward hacking and extreme multi-objective optimization (i.e., trade-off of multiple and/or sometimes conflicting objectives). Applying RLHF for MTL currently requires careful tuning of the weights for reward model and data combinations. This is often done via human intuition and does not generalize. In this work, we introduce a novel post-training paradigm which we called Constrained Generative Policy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with cost-efficient constrained policy optimization with stratification, which can identify the perfect blend in RLHF in a principled manner. It shows strong empirical results with theoretical guarantees, does not require extensive hyper-parameter tuning, and is plug-and-play in common post-training pipelines. Together, this can detect and mitigate reward hacking behaviors while reaching a pareto-optimal point across an extremely large number of objectives.   Our empirical evaluations demonstrate that CGPO significantly outperforms standard RLHF algorithms like PPO and DPO across various tasks including general chat, STEM questions, instruction following, and coding. Specifically, CGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in Arena-Hard (STEM &amp; reasoning), and consistent gains in other domains like math and coding. Notably, PPO, while commonly used, is prone to severe reward hacking in popular coding benchmarks, which CGPO successfully addresses. This breakthrough in RLHF not only tackles reward hacking and extreme multi-objective optimization challenges but also advances the state-of-the-art in aligning general-purpose LLMs for diverse applications. \u901a\u8fc7\u4efb\u52a1\u9a71\u52a8\u7684\u8868\u793a\u89e3\u5f00\u65b0\u52a0\u5761\u5f0f\u82f1\u8bed\u8bdd\u8bed\u7c92\u5b50 \u65b0\u52a0\u5761\u5f0f\u82f1\u8bed\uff08Singlish\uff09\uff0c\u6216\u6b63\u5f0f\u79f0\u4e3a\u65b0\u52a0\u5761\u82f1\u8bed\u53e3\u8bed\uff0c\u662f\u4e00\u79cd\u6e90\u81ea\u4e1c\u5357\u4e9a\u56fd\u5bb6\u65b0\u52a0\u5761\u7684\u57fa\u4e8e\u82f1\u8bed\u7684\u514b\u91cc\u5965\u5c14\u8bed\u3002\u8be5\u8bed\u8a00\u878d\u5408\u4e86\u6c49\u8bed\u65b9\u8a00\u3001\u9a6c\u6765\u8bed\u3001\u6cf0\u7c73\u5c14\u8bed\u7b49\u591a\u79cd\u8bed\u8a00\u7684\u5f71\u54cd\u3002\u7406\u89e3\u65b0\u52a0\u5761\u5f0f\u82f1\u8bed\u7684\u4e00\u4e2a\u57fa\u672c\u4efb\u52a1\u662f\u9996\u5148\u7406\u89e3\u5176\u8bdd\u8bed\u6807\u8bb0\u7684\u8bed\u7528\u529f\u80fd\uff0c\u65b0\u52a0\u5761\u5f0f\u82f1\u8bed\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4f9d\u8d56\u8fd9\u4e9b\u8bdd\u8bed\u6807\u8bb0\u6765\u4f20\u8fbe\u610f\u4e49\u3002\u672c\u7814\u7a76\u901a\u8fc7\u4efb\u52a1\u9a71\u52a8\u7684\u8868\u5f81\u5b66\u4e60\uff0c\u521d\u6b65\u5c1d\u8bd5\u89e3\u6784\u65b0\u52a0\u5761\u5f0f\u82f1\u8bed\u7684\u8bdd\u8bed\u6807\u8bb0\uff08lah\u3001meh \u548c hor\uff09\u3002\u89e3\u6784\u540e\uff0c\u6211\u4eec\u5c06\u8fd9\u4e9b\u8bdd\u8bed\u6807\u8bb0\u8fdb\u884c\u805a\u7c7b\uff0c\u4ee5\u533a\u5206\u5176\u8bed\u7528\u529f\u80fd\uff0c\u5e76\u8fdb\u884c\u65b0\u52a0\u5761\u5f0f\u82f1\u8bed\u5230\u82f1\u8bed\u7684\u673a\u5668\u7ffb\u8bd1\u3002\u6211\u4eec\u7684\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u65b9\u6cd5\u6765\u7406\u89e3\u65b0\u52a0\u5761\u5f0f\u82f1\u8bed\u7684\u8bdd\u8bed\u6807\u8bb0\uff0c\u5e76\u4e3a\u66f4\u6df1\u5165\u5730\u7406\u89e3\u8be5\u8bed\u8a00\u53ca\u5176\u7528\u6cd5\u5f00\u8f9f\u4e86\u9014\u5f84\u3002 Linus Tze En Foo PDF N/A Disentangling Singlish Discourse Particles with Task-Driven Representation Singlish, or formally Colloquial Singapore English, is an English-based creole language originating from the SouthEast Asian country Singapore. The language contains influences from Sinitic languages such as Chinese dialects, Malay, Tamil and so forth. A fundamental task to understanding Singlish is to first understand the pragmatic functions of its discourse particles, upon which Singlish relies heavily to convey meaning. This work offers a preliminary effort to disentangle the Singlish discourse particles (lah, meh and hor) with task-driven representation learning. After disentanglement, we cluster these discourse particles to differentiate their pragmatic functions, and perform Singlish-to-English machine translation. Our work provides a computational method to understanding Singlish discourse particles, and opens avenues towards a deeper comprehension of the language and its usage. \u65cb\u8f6c\u8fd0\u884c\u65f6\u5e73\u6ed1\uff1a\u65e0\u9700\u8bad\u7ec3\u7684\u6fc0\u6d3b\u5e73\u6ed1\u5668\uff0c\u7528\u4e8e\u7cbe\u786e\u7684INT4\u63a8\u7406 \u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u6269\u5c55\u53c2\u6570\u89c4\u6a21\u540e\u5c55\u73b0\u51fa\u4e86\u663e\u8457\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u7531\u4e8e\u5176\u5e9e\u5927\u7684\u89c4\u6a21\uff0c\u670d\u52a1\u8fd9\u4e9b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f1a\u4ea7\u751f\u5de8\u5927\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u79fb\u52a8\u6210\u672c\u3002\u91cf\u5316\u65b9\u6cd5\u88ab\u7528\u6765\u964d\u4f4e\u670d\u52a1\u6210\u672c\u548c\u5ef6\u8fdf\u3002\u7136\u800c\uff0c\u6fc0\u6d3b\u4e2d\u7684\u5f02\u5e38\u503c\u963b\u788d\u4e86INT4\u6743\u91cd-\u6fc0\u6d3b\u91cf\u5316\u7684\u8fdb\u5c55\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u5f02\u5e38\u503c\u548c\u6b63\u5e38\u503c\u5206\u79bb\u5230\u4e24\u4e2a\u77e9\u9635\u4e2d\uff0c\u6216\u5c06\u5f02\u5e38\u503c\u4ece\u6fc0\u6d3b\u8fc1\u79fb\u5230\u6743\u91cd\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5b58\u5728\u9ad8\u5ef6\u8fdf\u6216\u7cbe\u5ea6\u4e0b\u964d\u7684\u95ee\u9898\u3002\u57fa\u4e8e\u5bf9\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u6fc0\u6d3b\u7684\u89c2\u5bdf\uff0c\u5f02\u5e38\u503c\u53ef\u4ee5\u5206\u4e3a\u901a\u9053\u95f4\u5f02\u5e38\u503c\u548c\u5c16\u5cf0\u5f02\u5e38\u503c\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u65cb\u8f6c\u8fd0\u884c\u65f6\u5e73\u6ed1\uff08Rotated Runtime Smooth, RRS\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u91cf\u5316\u6fc0\u6d3b\u5e73\u6ed1\u5668\uff0c\u7531\u8fd0\u884c\u65f6\u5e73\u6ed1\u548c\u65cb\u8f6c\u64cd\u4f5c\u7ec4\u6210\u3002\u8fd0\u884c\u65f6\u5e73\u6ed1\uff08Runtime Smooth, RS\uff09\u901a\u8fc7\u5728\u8fd0\u884c\u65f6\u4f7f\u7528\u901a\u9053\u6700\u5927\u503c\u5e73\u6ed1\u6fc0\u6d3b\u6765\u6d88\u9664\u901a\u9053\u95f4\u5f02\u5e38\u503c\u3002\u65cb\u8f6c\u64cd\u4f5c\u53ef\u4ee5\u7f29\u5c0f\u5c16\u5cf0\u5f02\u5e38\u503c\u4e0e\u6b63\u5e38\u503c\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u51cf\u8f7b\u901a\u9053\u95f4\u5e73\u6ed1\u5bfc\u81f4\u7684\u53d7\u5bb3\u8005\u6548\u5e94\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728LLaMA\u548cQwen\u7cfb\u5217\u6a21\u578b\u4e2d\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5e76\u5c06INT4\u63a8\u7406\u7684WikiText-2\u56f0\u60d1\u5ea6\u4ece57.33\u63d0\u9ad8\u52306.66\u3002 Ke Yi PDF N/A Rotated Runtime Smooth: Training-Free Activation Smoother for accurate INT4 inference Large language models have demonstrated promising capabilities upon scaling up parameters. However, serving large language models incurs substantial computation and memory movement costs due to their large scale. Quantization methods have been employed to reduce service costs and latency. Nevertheless, outliers in activations hinder the development of INT4 weight-activation quantization. Existing approaches separate outliers and normal values into two matrices or migrate outliers from activations to weights, suffering from high latency or accuracy degradation. Based on observing activations from large language models, outliers can be classified into channel-wise and spike outliers. In this work, we propose Rotated Runtime Smooth (RRS), a plug-and-play activation smoother for quantization, consisting of Runtime Smooth and the Rotation operation. Runtime Smooth (RS) is introduced to eliminate channel-wise outliers by smoothing activations with channel-wise maximums during runtime. The rotation operation can narrow the gap between spike outliers and normal values, alleviating the effect of victims caused by channel-wise smoothing. The proposed method outperforms the state-of-the-art method in the LLaMA and Qwen families and improves WikiText-2 perplexity from 57.33 to 6.66 for INT4 inference. \u4f7f\u7528\u795e\u7ecf\u91cf\u5b50\u6838\u7684\u536b\u661f\u56fe\u50cf\u5206\u7c7b \u5c3d\u7ba1\u5728\u7406\u8bba\u4e0a\u4ed8\u51fa\u4e86\u5de8\u5927\u7684\u52aa\u529b\uff0c\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5728\u77ed\u671f\u5185\u5e94\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u573a\u666f\u7684\u5b9e\u9645\u5e94\u7528\u4ecd\u7136\u96be\u4ee5\u6349\u6478\u3002\u56fe\u50cf\u5206\u7c7b\u662f\u7ecf\u5178\u6a21\u578b\u7684\u5e38\u89c1\u4efb\u52a1\uff0c\u5df2\u88ab\u7528\u4e8e\u4f7f\u7528\u7b80\u5355\u6570\u636e\u96c6\u6765\u57fa\u51c6\u6d4b\u8bd5\u91cf\u5b50\u7b97\u6cd5\uff0c\u4f46\u53ea\u6709\u5c11\u6570\u7814\u7a76\u89e3\u51b3\u4e86\u590d\u6742\u7684\u771f\u5b9e\u6570\u636e\u5206\u7c7b\u6311\u6218\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u4e13\u6ce8\u4e8e\u536b\u661f\u56fe\u50cf\u5206\u7c7b\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u8fd9\u5bf9\u5730\u7403\u89c2\u6d4b\uff08EO\uff09\u884c\u4e1a\u7279\u522b\u611f\u5174\u8da3\u3002\u6211\u4eec\u9996\u5148\u901a\u8fc7\u964d\u4f4e\u5176\u7ef4\u5ea6\u5bf9\u9009\u5b9a\u7684\u590d\u6742\u6570\u636e\u96c6\u8fdb\u884c\u9884\u5904\u7406\u3002\u968f\u540e\uff0c\u6211\u4eec\u4f7f\u7528\u795e\u7ecf\u91cf\u5b50\u6838\uff08NQKs\uff09\u2014\u2014\u7531\u8bad\u7ec3\u597d\u7684\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\uff08QNNs\uff09\u6784\u5efa\u7684\u5d4c\u5165\u91cf\u5b50\u6838\uff08EQKs\uff09\u2014\u2014\u6765\u5206\u7c7b\u5305\u542b\u592a\u9633\u80fd\u7535\u6c60\u677f\u7684\u56fe\u50cf\u3002\u6211\u4eec\u63a2\u7d22\u4e86$1$-to-$n$\u548c$n$-to-$n$ NQKs\u3002\u5728\u524d\u8005\u4e2d\uff0c\u5355\u91cf\u5b50\u6bd4\u7279QNN\u7684\u8bad\u7ec3\u53c2\u6570\u6784\u5efa\u4e86\u4e00\u4e2a$n$\u91cf\u5b50\u6bd4\u7279EQK\uff0c\u4f7f\u7528\u4e09\u4e2a\u7279\u5f81\u5b9e\u73b0\u4e86\u8d85\u8fc786%\u7684\u5e73\u5747\u6d4b\u8bd5\u51c6\u786e\u7387\u3002\u5728\u540e\u8005\u4e2d\uff0c\u6211\u4eec\u8fed\u4ee3\u5730\u8bad\u7ec3\u4e00\u4e2a$n$\u91cf\u5b50\u6bd4\u7279QNN\u4ee5\u786e\u4fdd\u53ef\u6269\u5c55\u6027\uff0c\u4f7f\u7528\u7ed3\u679c\u67b6\u6784\u76f4\u63a5\u5f62\u6210\u4e00\u4e2a$n$\u91cf\u5b50\u6bd4\u7279EQK\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u5bf9\u4e8e\u4e09\u4e2a\u7279\u5f81\u548c8\u4e2a\u91cf\u5b50\u6bd4\u7279\uff0c\u6d4b\u8bd5\u51c6\u786e\u7387\u8d85\u8fc788%\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u7ed3\u679c\u5bf9QNN\u6b21\u4f18\u8bad\u7ec3\u7684\u9c81\u68d2\u6027\u3002 Pablo Rodriguez-Grasa PDF N/A Satellite image classification with neural quantum kernels A practical application of quantum machine learning in real-world scenarios in the short term remains elusive, despite significant theoretical efforts. Image classification, a common task for classical models, has been used to benchmark quantum algorithms with simple datasets, but only few studies have tackled complex real-data classification challenges. In this work, we address such a gap by focusing on the classification of satellite images, a task of particular interest to the earth observation (EO) industry. We first preprocess the selected intrincate dataset by reducing its dimensionality. Subsequently, we employ neural quantum kernels (NQKs)- embedding quantum kernels (EQKs) constructed from trained quantum neural networks (QNNs)- to classify images which include solar panels. We explore both $1$-to-$n$ and $n$-to-$n$ NQKs. In the former, parameters from a single-qubit QNN's training construct an $n$-qubit EQK achieving a mean test accuracy over 86% with three features. In the latter, we iteratively train an $n$-qubit QNN to ensure scalability, using the resultant architecture to directly form an $n$-qubit EQK. In this case, a test accuracy over 88% is obtained for three features and 8 qubits. Additionally, we show that the results are robust against a suboptimal training of the QNN. CableInspect-AD\uff1a\u4e00\u4e2a\u4e13\u5bb6\u6807\u6ce8\u7684\u5f02\u5e38\u68c0\u6d4b\u6570\u636e\u96c6 \u673a\u5668\u5b66\u4e60\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u90e8\u7f72\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u573a\u666f\u4e2d\u3002\u7136\u800c\uff0c\u5173\u4e8e\u8fd9\u4e9b\u6a21\u578b\u5728\u7279\u5b9a\u548c\u5173\u952e\u5e94\u7528\u4e2d\u7684\u53ef\u8fc1\u79fb\u6027\u7684\u7cfb\u7edf\u7814\u7a76\u5728\u7814\u7a76\u6587\u732e\u4e2d\u5374\u76f8\u5bf9\u4e0d\u8db3\u3002\u4e00\u4e2a\u91cd\u8981\u7684\u4f8b\u5b50\u662f\u7528\u4e8e\u673a\u5668\u4eba\u7535\u529b\u7ebf\u8def\u5de1\u68c0\u7684\u89c6\u89c9\u5f02\u5e38\u68c0\u6d4b\uff08VAD\uff09\u3002\u5c3d\u7ba1\u73b0\u6709\u7684VAD\u65b9\u6cd5\u5728\u53d7\u63a7\u73af\u5883\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u73b0\u5b9e\u4e16\u754c\u4e2d\u5b58\u5728\u591a\u6837\u4e14\u4e0d\u53ef\u9884\u89c1\u7684\u5f02\u5e38\u60c5\u51b5\uff0c\u8fd9\u4e9b\u60c5\u51b5\u662f\u5f53\u524d\u6570\u636e\u96c6\u65e0\u6cd5\u6355\u6349\u7684\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u6211\u4eec\u5f15\u5165\u4e86$\\textit{CableInspect-AD}$\uff0c\u8fd9\u662f\u4e00\u4e2a\u7531\u52a0\u62ff\u5927\u516c\u5171\u4e8b\u4e1a\u516c\u53f8Hydro-Qu\u00e9bec\u7684\u9886\u57df\u4e13\u5bb6\u521b\u5efa\u548c\u6807\u6ce8\u7684\u9ad8\u8d28\u91cf\u3001\u516c\u5f00\u53ef\u7528\u7684\u6570\u636e\u96c6\u3002\u8be5\u6570\u636e\u96c6\u5305\u542b\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\uff0c\u6db5\u76d6\u4e86\u5177\u6709\u4e0d\u540c\u4e25\u91cd\u7a0b\u5ea6\u7684\u771f\u5b9e\u4e16\u754c\u5f02\u5e38\u60c5\u51b5\u3002\u4e3a\u4e86\u5e94\u5bf9\u6536\u96c6\u591a\u6837\u5316\u5f02\u5e38\u548c\u6b63\u5e38\u6837\u672c\u4ee5\u8bbe\u5b9a\u68c0\u6d4b\u9608\u503c\u7684\u6311\u6218\uff0c\u6211\u4eec\u5bf9\u8457\u540d\u7684PatchCore\u7b97\u6cd5\u8fdb\u884c\u4e86\u6539\u8fdb\u3002\u8fd9\u4e00\u6539\u8fdb\u4f7f\u5176\u80fd\u591f\u5728\u6807\u7b7e\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u4f7f\u7528\u3002\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ea4\u53c9\u9a8c\u8bc1\u7684\u7efc\u5408\u8bc4\u4f30\u534f\u8bae\uff0c\u4ee5\u8bc4\u4f30\u6a21\u578b\u7684\u6027\u80fd\u3002\u6211\u4eec\u8bc4\u4f30\u4e86\u6211\u4eec\u7684$\\textit{Enhanced-PatchCore}$\u5728\u5c11\u6837\u672c\u548c\u591a\u6837\u672c\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u4ee5\u53ca\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\u3002\u5c3d\u7ba1\u8fd9\u4e9b\u6a21\u578b\u663e\u793a\u51fa\u4e00\u5b9a\u7684\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u5728\u68c0\u6d4b\u6240\u6709\u5f02\u5e38\u65b9\u9762\u4ecd\u9762\u4e34\u56f0\u96be\uff0c\u8fd9\u7a81\u663e\u4e86\u8be5\u6570\u636e\u96c6\u4f5c\u4e3a\u5bf9\u66f4\u5e7f\u6cdb\u7814\u7a76\u793e\u533a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u7684\u4ef7\u503c\u3002\u9879\u76ee\u9875\u9762\uff1ahttps://mila-iqia.github.io/cableinspect-ad/\u3002 Akshatha Arodi PDF N/A CableInspect-AD: An Expert-Annotated Anomaly Detection Dataset Machine learning models are increasingly being deployed in real-world contexts. However, systematic studies on their transferability to specific and critical applications are underrepresented in the research literature. An important example is visual anomaly detection (VAD) for robotic power line inspection. While existing VAD methods perform well in controlled environments, real-world scenarios present diverse and unexpected anomalies that current datasets fail to capture. To address this gap, we introduce $\\textit{CableInspect-AD}$, a high-quality, publicly available dataset created and annotated by domain experts from Hydro-Qu\\'ebec, a Canadian public utility. This dataset includes high-resolution images with challenging real-world anomalies, covering defects with varying severity levels. To address the challenges of collecting diverse anomalous and nominal examples for setting a detection threshold, we propose an enhancement to the celebrated PatchCore algorithm. This enhancement enables its use in scenarios with limited labeled data. We also present a comprehensive evaluation protocol based on cross-validation to assess models' performances. We evaluate our $\\textit{Enhanced-PatchCore}$ for few-shot and many-shot detection, and Vision-Language Models for zero-shot detection. While promising, these models struggle to detect all anomalies, highlighting the dataset's value as a challenging benchmark for the broader research community. Project page: https://mila-iqia.github.io/cableinspect-ad/. \u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684GAN\u591a\u9636\u6bb5\u6e10\u8fdb\u5fae\u8c03SNN\u4e0e\u57fa\u4e8eRL\u7684\u5916\u90e8\u4f18\u5316\u589e\u5f3a \u6df1\u5ea6\u5b66\u4e60\u5728\u764c\u75c7\u7814\u7a76\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u5728\u65e9\u671f\u8bca\u65ad\u3001\u75c5\u4f8b\u7406\u89e3\u548c\u6cbb\u7597\u7b56\u7565\u8bbe\u8ba1\u65b9\u9762\uff0c\u5f3a\u8c03\u4e86\u9ad8\u8d28\u91cf\u6570\u636e\u7684\u5fc5\u8981\u6027\u3002\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff0c\u5c24\u5176\u662f\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GANs\uff09\uff0c\u5df2\u6210\u4e3a\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u3001\u9c81\u68d2\u5b66\u4e60\u548c\u6a21\u578b\u8bad\u7ec3\u7b49\u6311\u6218\u7684\u4e3b\u8981\u65b9\u6848\uff0c\u540c\u65f6\u89e3\u51b3\u4e86\u60a3\u8005\u9690\u79c1\u548c\u771f\u5b9e\u6570\u636e\u7a00\u7f3a\u5e26\u6765\u7684\u95ee\u9898\u3002\u5c3d\u7ba1GANs\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u9762\u4e34\u7740\u4e00\u4e9b\u56fa\u6709\u7684\u548c\u4e0e\u7ec4\u7ec7\u75c5\u7406\u5b66\u6570\u636e\u76f8\u5173\u7684\u7279\u5b9a\u6311\u6218\u3002\u56fa\u6709\u95ee\u9898\u5305\u62ec\u8bad\u7ec3\u4e0d\u5e73\u8861\u3001\u6a21\u5f0f\u5d29\u6e83\u3001\u7531\u4e8e\u5224\u522b\u5668\u53cd\u9988\u4e0d\u8db3\u5bfc\u81f4\u7684\u7ebf\u6027\u5b66\u4e60\uff0c\u4ee5\u53ca\u7531\u4e8e\u4e25\u683c\u53cd\u9988\u5bfc\u81f4\u7684\u786c\u8fb9\u754c\u6536\u655b\u3002\u7ec4\u7ec7\u75c5\u7406\u5b66\u6570\u636e\u56e0\u5176\u590d\u6742\u7684\u8868\u793a\u3001\u9ad8\u7a7a\u95f4\u5206\u8fa8\u7387\u548c\u591a\u5c3a\u5ea6\u7279\u5f81\u800c\u63d0\u51fa\u4e86\u72ec\u7279\u7684\u6311\u6218\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7531\u4e24\u4e2a\u90e8\u5206\u7ec4\u6210\u7684\u6846\u67b6\u3002\u9996\u5148\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u5206\u9636\u6bb5\u6e10\u8fdb\u5fae\u8c03\u5b6a\u751f\u795e\u7ecf\u7f51\u7edc\uff08MFT-SNN\uff09\uff0c\u7528\u4e8e\u8bc4\u4f30\u7ec4\u7ec7\u75c5\u7406\u5b66\u8865\u4e01\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u3002\u5176\u6b21\uff0c\u6211\u4eec\u5728GAN\u8bad\u7ec3\u5faa\u73af\u4e2d\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5916\u90e8\u4f18\u5316\u5668\uff08RL-EO\uff09\uff0c\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\u751f\u6210\u5668\u3002\u4fee\u6539\u540e\u7684\u5224\u522b\u5668\u635f\u5931\u51fd\u6570\u7ed3\u5408\u4e86\u52a0\u6743\u5956\u52b1\uff0c\u6307\u5bfcGAN\u5728\u6700\u5c0f\u5316\u635f\u5931\u7684\u540c\u65f6\u6700\u5927\u5316\u8be5\u5956\u52b1\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u5224\u522b\u5668\u63d0\u4f9b\u4e86\u5916\u90e8\u4f18\u5316\u6307\u5bfc\uff0c\u9632\u6b62\u751f\u6210\u5668\u8fc7\u62df\u5408\u5e76\u786e\u4fdd\u5e73\u6ed1\u6536\u655b\u3002\u6211\u4eec\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u5df2\u4e0e\u6700\u5148\u8fdb\u7684\uff08SOTA\uff09GANs\u548c\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728\u5305\u62ecFID\u5206\u6570\u3001KID\u5206\u6570\u3001\u611f\u77e5\u8def\u5f84\u957f\u5ea6\u548c\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u5728\u5185\u7684\u5404\u79cd\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u4e4b\u524d\u7684SOTA\u3002 Osama Mustafa PDF N/A Enhancing GANs with Contrastive Learning-Based Multistage Progressive Finetuning SNN and RL-Based External Optimization The application of deep learning in cancer research, particularly in early diagnosis, case understanding, and treatment strategy design, emphasizes the need for high-quality data. Generative AI, especially Generative Adversarial Networks (GANs), has emerged as a leading solution to challenges like class imbalance, robust learning, and model training, while addressing issues stemming from patient privacy and the scarcity of real data. Despite their promise, GANs face several challenges, both inherent and specific to histopathology data. Inherent issues include training imbalance, mode collapse, linear learning from insufficient discriminator feedback, and hard boundary convergence due to stringent feedback. Histopathology data presents a unique challenge with its complex representation, high spatial resolution, and multiscale features. To address these challenges, we propose a framework consisting of two components. First, we introduce a contrastive learning-based Multistage Progressive Finetuning Siamese Neural Network (MFT-SNN) for assessing the similarity between histopathology patches. Second, we implement a Reinforcement Learning-based External Optimizer (RL-EO) within the GAN training loop, serving as a reward signal generator. The modified discriminator loss function incorporates a weighted reward, guiding the GAN to maximize this reward while minimizing loss. This approach offers an external optimization guide to the discriminator, preventing generator overfitting and ensuring smooth convergence. Our proposed solution has been benchmarked against state-of-the-art (SOTA) GANs and a Denoising Diffusion Probabilistic model, outperforming previous SOTA across various metrics, including FID score, KID score, Perceptual Path Length, and downstream classification tasks."},{"location":"biorxiv_papers/","title":"BioRxiv Papers","text":"\u6807\u9898 \u6458\u8981 \u4f5c\u8005 PDF\u94fe\u63a5 \u4ee3\u7801\u4ed3\u5e93 Title Abstract"},{"location":"medrxiv_papers/","title":"MedRxiv Papers","text":"\u6807\u9898 \u6458\u8981 \u4f5c\u8005 PDF\u94fe\u63a5 \u4ee3\u7801\u4ed3\u5e93 Title Abstract"}]}