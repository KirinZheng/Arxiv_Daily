{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Arxiv Daily","text":"<p>DeepSeek\uff0c\u4f60\u8bb0\u4e00\u4e0b\u6211\u505a\u5982\u4e0b\u90e8\u7f72 -- 101</p>"},{"location":"arxiv_papers/","title":"Arxiv Papers","text":"\u6807\u9898 \u6458\u8981 \u4f5c\u8005 PDF\u94fe\u63a5 \u4ee3\u7801\u4ed3\u5e93 Title Abstract \u8de8\u8d8a\u60c5\u8282\u4e0e\u8bed\u4e49\uff1a\u4e00\u79cd\u7406\u89e3\u957f\u7bc7\u89c6\u9891\u7684\u65b0\u6846\u67b6 \u5c3d\u7ba1\u73b0\u6709\u7814\u7a76\u5f80\u5f80\u5c06\u957f\u89c6\u9891\u89c6\u4e3a\u6269\u5c55\u7684\u77ed\u89c6\u9891\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u66f4\u51c6\u786e\u5730\u53cd\u6620\u4e86\u4eba\u7c7b\u8ba4\u77e5\u3002\u672c\u6587\u4ecb\u7ecd\u4e86BREASE\uff1a\u7528\u4e8e\u957f\u89c6\u9891\u7406\u89e3\u7684\u6865\u63a5\u5267\u96c6\u4e0e\u8bed\u4e49\uff0c\u8be5\u6a21\u578b\u6a21\u62df\u4e86\u60c5\u666f\u8bb0\u5fc6\u7684\u79ef\u7d2f\uff0c\u4ee5\u6355\u6349\u52a8\u4f5c\u5e8f\u5217\uff0c\u5e76\u901a\u8fc7\u5206\u6563\u5728\u6574\u4e2a\u89c6\u9891\u4e2d\u7684\u8bed\u4e49\u77e5\u8bc6\u5bf9\u5176\u8fdb\u884c\u5f3a\u5316\u3002\u6211\u4eec\u7684\u5de5\u4f5c\u505a\u51fa\u4e86\u4e24\u4e2a\u5173\u952e\u8d21\u732e\uff1a\u9996\u5148\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u60c5\u666f\u538b\u7f29\u5668\uff08ECO\uff09\uff0c\u80fd\u591f\u4ece\u5fae\u89c2\u5230\u534a\u5b8f\u89c2\u5c42\u9762\u9ad8\u6548\u5730\u805a\u5408\u5173\u952e\u8868\u5f81\u3002\u5176\u6b21\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u68c0\u7d22\u5668\uff08SeTR\uff09\uff0c\u901a\u8fc7\u5173\u6ce8\u66f4\u5e7f\u6cdb\u7684\u4e0a\u4e0b\u6587\uff0c\u7528\u8bed\u4e49\u4fe1\u606f\u589e\u5f3a\u8fd9\u4e9b\u805a\u5408\u8868\u5f81\uff0c\u663e\u8457\u964d\u4f4e\u7279\u5f81\u7ef4\u5ea6\uff0c\u540c\u65f6\u4fdd\u7559\u76f8\u5173\u7684\u5b8f\u89c2\u7ea7\u522b\u4fe1\u606f\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cBREASE\u5728\u96f6\u6837\u672c\u548c\u5b8c\u5168\u76d1\u7763\u8bbe\u7f6e\u4e0b\u7684\u591a\u4e2a\u957f\u89c6\u9891\u7406\u89e3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u9879\u76ee\u9875\u9762\u548c\u4ee3\u7801\u4f4d\u4e8e\uff1ahttps://joslefaure.github.io/assets/html/hermes.html\u3002 Gueter Josmy Faure PDF N/A Bridging Episodes and Semantics: A Novel Framework for Long-Form Video Understanding While existing research often treats long-form videos as extended short videos, we propose a novel approach that more accurately reflects human cognition. This paper introduces BREASE: BRidging Episodes And SEmantics for Long-Form Video Understanding, a model that simulates episodic memory accumulation to capture action sequences and reinforces them with semantic knowledge dispersed throughout the video. Our work makes two key contributions: First, we develop an Episodic COmpressor (ECO) that efficiently aggregates crucial representations from micro to semi-macro levels. Second, we propose a Semantics reTRiever (SeTR) that enhances these aggregated representations with semantic information by focusing on the broader context, dramatically reducing feature dimensionality while preserving relevant macro-level information. Extensive experiments demonstrate that BREASE achieves state-of-the-art performance across multiple long video understanding benchmarks in both zero-shot and fully-supervised settings. The project page and code are at: https://joslefaure.github.io/assets/html/hermes.html. SYNTHEVAL\uff1a\u7ed3\u5408\u5408\u6210\u68c0\u67e5\u6e05\u5355\u5bf9NLP\u6a21\u578b\u8fdb\u884c\u6df7\u5408\u884c\u4e3a\u6d4b\u8bd5 \u4f20\u7edf\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u57fa\u51c6\u6d4b\u8bd5\u901a\u5e38\u6d89\u53ca\u4f7f\u7528\u9759\u6001\u7684\u4fdd\u7559\u6d4b\u8bd5\u96c6\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5f80\u5f80\u5bfc\u81f4\u6027\u80fd\u7684\u9ad8\u4f30\uff0c\u5e76\u4e14\u7f3a\u4e4f\u63d0\u4f9b\u5168\u9762\u3001\u53ef\u89e3\u91ca\u548c\u52a8\u6001\u8bc4\u4f30NLP\u6a21\u578b\u7684\u80fd\u529b\u3002\u6700\u8fd1\uff0c\u50cfDynaBench\uff08Kiela\u7b49\u4eba\uff0c2021\uff09\u548cCheckList\uff08Ribeiro\u7b49\u4eba\uff0c2020\uff09\u8fd9\u6837\u7684\u5de5\u4f5c\u901a\u8fc7\u591a\u6b65\u9aa4\u4eba\u5de5\u6807\u6ce8\u6d41\u7a0b\u751f\u6210\u6d4b\u8bd5\u7c7b\u578b\uff0c\u5bf9NLP\u6a21\u578b\u8fdb\u884c\u884c\u4e3a\u6d4b\u8bd5\uff0c\u89e3\u51b3\u4e86\u8fd9\u4e9b\u5c40\u9650\u6027\u3002\u4e0d\u5e78\u7684\u662f\uff0c\u624b\u52a8\u521b\u5efa\u591a\u79cd\u6d4b\u8bd5\u7c7b\u578b\u9700\u8981\u5927\u91cf\u4eba\u529b\uff0c\u6210\u672c\u5f80\u5f80\u9ad8\u5f97\u4ee4\u4eba\u671b\u800c\u5374\u6b65\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86SYNTHEVAL\uff0c\u4e00\u4e2a\u6df7\u5408\u884c\u4e3a\u6d4b\u8bd5\u6846\u67b6\uff0c\u5b83\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u5e7f\u6cdb\u7684\u6d4b\u8bd5\u7c7b\u578b\uff0c\u4ee5\u5168\u9762\u8bc4\u4f30NLP\u6a21\u578b\u3002SYNTHEVAL\u9996\u5148\u901a\u8fc7LLMs\u4f7f\u7528\u53d7\u63a7\u751f\u6210\u751f\u6210\u53e5\u5b50\uff0c\u7136\u540e\u901a\u8fc7\u6bd4\u8f83LLMs\u4e0e\u7279\u5b9a\u4efb\u52a1NLP\u6a21\u578b\u7684\u9884\u6d4b\u6765\u8bc6\u522b\u5177\u6709\u6311\u6218\u6027\u7684\u793a\u4f8b\u3002\u5728\u6700\u540e\u9636\u6bb5\uff0c\u4eba\u7c7b\u4e13\u5bb6\u8c03\u67e5\u8fd9\u4e9b\u5177\u6709\u6311\u6218\u6027\u7684\u793a\u4f8b\uff0c\u624b\u52a8\u8bbe\u8ba1\u6a21\u677f\uff0c\u5e76\u8bc6\u522b\u7279\u5b9a\u4efb\u52a1\u6a21\u578b\u6301\u7eed\u8868\u73b0\u51fa\u7684\u5931\u8d25\u7c7b\u578b\u3002\u6211\u4eec\u5c06SYNTHEVAL\u5e94\u7528\u4e8e\u4e24\u4e2a\u5206\u7c7b\u4efb\u52a1\uff1a\u60c5\u611f\u5206\u6790\u548c\u6709\u6bd2\u8bed\u8a00\u68c0\u6d4b\uff0c\u5e76\u5c55\u793a\u4e86\u6211\u4eec\u7684\u6846\u67b6\u5728\u8bc6\u522b\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u5f3a\u5927\u6a21\u578b\u7684\u5f31\u70b9\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u6211\u4eec\u5728https://github.com/Loreley99/SynthEval_CheckList\u5206\u4eab\u4e86\u6211\u4eec\u7684\u4ee3\u7801\u3002 Raoyuan Zhao PDF N/A SYNTHEVAL: Hybrid Behavioral Testing of NLP Models with Synthetic CheckLists Traditional benchmarking in NLP typically involves using static held-out test sets. However, this approach often results in an overestimation of performance and lacks the ability to offer comprehensive, interpretable, and dynamic assessments of NLP models. Recently, works like DynaBench (Kiela et al., 2021) and CheckList (Ribeiro et al., 2020) have addressed these limitations through behavioral testing of NLP models with test types generated by a multistep human-annotated pipeline. Unfortunately, manually creating a variety of test types requires much human labor, often at prohibitive cost. In this work, we propose SYNTHEVAL, a hybrid behavioral testing framework that leverages large language models (LLMs) to generate a wide range of test types for a comprehensive evaluation of NLP models. SYNTHEVAL first generates sentences via LLMs using controlled generation, and then identifies challenging examples by comparing the predictions made by LLMs with task-specific NLP models. In the last stage, human experts investigate the challenging examples, manually design templates, and identify the types of failures the taskspecific models consistently exhibit. We apply SYNTHEVAL to two classification tasks, sentiment analysis and toxic language detection, and show that our framework is effective in identifying weaknesses of strong models on these tasks. We share our code in https://github.com/Loreley99/SynthEval_CheckList. SelectTTS\uff1a\u901a\u8fc7\u57fa\u4e8e\u79bb\u6563\u5355\u5143\u7684\u5e27\u9009\u62e9\u5408\u6210\u4efb\u4f55\u4eba\u7684\u58f0\u97f3 \u5408\u6210\u672a\u89c1\u8bf4\u8bdd\u8005\u7684\u58f0\u97f3\u662f\u591a\u8bf4\u8bdd\u8005\u6587\u672c\u5230\u8bed\u97f3\uff08TTS\uff09\u4e2d\u6301\u7eed\u5b58\u5728\u7684\u6311\u6218\u3002\u5927\u591a\u6570\u591a\u8bf4\u8bdd\u8005TTS\u6a21\u578b\u4f9d\u8d56\u4e8e\u5728\u8bad\u7ec3\u671f\u95f4\u901a\u8fc7\u8bf4\u8bdd\u8005\u8c03\u8282\u6765\u5efa\u6a21\u8bf4\u8bdd\u8005\u7279\u5f81\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\u5efa\u6a21\u672a\u89c1\u8bf4\u8bdd\u8005\u5c5e\u6027\u9700\u8981\u589e\u52a0\u6a21\u578b\u590d\u6742\u6027\uff0c\u8fd9\u4f7f\u5f97\u91cd\u73b0\u7ed3\u679c\u548c\u6539\u8fdb\u7ed3\u679c\u53d8\u5f97\u56f0\u96be\u3002\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u6211\u4eec\u63d0\u51fa\u4e86SelectTTS\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u4ece\u76ee\u6807\u8bf4\u8bdd\u8005\u4e2d\u9009\u62e9\u9002\u5f53\u7684\u5e27\uff0c\u5e76\u4f7f\u7528\u5e27\u7ea7\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u7279\u5f81\u8fdb\u884c\u89e3\u7801\u3002\u6211\u4eec\u5c55\u793a\u4e86\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u6355\u6349\u672a\u89c1\u8bf4\u8bdd\u8005\u7684\u8bf4\u8bdd\u8005\u7279\u5f81\uff0c\u5e76\u5728\u5ba2\u89c2\u548c\u4e3b\u89c2\u6307\u6807\u4e0a\u4e0e\u5176\u4ed6\u591a\u8bf4\u8bdd\u8005TTS\u6846\u67b6\u53d6\u5f97\u53ef\u6bd4\u7684\u7ed3\u679c\u3002\u901a\u8fc7SelectTTS\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u4ece\u76ee\u6807\u8bf4\u8bdd\u8005\u7684\u8bed\u97f3\u4e2d\u9009\u62e9\u5e27\u662f\u5b9e\u73b0\u672a\u89c1\u8bf4\u8bdd\u8005\u6cdb\u5316\u7684\u76f4\u63a5\u65b9\u5f0f\uff0c\u4e14\u6a21\u578b\u590d\u6742\u5ea6\u8f83\u4f4e\u3002\u6211\u4eec\u7684\u8bf4\u8bdd\u8005\u76f8\u4f3c\u6027\u6027\u80fd\u4f18\u4e8eSOTA\u57fa\u7ebfXTTS-v2\u548cVALL-E\uff0c\u6a21\u578b\u53c2\u6570\u51cf\u5c11\u4e868\u500d\u4ee5\u4e0a\uff0c\u8bad\u7ec3\u6570\u636e\u51cf\u5c11\u4e86270\u500d\u3002 Ismail Rasim Ulgen PDF N/A SelectTTS: Synthesizing Anyone's Voice via Discrete Unit-Based Frame Selection Synthesizing the voices of unseen speakers is a persisting challenge in multi-speaker text-to-speech (TTS). Most multi-speaker TTS models rely on modeling speaker characteristics through speaker conditioning during training. Modeling unseen speaker attributes through this approach has necessitated an increase in model complexity, which makes it challenging to reproduce results and improve upon them. We design a simple alternative to this. We propose SelectTTS, a novel method to select the appropriate frames from the target speaker and decode using frame-level self-supervised learning (SSL) features. We show that this approach can effectively capture speaker characteristics for unseen speakers, and achieves comparable results to other multi-speaker TTS frameworks in both objective and subjective metrics. With SelectTTS, we show that frame selection from the target speaker's speech is a direct way to achieve generalization in unseen speakers with low model complexity. We achieve better speaker similarity performance than SOTA baselines XTTS-v2 and VALL-E with over an 8x reduction in model parameters and a 270x reduction in training data CLOCR-C\uff1a\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e0a\u4e0b\u6587\u589e\u5f3a\u7684OCR\u6821\u6b63 \u5386\u53f2\u5370\u5237\u5a92\u4f53\u6863\u6848\u7684\u6570\u5b57\u5316\u5bf9\u4e8e\u63d0\u9ad8\u5f53\u4ee3\u8bb0\u5f55\u7684\u53ef\u8bbf\u95ee\u6027\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5c06\u5b9e\u4f53\u8bb0\u5f55\u8f6c\u6362\u4e3a\u6570\u5b57\u6587\u672c\u7684\u5149\u5b66\u5b57\u7b26\u8bc6\u522b\uff08OCR\uff09\u8fc7\u7a0b\u5bb9\u6613\u51fa\u9519\uff0c\u5c24\u5176\u662f\u62a5\u7eb8\u548c\u671f\u520a\u56e0\u5176\u590d\u6742\u7684\u7248\u9762\u8bbe\u8ba1\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u5229\u7528\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u8bed\u8a00\u6a21\u578b\uff08LMs\uff09\u7684\u586b\u8865\u548c\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u80fd\u529b\u6765\u63d0\u9ad8OCR\u8d28\u91cf\u7684\u4e0a\u4e0b\u6587\u5229\u7528OCR\u6821\u6b63\uff08CLOCR-C\uff09\u65b9\u6cd5\u3002\u7814\u7a76\u65e8\u5728\u786e\u5b9aLMs\u662f\u5426\u80fd\u591f\u6267\u884cOCR\u540e\u6821\u6b63\u3001\u6539\u5584\u4e0b\u6e38NLP\u4efb\u52a1\uff0c\u4ee5\u53ca\u5728\u4fee\u6b63\u8fc7\u7a0b\u4e2d\u63d0\u4f9b\u793e\u4f1a\u6587\u5316\u80cc\u666f\u7684\u4ef7\u503c\u3002\u5b9e\u9a8c\u4f7f\u7528\u4e86\u4e03\u79cdLMs\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\uff1a19\u4e16\u7eaa\u671f\u520a\u7248\uff08NCSE\uff09\u548cOverproof\u6536\u85cf\u7684\u4e24\u4e2a\u6570\u636e\u96c6\u3002\u7ed3\u679c\u663e\u793a\uff0c\u67d0\u4e9bLMs\u80fd\u591f\u663e\u8457\u964d\u4f4e\u9519\u8bef\u7387\uff0c\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\u5728NCSE\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8fc760%\u7684\u5b57\u7b26\u9519\u8bef\u7387\u964d\u4f4e\u3002OCR\u6539\u8fdb\u5ef6\u4f38\u81f3\u4e0b\u6e38\u4efb\u52a1\uff0c\u5982\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff0c\u63d0\u9ad8\u4e86\u4f59\u5f26\u547d\u540d\u5b9e\u4f53\u76f8\u4f3c\u5ea6\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8868\u660e\uff0c\u5728\u63d0\u793a\u4e2d\u63d0\u4f9b\u793e\u4f1a\u6587\u5316\u80cc\u666f\u53ef\u4ee5\u63d0\u5347\u6027\u80fd\uff0c\u800c\u8bef\u5bfc\u6027\u63d0\u793a\u5219\u4f1a\u964d\u4f4e\u6027\u80fd\u3002\u9664\u4e86\u8fd9\u4e9b\u53d1\u73b0\uff0c\u672c\u7814\u7a76\u8fd8\u53d1\u5e03\u4e86\u6765\u81eaNCSE\u768491\u7bc7\u8f6c\u5f55\u6587\u7ae0\u7684\u6570\u636e\u96c6\uff0c\u5171\u5305\u542b4\u4e07\u4e2a\u5355\u8bcd\uff0c\u4ee5\u652f\u6301\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cCLOCR-C\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528LMs\u4e2d\u5d4c\u5165\u7684\u793e\u4f1a\u6587\u5316\u4fe1\u606f\u548c\u9700\u8981\u6821\u6b63\u7684\u6587\u672c\uff0c\u53ef\u4ee5\u63d0\u9ad8\u73b0\u6709\u6570\u5b57\u6863\u6848\u7684\u8d28\u91cf\u3002 Jonathan Bourne PDF N/A CLOCR-C: Context Leveraging OCR Correction with Pre-trained Language Models The digitisation of historical print media archives is crucial for increasing accessibility to contemporary records. However, the process of Optical Character Recognition (OCR) used to convert physical records to digital text is prone to errors, particularly in the case of newspapers and periodicals due to their complex layouts. This paper introduces Context Leveraging OCR Correction (CLOCR-C), which utilises the infilling and context-adaptive abilities of transformer-based language models (LMs) to improve OCR quality. The study aims to determine if LMs can perform post-OCR correction, improve downstream NLP tasks, and the value of providing the socio-cultural context as part of the correction process. Experiments were conducted using seven LMs on three datasets: the 19th Century Serials Edition (NCSE) and two datasets from the Overproof collection. The results demonstrate that some LMs can significantly reduce error rates, with the top-performing model achieving over a 60% reduction in character error rate on the NCSE dataset. The OCR improvements extend to downstream tasks, such as Named Entity Recognition, with increased Cosine Named Entity Similarity. Furthermore, the study shows that providing socio-cultural context in the prompts improves performance, while misleading prompts lower performance. In addition to the findings, this study releases a dataset of 91 transcribed articles from the NCSE, containing a total of 40 thousand words, to support further research in this area. The findings suggest that CLOCR-C is a promising approach for enhancing the quality of existing digital archives by leveraging the socio-cultural information embedded in the LMs and the text requiring correction. \u516c\u5e73\u610f\u8bc6\u4e0b\u7684\u56fe\u5f62\u6a21\u578b\u4f30\u8ba1 \u672c\u6587\u63a2\u8ba8\u4e86\u56fe\u6a21\u578b\uff08GMs\uff09\u4f30\u8ba1\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5c24\u5176\u662f\u9ad8\u65af\u6a21\u578b\u3001\u534f\u65b9\u5dee\u6a21\u578b\u548c\u4f0a\u8f9b\u6a21\u578b\u3002\u8fd9\u4e9b\u6a21\u578b\u5728\u7406\u89e3\u9ad8\u7ef4\u6570\u636e\u4e2d\u7684\u590d\u6742\u5173\u7cfb\u65b9\u9762\u53d1\u6325\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\u3002\u7136\u800c\uff0c\u6807\u51c6\u7684\u56fe\u6a21\u578b\u53ef\u80fd\u4f1a\u5bfc\u81f4\u504f\u89c1\u7ed3\u679c\uff0c\u7279\u522b\u662f\u5728\u57fa\u7840\u6570\u636e\u6d89\u53ca\u654f\u611f\u7279\u5f81\u6216\u53d7\u4fdd\u62a4\u7fa4\u4f53\u65f6\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u6846\u67b6\uff0c\u65e8\u5728\u51cf\u5c11\u4e0e\u53d7\u4fdd\u62a4\u5c5e\u6027\u76f8\u5173\u7684\u56fe\u6a21\u578b\u4f30\u8ba1\u4e2d\u7684\u504f\u89c1\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u6d89\u53ca\u5c06\u6210\u5bf9\u56fe\u5dee\u5f02\u8bef\u5dee\u548c\u5b9a\u5236\u635f\u5931\u51fd\u6570\u6574\u5408\u5230\u4e00\u4e2a\u975e\u5149\u6ed1\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u4e2d\uff0c\u529b\u6c42\u5728\u4e0d\u540c\u654f\u611f\u7fa4\u4f53\u4e2d\u5b9e\u73b0\u516c\u5e73\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u56fe\u6a21\u578b\u7684\u6709\u6548\u6027\u3002\u5bf9\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u6211\u4eec\u7684\u6846\u67b6\u80fd\u6709\u6548\u51cf\u8f7b\u504f\u89c1\uff0c\u800c\u4e0d\u635f\u5bb3\u56fe\u6a21\u578b\u7684\u6027\u80fd\u3002 Zhuoping Zhou PDF N/A Fairness-Aware Estimation of Graphical Models This paper examines the issue of fairness in the estimation of graphical models (GMs), particularly Gaussian, Covariance, and Ising models. These models play a vital role in understanding complex relationships in high-dimensional data. However, standard GMs can result in biased outcomes, especially when the underlying data involves sensitive characteristics or protected groups. To address this, we introduce a comprehensive framework designed to reduce bias in the estimation of GMs related to protected attributes. Our approach involves the integration of the pairwise graph disparity error and a tailored loss function into a nonsmooth multi-objective optimization problem, striving to achieve fairness across different sensitive groups while maintaining the effectiveness of the GMs. Experimental evaluations on synthetic and real-world datasets demonstrate that our framework effectively mitigates bias without undermining GMs' performance. \u795e\u7ecf\u5207\u7ebf\u96c6\u5408\u7684\u6301\u7eed\u5b66\u4e60 \u6301\u7eed\u5b66\u4e60\u7684\u4e00\u79cd\u81ea\u7136\u7b56\u7565\u662f\u6743\u8861\u4e00\u7ec4\u56fa\u5b9a\u51fd\u6570\u7684\u8d1d\u53f6\u65af\u96c6\u6210\u3002\u8fd9\u8868\u660e\uff0c\u5982\u679c\u4e00\u4e2a\uff08\u5355\u4e00\u7684\uff09\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u88ab\u89e3\u91ca\u4e3a\u4e00\u4e2a\u96c6\u6210\uff0c\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u8bbe\u8ba1\u51fa\u4e0d\u9057\u5fd8\u7684\u6709\u6548\u5b66\u4e60\u7b97\u6cd5\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u53ef\u80fd\u6027\uff0c\u6211\u4eec\u89c2\u5bdf\u5230\uff0c\u5177\u6709N\u4e2a\u53c2\u6570\u7684\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u5668\u53ef\u4ee5\u88ab\u89e3\u91ca\u4e3aN\u4e2a\u5206\u7c7b\u5668\u7684\u52a0\u6743\u96c6\u6210\uff0c\u5e76\u4e14\u5728\u61d2\u60f0\u5b66\u4e60\u673a\u5236\u7684\u6781\u9650\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e9b\u5206\u7c7b\u5668\u5728\u6574\u4e2a\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u662f\u56fa\u5b9a\u7684\u3002\u6211\u4eec\u79f0\u8fd9\u4e9b\u5206\u7c7b\u5668\u4e3a\u795e\u7ecf\u5207\u7ebf\u4e13\u5bb6\uff0c\u5e76\u8bc1\u660e\u5b83\u4eec\u8f93\u51fa\u7684\u6807\u7b7e\u6982\u7387\u5206\u5e03\u662f\u6709\u6548\u7684\u3002\u7136\u540e\uff0c\u6211\u4eec\u63a8\u5bfc\u51fa\u7ed9\u5b9a\u8fc7\u53bb\u6570\u636e\u65f6\u6bcf\u4e2a\u4e13\u5bb6\u7684\u4f3c\u7136\u548c\u540e\u9a8c\u6982\u7387\u3002\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u6211\u4eec\u53d1\u73b0\u8fd9\u4e9b\u4e13\u5bb6\u7684\u540e\u9a8c\u66f4\u65b0\u7b49\u540c\u4e8e\u7f51\u7edc\u6743\u91cd\u4e0a\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u7684\u7f29\u653e\u548c\u6295\u5f71\u5f62\u5f0f\u3002\u5728\u8fdc\u79bb\u61d2\u60f0\u673a\u5236\u7684\u60c5\u51b5\u4e0b\uff0c\u7f51\u7edc\u53ef\u4ee5\u88ab\u89c6\u4e3a\u968f\u65f6\u95f4\u6539\u8fdb\u7684\u81ea\u9002\u5e94\u4e13\u5bb6\u7684\u96c6\u6210\u3002\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u91ca\uff0c\u5373\u4f5c\u4e3a\u4e13\u5bb6\u7684\u8d1d\u53f6\u65af\u96c6\u6210\uff0c\u4e3a\u7406\u89e3\u548c\u7f13\u89e3\u6301\u7eed\u5b66\u4e60\u73af\u5883\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u6846\u67b6\u3002 Ari S. Benjamin PDF N/A Continual learning with the neural tangent ensemble A natural strategy for continual learning is to weigh a Bayesian ensemble of fixed functions. This suggests that if a (single) neural network could be interpreted as an ensemble, one could design effective algorithms that learn without forgetting. To realize this possibility, we observe that a neural network classifier with N parameters can be interpreted as a weighted ensemble of N classifiers, and that in the lazy regime limit these classifiers are fixed throughout learning. We term these classifiers the neural tangent experts and show they output valid probability distributions over the labels. We then derive the likelihood and posterior probability of each expert given past data. Surprisingly, we learn that the posterior updates for these experts are equivalent to a scaled and projected form of stochastic gradient descent (SGD) over the network weights. Away from the lazy regime, networks can be seen as ensembles of adaptive experts which improve over time. These results offer a new interpretation of neural networks as Bayesian ensembles of experts, providing a principled framework for understanding and mitigating catastrophic forgetting in continual learning settings. \u975e\u51f8\u4e24\u9636\u6bb5\u968f\u673a\u4f18\u5316\u95ee\u9898\u7684\u8d1d\u53f6\u65af\u4f18\u5316 \u8d1d\u53f6\u65af\u4f18\u5316\u662f\u4e00\u79cd\u89e3\u51b3\u6602\u8d35\u3001\u9ed1\u7bb1\u4f18\u5316\u95ee\u9898\u7684\u6837\u672c\u9ad8\u6548\u65b9\u6cd5\u3002\u968f\u673a\u89c4\u5212\u5173\u6ce8\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u4f18\u5316\u95ee\u9898\uff0c\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u5e73\u5747\u6027\u80fd\u662f\u5173\u6ce8\u7684\u91cf\u3002\u5728\u4e24\u9636\u6bb5\u95ee\u9898\u7684\u7b2c\u4e00\u9636\u6bb5\uff0c\u5fc5\u987b\u5728\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u4e0b\u505a\u51fa\u5373\u523b\u51b3\u5b9a\uff0c\u800c\u5728\u7b2c\u4e8c\u9636\u6bb5\uff0c\u5219\u5728\u4e0d\u786e\u5b9a\u6027\u89e3\u51b3\u540e\u505a\u51fa\u89c2\u671b\u51b3\u5b9a\u3002\u8bb8\u591a\u968f\u673a\u89c4\u5212\u65b9\u6cd5\u5047\u8bbe\u76ee\u6807\u51fd\u6570\u7684\u8bc4\u4f30\u6210\u672c\u4f4e\u5ec9\u4e14\u4e3a\u7ebf\u6027\u6216\u51f8\u6027\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u5e94\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u6765\u89e3\u51b3\u8bc4\u4f30\u6210\u672c\u9ad8\u6602\u7684\u975e\u51f8\u4e24\u9636\u6bb5\u968f\u673a\u89c4\u5212\u95ee\u9898\u3002\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u68af\u5ea6\u7684\u91c7\u96c6\u51fd\u6570\u6765\u8054\u5408\u4f18\u5316\u7b2c\u4e00\u9636\u6bb5\u548c\u7b2c\u4e8c\u9636\u6bb5\u7684\u53d8\u91cf\uff0c\u786e\u7acb\u4e86\u6e10\u8fdb\u4e00\u81f4\u6027\u7684\u4fdd\u8bc1\uff0c\u5e76\u63d0\u4f9b\u4e86\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u8fd1\u4f3c\u65b9\u6cd5\u3002\u6211\u4eec\u5c55\u793a\u4e86\u4e0e\u53e6\u4e00\u79cd\u6211\u4eec\u6784\u5efa\u7684\u4ea4\u66ff\u5173\u6ce8\u4e24\u79cd\u53d8\u91cf\u7c7b\u578b\u7684\u65b9\u6cd5\u76f8\u6bd4\u62df\u7684\u7ecf\u9a8c\u7ed3\u679c\uff0c\u4ee5\u53ca\u4f18\u4e8e\u6807\u51c6\u3001\u6734\u7d20\u7684\u4e24\u6b65\u57fa\u51c6\u7684\u4f18\u8d8a\u7ecf\u9a8c\u7ed3\u679c\u3002\u6211\u4eec\u8868\u660e\uff0c\u53d8\u91cf\u7c7b\u578b\u4e4b\u95f4\u7684\u7ef4\u5ea6\u5dee\u5f02\u548c\u957f\u5ea6\u5c3a\u5ea6\u53ef\u80fd\u5bfc\u81f4\u4e24\u6b65\u7b97\u6cd5\u7684\u6548\u7387\u4f4e\u4e0b\uff0c\u800c\u8054\u5408\u548c\u4ea4\u66ff\u91c7\u96c6\u51fd\u6570\u5728\u6240\u6709\u6d4b\u8bd5\u95ee\u9898\u4e2d\u8868\u73b0\u826f\u597d\u3002\u5b9e\u9a8c\u5728\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u4e16\u754c\u793a\u4f8b\u4e0a\u8fdb\u884c\u3002 Jack M. Buckingham PDF N/A Bayesian Optimization for Non-Convex Two-Stage Stochastic Optimization Problems Bayesian optimization is a sample-efficient method for solving expensive, black-box optimization problems. Stochastic programming concerns optimization under uncertainty where, typically, average performance is the quantity of interest. In the first stage of a two-stage problem, here-and-now decisions must be made in the face of this uncertainty, while in the second stage, wait-and-see decisions are made after the uncertainty has been resolved. Many methods in stochastic programming assume that the objective is cheap to evaluate and linear or convex. In this work, we apply Bayesian optimization to solve non-convex, two-stage stochastic programs which are expensive to evaluate. We formulate a knowledge-gradient-based acquisition function to jointly optimize the first- and second-stage variables, establish a guarantee of asymptotic consistency and provide a computationally efficient approximation. We demonstrate comparable empirical results to an alternative we formulate which alternates its focus between the two variable types, and superior empirical results over the standard, naive, two-step benchmark. We show that differences in the dimension and length scales between the variable types can lead to inefficiencies of the two-step algorithm, while the joint and alternating acquisition functions perform well in all problems tested. Experiments are conducted on both synthetic and real-world examples. LASSO-MOGAT\uff1a\u4e00\u79cd\u7528\u4e8e\u764c\u75c7\u5206\u7c7b\u7684\u591a\u7ec4\u5b66\u56fe\u6ce8\u610f\u529b\u6846\u67b6 \u5c06\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5e94\u7528\u4e8e\u5206\u6790\u57fa\u56e0\u8868\u8fbe\u6a21\u5f0f\u7684\u53d8\u5316\uff0c\u6700\u8fd1\u5728\u764c\u75c7\u7814\u7a76\u4e2d\u5d2d\u9732\u5934\u89d2\uff0c\u6210\u4e3a\u4e00\u79cd\u5f3a\u5927\u7684\u7814\u7a76\u9014\u5f84\uff0c\u52a0\u6df1\u4e86\u6211\u4eec\u5bf9\u764c\u75c7\u53d1\u5c55\u548c\u8fdb\u5c55\u80cc\u540e\u5206\u5b50\u673a\u5236\u7684\u7406\u89e3\u3002\u7ed3\u5408\u57fa\u56e0\u8868\u8fbe\u6570\u636e\u4e0e\u5176\u4ed6\u7c7b\u578b\u7684\u7ec4\u5b66\u6570\u636e\uff0c\u5df2\u88ab\u4f17\u591a\u7814\u7a76\u8bc1\u5b9e\u80fd\u591f\u6539\u5584\u764c\u75c7\u5206\u7c7b\u7ed3\u679c\u3002\u5c3d\u7ba1\u53d6\u5f97\u4e86\u8fd9\u4e9b\u8fdb\u5c55\uff0c\u6709\u6548\u6574\u5408\u9ad8\u7ef4\u591a\u7ec4\u5b66\u6570\u636e\u5e76\u6355\u6349\u4e0d\u540c\u751f\u7269\u5c42\u9762\u95f4\u7684\u590d\u6742\u5173\u7cfb\u4ecd\u7136\u5145\u6ee1\u6311\u6218\u3002\u672c\u6587\u4ecb\u7ecd\u4e86LASSO-MOGAT\uff08LASSO-\u591a\u7ec4\u5b66\u95e8\u63a7\u6ce8\u610f\u529b\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u56fe\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u6574\u5408\u4e86\u4fe1\u4f7fRNA\u3001\u5fae\u5c0fRNA\u548cDNA\u7532\u57fa\u5316\u6570\u636e\uff0c\u7528\u4e8e\u5206\u7c7b31\u79cd\u764c\u75c7\u7c7b\u578b\u3002\u5229\u7528LIMMA\u8fdb\u884c\u5dee\u5f02\u8868\u8fbe\u5206\u6790\u548cLASSO\u56de\u5f52\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u5e76\u501f\u52a9\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\uff08GATs\uff09\u7eb3\u5165\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\uff08PPI\uff09\u7f51\u7edc\uff0cLASSO-MOGAT\u6709\u6548\u5730\u6355\u6349\u4e86\u591a\u7ec4\u5b66\u6570\u636e\u4e2d\u7684\u590d\u6742\u5173\u7cfb\u3002\u901a\u8fc7\u4e94\u6298\u4ea4\u53c9\u9a8c\u8bc1\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u7cbe\u786e\u6027\u3001\u53ef\u9760\u6027\u548c\u63d0\u4f9b\u764c\u75c7\u5206\u5b50\u673a\u5236\u5168\u9762\u6d1e\u5bdf\u7684\u80fd\u529b\u3002\u63d0\u51fa\u7684\u57fa\u4e8e\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u7684\u56fe\u6ce8\u610f\u529b\u67b6\u6784\u5bf9\u56fe\u4e2d\u8fb9\u8fdb\u884c\u6ce8\u610f\u529b\u7cfb\u6570\u7684\u8ba1\u7b97\uff0c\u8bc1\u5b9e\u4e86\u8fd9\u5bf9\u4e8e\u8bc6\u522b\u591a\u7ec4\u5b66\u6570\u636e\u4e2d\u764c\u75c7\u5206\u7c7b\u7684\u534f\u540c\u4f5c\u7528\u662f\u6709\u76ca\u7684\u3002 Fadi Alharbi PDF N/A LASSO-MOGAT: A Multi-Omics Graph Attention Framework for Cancer Classification The application of machine learning methods to analyze changes in gene expression patterns has recently emerged as a powerful approach in cancer research, enhancing our understanding of the molecular mechanisms underpinning cancer development and progression. Combining gene expression data with other types of omics data has been reported by numerous works to improve cancer classification outcomes. Despite these advances, effectively integrating high-dimensional multi-omics data and capturing the complex relationships across different biological layers remains challenging. This paper introduces LASSO-MOGAT (LASSO-Multi-Omics Gated ATtention), a novel graph-based deep learning framework that integrates messenger RNA, microRNA, and DNA methylation data to classify 31 cancer types. Utilizing differential expression analysis with LIMMA and LASSO regression for feature selection, and leveraging Graph Attention Networks (GATs) to incorporate protein-protein interaction (PPI) networks, LASSO-MOGAT effectively captures intricate relationships within multi-omics data. Experimental validation using five-fold cross-validation demonstrates the method's precision, reliability, and capacity for providing comprehensive insights into cancer molecular mechanisms. The computation of attention coefficients for the edges in the graph by the proposed graph-attention architecture based on protein-protein interactions proved beneficial for identifying synergies in multi-omics data for cancer classification. \u4f7f\u752810\u500d\u5c11\u5f97\u591a\u7684\u53c2\u6570\u8fdb\u884c\u66f4\u591a\u5fae\u8c03 \u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\uff08PEFT\uff09\u6280\u672f\u5df2\u7ecf\u91ca\u653e\u4e86\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u5ec9\u4ef7\u4e14\u6613\u4e8e\u4e13\u7528\u7684\u6f5c\u529b\u3002\u7136\u800c\uff0c\u6700\u7a81\u51fa\u7684\u65b9\u6cd5\uff0c\u5982\u4f4e\u79e9\u9002\u914d\u5668\uff08LoRA\uff09\uff0c\u4f9d\u8d56\u4e8e\u542f\u53d1\u5f0f\u6216\u7ecf\u9a8c\u6cd5\u5219\u6765\u505a\u51fa\u5176\u67b6\u6784\u9009\u62e9\u2014\u2014\u8fd9\u53ef\u80fd\u9650\u5236\u4e86\u5b83\u4eec\u5bf9\u4e8e\u65b0\u6a21\u578b\u548c\u67b6\u6784\u7684\u6027\u80fd\u3002\u8fd9\u4e00\u5c40\u9650\u6027\u8868\u660e\uff0c\u53ef\u4ee5\u5229\u7528\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u7684\u6280\u672f\u6765\u83b7\u5f97\u6700\u4f18\u7684\u9002\u914d\u5668\u67b6\u6784\uff0c\u4f46\u8fd9\u4e9b\u6280\u672f\u5f80\u5f80\u6210\u672c\u9ad8\u6602\u4e14\u96be\u4ee5\u5b9e\u65bd\u3002\u6211\u4eec\u901a\u8fc7Monarch\u77e9\u5f62\u5fae\u8c03\uff08MoRe\uff09\u8fd9\u4e00\u7b80\u5355\u6846\u67b6\u6765\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u8be5\u6846\u67b6\u4f9d\u8d56\u4e8eMonarch\u77e9\u9635\u7c7b\u522b\u6765\u641c\u7d22\u9002\u914d\u5668\u67b6\u6784\u3002\u7406\u8bba\u4e0a\uff0c\u6211\u4eec\u8bc1\u660e\u4e86MoRe\u6bd4LoRA\u66f4\u5177\u8868\u8fbe\u529b\u3002\u5b9e\u8bc1\u4e0a\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u5404\u79cd\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u6bd4\u6700\u5148\u8fdb\u7684PEFTs\u66f4\u52a0\u53c2\u6570\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\uff0c\u4ec5\u9700LoRA\u53c2\u6570\u76845%\u3002 Wenxuan Tan PDF N/A MoRe Fine-Tuning with 10x Fewer Parameters Parameter-efficient fine-tuning (PEFT) techniques have unlocked the potential to cheaply and easily specialize large pretrained models. However, the most prominent approaches, like low-rank adapters (LoRA), depend on heuristics or rules-of-thumb for their architectural choices -- potentially limiting their performance for new models and architectures. This limitation suggests that techniques from neural architecture search could be used to obtain optimal adapter architectures, but these are often expensive and difficult to implement. We address this challenge with Monarch Rectangular Fine-tuning (MoRe), a simple framework to search over adapter architectures that relies on the Monarch matrix class. Theoretically, we show that MoRe is more expressive than LoRA. Empirically, our approach is more parameter-efficient and performant than state-of-the-art PEFTs on a range of tasks and models, with as few as 5\\% of LoRA's parameters. \u4ea4\u901a\u4e13\u4e1a\u77e5\u8bc6\u9047\u4e0a\u6b8b\u5dee\u5f3a\u5316\u5b66\u4e60\uff1a\u57fa\u4e8e\u77e5\u8bc6\u7684\u6a21\u578b\u5316\u6b8b\u5dee\u5f3a\u5316\u5b66\u4e60\u5728CAV\u8f68\u8ff9\u63a7\u5236\u4e2d\u7684\u5e94\u7528 \u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u901a\u8fc7\u5229\u7528\u865a\u62df\u73af\u5883\u6a21\u578b\uff0c\u9884\u8ba1\u6bd4\u65e0\u6a21\u578bRL\u5c55\u73b0\u51fa\u66f4\u9ad8\u7684\u6837\u672c\u6548\u7387\u3002\u7136\u800c\uff0c\u7531\u4e8e\u590d\u6742\u7cfb\u7edf\u548c\u73af\u5883\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u83b7\u53d6\u8db3\u591f\u51c6\u786e\u7684\u73af\u5883\u52a8\u529b\u5b66\u8868\u793a\u662f\u5177\u6709\u6311\u6218\u6027\u7684\u3002\u4e0d\u51c6\u786e\u7684\u73af\u5883\u6a21\u578b\u53ef\u80fd\u4f1a\u964d\u4f4e\u57fa\u4e8e\u6a21\u578b\u7684RL\u7684\u6837\u672c\u6548\u7387\u548c\u6027\u80fd\u3002\u6b64\u5916\uff0c\u5c3d\u7ba1\u57fa\u4e8e\u6a21\u578b\u7684RL\u53ef\u4ee5\u63d0\u9ad8\u6837\u672c\u6548\u7387\uff0c\u4f46\u5b83\u901a\u5e38\u4ecd\u7136\u9700\u8981\u5927\u91cf\u7684\u8bad\u7ec3\u65f6\u95f4\u4ece\u5934\u5f00\u59cb\u5b66\u4e60\uff0c\u8fd9\u53ef\u80fd\u9650\u5236\u5176\u76f8\u5bf9\u4e8e\u65e0\u6a21\u578b\u65b9\u6cd5\u7684\u4f18\u52bf\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u672c\u6587\u5f15\u5165\u4e86\u4e00\u79cd\u77e5\u8bc6\u542f\u53d1\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u6b8b\u5dee\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u5c06\u5df2\u5efa\u7acb\u7684\u4e13\u5bb6\u77e5\u8bc6\u878d\u5165\u5b66\u4e60\u8fc7\u7a0b\u5e76\u907f\u514d\u4ece\u96f6\u5f00\u59cb\u7684\u95ee\u9898\uff0c\u6765\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5c06\u4ea4\u901a\u4e13\u5bb6\u77e5\u8bc6\u6574\u5408\u5230\u865a\u62df\u73af\u5883\u6a21\u578b\u4e2d\uff0c\u91c7\u7528\u667a\u80fd\u9a7e\u9a76\u5458\u6a21\u578b\uff08IDM\uff09\u4f5c\u4e3a\u57fa\u7840\u52a8\u529b\u5b66\uff0c\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u6b8b\u5dee\u52a8\u529b\u5b66\uff0c\u4ece\u800c\u786e\u4fdd\u9002\u5e94\u590d\u6742\u573a\u666f\u7684\u80fd\u529b\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\u4e0e\u6b8b\u5deeRL\u76f8\u7ed3\u5408\u7684\u65b0\u7b56\u7565\uff0c\u4fbf\u4e8e\u9ad8\u6548\u5b66\u4e60\u548c\u7b56\u7565\u4f18\u5316\uff0c\u65e0\u9700\u4ece\u5934\u5f00\u59cb\u5b66\u4e60\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5e94\u7528\u4e8eCAV\u8f68\u8ff9\u63a7\u5236\u4efb\u52a1\uff0c\u4ee5\u6d88\u6563\u6df7\u5408\u4ea4\u901a\u6d41\u4e2d\u7684\u505c\u8f66-\u542f\u52a8\u6ce2\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u63d0\u51fa\u7684\u65b9\u6cd5\u4f7fCAV\u4ee3\u7406\u5728\u8f68\u8ff9\u63a7\u5236\u65b9\u9762\u76f8\u5bf9\u4e8e\u57fa\u51c6\u4ee3\u7406\u5728\u6837\u672c\u6548\u7387\u3001\u4ea4\u901a\u6d41\u5e73\u6ed1\u5ea6\u548c\u4ea4\u901a\u6d41\u52a8\u6027\u65b9\u9762\u5b9e\u73b0\u4e86\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u3002\u6e90\u4ee3\u7801\u548c\u8865\u5145\u6750\u6599\u53ef\u5728https://github.com/zihaosheng/traffic-expertise-RL/\u83b7\u53d6\u3002 Zihao Sheng PDF N/A Traffic expertise meets residual RL: Knowledge-informed model-based residual reinforcement learning for CAV trajectory control Model-based reinforcement learning (RL) is anticipated to exhibit higher sample efficiency compared to model-free RL by utilizing a virtual environment model. However, it is challenging to obtain sufficiently accurate representations of the environmental dynamics due to uncertainties in complex systems and environments. An inaccurate environment model may degrade the sample efficiency and performance of model-based RL. Furthermore, while model-based RL can improve sample efficiency, it often still requires substantial training time to learn from scratch, potentially limiting its advantages over model-free approaches. To address these challenges, this paper introduces a knowledge-informed model-based residual reinforcement learning framework aimed at enhancing learning efficiency by infusing established expert knowledge into the learning process and avoiding the issue of beginning from zero. Our approach integrates traffic expert knowledge into a virtual environment model, employing the Intelligent Driver Model (IDM) for basic dynamics and neural networks for residual dynamics, thus ensuring adaptability to complex scenarios. We propose a novel strategy that combines traditional control methods with residual RL, facilitating efficient learning and policy optimization without the need to learn from scratch. The proposed approach is applied to CAV trajectory control tasks for the dissipation of stop-and-go waves in mixed traffic flow. Experimental results demonstrate that our proposed approach enables the CAV agent to achieve superior performance in trajectory control compared to the baseline agents in terms of sample efficiency, traffic flow smoothness and traffic mobility. The source code and supplementary materials are available at https://github.com/zihaosheng/traffic-expertise-RL/. NDP\uff1a\u4e0b\u4e00\u4e2a\u5206\u914d\u9884\u6d4b\u4f5c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u9776\u6807 \u7ecf\u8fc7\u5728\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\uff08NTP\uff09\u8303\u5f0f\u4e0a\u8bad\u7ec3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5df2\u7ecf\u5c55\u73b0\u51fa\u4e86\u5f3a\u5927\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684NTP\u8303\u5f0f\u5b58\u5728\u82e5\u5e72\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u8ba1\u5212\u4efb\u52a1\u590d\u6742\u6027\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\u4f20\u64ad\u65b9\u9762\u3002\u5728\u6211\u4eec\u7684\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u6269\u5c55\u4e86\u5bf9NTP\u7684\u6279\u8bc4\uff0c\u5f3a\u8c03\u5176\u5c40\u9650\u6027\u4e5f\u6e90\u4e8e\u8bad\u7ec3\u65f6\u91c7\u7528\u7684\u72ed\u7a84\u76ee\u6807\uff1a\u9884\u6d4b\u4e00\u4e2a\u6b21\u4f18\u7684\u4e00\u70ed\u5206\u5e03\u3002\u4e3a\u4e86\u652f\u6301\u8fd9\u4e00\u6279\u8bc4\uff0c\u6211\u4eec\u8fdb\u884c\u4e86\u4e00\u9879\u9884\u5b9e\u9a8c\uff0c\u5c06\u5f3a\u5927LLMs\u7684\u8f93\u51fa\u5206\u5e03\u89c6\u4e3a\u9ad8\u6548\u7684\u4e16\u754c\u6570\u636e\u538b\u7f29\u3002\u901a\u8fc7\u8bc4\u4f30$n$-gram\u5206\u5e03\u4e0eLLMs\u7684\u4e00\u70ed\u5206\u5e03\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u6211\u4eec\u89c2\u5bdf\u5230$n$-gram\u5206\u5e03\u4e0eLLMs\u7684\u8f93\u51fa\u5206\u5e03\u66f4\u4e3a\u63a5\u8fd1\u3002\u57fa\u4e8e\u8fd9\u4e00\u6d1e\u5bdf\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e0b\u4e00\u4e2a\u5206\u5e03\u9884\u6d4b\uff08NDP\uff09\uff0c\u5b83\u4f7f\u7528$n$-gram\u5206\u5e03\u6765\u66ff\u4ee3\u4e00\u70ed\u76ee\u6807\uff0c\u4ece\u800c\u5728\u4e0d\u589e\u52a0\u5728\u7ebf\u8bad\u7ec3\u65f6\u95f4\u7684\u60c5\u51b5\u4e0b\u589e\u5f3a\u5b66\u4e60\u3002\u6211\u4eec\u5728\u7ffb\u8bd1\u3001\u901a\u7528\u4efb\u52a1\u3001\u8bed\u8a00\u8fc1\u79fb\u548c\u533b\u5b66\u9886\u57df\u9002\u5e94\u7b49\u591a\u4e2a\u9886\u57df\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002\u4e0eNTP\u76f8\u6bd4\uff0cNDP\u5728\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u53ef\u5b9e\u73b0\u9ad8\u8fbe+2.97\u7684COMET\u6539\u8fdb\uff0c\u5728\u901a\u7528\u4efb\u52a1\u4e2d\u5e73\u5747\u63d0\u5347+0.61\uff0c\u800c\u5728\u533b\u5b66\u9886\u57df\u5e73\u5747\u63d0\u5347\u60ca\u4eba\u5730\u8fbe\u5230+10.75\u3002\u8fd9\u8868\u660e\u89e3\u51b3\u76ee\u6807\u72ed\u7a84\u95ee\u9898\u5177\u6709\u5b9e\u8d28\u6027\u7684\u597d\u5904\uff0c\u5e76\u4e3a\u672a\u6765\u6539\u8fdbNTP\u7684\u5de5\u4f5c\u6307\u660e\u4e86\u65b0\u7684\u65b9\u5411\u3002 Junhao Ruan PDF N/A NDP: Next Distribution Prediction as a More Broad Target Large language models (LLMs) trained on next-token prediction (NTP) paradigm have demonstrated powerful capabilities. However, the existing NTP paradigm contains several limitations, particularly related to planned task complications and error propagation during inference. In our work, we extend the critique of NTP, highlighting its limitation also due to training with a narrow objective: the prediction of a sub-optimal one-hot distribution. To support this critique, we conducted a pre-experiment treating the output distribution from powerful LLMs as efficient world data compression. By evaluating the similarity between the $n$-gram distribution and the one-hot distribution with LLMs, we observed that the $n$-gram distributions align more closely with the output distribution of LLMs. Based on this insight, we introduce Next Distribution Prediction (NDP), which uses $n$-gram distributions to replace the one-hot targets, enhancing learning without extra online training time. We conducted experiments across translation, general task, language transfer, and medical domain adaptation. Compared to NTP, NDP can achieve up to +2.97 COMET improvement in translation tasks, +0.61 average improvement in general tasks, and incredible +10.75 average improvement in the medical domain. This demonstrates the concrete benefits of addressing the target narrowing problem, pointing to a new direction for future work on improving NTP. \u63a2\u7d22\u73af\u5883\u6c61\u67d3\u7269\u5bf9\u591a\u53d1\u6027\u786c\u5316\u75c7\u8fdb\u5c55\u7684\u5f71\u54cd \u591a\u53d1\u6027\u786c\u5316\u75c7\uff08MS\uff09\u662f\u4e00\u79cd\u6162\u6027\u81ea\u8eab\u514d\u75ab\u6027\u548c\u708e\u75c7\u6027\u795e\u7ecf\u7cfb\u7edf\u75be\u75c5\uff0c\u5176\u7279\u70b9\u662f\u75c7\u72b6\u52a0\u5267\u7684\u53d1\u4f5c\uff0c\u79f0\u4e3a\u590d\u53d1\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u5229\u7528H2020 BRAINTEASER\u9879\u76ee\u7684\u6570\u636e\uff0c\u63a2\u8ba8\u73af\u5883\u56e0\u7d20\u5728MS\u60a3\u8005\u590d\u53d1\u53d1\u751f\u4e2d\u7684\u4f5c\u7528\u3002\u6211\u4eec\u91c7\u7528\u4e86\u5305\u62ec\u968f\u673a\u68ee\u6797\uff08RF\uff09\u548c\u903b\u8f91\u56de\u5f52\uff08LR\uff09\u5728\u5185\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u4e0d\u540c\u96c6\u5408\u7684\u8f93\u5165\u7279\u5f81\uff0c\u57fa\u4e8e\u4e00\u5468\u5185\u6536\u96c6\u7684\u4e34\u5e8a\u548c\u6c61\u67d3\u7269\u6570\u636e\u6765\u9884\u6d4b\u590d\u53d1\u7684\u53d1\u751f\u3002\u968f\u673a\u68ee\u6797\u6a21\u578b\u53d6\u5f97\u4e86\u6700\u4f73\u7ed3\u679c\uff0cAUC-ROC\u5f97\u5206\u4e3a0.713\u3002\u73af\u5883\u53d8\u91cf\uff0c\u5982\u964d\u6c34\u91cf\u3001\u4e8c\u6c27\u5316\u6c2e\uff08NO2\uff09\u3001\u7ec6\u9897\u7c92\u7269\uff08PM2.5\uff09\u3001\u6e7f\u5ea6\u548c\u6e29\u5ea6\uff0c\u88ab\u53d1\u73b0\u4e0e\u9884\u6d4b\u76f8\u5173\u3002 Elena Marinello PDF N/A Exploring the Impact of Environmental Pollutants on Multiple Sclerosis Progression Multiple Sclerosis (MS) is a chronic autoimmune and inflammatory neurological disorder characterised by episodes of symptom exacerbation, known as relapses. In this study, we investigate the role of environmental factors in relapse occurrence among MS patients, using data from the H2020 BRAINTEASER project. We employed predictive models, including Random Forest (RF) and Logistic Regression (LR), with varying sets of input features to predict the occurrence of relapses based on clinical and pollutant data collected over a week. The RF yielded the best result, with an AUC-ROC score of 0.713. Environmental variables, such as precipitation, NO2, PM2.5, humidity, and temperature, were found to be relevant to the prediction. \u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u7535\u529b\u6d88\u8017 \u7cbe\u786e\u7684\u7535\u529b\u9700\u6c42\u9884\u6d4b\u5bf9\u4e8e\u591a\u4e2a\u65b9\u9762\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u53ef\u518d\u751f\u80fd\u6e90\u7684\u6574\u5408\u4ee5\u53ca\u5411\u53bb\u4e2d\u5fc3\u5316\u7f51\u7edc\u8303\u5f0f\u7684\u8fc7\u6e21\u5f15\u5165\u4e86\u66f4\u5927\u7684\u590d\u6742\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u4e4b\u9645\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5229\u7528\u57fa\u4e8e\u56fe\u7684\u8868\u793a\u6cd5\uff0c\u6709\u6548\u5730\u6355\u6349\u8fd9\u79cd\u53bb\u4e2d\u5fc3\u5316\u7f51\u7edc\u7ed3\u6784\u4e2d\u56fa\u6709\u7684\u7a7a\u95f4\u5206\u5e03\u548c\u5173\u7cfb\u590d\u6742\u6027\u3002\u672c\u7814\u7a76\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u5e7f\u4e49\u52a0\u6027\u6a21\u578b\u6846\u67b6\uff0c\u8003\u8651\u4e86\u8bf8\u5982\u56fe\u5377\u79ef\u7f51\u7edc\u6216\u56feSAGE\u7b49\u6a21\u578b\u3002\u8fd9\u4e9b\u57fa\u4e8e\u56fe\u7684\u6a21\u578b\u4f7f\u5f97\u80fd\u591f\u7eb3\u5165\u8282\u70b9\u95f4\u4e0d\u540c\u5c42\u6b21\u7684\u4e92\u8054\u6027\u548c\u4fe1\u606f\u5171\u4eab\uff0c\u5176\u4e2d\u6bcf\u4e2a\u8282\u70b9\u5bf9\u5e94\u4e8e\u4e00\u90e8\u5206\u6d88\u8d39\u8005\uff08\u4f8b\u5982\u56fd\u5bb6\u5404\u5730\u533a\uff09\u7684\u7efc\u5408\u8d1f\u8377\uff08\u5373\u6d88\u8d39\u91cf\uff09\u3002\u66f4\u5177\u4f53\u5730\u8bf4\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u7cfb\u5217\u9488\u5bf9\u6d88\u8d39\u9884\u6d4b\u5b9a\u5236\u56fe\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u4ee5\u53ca\u4e00\u4e2a\u8bc4\u4f30\u6240\u5f00\u53d1\u6a21\u578b\u5728\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u6846\u67b6\u3002\u6211\u4eec\u5728\u5408\u6210\u548c\u771f\u5b9e\u6846\u67b6\u4e0b\u8fdb\u884c\u4e86\u7535\u529b\u9884\u6d4b\u5b9e\u9a8c\uff0c\u8003\u8651\u4e86\u6cd5\u56fd\u672c\u571f\u5730\u533a\uff0c\u5e76\u8ba8\u8bba\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u6027\u80fd\u548c\u4f18\u70b9\u3002 Eloi Campagne PDF N/A Leveraging Graph Neural Networks to Forecast Electricity Consumption Accurate electricity demand forecasting is essential for several reasons, especially as the integration of renewable energy sources and the transition to a decentralized network paradigm introduce greater complexity and uncertainty. The proposed methodology leverages graph-based representations to effectively capture the spatial distribution and relational intricacies inherent in this decentralized network structure. This research work offers a novel approach that extends beyond the conventional Generalized Additive Model framework by considering models like Graph Convolutional Networks or Graph SAGE. These graph-based models enable the incorporation of various levels of interconnectedness and information sharing among nodes, where each node corresponds to the combined load (i.e. consumption) of a subset of consumers (e.g. the regions of a country). More specifically, we introduce a range of methods for inferring graphs tailored to consumption forecasting, along with a framework for evaluating the developed models in terms of both performance and explainability. We conduct experiments on electricity forecasting, in both a synthetic and a real framework considering the French mainland regions, and the performance and merits of our approach are discussed. \u8bc4\u4f30\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff1a\u73af\u5883\u4e0e\u6c14\u5019\u53d8\u5316\u9886\u57df\u7684\u6027\u80fd\u4e0e\u81ea\u6211\u8bc4\u4f30\u80fd\u529b \u672c\u6587\u7814\u7a76\u4e86\u4e24\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09GPT3.5\u548cLlama2\u4ee5\u53ca\u4e00\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09Gemma\u5728\u6c14\u5019\u53d8\u5316\uff08CC\uff09\u548c\u73af\u5883\u9886\u57df\u5185\u4e09\u4e2a\u4e0d\u540c\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u91c7\u7528\u57fa\u4e8eBERT\u7684\u6a21\u578b\u4f5c\u4e3a\u57fa\u7ebf\uff0c\u6211\u4eec\u5c06\u5b83\u4eec\u4e0e\u8fd9\u4e9b\u57fa\u4e8etransformer\u7684\u6a21\u578b\u8fdb\u884c\u6548\u80fd\u6bd4\u8f83\u3002\u6b64\u5916\uff0c\u6211\u4eec\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u53e3\u5934\u8868\u8ff0\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\u7684\u6821\u51c6\u60c5\u51b5\uff0c\u8bc4\u4f30\u4e86\u6a21\u578b\u7684\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\u3002\u6211\u4eec\u7684\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u57fa\u4e8eBERT\u7684\u6a21\u578b\u603b\u4f53\u4e0a\u4f18\u4e8eLLMs\u548cSLM\uff0c\u4f46\u5927\u578b\u751f\u6210\u6a21\u578b\u7684\u8868\u73b0\u4ecd\u7136\u503c\u5f97\u6ce8\u610f\u3002\u8fdb\u4e00\u6b65\u7684\u6821\u51c6\u5206\u6790\u663e\u793a\uff0c\u867d\u7136Gemma\u5728\u521d\u59cb\u4efb\u52a1\u4e2d\u6821\u51c6\u826f\u597d\uff0c\u4f46\u968f\u540e\u4ea7\u751f\u4e86\u4e0d\u4e00\u81f4\u7684\u7ed3\u679c\uff1bLlama\u6821\u51c6\u5408\u7406\uff0c\u800cGPT\u5219\u59cb\u7ec8\u8868\u73b0\u51fa\u5f3a\u6821\u51c6\u3002\u901a\u8fc7\u8fd9\u9879\u7814\u7a76\uff0c\u6211\u4eec\u65e8\u5728\u4e3a\u5173\u4e8e\u751f\u6210\u5f0fLM\u5728\u89e3\u51b3\u5730\u7403\u4e0a\u4e00\u4e9b\u6700\u7d27\u8feb\u95ee\u9898\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\u7684\u6301\u7eed\u8ba8\u8bba\u505a\u51fa\u8d21\u732e\uff0c\u5f3a\u8c03\u5b83\u4eec\u5728\u751f\u6001\u548cCC\u80cc\u666f\u4e0b\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002 Francesca Grasso PDF N/A Assessing Generative Language Models in Classification Tasks: Performance and Self-Evaluation Capabilities in the Environmental and Climate Change Domain This paper examines the performance of two Large Language Models (LLMs), GPT3.5 and Llama2 and one Small Language Model (SLM) Gemma, across three different classification tasks within the climate change (CC) and environmental domain. Employing BERT-based models as a baseline, we compare their efficacy against these transformer-based models. Additionally, we assess the models' self-evaluation capabilities by analyzing the calibration of verbalized confidence scores in these text classification tasks. Our findings reveal that while BERT-based models generally outperform both the LLMs and SLM, the performance of the large generative models is still noteworthy. Furthermore, our calibration analysis reveals that although Gemma is well-calibrated in initial tasks, it thereafter produces inconsistent results; Llama is reasonably calibrated, and GPT consistently exhibits strong calibration. Through this research, we aim to contribute to the ongoing discussion on the utility and effectiveness of generative LMs in addressing some of the planet's most urgent issues, highlighting their strengths and limitations in the context of ecology and CC. \u300a\u7d27\u7d27\u76f8\u62e5\uff1a\u8bed\u97f3\u589e\u5f3a\u7684\u7a33\u5b9a\u7f16\u7801\u5668-\u89e3\u7801\u5668\u8bbe\u8ba1\u300b \u4e00\u7ef4\u5377\u79ef\u5c42\u5e38\u88ab\u7528\u4f5c\u97f3\u9891\u4fe1\u53f7\u7f16\u7801\u7684\u524d\u7aef\uff0c\u8fd9\u4e9b\u5c42\u4f7f\u7528\u4e00\u7ef4\u6ee4\u6ce2\u5668\u3002\u4e0e\u56fa\u5b9a\u7684\u65f6\u95f4-\u9891\u7387\u8868\u793a\u4e0d\u540c\uff0c\u5b83\u4eec\u80fd\u591f\u9002\u5e94\u8f93\u5165\u6570\u636e\u7684\u5c40\u90e8\u7279\u5f81\u3002\u7136\u800c\uff0c\u5728\u539f\u59cb\u97f3\u9891\u4e0a\u8bad\u7ec3\u4e00\u7ef4\u6ee4\u6ce2\u5668\u8f83\u4e3a\u56f0\u96be\uff0c\u4e14\u5e38\u5e38\u9762\u4e34\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u6df7\u5408\u89e3\u51b3\u65b9\u6848\u6765\u5e94\u5bf9\u8fd9\u4e9b\u95ee\u9898\uff0c\u5373\u7ed3\u5408\u7406\u8bba\u9a71\u52a8\u548c\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u3002\u9996\u5148\uff0c\u6211\u4eec\u901a\u8fc7\u542c\u89c9\u6ee4\u6ce2\u5668\u7ec4\u5bf9\u97f3\u9891\u4fe1\u53f7\u8fdb\u884c\u9884\u5904\u7406\uff0c\u786e\u4fdd\u5b66\u4e60\u5230\u7684\u7f16\u7801\u5668\u5177\u6709\u826f\u597d\u7684\u9891\u7387\u5b9a\u4f4d\u80fd\u529b\u3002\u5176\u6b21\uff0c\u6211\u4eec\u5229\u7528\u6846\u67b6\u7406\u8bba\u7684\u7ed3\u679c\u5b9a\u4e49\u4e86\u4e00\u4e2a\u65e0\u76d1\u7763\u5b66\u4e60\u76ee\u6807\uff0c\u8be5\u76ee\u6807\u9f13\u52b1\u80fd\u91cf\u5b88\u6052\u548c\u5b8c\u7f8e\u91cd\u5efa\u3002\u7b2c\u4e09\uff0c\u6211\u4eec\u5c06\u6df7\u5408\u538b\u7f29\u8c31\u8303\u6570\u4f5c\u4e3a\u5b66\u4e60\u76ee\u6807\u5e94\u7528\u4e8e\u7f16\u7801\u5668\u7cfb\u6570\u3002\u5728\u4f4e\u590d\u6742\u5ea6\u7684\u7f16\u7801\u5668-\u63a9\u7801-\u89e3\u7801\u5668\u6a21\u578b\u4e2d\u5e94\u7528\u8fd9\u4e9b\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bed\u97f3\u589e\u5f3a\u4e2d\u7684\u8bed\u97f3\u8d28\u91cf\u611f\u77e5\u8bc4\u4f30\uff08PESQ\uff09\u3002 Daniel Haider PDF N/A Hold Me Tight: Stable Encoder-Decoder Design for Speech Enhancement Convolutional layers with 1-D filters are often used as frontend to encode audio signals. Unlike fixed time-frequency representations, they can adapt to the local characteristics of input data. However, 1-D filters on raw audio are hard to train and often suffer from instabilities. In this paper, we address these problems with hybrid solutions, i.e., combining theory-driven and data-driven approaches. First, we preprocess the audio signals via a auditory filterbank, guaranteeing good frequency localization for the learned encoder. Second, we use results from frame theory to define an unsupervised learning objective that encourages energy conservation and perfect reconstruction. Third, we adapt mixed compressed spectral norms as learning objectives to the encoder coefficients. Using these solutions in a low-complexity encoder-mask-decoder model significantly improves the perceptual evaluation of speech quality (PESQ) in speech enhancement. C-RADAR\uff1a\u4e00\u79cd\u7528\u4e8e\u8f6f\u4ef6\u5b9a\u4e49\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7684\u96c6\u4e2d\u5f0f\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf \u8f6f\u4ef6\u5b9a\u4e49\u7f51\u7edc\uff08SDN\uff09\u8fd1\u5e74\u6765\u56e0\u5176\u7b80\u5316\u7f51\u7edc\u7ba1\u7406\u548c\u63d0\u9ad8\u7f51\u7edc\u7075\u6d3b\u6027\u7684\u80fd\u529b\u800c\u5e7f\u53d7\u6b22\u8fce\u3002\u7136\u800c\uff0c\u8fd9\u4e5f\u4f7f\u5f97\u5b83\u4eec\u5bb9\u6613\u53d7\u5230\u5404\u79cd\u7c7b\u578b\u7684\u7f51\u7edc\u653b\u51fb\u3002SDN\u91c7\u7528\u96c6\u4e2d\u5f0f\u63a7\u5236\u5e73\u9762\u5de5\u4f5c\uff0c\u8fd9\u4f7f\u5f97\u5b83\u4eec\u66f4\u5bb9\u6613\u906d\u53d7\u7f51\u7edc\u653b\u51fb\u3002\u7814\u7a76\u8868\u660e\uff0c\u6df1\u5ea6\u5b66\u4e60\uff08DL\uff09\u65b9\u6cd5\u5728\u8bc6\u522b\u4f20\u7edf\u7f51\u7edc\u4e2d\u7684\u5165\u4fb5\u65b9\u9762\u53ef\u4ee5\u53d6\u5f97\u6210\u529f\uff0c\u4f46\u5176\u5728SDN\u4e2d\u7684\u5e94\u7528\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u7684\u7814\u7a76\u9886\u57df\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u8fdb\u884cSDN\u5165\u4fb5\u68c0\u6d4b\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u901a\u8fc7\u5728\u4e00\u4e2a\u7f51\u7edc\u6d41\u91cf\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u5c06\u5176\u4e0e\u73b0\u6709\u6280\u672f\u8fdb\u884c\u6bd4\u8f83\uff0c\u6765\u8861\u91cf\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u6211\u4eec\u7684\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002\u672c\u7814\u7a76\u4e2d\u4f7f\u7528\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u662f\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u548c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u7ed3\u5408\uff0c\u5373LSTM-Attn\uff0c\u5176F1\u5206\u6570\u8fbe\u5230\u4e860.9721\u3002\u6b64\u5916\uff0c\u8fd9\u79cd\u6280\u672f\u53ef\u4ee5\u88ab\u8bad\u7ec3\u6765\u68c0\u6d4b\u65b0\u7684\u653b\u51fb\u6a21\u5f0f\uff0c\u5e76\u63d0\u9ad8SDN\u7684\u6574\u4f53\u5b89\u5168\u6027\u3002 Osama Mustafa PDF N/A C-RADAR: A Centralized Deep Learning System for Intrusion Detection in Software Defined Networks The popularity of Software Defined Networks (SDNs) has grown in recent years, mainly because of their ability to simplify network management and improve network flexibility. However, this also makes them vulnerable to various types of cyber attacks. SDNs work on a centralized control plane which makes them more prone to network attacks. Research has demonstrated that deep learning (DL) methods can be successful in identifying intrusions in conventional networks, but their application in SDNs is still an open research area. In this research, we propose the use of DL techniques for intrusion detection in SDNs. We measure the effectiveness of our method by experimentation on a dataset of network traffic and comparing it to existing techniques. Our results show that the DL-based approach outperforms traditional methods in terms of detection accuracy and computational efficiency. The deep learning architecture that has been used in this research is a Long Short Term Memory Network and Self-Attention based architecture i.e. LSTM-Attn which achieves an Fl-score of 0.9721. Furthermore, this technique can be trained to detect new attack patterns and improve the overall security of SDNs. \u53cc\u5411\u89e3\u7801\uff1a\u901a\u8fc7\u95ed\u73af\u91cd\u91c7\u6837\u6539\u8fdb\u52a8\u4f5c\u5206\u5757 \u9884\u6d4b\u5e76\u6267\u884c\u4e00\u7cfb\u5217\u52a8\u4f5c\u800c\u4e0d\u8fdb\u884c\u4e2d\u95f4\u91cd\u89c4\u5212\uff0c\u5373\u6240\u8c13\u7684\u52a8\u4f5c\u5206\u5757\uff0c\u5728\u4ece\u4eba\u7c7b\u6f14\u793a\u4e2d\u5b66\u4e60\u673a\u5668\u4eba\u6280\u80fd\u7684\u8fc7\u7a0b\u4e2d\u8d8a\u6765\u8d8a\u5e38\u7528\u3002\u7136\u800c\uff0c\u52a8\u4f5c\u5206\u5757\u5bf9\u5b66\u4e60\u5230\u7684\u7b56\u7565\u7684\u5f71\u54cd\u4ecd\u662f\u4e00\u4e2a\u8c1c\uff1a\u4e00\u4e9b\u7814\u7a76\u8868\u660e\u5b83\u5bf9\u4e8e\u5b9e\u73b0\u9ad8\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u800c\u5176\u4ed6\u7814\u7a76\u5219\u89c2\u5bdf\u5230\u5176\u6709\u5bb3\u6548\u679c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u9996\u5148\u901a\u8fc7\u5206\u6790\u5b66\u4e60\u8005\u4e0e\u6f14\u793a\u8005\u4e4b\u95f4\u7684\u5dee\u5f02\u6765\u5256\u6790\u52a8\u4f5c\u5206\u5757\u7684\u4f5c\u7528\u3002\u6211\u4eec\u53d1\u73b0\uff0c\u8f83\u957f\u7684\u52a8\u4f5c\u5757\u80fd\u591f\u8ba9\u7b56\u7565\u66f4\u597d\u5730\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u56e0\u4e3a\u5b83\u8003\u8651\u4e86\u5757\u5185\u66f4\u591a\u7684\u8fc7\u53bb\u72b6\u6001\u548c\u52a8\u4f5c\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u4f18\u52bf\u662f\u4ee5\u5728\u968f\u673a\u73af\u5883\u4e2d\u52a0\u5267\u8fd1\u671f\u72b6\u6001\u89c2\u5bdf\u8f83\u5c11\u5bfc\u81f4\u7684\u9519\u8bef\u4e3a\u4ee3\u4ef7\u7684\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u53cc\u5411\u89e3\u7801\uff08Bidirectional Decoding, BID\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u6d4b\u8bd5\u65f6\u63a8\u7406\u7b97\u6cd5\uff0c\u5b83\u5c06\u52a8\u4f5c\u5206\u5757\u4e0e\u95ed\u73af\u64cd\u4f5c\u7ed3\u5408\u8d77\u6765\u3002BID\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u91c7\u6837\u591a\u4e2a\u9884\u6d4b\uff0c\u5e76\u6839\u636e\u4e24\u4e2a\u6807\u51c6\u641c\u7d22\u6700\u4f18\u7684\u9884\u6d4b\uff1a(i) \u5411\u540e\u4e00\u81f4\u6027\uff0c\u503e\u5411\u4e8e\u4e0e\u5148\u524d\u51b3\u7b56\u76f8\u7b26\u7684\u6837\u672c\uff1b(ii) \u5411\u524d\u5bf9\u6bd4\uff0c\u503e\u5411\u4e8e\u63a5\u8fd1\u66f4\u5f3a\u7b56\u7565\u8f93\u51fa\u4e14\u8fdc\u79bb\u8f83\u5f31\u7b56\u7565\u8f93\u51fa\u7684\u6837\u672c\u3002\u901a\u8fc7\u5728\u52a8\u4f5c\u5757\u5185\u548c\u5757\u95f4\u8026\u5408\u51b3\u7b56\uff0cBID\u5728\u5ef6\u957f\u5e8f\u5217\u4e2d\u589e\u5f3a\u4e86\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u4f7f\u7b56\u7565\u80fd\u591f\u5728\u968f\u673a\u73af\u5883\u4e2d\u8fdb\u884c\u81ea\u9002\u5e94\u91cd\u89c4\u5212\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cBID\u5728\u4e03\u4e2a\u6a21\u62df\u57fa\u51c6\u548c\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u4e24\u79cd\u6700\u5148\u8fdb\u7684\u751f\u6210\u7b56\u7565\u7684\u4f20\u7edf\u95ed\u73af\u64cd\u4f5c\u3002 Yuejiang Liu PDF N/A Bidirectional Decoding: Improving Action Chunking via Closed-Loop Resampling Predicting and executing a sequence of actions without intermediate replanning, known as action chunking, is increasingly used in robot learning from human demonstrations. However, its effects on learned policies remain puzzling: some studies highlight its importance for achieving strong performance, while others observe detrimental effects. In this paper, we first dissect the role of action chunking by analyzing the divergence between the learner and the demonstrator. We find that longer action chunks enable a policy to better capture temporal dependencies by taking into account more past states and actions within the chunk. However, this advantage comes at the cost of exacerbating errors in stochastic environments due to fewer observations of recent states. To address this, we propose Bidirectional Decoding (BID), a test-time inference algorithm that bridges action chunking with closed-loop operations. BID samples multiple predictions at each time step and searches for the optimal one based on two criteria: (i) backward coherence, which favors samples aligned with previous decisions, (ii) forward contrast, which favors samples close to outputs of a stronger policy and distant from those of a weaker policy. By coupling decisions within and across action chunks, BID enhances temporal consistency over extended sequences while enabling adaptive replanning in stochastic environments. Experimental results show that BID substantially outperforms conventional closed-loop operations of two state-of-the-art generative policies across seven simulation benchmarks and two real-world tasks. \u9057\u5fd8\u4ee5\u7e41\u8363\uff1a\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u673a\u5668\u9057\u5fd8\u6280\u672f\u9632\u8303\u9690\u79c1\u6cc4\u9732 \u5728\u4e0b\u6e38\u5e94\u7528\u4e2d\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u79c1\u6709\u6570\u636e\u5fae\u8c03\uff0c\u53ef\u80fd\u4f1a\u66b4\u9732\u654f\u611f\u4fe1\u606f\uff0c\u4ece\u800c\u5e26\u6765\u663e\u8457\u7684\u9690\u79c1\u98ce\u9669\u3002\u76ee\u524d\uff0c\u591a\u4e2a\u70ed\u95e8\u793e\u533a\u5e73\u53f0\u63d0\u4f9b\u4e86\u4fbf\u6377\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u5206\u53d1\u670d\u52a1\uff0c\u5141\u8bb8\u4efb\u4f55\u4eba\u65e0\u9700\u4e25\u683c\u5ba1\u6838\u5373\u53ef\u53d1\u5e03\u3002\u8fd9\u79cd\u60c5\u51b5\u9020\u6210\u4e86\u9690\u79c1\u5a01\u80c1\uff0c\u56e0\u4e3a\u9884\u8bad\u7ec3\u6a21\u578b\u53ef\u80fd\u88ab\u6545\u610f\u8bbe\u8ba1\u6765\u4fb5\u72af\u5fae\u8c03\u6570\u636e\u96c6\u7684\u9690\u79c1\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e2d\u6bd2\u6280\u672f\uff0c\u5229\u7528\u6a21\u578b\u9057\u5fd8\u4f5c\u4e3a\u653b\u51fb\u624b\u6bb5\u3002\u8be5\u65b9\u6cd5\u64cd\u7eb5\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u589e\u52a0\u79c1\u6709\u6570\u636e\u7684\u6cc4\u9732\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u65e2\u589e\u5f3a\u4e86\u6210\u5458\u63a8\u7406\u548c\u6570\u636e\u63d0\u53d6\u653b\u51fb\uff0c\u53c8\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u5b9e\u7528\u6027\u3002\u5728\u4e0d\u540c\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u5fae\u8c03\u8bbe\u7f6e\u4e0b\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u653b\u51fb\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u6027\u80fd\u3002\u8fd9\u9879\u5de5\u4f5c\u5bf9\u4ece\u975e\u9a8c\u8bc1\u6765\u6e90\u4e0b\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u7528\u6237\u53d1\u51fa\u4e86\u8b66\u793a\uff0c\u5f3a\u8c03\u4e86\u6f5c\u5728\u7684\u98ce\u9669\u3002 Md Rafi Ur Rashid PDF N/A Forget to Flourish: Leveraging Machine-Unlearning on Pretrained Language Models for Privacy Leakage Fine-tuning large language models on private data for downstream applications poses significant privacy risks in potentially exposing sensitive information. Several popular community platforms now offer convenient distribution of a large variety of pre-trained models, allowing anyone to publish without rigorous verification. This scenario creates a privacy threat, as pre-trained models can be intentionally crafted to compromise the privacy of fine-tuning datasets. In this study, we introduce a novel poisoning technique that uses model-unlearning as an attack tool. This approach manipulates a pre-trained language model to increase the leakage of private data during the fine-tuning process. Our method enhances both membership inference and data extraction attacks while preserving model utility. Experimental results across different models, datasets, and fine-tuning setups demonstrate that our attacks significantly surpass baseline performance. This work serves as a cautionary note for users who download pre-trained models from unverified sources, highlighting the potential risks involved. \u8bc4\u4f30\u533b\u5b66\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u9760\u6027\uff1a\u57fa\u4e8e\u7279\u5f81\u548c\u7f6e\u4fe1\u5ea6\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u7684\u5173\u952e\u5206\u6790 \u53ef\u9760\u5730\u4f7f\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNNs\uff09\u8fdb\u884c\u533b\u5b66\u56fe\u50cf\u5206\u6790\u9700\u8981\u8bc6\u522b\u4e0e\u8bad\u7ec3\u6570\u636e\u663e\u8457\u4e0d\u540c\u7684\u8f93\u5165\uff0c\u5373\u5206\u5e03\u5916\uff08OOD\uff09\u6570\u636e\uff0c\u4ee5\u9632\u6b62\u9519\u8bef\u7684\u9884\u6d4b\u3002OOD\u68c0\u6d4b\u65b9\u6cd5\u53ef\u4ee5\u5206\u4e3a\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\uff08\u4f7f\u7528\u6a21\u578b\u7684\u8f93\u51fa\u5c42\u8fdb\u884cOOD\u68c0\u6d4b\uff09\u6216\u57fa\u4e8e\u7279\u5f81\u7684\uff08\u4e0d\u4f7f\u7528\u8f93\u51fa\u5c42\uff09\u3002\u6211\u4eec\u901a\u8fc7\u5c06D7P\uff08\u76ae\u80a4\u75c5\u5b66\uff09\u548cBreastMNIST\uff08\u8d85\u58f0\uff09\u6570\u636e\u96c6\u5206\u6210\u5305\u542b\u6216\u4e0d\u5305\u542b\u4eba\u5de5\u5236\u54c1\uff08\u5206\u522b\u662f\u6807\u5c3a\u6216\u6ce8\u91ca\uff09\u7684\u5b50\u96c6\uff0c\u521b\u5efa\u4e86\u4e24\u4e2a\u65b0\u7684OOD\u57fa\u51c6\u3002\u6a21\u578b\u4f7f\u7528\u65e0\u4eba\u5de5\u5236\u54c1\u7684\u56fe\u50cf\u8fdb\u884c\u8bad\u7ec3\uff0c\u800c\u5305\u542b\u4eba\u5de5\u5236\u54c1\u7684\u56fe\u50cf\u5219\u7528\u4f5cOOD\u6d4b\u8bd5\u96c6\u3002\u5bf9\u4e8e\u6bcf\u4e2aOOD\u56fe\u50cf\uff0c\u6211\u4eec\u901a\u8fc7\u624b\u52a8\u53bb\u9664\u4eba\u5de5\u5236\u54c1\u6765\u521b\u5efa\u4e00\u4e2a\u53cd\u4e8b\u5b9e\u56fe\u50cf\uff0c\u4ee5\u8bc4\u4f30\u4eba\u5de5\u5236\u54c1\u5bf9\u6a21\u578b\u9884\u6d4b\u7684\u5f71\u54cd\u3002\u6211\u4eec\u53d1\u73b0\uff0c\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u76f8\u5173\u6027\u7b49\u56e0\u7d20\uff0cOOD\u4eba\u5de5\u5236\u54c1\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u5bf9\u5176\u9884\u6d4b\u7684softmax\u7f6e\u4fe1\u5ea6\u3002\u8fd9\u4e0e\u901a\u5e38\u8ba4\u4e3aOOD\u4eba\u5de5\u5236\u54c1\u5e94\u5bfc\u81f4\u66f4\u4e0d\u786e\u5b9a\u8f93\u51fa\u7684\u5047\u8bbe\u76f8\u77db\u76fe\uff0c\u800c\u5927\u591a\u6570\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u65b9\u6cd5\u6b63\u662f\u57fa\u4e8e\u8fd9\u4e00\u5047\u8bbe\u3002\u6211\u4eec\u5229\u7528\u8fd9\u4e00\u70b9\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u57fa\u4e8e\u7279\u5f81\u7684\u65b9\u6cd5\uff08\u5982\u9a6c\u6c0f\u8ddd\u79bb\u5206\u6570\uff09\u901a\u5e38\u6bd4\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u65b9\u6cd5\uff08\u5982\u6700\u5927\u7c7b\u95f4\u6982\u7387MCP\uff09\u5177\u6709\u66f4\u597d\u7684OOD\u68c0\u6d4b\u6027\u80fd\u3002\u7136\u800c\uff0c\u6211\u4eec\u4e5f\u8868\u660e\uff0c\u57fa\u4e8e\u7279\u5f81\u7684\u65b9\u6cd5\u5728\u533a\u5206\u5bfc\u81f4\u6b63\u786e\u548c\u9519\u8bef\u9884\u6d4b\u7684\u8f93\u5165\uff08\u65e0\u8bba\u662fOOD\u8fd8\u662fID\u6570\u636e\uff09\u65b9\u9762\u901a\u5e38\u8868\u73b0\u8f83\u5dee\u3002\u57fa\u4e8e\u8fd9\u4e9b\u89c1\u89e3\uff0c\u6211\u4eec\u8ba4\u4e3a\u5e94\u5728DNN\u6d41\u7a0b\u4e2d\u7ed3\u5408\u4f7f\u7528\u57fa\u4e8e\u7279\u5f81\u548c\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u65b9\u6cd5\uff0c\u4ee5\u7f13\u89e3\u5404\u81ea\u7684\u5f31\u70b9\u3002\u8be5\u9879\u76ee\u4ee3\u7801\u548cOOD\u57fa\u51c6\u53ef\u5728\u4ee5\u4e0b\u94fe\u63a5\u83b7\u53d6\uff1ahttps://github.com/HarryAnthony/Evaluating_OOD_detection\u3002 Harry Anthony PDF N/A Evaluating Reliability in Medical DNNs: A Critical Analysis of Feature and Confidence-Based OOD Detection Reliable use of deep neural networks (DNNs) for medical image analysis requires methods to identify inputs that differ significantly from the training data, called out-of-distribution (OOD), to prevent erroneous predictions. OOD detection methods can be categorised as either confidence-based (using the model's output layer for OOD detection) or feature-based (not using the output layer). We created two new OOD benchmarks by dividing the D7P (dermatology) and BreastMNIST (ultrasound) datasets into subsets which either contain or don't contain an artefact (rulers or annotations respectively). Models were trained with artefact-free images, and images with the artefacts were used as OOD test sets. For each OOD image, we created a counterfactual by manually removing the artefact via image processing, to assess the artefact's impact on the model's predictions. We show that OOD artefacts can boost a model's softmax confidence in its predictions, due to correlations in training data among other factors. This contradicts the common assumption that OOD artefacts should lead to more uncertain outputs, an assumption on which most confidence-based methods rely. We use this to explain why feature-based methods (e.g. Mahalanobis score) typically have greater OOD detection performance than confidence-based methods (e.g. MCP). However, we also show that feature-based methods typically perform worse at distinguishing between inputs that lead to correct and incorrect predictions (for both OOD and ID data). Following from these insights, we argue that a combination of feature-based and confidence-based methods should be used within DNN pipelines to mitigate their respective weaknesses. These project's code and OOD benchmarks are available at: https://github.com/HarryAnthony/Evaluating_OOD_detection. \u4ece\u5fc3\u7535\u56fe\u7279\u5f81\u4f30\u7b97\u5fc3\u810f\u4e0e\u975e\u5fc3\u810f\u8bca\u65ad \u5f15\u8a00\uff1a\u786e\u4fdd\u533b\u7597\u72b6\u51b5\u7684\u53ca\u65f6\u51c6\u786e\u8bca\u65ad\u5bf9\u4e8e\u6709\u6548\u7684\u60a3\u8005\u62a4\u7406\u81f3\u5173\u91cd\u8981\u3002\u5fc3\u7535\u56fe\uff08ECG\uff09\u4fe1\u53f7\u662f\u8bc4\u4f30\u60a3\u8005\u5fc3\u810f\u5065\u5eb7\u7684\u57fa\u7840\uff0c\u5e76\u4e14\u6613\u4e8e\u83b7\u53d6\u3002\u5c3d\u7ba1\u5982\u6b64\uff0cECG\u6570\u636e\u5728\u68c0\u6d4b\u975e\u5fc3\u810f\u72b6\u51b5\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b\u5374\u9c9c\u5c11\u53d7\u5230\u5173\u6ce8\u3002\u65b9\u6cd5\uff1a\u5728\u6211\u4eec\u7684\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e86\u516c\u5f00\u53ef\u7528\u7684\u6570\u636e\u96c6\uff08MIMIC-IV-ECG-ICD\u548cECG-VIEW II\uff09\u6765\u63a2\u8ba8\u4eceECG\u7279\u5f81\u63a8\u65ad\u4e00\u822c\u8bca\u65ad\u72b6\u51b5\u7684\u53ef\u884c\u6027\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u57fa\u4e8eECG\u7279\u5f81\u548c\u57fa\u672c\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u8bad\u7ec3\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6811\u7684\u6a21\u578b\uff08XGBoost\uff09\uff0c\u4ee5\u4f30\u8ba1\u5e7f\u6cdb\u8303\u56f4\u7684\u8bca\u65ad\uff0c\u5305\u62ec\u5fc3\u810f\u548c\u975e\u5fc3\u810f\u72b6\u51b5\u3002\u7ed3\u679c\uff1a\u6211\u4eec\u7684\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5e7f\u6cdb\u7684\u751f\u7406\u7c7b\u522b\u4e2d\uff0c\u4ee5\u7edf\u8ba1\u5b66\u4e0a\u663e\u8457\u7684\u65b9\u5f0f\uff0c\u53ef\u9760\u5730\u4f30\u8ba1\u4e8623\u79cd\u5fc3\u810f\u72b6\u51b5\u4ee5\u53ca21\u79cd\u975e\u5fc3\u810f\u72b6\u51b5\uff0cAUROC\u503c\u5747\u8d85\u8fc70.7\u3002\u6211\u4eec\u7684\u53d1\u73b0\u5f3a\u8c03\u4e86ECG\u6570\u636e\u5728\u8bc6\u522b\u5df2\u77e5\u5fc3\u810f\u72b6\u51b5\u65b9\u9762\u7684\u9884\u6d4b\u6f5c\u529b\u3002\u7136\u800c\uff0c\u66f4\u4e3a\u5f15\u4eba\u6ce8\u76ee\u7684\u662f\uff0c\u8fd9\u9879\u7814\u7a76\u4ee3\u8868\u4e86\u7cfb\u7edf\u6027\u5730\u6269\u5c55\u57fa\u4e8eECG\u8bca\u65ad\u8303\u56f4\u5230\u4f20\u7edf\u4e0a\u4e0d\u4e0e\u5fc3\u810f\u7cfb\u7edf\u76f8\u5173\u8054\u7684\u72b6\u51b5\u7684\u5f00\u521b\u6027\u52aa\u529b\u3002 Juan Miguel Lopez Alcaraz PDF N/A Estimation of Cardiac and Non-cardiac Diagnosis from Electrocardiogram Features Introduction: Ensuring timely and accurate diagnosis of medical conditions is paramount for effective patient care. Electrocardiogram (ECG) signals are fundamental for evaluating a patient's cardiac health and are readily available. Despite this, little attention has been given to the remarkable potential of ECG data in detecting non-cardiac conditions.   Methods: In our study, we used publicly available datasets (MIMIC-IV-ECG-ICD and ECG-VIEW II) to investigate the feasibility of inferring general diagnostic conditions from ECG features. To this end, we trained a tree-based model (XGBoost) based on ECG features and basic demographic features to estimate a wide range of diagnoses, encompassing both cardiac and non-cardiac conditions.   Results: Our results demonstrate the reliability of estimating 23 cardiac as well as 21 non-cardiac conditions above 0.7 AUROC in a statistically significant manner across a wide range of physiological categories. Our findings underscore the predictive potential of ECG data in identifying well-known cardiac conditions. However, even more striking, this research represents a pioneering effort in systematically expanding the scope of ECG-based diagnosis to conditions not traditionally associated with the cardiac system. ChatGPT\u5bf9\u51dd\u805a\u6001\u7269\u7406\u5b66\u5bb6\u5199\u4f5c\u98ce\u683c\u7684\u5f71\u54cd \u6211\u4eec\u91c7\u7528\u4e86\u4e00\u79cd\u5148\u8fdb\u7684\u5dee\u5f02\u5206\u6790\u65b9\u6cd5\u6765\u8bc4\u4f30ChatGPT\u53d1\u5e03\u5bf9arXiv\u4e0a\u51dd\u805a\u6001\u7269\u7406\u8bba\u6587\u5199\u4f5c\u98ce\u683c\u7684\u5f71\u54cd\u3002\u6211\u4eec\u7684\u5206\u6790\u663e\u793a\uff0c\u975e\u82f1\u8bed\u6bcd\u8bed\u8005\u5728\u64b0\u5199\u6458\u8981\u65f6\uff0c\u82f1\u8bed\u8d28\u91cf\u6709\u4e86\u7edf\u8ba1\u5b66\u610f\u4e49\u4e0a\u7684\u663e\u8457\u63d0\u5347\u3002\u91cd\u8981\u7684\u662f\uff0c\u5373\u4f7f\u5728\u8003\u8651\u4e86\u5176\u4ed6\u6f5c\u5728\u56e0\u7d20\u540e\uff0c\u8fd9\u4e00\u63d0\u5347\u4f9d\u7136\u7a33\u56fa\uff0c\u8bc1\u5b9e\u4e86\u8fd9\u4e00\u53d8\u5316\u53ef\u4ee5\u5f52\u56e0\u4e8eChatGPT\u7684\u53d1\u5e03\u3002\u8fd9\u8868\u660e\u8be5\u5de5\u5177\u5df2\u88ab\u5e7f\u6cdb\u91c7\u7eb3\u3002ChatGPT\u53d1\u5e03\u540e\uff0c\u72ec\u7279\u8bcd\u6c47\u7684\u4f7f\u7528\u663e\u8457\u589e\u52a0\uff0c\u800c\u7f55\u89c1\u8bcd\u6c47\u7684\u4f7f\u7528\u9891\u7387\u5219\u6709\u6240\u4e0b\u964d\u3002\u5728\u4e0d\u540c\u8bed\u7cfb\u4e2d\uff0c\u5199\u4f5c\u98ce\u683c\u7684\u53d8\u5316\u5728\u62c9\u4e01\u8bed\u7cfb\u548c\u4e4c\u62c9\u5c14-\u963f\u5c14\u6cf0\u8bed\u7cfb\u7684\u4f5c\u8005\u4e2d\u5c24\u4e3a\u663e\u8457\uff0c\u800c\u5728\u65e5\u8033\u66fc\u8bed\u7cfb\u6216\u5176\u4ed6\u5370\u6b27\u8bed\u7cfb\u7684\u4f5c\u8005\u4e2d\u5219\u4e0d\u7136\u3002 Shaojun Xu PDF N/A Impact of ChatGPT on the writing style of condensed matter physicists We apply a state-of-the-art difference-in-differences approach to estimate the impact of ChatGPT's release on the writing style of condensed matter papers on arXiv. Our analysis reveals a statistically significant improvement in the English quality of abstracts written by non-native English speakers. Importantly, this improvement remains robust even after accounting for other potential factors, confirming that it can be attributed to the release of ChatGPT. This indicates widespread adoption of the tool. Following the release of ChatGPT, there is a significant increase in the use of unique words, while the frequency of rare words decreases. Across language families, the changes in writing style are significant for authors from the Latin and Ural-Altaic groups, but not for those from the Germanic or other Indo-European groups. \u53d8\u538b\u5668\u4e2d\u7684\u6a21\u5757\u5316\uff1a\u63a2\u7a76\u795e\u7ecf\u5143\u5206\u79bb\u6027\u4e0e\u4e13\u4e1a\u5316 Transformer\u6a21\u578b\u5728\u5404\u79cd\u5e94\u7528\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u7136\u800c\u6211\u4eec\u5bf9\u5176\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u7684\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002\u672c\u6587\u7814\u7a76\u4e86Transformer\u67b6\u6784\u4e2d\u795e\u7ecf\u5143\u7684\u6a21\u5757\u5316\u548c\u4efb\u52a1\u7279\u5316\uff0c\u91cd\u70b9\u5173\u6ce8\u89c6\u89c9\uff08ViT\uff09\u548c\u8bed\u8a00\uff08Mistral 7B\uff09\u6a21\u578b\u3002\u901a\u8fc7\u7ed3\u5408\u9009\u62e9\u6027\u526a\u679d\u548cMoEfication\u805a\u7c7b\u6280\u672f\uff0c\u6211\u4eec\u5206\u6790\u4e86\u4e0d\u540c\u4efb\u52a1\u548c\u6570\u636e\u5b50\u96c6\u4e4b\u95f4\u795e\u7ecf\u5143\u7684\u91cd\u53e0\u548c\u7279\u5316\u60c5\u51b5\u3002\u6211\u4eec\u7684\u7814\u7a76\u53d1\u73b0\uff0c\u5b58\u5728\u4efb\u52a1\u7279\u5b9a\u7684\u795e\u7ecf\u5143\u96c6\u7fa4\uff0c\u76f8\u5173\u4efb\u52a1\u4e4b\u95f4\u5b58\u5728\u4e0d\u540c\u7a0b\u5ea6\u7684\u91cd\u53e0\u3002\u6211\u4eec\u89c2\u5bdf\u5230\uff0c\u5373\u4f7f\u5728\u968f\u673a\u521d\u59cb\u5316\u7684\u6a21\u578b\u4e2d\uff0c\u795e\u7ecf\u5143\u91cd\u8981\u6027\u6a21\u5f0f\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u4e5f\u5f97\u4ee5\u4fdd\u6301\uff0c\u8fd9\u8868\u660e\u5b58\u5728\u4e00\u79cd\u8bad\u7ec3\u6240\u7cbe\u70bc\u7684\u56fa\u6709\u7ed3\u6784\u3002\u6b64\u5916\uff0c\u6211\u4eec\u53d1\u73b0\u901a\u8fc7MoEfication\u8bc6\u522b\u7684\u795e\u7ecf\u5143\u96c6\u7fa4\u5728\u6a21\u578b\u7684\u65e9\u671f\u548c\u665a\u671f\u5c42\u4e2d\u4e0e\u4efb\u52a1\u7279\u5b9a\u7684\u795e\u7ecf\u5143\u6709\u66f4\u5f3a\u7684\u5bf9\u5e94\u5173\u7cfb\u3002\u8fd9\u9879\u5de5\u4f5c\u6709\u52a9\u4e8e\u66f4\u7ec6\u81f4\u5730\u7406\u89e3Transformer\u7684\u5185\u90e8\u673a\u5236\uff0c\u5e76\u4e3a\u63d0\u9ad8\u6a21\u578b\u89e3\u91ca\u6027\u548c\u6548\u7387\u7684\u6f5c\u5728\u9014\u5f84\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002 Nicholas Pochinkov PDF N/A Modularity in Transformers: Investigating Neuron Separability &amp; Specialization Transformer models are increasingly prevalent in various applications, yet our understanding of their internal workings remains limited. This paper investigates the modularity and task specialization of neurons within transformer architectures, focusing on both vision (ViT) and language (Mistral 7B) models. Using a combination of selective pruning and MoEfication clustering techniques, we analyze the overlap and specialization of neurons across different tasks and data subsets. Our findings reveal evidence of task-specific neuron clusters, with varying degrees of overlap between related tasks. We observe that neuron importance patterns persist to some extent even in randomly initialized models, suggesting an inherent structure that training refines. Additionally, we find that neuron clusters identified through MoEfication correspond more strongly to task-specific neurons in earlier and later layers of the models. This work contributes to a more nuanced understanding of transformer internals and offers insights into potential avenues for improving model interpretability and efficiency. \u63a2\u7a76\u6ce8\u610f\u529b\u5934\u4e2d\u795e\u7ecf\u5143\u6d88\u878d\u73b0\u8c61\uff1a\u5cf0\u503c\u6fc0\u6d3b\u4e2d\u5fc3\u5316\u6848\u4f8b \u57fa\u4e8eTransformer\u7684\u6a21\u578b\u5728\u793e\u4f1a\u4e2d\u7684\u5e94\u7528\u6b63\u5728\u8fc5\u901f\u589e\u957f\u3002\u968f\u7740\u8fd9\u79cd\u589e\u957f\uff0c\u7406\u89e3\u5b83\u4eec\u7684\u5de5\u4f5c\u539f\u7406\uff0c\u7279\u522b\u662f\u6ce8\u610f\u529b\u673a\u5236\u5982\u4f55\u8868\u793a\u6982\u5ff5\uff0c\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u5c3d\u7ba1\u5b58\u5728\u8bb8\u591a\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u4f46\u8bb8\u591a\u65b9\u6cd5\u901a\u8fc7\u795e\u7ecf\u5143\u6fc0\u6d3b\u6765\u89c2\u5bdf\u6a21\u578b\uff0c\u800c\u8fd9\u4e9b\u6fc0\u6d3b\u7684\u673a\u5236\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002\u6211\u4eec\u63cf\u8ff0\u4e86\u4e0d\u540c\u7684\u89c6\u89d2\u6765\u89c2\u5bdf\u795e\u7ecf\u5143\u6fc0\u6d3b\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u795e\u7ecf\u5143\u6d88\u878d\u65b9\u6cd5\uff0c\u5373\u96f6\u6d88\u878d\u3001\u5747\u503c\u6d88\u878d\u3001\u6fc0\u6d3b\u91cd\u91c7\u6837\u4ee5\u53ca\u6211\u4eec\u79f0\u4e4b\u4e3a\u201c\u5cf0\u503c\u6d88\u878d\u201d\u7684\u65b0\u65b9\u6cd5\uff0c\u7814\u7a76\u4e86\u5176\u5728\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9Transformer\u4e2d\u7684\u6709\u6548\u6027\u3002\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\uff0c\u6211\u4eec\u53d1\u73b0\uff0c\u5728\u4e0d\u540c\u7684\u6a21\u578b\u548c\u60c5\u51b5\u4e0b\uff0c\u6bcf\u79cd\u65b9\u6cd5\u90fd\u80fd\u5728\u76f8\u6bd4\u5176\u4ed6\u65b9\u6cd5\u4e2d\u63d0\u4f9b\u6700\u4f4e\u7684\u6a21\u578b\u6027\u80fd\u9000\u5316\uff0c\u800c\u91cd\u91c7\u6837\u901a\u5e38\u4f1a\u5bfc\u81f4\u6700\u663e\u8457\u7684\u6027\u80fd\u4e0b\u964d\u3002\u6211\u4eec\u5728https://github.com/nickypro/investigating-ablation\u63d0\u4f9b\u4e86\u6211\u4eec\u7684\u4ee3\u7801\u3002 Nicholas Pochinkov PDF N/A Investigating Neuron Ablation in Attention Heads: The Case for Peak Activation Centering The use of transformer-based models is growing rapidly throughout society. With this growth, it is important to understand how they work, and in particular, how the attention mechanisms represent concepts. Though there are many interpretability methods, many look at models through their neuronal activations, which are poorly understood. We describe different lenses through which to view neuron activations, and investigate the effectiveness in language models and vision transformers through various methods of neural ablation: zero ablation, mean ablation, activation resampling, and a novel approach we term 'peak ablation'. Through experimental analysis, we find that in different regimes and models, each method can offer the lowest degradation of model performance compared to other methods, with resampling usually causing the most significant performance deterioration. We make our code available at https://github.com/nickypro/investigating-ablation. \u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fde\u63a5\u9886\u57df\u77e5\u8bc6\u548c\u8fc7\u7a0b\u53d1\u73b0 \u53d1\u73b0\u826f\u597d\u7684\u8fc7\u7a0b\u6a21\u578b\u5bf9\u4e8e\u5404\u79cd\u8fc7\u7a0b\u5206\u6790\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u5982\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u8fc7\u7a0b\u6539\u8fdb\u3002\u81ea\u52a8\u5316\u7684\u8fc7\u7a0b\u53d1\u73b0\u65b9\u6cd5\u5f80\u5f80\u5ffd\u89c6\u4e86\u5b9d\u8d35\u7684\u9886\u57df\u77e5\u8bc6\u3002\u8fd9\u4e9b\u77e5\u8bc6\uff0c\u5305\u62ec\u9886\u57df\u4e13\u5bb6\u7684\u89c1\u89e3\u548c\u8be6\u7ec6\u7684\u6d41\u7a0b\u6587\u6863\uff0c\u5728\u6d41\u7a0b\u53d1\u73b0\u8fc7\u7a0b\u4e2d\u5f88\u5927\u7a0b\u5ea6\u4e0a\u672a\u88ab\u5229\u7528\u3002\u672c\u6587\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c06\u6b64\u7c7b\u77e5\u8bc6\u76f4\u63a5\u6574\u5408\u5230\u6d41\u7a0b\u53d1\u73b0\u4e2d\u3002\u6211\u4eec\u4f7f\u7528\u4eceLLMs\u4e2d\u63d0\u53d6\u7684\u89c4\u5219\u6765\u6307\u5bfc\u6a21\u578b\u6784\u5efa\uff0c\u786e\u4fdd\u4e0e\u9886\u57df\u77e5\u8bc6\u548c\u5b9e\u9645\u6d41\u7a0b\u6267\u884c\u7684\u4e00\u81f4\u6027\u3002\u901a\u8fc7\u6574\u5408LLMs\uff0c\u6211\u4eec\u5728\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u7684\u6d41\u7a0b\u77e5\u8bc6\u548c\u7a33\u5065\u6d41\u7a0b\u6a21\u578b\u7684\u53d1\u73b0\u4e4b\u95f4\u67b6\u8d77\u4e86\u4e00\u5ea7\u6865\u6881\uff0c\u663e\u8457\u63a8\u8fdb\u4e86\u6d41\u7a0b\u53d1\u73b0\u65b9\u6cd5\u8bba\u3002\u4e3a\u4e86\u5c55\u793a\u6211\u4eec\u6846\u67b6\u7684\u53ef\u7528\u6027\uff0c\u6211\u4eec\u4e0eUWV\u5458\u5de5\u4fdd\u9669\u673a\u6784\u8fdb\u884c\u4e86\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u5176\u5b9e\u9645\u6548\u76ca\u548c\u6709\u6548\u6027\u3002 Ali Norouzifar PDF N/A Bridging Domain Knowledge and Process Discovery Using Large Language Models Discovering good process models is essential for different process analysis tasks such as conformance checking and process improvements. Automated process discovery methods often overlook valuable domain knowledge. This knowledge, including insights from domain experts and detailed process documentation, remains largely untapped during process discovery. This paper leverages Large Language Models (LLMs) to integrate such knowledge directly into process discovery. We use rules derived from LLMs to guide model construction, ensuring alignment with both domain knowledge and actual process executions. By integrating LLMs, we create a bridge between process knowledge expressed in natural language and the discovery of robust process models, advancing process discovery methodologies significantly. To showcase the usability of our framework, we conducted a case study with the UWV employee insurance agency, demonstrating its practical benefits and effectiveness. \u5728\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u4e0b\u8fdb\u884c\u6700\u4f73\u81c2\u8bc6\u522b \u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u516c\u5e73\u6027\u7ea6\u675f\u4e0b\u7684\u6700\u4f73\u81c2\u8bc6\u522b\uff08Best Arm Identification, BAI\uff09\uff0c\u6211\u4eec\u79f0\u4e4b\u4e3a \\textit{F-BAI}\uff08\u516c\u5e73 BAI\uff09\u3002\u4e0e\u4f20\u7edf BAI \u4ec5\u5173\u6ce8\u4ee5\u6700\u5c0f\u6837\u672c\u590d\u6742\u5ea6\u8bc6\u522b\u6700\u4f18\u81c2\u4e0d\u540c\uff0cF-BAI \u8fd8\u5305\u542b\u4e00\u7ec4\u516c\u5e73\u6027\u7ea6\u675f\u3002\u8fd9\u4e9b\u7ea6\u675f\u5bf9\u6bcf\u4e2a\u81c2\u7684\u9009\u62e9\u7387\u8bbe\u5b9a\u4e86\u4e0b\u9650\uff0c\u5e76\u4e14\u53ef\u4ee5\u662f\u6a21\u578b\u65e0\u5173\u7684\u6216\u6a21\u578b\u4f9d\u8d56\u7684\u3002\u9488\u5bf9\u8fd9\u4e00\u8bbe\u5b9a\uff0c\u6211\u4eec\u5efa\u7acb\u4e86\u5b9e\u4f8b\u7279\u5b9a\u7684\u6837\u672c\u590d\u6742\u5ea6\u4e0b\u754c\uff0c\u5e76\u5206\u6790\u4e86 \\textit{\u516c\u5e73\u6027\u4ee3\u4ef7}\uff0c\u91cf\u5316\u4e86\u516c\u5e73\u6027\u5982\u4f55\u5f71\u54cd\u6837\u672c\u590d\u6742\u5ea6\u3002\u57fa\u4e8e\u6837\u672c\u590d\u6742\u5ea6\u4e0b\u754c\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 F-TaS \u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u786e\u4fdd\u6ee1\u8db3\u516c\u5e73\u6027\u7ea6\u675f\u7684\u540c\u65f6\uff0c\u8bc1\u660e\u4e86\u4e0e\u6837\u672c\u590d\u6742\u5ea6\u4e0b\u754c\u5339\u914d\u3002\u901a\u8fc7\u4f7f\u7528\u5408\u6210\u6a21\u578b\u548c\u5b9e\u9645\u65e0\u7ebf\u8c03\u5ea6\u5e94\u7528\u8fdb\u884c\u7684\u6570\u503c\u7ed3\u679c\u663e\u793a\uff0cF-TaS \u5728\u5b9e\u73b0\u4f4e\u516c\u5e73\u6027\u8fdd\u89c4\u7684\u540c\u65f6\uff0c\u6709\u6548\u5730\u6700\u5c0f\u5316\u4e86\u6837\u672c\u590d\u6742\u5ea6\u3002 Alessio Russo PDF N/A Fair Best Arm Identification with Fixed Confidence In this work, we present a novel framework for Best Arm Identification (BAI) under fairness constraints, a setting that we refer to as \\textit{F-BAI} (fair BAI). Unlike traditional BAI, which solely focuses on identifying the optimal arm with minimal sample complexity, F-BAI also includes a set of fairness constraints. These constraints impose a lower limit on the selection rate of each arm and can be either model-agnostic or model-dependent. For this setting, we establish an instance-specific sample complexity lower bound and analyze the \\textit{price of fairness}, quantifying how fairness impacts sample complexity. Based on the sample complexity lower bound, we propose F-TaS, an algorithm provably matching the sample complexity lower bound, while ensuring that the fairness constraints are satisfied. Numerical results, conducted using both a synthetic model and a practical wireless scheduling application, show the efficiency of F-TaS in minimizing the sample complexity while achieving low fairness violations. \u6784\u5efa\u8bad\u7ec3\u7b56\u7565\u4ee5\u901a\u8fc7\u73b0\u5b9e\u56fe\u50cf\u589e\u5f3a\u6765\u5f3a\u5316\u611f\u77e5\u6a21\u578b \u63a8\u8fdb\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u7684\u81ea\u4e3b\u7cfb\u7edf\u611f\u77e5\u6a21\u578b\u9700\u8981\u89e3\u51b3\u6a21\u578b\u4e2d\u7684\u8584\u5f31\u73af\u8282\uff0c\u5c24\u5176\u662f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u64cd\u4f5c\u8bbe\u8ba1\u57df\uff08ODD\uff09\u4e2d\u3002\u8fd9\u4e9b\u662f\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u73af\u5883\u64cd\u4f5c\u6761\u4ef6\uff0c\u53ef\u80fd\u5305\u542b\u56f0\u96be\u7684\u60c5\u51b5\uff0c\u4f8b\u5982\u591c\u95f4\u955c\u5934\u7729\u5149\u6216\u6e7f\u6ed1\u8857\u9053\u4e0a\u7684\u7269\u4f53\u53cd\u5c04\u3002\u672c\u62a5\u544a\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u589e\u5f3a\u6765\u63d0\u9ad8\u6a21\u578b\u5728\u8fd9\u4e9b\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5229\u7528\u5b9a\u5236\u7684\u57fa\u4e8e\u7269\u7406\u7684\u589e\u5f3a\u529f\u80fd\uff0c\u751f\u6210\u6a21\u62df\u591a\u6837ODD\u573a\u666f\u7684\u771f\u5b9e\u8bad\u7ec3\u6570\u636e\u3002 <p>\u6211\u4eec\u63d0\u51fa\u4e00\u4e2a\u5168\u9762\u7684\u6846\u67b6\uff0c\u5305\u62ec\u8bc6\u522bML\u6a21\u578b\u4e2d\u7684\u8584\u5f31\u73af\u8282\u3001\u9009\u62e9\u5408\u9002\u7684\u589e\u5f3a\u65b9\u6cd5\u4ee5\u53ca\u5236\u5b9a\u6709\u6548\u7684\u8bad\u7ec3\u7b56\u7565\u3002\u8be5\u65b9\u6cd5\u96c6\u6210\u4e86\u8d85\u53c2\u6570\u4f18\u5316\u548c\u6f5c\u5728\u7a7a\u95f4\u4f18\u5316\uff0c\u4ee5\u5fae\u8c03\u589e\u5f3a\u53c2\u6570\uff0c\u786e\u4fdd\u5b83\u4eec\u6700\u5927\u9650\u5ea6\u5730\u63d0\u9ad8ML\u6a21\u578b\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u6027\u80fd\u6709\u6240\u63d0\u5347\uff0c\u901a\u8fc7\u5e38\u7528\u7684\u6307\u6807\u5982\u5e73\u5747\u7cbe\u5ea6\uff08mAP\uff09\u548c\u5e73\u5747\u4ea4\u5e76\u6bd4\uff08mIoU\uff09\u8861\u91cf\uff0c\u5728\u5f00\u6e90\u5bf9\u8c61\u68c0\u6d4b\u548c\u8bed\u4e49\u5206\u5272\u6a21\u578b\u53ca\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002</p> <p>\u6211\u4eec\u7684\u7814\u7a76\u5f3a\u8c03\uff0c\u6700\u4f73\u8bad\u7ec3\u7b56\u7565\u662f\u6a21\u578b\u548c\u6570\u636e\u7279\u5b9a\u7684\uff0c\u5e76\u7a81\u51fa\u4e86\u5c06\u589e\u5f3a\u96c6\u6210\u5230\u8bad\u7ec3\u6d41\u7a0b\u4e2d\u7684\u76ca\u5904\u3002\u901a\u8fc7\u52a0\u5165\u589e\u5f3a\uff0c\u6211\u4eec\u89c2\u5bdf\u5230\u57fa\u4e8eML\u7684\u611f\u77e5\u6a21\u578b\u9c81\u68d2\u6027\u589e\u5f3a\uff0c\u4f7f\u5176\u66f4\u80fd\u9002\u5e94\u73b0\u5b9e\u4e16\u754cODD\u4e2d\u9047\u5230\u7684\u8fb9\u7f18\u60c5\u51b5\u3002\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u5b9a\u5236\u589e\u5f3a\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u529f\u80fd\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002 | Ahmed Hammam | PDF | N/A | Structuring a Training Strategy to Robustify Perception Models with Realistic Image Augmentations | Advancing Machine Learning (ML)-based perception models for autonomous systems necessitates addressing weak spots within the models, particularly in challenging Operational Design Domains (ODDs). These are environmental operating conditions of an autonomous vehicle which can contain difficult conditions, e.g., lens flare at night or objects reflected in a wet street. This report introduces a novel methodology for training with augmentations to enhance model robustness and performance in such conditions. The proposed approach leverages customized physics-based augmentation functions, to generate realistic training data that simulates diverse ODD scenarios.   We present a comprehensive framework that includes identifying weak spots in ML models, selecting suitable augmentations, and devising effective training strategies. The methodology integrates hyperparameter optimization and latent space optimization to fine-tune augmentation parameters, ensuring they maximally improve the ML models' performance. Experimental results demonstrate improvements in model performance, as measured by commonly used metrics such as mean Average Precision (mAP) and mean Intersection over Union (mIoU) on open-source object detection and semantic segmentation models and datasets.   Our findings emphasize that optimal training strategies are model- and data-specific and highlight the benefits of integrating augmentations into the training pipeline. By incorporating augmentations, we observe enhanced robustness of ML-based perception models, making them more resilient to edge cases encountered in real-world ODDs. This work underlines the importance of customized augmentations and offers an effective solution for improving the safety and reliability of autonomous driving functions. | | \u671d\u5411\u6587\u5b66\u673a\u5668\u7ffb\u8bd1\u4e2d\u8bcd\u6c47\u591a\u6837\u6027\u7684\u5b9a\u5236\u5316\u6062\u590d | \u673a\u5668\u7ffb\u8bd1\u88ab\u53d1\u73b0\u6bd4\u4eba\u5de5\u7ffb\u8bd1\u5728\u8bcd\u6c47\u4e0a\u66f4\u4e3a\u8d2b\u4e4f\u3002\u673a\u5668\u7ffb\u8bd1\u8fc7\u7a0b\u4e2d\u8bcd\u6c47\u591a\u6837\u6027\u7684\u4e27\u5931\uff0c\u5728\u6587\u5b66\u4f5c\u54c1\u7684\u81ea\u52a8\u7ffb\u8bd1\u4e2d\u6210\u4e3a\u4e00\u4e2a\u95ee\u9898\uff0c\u56e0\u4e3a\u5728\u6587\u5b66\u7ffb\u8bd1\u4e2d\uff0c\u4e0d\u4ec5\u5173\u6ce8\u5199\u4e86\u4ec0\u4e48\uff0c\u8fd8\u5173\u6ce8\u662f\u5982\u4f55\u5199\u7684\u3002\u76ee\u524d\u589e\u52a0\u673a\u5668\u7ffb\u8bd1\u8bcd\u6c47\u591a\u6837\u6027\u7684\u65b9\u6cd5\u8f83\u4e3a\u50f5\u5316\u3002\u7136\u800c\uff0c\u5982\u6211\u4eec\u6240\u5c55\u793a\uff0c\u4e0d\u540c\u5c0f\u8bf4\u4e4b\u95f4\u7684\u8bcd\u6c47\u591a\u6837\u6027\u7a0b\u5ea6\u53ef\u4ee5\u6709\u663e\u8457\u5dee\u5f02\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u4e0d\u518d\u8ffd\u6c42\u50f5\u5316\u5730\u589e\u52a0\u8bcd\u6c47\u591a\u6837\u6027\uff0c\u800c\u662f\u5c06\u4efb\u52a1\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6062\u590d\u673a\u5668\u7ffb\u8bd1\u8fc7\u7a0b\u4e2d\u4e22\u5931\u7684\u5185\u5bb9\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u4e00\u4e2a\u533a\u5206\u539f\u6587\u548c\u7ffb\u8bd1\u6587\u672c\u7684\u5206\u7c7b\u5668\u5bf9\u7ffb\u8bd1\u5019\u9009\u8fdb\u884c\u91cd\u65b0\u6392\u5e8f\u3002\u6211\u4eec\u572831\u672c\u82f1\u8bd1\u8377\u7684\u4e66\u7c4d\u7ffb\u8bd1\u4e0a\u8bc4\u4f30\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u5bf9\u4e8e\u67d0\u4e9b\u4e66\u7c4d\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u6062\u590d\u7684\u8bcd\u6c47\u591a\u6837\u6027\u5f97\u5206\u63a5\u8fd1\u4eba\u5de5\u7ffb\u8bd1\u7684\u6c34\u5e73\u3002 | Esther Ploeger | PDF | N/A | Towards Tailored Recovery of Lexical Diversity in Literary Machine Translation | Machine translations are found to be lexically poorer than human translations. The loss of lexical diversity through MT poses an issue in the automatic translation of literature, where it matters not only what is written, but also how it is written. Current methods for increasing lexical diversity in MT are rigid. Yet, as we demonstrate, the degree of lexical diversity can vary considerably across different novels. Thus, rather than aiming for the rigid increase of lexical diversity, we reframe the task as recovering what is lost in the machine translation process. We propose a novel approach that consists of reranking translation candidates with a classifier that distinguishes between original and translated text. We evaluate our approach on 31 English-to-Dutch book translations, and find that, for certain books, our approach retrieves lexical diversity scores that are close to human translation. | | \u5c06\u57fa\u7ebf2D-CNN\u6a21\u578b\u4e0e\u732b\u7fa4\u4f18\u5316\u6df7\u5408\uff0c\u4ee5\u589e\u5f3a\u9ad8\u7ea7\u6301\u7eed\u5a01\u80c1\u68c0\u6d4b | \u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\uff0c\u7531\u4e8e\u9ad8\u7ea7\u6301\u7eed\u6027\u5a01\u80c1\uff08APT\uff09\u7684\u9690\u853d\u6027\u548c\u590d\u6742\u6027\uff0c\u68c0\u6d4b\u5b83\u4eec\u4ecd\u7136\u662f\u4e00\u4e2a\u8270\u5de8\u7684\u6311\u6218\u3002\u672c\u7814\u7a76\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u5e26\u6709\u4e8c\u7ef4\u57fa\u51c6\u6a21\u578b\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\uff0c\u5e76\u7ed3\u5408\u5c16\u7aef\u7684\u732b\u7fa4\u4f18\u5316\uff08CSO\uff09\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86APT\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u3002\u901a\u8fc7\u5c06\u4e8c\u7ef4CNN\u57fa\u51c6\u6a21\u578b\u4e0eCSO\u65e0\u7f1d\u96c6\u6210\uff0c\u6211\u4eec\u5f00\u542f\u4e86\u5728APT\u68c0\u6d4b\u4e2d\u5b9e\u73b0\u524d\u6240\u672a\u6709\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u6f5c\u529b\u3002\u7ed3\u679c\u663e\u793a\uff0c\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe\u5230\u4e86\u60ca\u4eba\u768498.4%\uff0c\u6807\u5fd7\u7740\u5728\u5404\u79cd\u653b\u51fb\u9636\u6bb5\u4e2dAPT\u68c0\u6d4b\u7684\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u5bf9\u6297\u8fd9\u4e9b\u6301\u7eed\u4e14\u590d\u6742\u7684\u5a01\u80c1\u6307\u660e\u4e86\u524d\u8fdb\u7684\u9053\u8def\u3002 | Ali M. Bakhiet | PDF | N/A | Hybridizing Base-Line 2D-CNN Model with Cat Swarm Optimization for Enhanced Advanced Persistent Threat Detection | In the realm of cyber-security, detecting Advanced Persistent Threats (APTs) remains a formidable challenge due to their stealthy and sophisticated nature. This research paper presents an innovative approach that leverages Convolutional Neural Networks (CNNs) with a 2D baseline model, enhanced by the cutting-edge Cat Swarm Optimization (CSO) algorithm, to significantly improve APT detection accuracy. By seamlessly integrating the 2D-CNN baseline model with CSO, we unlock the potential for unprecedented accuracy and efficiency in APT detection. The results unveil an impressive accuracy score of $98.4\\%$, marking a significant enhancement in APT detection across various attack stages, illuminating a path forward in combating these relentless and sophisticated threats. | | \u5229\u7528\u673a\u5668\u5b66\u4e60\u52a0\u901f\u884c\u661f\u5185\u90e8\u52a8\u529b\u5b66\u7a33\u6001\u7684\u53d1\u73b0 | \u6a21\u62df\u5730\u5e54\u5bf9\u6d41\u901a\u5e38\u9700\u8981\u8fbe\u5230\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u7684\u7a33\u6001\uff0c\u8fd9\u5bf9\u4e8e\u63a8\u5bfc\u70ed\u529b\u5b66\u548c\u52a8\u529b\u5b66\u6d41\u52a8\u7279\u6027\u7684\u6807\u5ea6\u5f8b\u4ee5\u53ca\u57fa\u51c6\u6570\u503c\u89e3\u81f3\u5173\u91cd\u8981\u3002\u5730\u5e54\u5ca9\u77f3\u6d41\u53d8\u6027\u7684\u5f3a\u70c8\u6e29\u5ea6\u4f9d\u8d56\u6027\u5bfc\u81f4\u7c98\u5ea6\u53d8\u5316\u9ad8\u8fbe\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u4ece\u800c\u5f62\u6210\u4e00\u4e2a\u7f13\u6162\u6f14\u5316\u7684\u505c\u6ede\u76d6\u5c42\uff0c\u5176\u4e2d\u70ed\u4f20\u5bfc\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u8986\u76d6\u5728\u4e00\u4e2a\u5feb\u901f\u6f14\u5316\u4e14\u5f3a\u70c8\u5bf9\u6d41\u7684\u533a\u57df\u4e4b\u4e0a\u3002\u5c3d\u7ba1\u65f6\u95f4\u6b65\u8fdb\u65b9\u6cd5\u5bf9\u4e8e\u7c98\u5ea6\u6052\u5b9a\u7684\u6d41\u4f53\u6709\u6548\uff0c\u4f46\u7531\u4e8e\u5e93\u6717\u51c6\u5219\u9650\u5236\u4e86\u65f6\u95f4\u6b65\u957f\u57fa\u4e8e\u7cfb\u7edf\u7684\u6700\u5927\u901f\u5ea6\u548c\u7f51\u683c\u5927\u5c0f\uff0c\u56e0\u6b64\u53d7\u5230\u963b\u788d\u3002\u56e0\u6b64\uff0c\u7531\u4e8e\u63a7\u5236\u505c\u6ede\u548c\u5bf9\u6d41\u533a\u57df\u7684\u622a\u7136\u4e0d\u540c\u7684\u65f6\u95f4\u5c3a\u5ea6\uff0c\u8fbe\u5230\u7a33\u6001\u9700\u8981\u5927\u91cf\u65f6\u95f4\u6b65\u957f\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u673a\u5668\u5b66\u4e60\u52a0\u901f\u5730\u5e54\u5bf9\u6d41\u6a21\u62df\u7684\u6982\u5ff5\u3002\u6211\u4eec\u751f\u6210\u4e86128\u4e2a\u5177\u6709\u6df7\u5408\u57fa\u5e95\u548c\u5185\u90e8\u52a0\u70ed\u4ee5\u53ca\u538b\u529b\u548c\u6e29\u5ea6\u4f9d\u8d56\u7c98\u5ea6\u7684\u4e8c\u7ef4\u6a21\u62df\u6570\u636e\u96c6\u3002\u6211\u4eec\u572897\u4e2a\u6a21\u62df\u4e0a\u8bad\u7ec3\u4e86\u4e00\u4e2a\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u9884\u6d4b\u7a33\u6001\u6e29\u5ea6\u5206\u5e03\u3002\u7136\u540e\u53ef\u4ee5\u5c06\u5176\u7528\u4e8e\u521d\u59cb\u5316\u4e0d\u540c\u6a21\u62df\u53c2\u6570\u7684\u6570\u503c\u65f6\u95f4\u6b65\u8fdb\u65b9\u6cd5\u3002\u4e0e\u5178\u578b\u521d\u59cb\u5316\u76f8\u6bd4\uff0c\u8fbe\u5230\u7a33\u6001\u6240\u9700\u7684\u65f6\u95f4\u6b65\u957f\u6570\u91cf\u51cf\u5c11\u4e86\u4e2d\u4f4d\u6570\u56e0\u5b503.75\u3002\u8fd9\u79cd\u65b9\u6cd5\u7684\u597d\u5904\u5728\u4e8e\u53ea\u9700\u8981\u975e\u5e38\u5c11\u7684\u6a21\u62df\u8fdb\u884c\u8bad\u7ec3\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65e0\u9884\u6d4b\u8bef\u5dee\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u56e0\u4e3a\u6211\u4eec\u521d\u59cb\u5316\u4e86\u4e00\u79cd\u6570\u503c\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u63a8\u7406\u65f6\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\u3002\u6211\u4eec\u5c55\u793a\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u8ba8\u8bba\u4e86\u52a0\u901f\u6a21\u62df\u5bf9\u63a8\u8fdb\u5730\u5e54\u5bf9\u6d41\u7814\u7a76\u7684\u6f5c\u5728\u5f71\u54cd\u3002 | Siddhant Agarwal | PDF | N/A | Accelerating the discovery of steady-states of planetary interior dynamics with machine learning | Simulating mantle convection often requires reaching a computationally expensive steady-state, crucial for deriving scaling laws for thermal and dynamical flow properties and benchmarking numerical solutions. The strong temperature dependence of the rheology of mantle rocks causes viscosity variations of several orders of magnitude, leading to a slow-evolving stagnant lid where heat conduction dominates, overlying a rapidly-evolving and strongly convecting region. Time-stepping methods, while effective for fluids with constant viscosity, are hindered by the Courant criterion, which restricts the time step based on the system's maximum velocity and grid size. Consequently, achieving steady-state requires a large number of time steps due to the disparate time scales governing the stagnant and convecting regions.   We present a concept for accelerating mantle convection simulations using machine learning. We generate a dataset of 128 two-dimensional simulations with mixed basal and internal heating, and pressure- and temperature-dependent viscosity. We train a feedforward neural network on 97 simulations to predict steady-state temperature profiles. These can then be used to initialize numerical time stepping methods for different simulation parameters. Compared to typical initializations, the number of time steps required to reach steady-state is reduced by a median factor of 3.75. The benefit of this method lies in requiring very few simulations to train on, providing a solution with no prediction error as we initialize a numerical method, and posing minimal computational overhead at inference time. We demonstrate the effectiveness of our approach and discuss the potential implications for accelerated simulations for advancing mantle convection research. | | \u5728\u98ce\u9669\u89c4\u907f\u578b\u603b\u5956\u52b1\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDPs\uff09\u4e2d\uff0c\u56fa\u5b9a\u7b56\u7565\u662f\u6700\u4f18\u7684\uff0c\u5176\u4e2d\u4f7f\u7528\u4e86\u671f\u671b\u503c-\u5728\u98ce\u9669\uff08EVaR\uff09\u7684\u5ea6\u91cf\u65b9\u6cd5\u3002 | \u5728\u6298\u6263\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDPs\uff09\u4e2d\u4f18\u5316\u98ce\u9669\u89c4\u907f\u76ee\u6807\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5927\u591a\u6570\u6a21\u578b\u4e0d\u627f\u8ba4\u76f4\u63a5\u7684\u52a8\u6001\u89c4\u5212\u65b9\u7a0b\uff0c\u5e76\u4e14\u9700\u8981\u590d\u6742\u7684\u4f9d\u8d56\u5386\u53f2\u7684\u7b56\u7565\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u8bc1\u660e\u5728\u71b5\u98ce\u9669\u5ea6\u91cf\uff08ERM\uff09\u548c\u71b5\u5728\u9669\u4ef7\u503c\uff08EVaR\uff09\u98ce\u9669\u5ea6\u91cf\u4e0b\uff0c\u98ce\u9669\u89c4\u907f\u7684\u603b\u5956\u52b1\u51c6\u5219\u53ef\u4ee5\u901a\u8fc7\u56fa\u5b9a\u7b56\u7565\u8fdb\u884c\u4f18\u5316\uff0c\u4ece\u800c\u4f7f\u5176\u6613\u4e8e\u5206\u6790\u3001\u89e3\u91ca\u548c\u90e8\u7f72\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u6307\u6570\u503c\u8fed\u4ee3\u3001\u7b56\u7565\u8fed\u4ee3\u548c\u7ebf\u6027\u89c4\u5212\u6765\u8ba1\u7b97\u6700\u4f18\u7b56\u7565\u3002\u4e0e\u5148\u524d\u7684\u5de5\u4f5c\u76f8\u6bd4\uff0c\u6211\u4eec\u7684\u7ed3\u679c\u4ec5\u9700\u8981\u76f8\u5bf9\u6e29\u548c\u7684\u77ac\u6001MDPs\u6761\u4ef6\uff0c\u5e76\u4e14\u5141\u8bb8\u540c\u65f6\u5b58\u5728\u6b63\u8d1f\u5956\u52b1\u3002\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5e7f\u6cdb\u7684\u89c4\u907f\u98ce\u9669\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u4e2d\uff0c\u603b\u5956\u52b1\u51c6\u5219\u53ef\u80fd\u4f18\u4e8e\u6298\u6263\u51c6\u5219\u3002 | Xihong Su | PDF | N/A | Stationary Policies are Optimal in Risk-averse Total-reward MDPs with EVaR | Optimizing risk-averse objectives in discounted MDPs is challenging because most models do not admit direct dynamic programming equations and require complex history-dependent policies. In this paper, we show that the risk-averse {\\em total reward criterion}, under the Entropic Risk Measure (ERM) and Entropic Value at Risk (EVaR) risk measures, can be optimized by a stationary policy, making it simple to analyze, interpret, and deploy. We propose exponential value iteration, policy iteration, and linear programming to compute optimal policies. In comparison with prior work, our results only require the relatively mild condition of transient MDPs and allow for {\\em both} positive and negative rewards. Our results indicate that the total reward criterion may be preferable to the discounted criterion in a broad range of risk-averse reinforcement learning domains. | | \u56fe\u50cf\u4e2d\u7684\u5b8c\u7f8e\u7455\u75b5\uff1a\u5728\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u6f14\u8fdb\u4e4b\u5f71\u4e0b\uff0c\u5b89\u5168\u3001\u504f\u89c1\u4e0e\u771f\u5b9e\u6027\u7684\u8003\u91cf | \u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\uff0c\u5982\u7a33\u5b9a\u6269\u6563\uff08SD\uff09\uff0c\u7ecf\u5386\u8fed\u4ee3\u66f4\u65b0\u4ee5\u63d0\u5347\u56fe\u50cf\u8d28\u91cf\u5e76\u89e3\u51b3\u5982\u5b89\u5168\u6027\u7b49\u5173\u5207\u3002\u56fe\u50cf\u8d28\u91cf\u7684\u6539\u8fdb\u6613\u4e8e\u8bc4\u4f30\u3002\u7136\u800c\uff0c\u6a21\u578b\u66f4\u65b0\u5982\u4f55\u89e3\u51b3\u65e2\u6709\u95ee\u9898\u4ee5\u53ca\u662f\u5426\u5e26\u6765\u65b0\u7684\u7591\u95ee\u4ecd\u5f85\u63a2\u7d22\u3002\u672c\u7814\u7a76\u9996\u6b21\u4ece\u5b89\u5168\u6027\u3001\u504f\u89c1\u548c\u771f\u5b9e\u6027\u89d2\u5ea6\u63a2\u8ba8\u4e86\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7684\u6f14\u53d8\u3002\u4ee5\u7a33\u5b9a\u6269\u6563\u4e3a\u4e2d\u5fc3\u7684\u53d1\u73b0\u8868\u660e\uff0c\u6a21\u578b\u66f4\u65b0\u5448\u73b0\u590d\u6742\u6001\u52bf\u3002\u867d\u7136\u66f4\u65b0\u9010\u6b65\u51cf\u5c11\u4e86\u4e0d\u5b89\u5168\u56fe\u50cf\u7684\u751f\u6210\uff0c\u4f46\u504f\u89c1\u95ee\u9898\uff0c\u5c24\u5176\u662f\u6027\u522b\u504f\u89c1\uff0c\u5374\u6709\u6240\u52a0\u5267\u3002\u6211\u4eec\u8fd8\u53d1\u73b0\uff0c\u8d1f\u9762\u523b\u677f\u5370\u8c61\u8981\u4e48\u5728\u540c\u4e00\u975e\u767d\u4eba\u79cd\u65cf\u7fa4\u4f53\u5185\u6301\u7eed\u5b58\u5728\uff0c\u8981\u4e48\u901a\u8fc7SD\u66f4\u65b0\u8f6c\u5411\u5176\u4ed6\u975e\u767d\u4eba\u79cd\u65cf\u7fa4\u4f53\uff0c\u800c\u8fd9\u4e9b\u7279\u8d28\u4e0e\u767d\u4eba\u79cd\u65cf\u7fa4\u4f53\u7684\u5173\u8054\u751a\u5fae\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u8bc4\u4f30\u63ed\u793a\u4e86SD\u66f4\u65b0\u5f15\u53d1\u7684\u65b0\u95ee\u9898\uff1a\u6700\u521d\u4e3a\u65e9\u671fSD\u7248\u672c\u8bad\u7ec3\u7684\u5c16\u7aef\u5047\u56fe\u50cf\u68c0\u6d4b\u5668\u5728\u8bc6\u522b\u66f4\u65b0\u7248\u672c\u751f\u6210\u7684\u5047\u56fe\u50cf\u65f6\u9047\u5230\u56f0\u96be\u3002\u6211\u4eec\u5c55\u793a\u4e86\uff0c\u5728\u66f4\u65b0\u7248\u672c\u751f\u6210\u7684\u5047\u56fe\u50cf\u4e0a\u5fae\u8c03\u8fd9\u4e9b\u68c0\u6d4b\u5668\uff0c\u80fd\u5728\u591a\u4e2aSD\u7248\u672c\u4e0a\u8fbe\u5230\u81f3\u5c1196.6%\u7684\u51c6\u786e\u7387\uff0c\u4ece\u800c\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\u6211\u4eec\u7684\u89c1\u89e3\u5f3a\u8c03\u4e86\u6301\u7eed\u52aa\u529b\u4ee5\u51cf\u8f7b\u6f14\u5316\u4e2d\u7684\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u504f\u89c1\u548c\u8106\u5f31\u6027\u7684\u91cd\u8981\u6027\u3002 | Yixin Wu | PDF | N/A | Image-Perfect Imperfections: Safety, Bias, and Authenticity in the Shadow of Text-To-Image Model Evolution | Text-to-image models, such as Stable Diffusion (SD), undergo iterative updates to improve image quality and address concerns such as safety. Improvements in image quality are straightforward to assess. However, how model updates resolve existing concerns and whether they raise new questions remain unexplored. This study takes an initial step in investigating the evolution of text-to-image models from the perspectives of safety, bias, and authenticity. Our findings, centered on Stable Diffusion, indicate that model updates paint a mixed picture. While updates progressively reduce the generation of unsafe images, the bias issue, particularly in gender, intensifies. We also find that negative stereotypes either persist within the same Non-White race group or shift towards other Non-White race groups through SD updates, yet with minimal association of these traits with the White race group. Additionally, our evaluation reveals a new concern stemming from SD updates: State-of-the-art fake image detectors, initially trained for earlier SD versions, struggle to identify fake images generated by updated versions. We show that fine-tuning these detectors on fake images generated by updated versions achieves at least 96.6\\% accuracy across various SD versions, addressing this issue. Our insights highlight the importance of continued efforts to mitigate biases and vulnerabilities in evolving text-to-image models. | | \u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7075\u6d3b\u6709\u6548\u5730\u878d\u5165\u9886\u57df\u4e13\u5bb6\u6df7\u5408\u4f53 | \u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u5957\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u4ece\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4e2d\u521b\u5efa\u4f4e\u6210\u672c\u7684\u9886\u57df\u4e13\u5bb6\u6df7\u5408\u4f53\uff08Mixture-of-Domain-Experts, MOE\uff09\u3002\u8be5\u5de5\u5177\u5305\u53ef\u7528\u4e8e\u4ece\u6a21\u578b\u672c\u8eab\u6216\u4ece\u9002\u914d\u5668\u521b\u5efa\u6df7\u5408\u4f53\u3002\u6211\u4eec\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u6d4b\u8bd5\uff0c\u5e76\u5c31\u5982\u4f55\u4f7f\u7528\u8be5\u5de5\u5177\u5305\u5b9a\u4e49\u751f\u6210\u7684MOE\u67b6\u6784\u63d0\u4f9b\u6307\u5bfc\u3002\u6709\u4e00\u4e2a\u516c\u5f00\u7684\u4ee3\u7801\u4ed3\u5e93\u53ef\u4f9b\u4f7f\u7528\u3002 | Rhui Dih Lee | PDF | N/A | Flexible and Effective Mixing of Large Language Models into a Mixture of Domain Experts | We present a toolkit for creating low-cost Mixture-of-Domain-Experts (MOE) from trained models. The toolkit can be used for creating a mixture from models or from adapters. We perform extensive tests and offer guidance on defining the architecture of the resulting MOE using the toolkit. A public repository is available. | | \u6700\u5c0f\u5316\u4e0e\u9ad8\u6548\u901a\u4fe1\u7684\u5206\u5e03\u5f0f\u6700\u4f73\u5b50\u96c6\u9009\u62e9\uff1a\u5177\u5907\u9884\u8a00\u673a\u5c5e\u6027 | \u91d1\u878d\u3001\u7535\u5b50\u5546\u52a1\u548c\u793e\u4ea4\u5a92\u4f53\u7b49\u9886\u57df\u5927\u89c4\u6a21\u6570\u636e\u7684\u7206\u70b8\u6027\u589e\u957f\uff0c\u5df2\u7ecf\u8d85\u51fa\u4e86\u5355\u673a\u7cfb\u7edf\u5904\u7406\u80fd\u529b\u7684\u8303\u7574\uff0c\u4ece\u800c\u63a8\u52a8\u4e86\u5bf9\u5206\u5e03\u5f0f\u7edf\u8ba1\u63a8\u65ad\u65b9\u6cd5\u7684\u9700\u6c42\u3002\u4f20\u7edf\u7684\u5206\u5e03\u5f0f\u63a8\u65ad\u65b9\u6cd5\u5f80\u5f80\u96be\u4ee5\u5728\u9ad8\u7ef4\u6570\u636e\u96c6\u4e2d\u5b9e\u73b0\u771f\u6b63\u7684\u7a00\u758f\u6027\uff0c\u5e76\u4e14\u6d89\u53ca\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e24\u9636\u6bb5\u5206\u5e03\u5f0f\u6700\u4f73\u5b50\u96c6\u9009\u62e9\u7b97\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u9996\u5148\u901a\u8fc7\u9075\u5faa$\\ell_0$\u8303\u6570\u7ea6\u675f\u7684\u4ee3\u7406\u4f3c\u7136\u51fd\u6570\uff0c\u9ad8\u6548\u5730\u4f30\u8ba1\u6d3b\u8dc3\u96c6\uff0c\u4ece\u800c\u6709\u6548\u964d\u4f4e\u7ef4\u5ea6\u5e76\u7b5b\u9009\u51fa\u5173\u952e\u53d8\u91cf\u3002\u968f\u540e\uff0c\u5728\u6d3b\u8dc3\u96c6\u5185\u8fdb\u884c\u7cbe\u7ec6\u4f30\u8ba1\uff0c\u786e\u4fdd\u7a00\u758f\u4f30\u8ba1\u503c\u5e76\u5339\u914d\u6700\u5c0f\u6700\u5927$\\ell_2$\u8bef\u5dee\u754c\u9650\u3002\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u62fc\u63a5\u6280\u672f\u7528\u4e8e\u81ea\u9002\u5e94\u53c2\u6570\u9009\u62e9\uff0c\u4ee5\u5e94\u5bf9\u5728$\\ell_0$\u7ea6\u675f\u548c\u5e7f\u4e49\u4fe1\u606f\u51c6\u5219\uff08GIC\uff09\u4e0b\u7684\u5b50\u95ee\u9898\u3002\u6211\u4eec\u7684\u7406\u8bba\u548c\u6570\u503c\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u6b63\u786e\u53d1\u73b0\u771f\u5b9e\u7684\u7a00\u758f\u6a21\u5f0f\uff0c\u5177\u6709oracle\u5c5e\u6027\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u901a\u4fe1\u6210\u672c\u3002\u8fd9\u662f\u5206\u5e03\u5f0f\u7a00\u758f\u4f30\u8ba1\u9886\u57df\u7684\u4e00\u5927\u8fdb\u6b65\u3002 | Jingguo Lan | PDF | N/A | Minimax and Communication-Efficient Distributed Best Subset Selection with Oracle Property | The explosion of large-scale data in fields such as finance, e-commerce, and social media has outstripped the processing capabilities of single-machine systems, driving the need for distributed statistical inference methods. Traditional approaches to distributed inference often struggle with achieving true sparsity in high-dimensional datasets and involve high computational costs. We propose a novel, two-stage, distributed best subset selection algorithm to address these issues. Our approach starts by efficiently estimating the active set while adhering to the $\\ell_0$ norm-constrained surrogate likelihood function, effectively reducing dimensionality and isolating key variables. A refined estimation within the active set follows, ensuring sparse estimates and matching the minimax $\\ell_2$ error bound. We introduce a new splicing technique for adaptive parameter selection to tackle subproblems under $\\ell_0$ constraints and a Generalized Information Criterion (GIC). Our theoretical and numerical studies show that the proposed algorithm correctly finds the true sparsity pattern, has the oracle property, and greatly lowers communication costs. This is a big step forward in distributed sparse estimation. | | \u4e0b\u91c7\u6837\u7a00\u758f\u56fe\u5377\u79ef\u7f51\u7edc\u7684\u53ef\u8fc1\u79fb\u6027 | \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u968f\u673a\u56fe\u6a21\u578b\u7684\u5927\u89c4\u6a21\u7a00\u758f\u56fe\u964d\u91c7\u6837\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5141\u8bb8\u8c03\u6574\u4e0d\u540c\u7684\u7a00\u758f\u5ea6\u6c34\u5e73\u3002\u6211\u4eec\u5c06\u7a00\u758f\u6027\u548c\u62d3\u6251\u76f8\u4f3c\u6027\u7ed3\u5408\u8d77\u6765\uff1a\u7a00\u758f\u56fe\u6a21\u578b\u968f\u7740\u56fe\u89c4\u6a21\u7684\u589e\u5927\u800c\u964d\u4f4e\u8282\u70b9\u8fde\u63a5\u6982\u7387\uff0c\u800c\u964d\u91c7\u6837\u65b9\u6cd5\u5728\u6b64\u53d8\u5316\u8fc7\u7a0b\u4e2d\u4fdd\u7559\u7279\u5b9a\u7684\u62d3\u6251\u8fde\u63a5\u6a21\u5f0f\u3002\u57fa\u4e8e\u964d\u91c7\u6837\u65b9\u6cd5\uff0c\u6211\u4eec\u63a8\u5bfc\u4e86\u5173\u4e8e\u964d\u91c7\u6837\u7a00\u758f\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCNs\uff09\u7684\u53ef\u8fc1\u79fb\u6027\u754c\u9650\uff0c\u5373\u66f4\u9ad8\u7684\u91c7\u6837\u7387\u3001\u66f4\u5927\u7684\u5e73\u5747\u5ea6\u671f\u671b\u548c\u66f4\u5c0f\u7684\u521d\u59cb\u56fe\u89c4\u6a21\u4f1a\u5e26\u6765\u66f4\u597d\u7684\u964d\u91c7\u6837\u8fc1\u79fb\u6027\u80fd\u3002 | Qinji Shu | PDF | N/A | The Transferability of Downsampling Sparse Graph Convolutional Networks | In this paper, we propose a large-scale sparse graph downsampling method based on a sparse random graph model, which allows for the adjustment of different sparsity levels. We combine sparsity and topological similarity: the sparse graph model reduces the node connection probability as the graph size increases, while the downsampling method preserves a specific topological connection pattern during this change. Based on the downsampling method, we derive a theoretical transferability bound about downsampling sparse graph convolutional networks (GCNs), that higher sampling rates, greater average degree expectations, and smaller initial graph sizes lead to better downsampling transferability performance. | | \u901a\u8fc7\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u6d41\u4f53\u6d41\u52a8\u7684\u65b9\u7a0b\u8bc6\u522b | \u79d1\u5b66\u673a\u5668\u5b66\u4e60\uff08SciML\uff09\u65b9\u6cd5\uff0c\u5982\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\uff0c\u88ab\u7528\u4e8e\u6839\u636e\u63a7\u5236\u65b9\u7a0b\u548c\u5c0f\u91cf\u6570\u636e\u6765\u4f30\u8ba1\u611f\u5174\u8da3\u7684\u53c2\u6570\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u8de8\u5e7f\u6cdb\u7684\u6570\u5b66\u79d1\u5b66\u9886\u57df\u5185\u7684\u63a7\u5236\u65b9\u7a0b\uff0cPINNs\u5728\u9006\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u5982\u4f55\u8fdb\u884c\u8bc4\u4f30\u7684\u7814\u7a76\u8fd8\u5f88\u5c11\u3002\u6211\u4eec\u57fa\u4e8e\u5e26\u6709\u65cb\u8f6c\u6d41\u52a8\u7684\u4e8c\u7ef4Burgers\u65b9\u7a0b\u7684\u53c2\u6570\u626b\u63cf\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u9006PINNs\u57fa\u51c6\u95ee\u9898\u3002\u6211\u4eec\u5c55\u793a\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u5728\u7b2c\u4e00\u548c\u7b2c\u4e8c\u9636\u4f18\u5316\u4e4b\u95f4\u4ea4\u66ff\u8fdb\u884c\uff0c\u8bc1\u660e\u5176\u4f18\u4e8e\u5178\u578b\u7684\u7b2c\u4e00\u9636\u7b56\u7565\u7528\u4e8e\u53c2\u6570\u4f30\u8ba1\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u6765\u63cf\u8ff0PINN\u5728\u9006\u8bbe\u7f6e\u4e2d\u7684\u6709\u6548\u6027\u3002PINNs\u7684\u7269\u7406\u4fe1\u606f\u6b63\u5219\u5316\u4f7f\u5b83\u4eec\u80fd\u591f\u6bd4\u6570\u636e\u9a71\u52a8\u7684\u57fa\u7ebf\u66f4\u6709\u6548\u5730\u5229\u7528\u5c0f\u91cf\u6570\u636e\u3002\u7136\u800c\uff0c\u65e0\u8bba\u662fPINNs\u8fd8\u662f\u57fa\u7ebf\uff0c\u5728\u5904\u7406\u9ad8\u5ea6\u65e0\u7c98\u6d41\u52a8\u65f6\u90fd\u53ef\u80fd\u65e0\u6cd5\u6062\u590d\u53c2\u6570\uff0c\u8fd9\u4fc3\u4f7f\u4e86\u8fdb\u4e00\u6b65\u53d1\u5c55PINN\u65b9\u6cd5\u7684\u9700\u6c42\u3002 | Alexander New | PDF | N/A | Equation identification for fluid flows via physics-informed neural networks | Scientific machine learning (SciML) methods such as physics-informed neural networks (PINNs) are used to estimate parameters of interest from governing equations and small quantities of data. However, there has been little work in assessing how well PINNs perform for inverse problems across wide ranges of governing equations across the mathematical sciences. We present a new and challenging benchmark problem for inverse PINNs based on a parametric sweep of the 2D Burgers' equation with rotational flow. We show that a novel strategy that alternates between first- and second-order optimization proves superior to typical first-order strategies for estimating parameters. In addition, we propose a novel data-driven method to characterize PINN effectiveness in the inverse setting. PINNs' physics-informed regularization enables them to leverage small quantities of data more efficiently than the data-driven baseline. However, both PINNs and the baseline can fail to recover parameters for highly inviscid flows, motivating the need for further development of PINN methods. | | \u57ce\u5e02\u8303\u56f4\u5185\u914d\u9001\u9700\u6c42\u7684\u8054\u5408\u4f30\u8ba1\u4e0e\u9884\u6d4b\uff1a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u56fe\u5b66\u4e60\u65b9\u6cd5 | \u7535\u5b50\u5546\u52a1\u7684\u84ec\u52c3\u53d1\u5c55\u548c\u57ce\u5e02\u5316\u8fdb\u7a0b\u7684\u52a0\u901f\u663e\u8457\u52a0\u5267\u4e86\u57ce\u5e02\u5730\u533a\u7684\u914d\u9001\u64cd\u4f5c\uff0c\u589e\u52a0\u4e86\u914d\u9001\u9700\u6c42\u7684\u6570\u91cf\u548c\u590d\u6742\u6027\u3002\u6570\u636e\u9a71\u52a8\u7684\u9884\u6d4b\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u5229\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u7684\u65b9\u6cd5\uff0c\u5df2\u7ecf\u51fa\u73b0\u6765\u5e94\u5bf9\u8fd9\u4e9b\u57ce\u5e02\u914d\u9001\u9700\u6c42\u7ba1\u7406\u95ee\u9898\u4e2d\u7684\u590d\u6742\u6027\u3002\u4e00\u4e2a\u7279\u522b\u7d27\u8feb\u4e14\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u7684\u95ee\u9898\u662f\u57ce\u5e02\u8303\u56f4\u5185\u914d\u9001\u9700\u6c42\u7684\u8054\u5408\u4f30\u8ba1\u548c\u9884\u6d4b\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u5c06\u8fd9\u4e2a\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u4e00\u4e2a\u57fa\u4e8e\u56fe\u7684\u65f6\u7a7a\u5b66\u4e60\u4efb\u52a1\u3002\u9996\u5148\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u6d88\u606f\u4f20\u9012\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u4ee5\u6355\u6349\u76f8\u5173\u5730\u533a\u9700\u6c42\u6a21\u5f0f\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u5176\u6b21\uff0c\u901a\u8fc7\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u6211\u4eec\u4ece\u975e\u7ed3\u6784\u5316\u7684\u4f4d\u7f6e\u6570\u636e\u4e2d\u63d0\u53d6\u901a\u7528\u5730\u7406\u7a7a\u95f4\u77e5\u8bc6\u7f16\u7801\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u9700\u6c42\u9884\u6d4b\u5668\u4e2d\u3002\u6700\u540e\uff0c\u4e3a\u4e86\u4fc3\u8fdb\u6a21\u578b\u7684\u8de8\u57ce\u5e02\u53ef\u8fc1\u79fb\u6027\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u5f52\u7eb3\u8bad\u7ec3\u65b9\u6848\u3002\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u914d\u9001\u6570\u636e\u96c6\uff08\u5305\u62ec\u4e2d\u56fd\u548c\u7f8e\u56fd\u7684\u516b\u4e2a\u57ce\u5e02\uff09\u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u6211\u4eec\u7684\u6a21\u578b\u5728\u8fd9\u4e9b\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u6a21\u578b\u3002 | Tong Nie | PDF | N/A | Joint Estimation and Prediction of City-wide Delivery Demand: A Large Language Model Empowered Graph-based Learning Approach | The proliferation of e-commerce and urbanization has significantly intensified delivery operations in urban areas, boosting the volume and complexity of delivery demand. Data-driven predictive methods, especially those utilizing machine learning techniques, have emerged to handle these complexities in urban delivery demand management problems. One particularly pressing problem that has not yet been sufficiently studied is the joint estimation and prediction of city-wide delivery demand. To this end, we formulate this problem as a graph-based spatiotemporal learning task. First, a message-passing neural network model is formalized to capture the interaction between demand patterns of associated regions. Second, by exploiting recent advances in large language models, we extract general geospatial knowledge encodings from the unstructured locational data and integrate them into the demand predictor. Last, to encourage the cross-city transferability of the model, an inductive training scheme is developed in an end-to-end routine. Extensive empirical results on two real-world delivery datasets, including eight cities in China and the US, demonstrate that our model significantly outperforms state-of-the-art baselines in these challenging tasks. | | \u901a\u8fc7\u53bb\u566a\u8fdb\u884c\u6676\u4f53\u6027\u8d28\u9884\u6d4b\u7684\u81ea\u76d1\u7763\u5b66\u4e60 | \u7cbe\u786e\u9884\u6d4b\u6676\u4f53\u6750\u6599\u7684\u6027\u8d28\u5bf9\u4e8e\u5b9a\u5411\u53d1\u73b0\u81f3\u5173\u91cd\u8981\uff0c\u800c\u8fd9\u79cd\u9884\u6d4b\u8d8a\u6765\u8d8a\u591a\u5730\u91c7\u7528\u6570\u636e\u9a71\u52a8\u6a21\u578b\u6765\u5b8c\u6210\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u8bb8\u591a\u611f\u5174\u8da3\u7684\u6027\u8d28\uff0c\u5df2\u786e\u5b9a\u7279\u5b9a\u6027\u8d28\u7684\u6750\u6599\u6570\u91cf\u8fdc\u5c11\u4e8e\u5df2\u77e5\u6750\u6599\u7684\u603b\u6570\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u5dee\u5f02\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u7b56\u7565\uff0c\u7528\u4e8e\u6750\u6599\u6027\u8d28\u9884\u6d4b\u3002\u6211\u4eec\u7684\u65b9\u6cd5\uff0c\u5373\u6676\u4f53\u53bb\u566a\u81ea\u76d1\u7763\u5b66\u4e60\uff08CDSSL\uff09\uff0c\u901a\u8fc7\u4e00\u4e2a\u57fa\u4e8e\u5728\u7ed9\u5b9a\u8fd9\u4e9b\u7ed3\u6784\u7684\u6270\u52a8\u7248\u672c\u65f6\u6062\u590d\u6709\u6548\u6750\u6599\u7ed3\u6784\u7684\u9884\u6587\u672c\u4efb\u52a1\uff0c\u5bf9\u9884\u6d4b\u6a21\u578b\uff08\u4f8b\u5982\uff0c\u56fe\u7f51\u7edc\uff09\u8fdb\u884c\u9884\u8bad\u7ec3\u3002\u6211\u4eec\u8bc1\u660e\uff0c\u5728\u4e0d\u540c\u6750\u6599\u7c7b\u578b\u3001\u6027\u8d28\u548c\u6570\u636e\u96c6\u5927\u5c0f\u7684\u60c5\u51b5\u4e0b\uff0cCDSSL\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u672a\u91c7\u7528SSL\u8bad\u7ec3\u7684\u6a21\u578b\u3002 | Alexander New | PDF | N/A | Self-supervised learning for crystal property prediction via denoising | Accurate prediction of the properties of crystalline materials is crucial for targeted discovery, and this prediction is increasingly done with data-driven models. However, for many properties of interest, the number of materials for which a specific property has been determined is much smaller than the number of known materials. To overcome this disparity, we propose a novel self-supervised learning (SSL) strategy for material property prediction. Our approach, crystal denoising self-supervised learning (CDSSL), pretrains predictive models (e.g., graph networks) with a pretext task based on recovering valid material structures when given perturbed versions of these structures. We demonstrate that CDSSL models out-perform models trained without SSL, across material types, properties, and dataset sizes. | | \u5b66\u4e60\u548c\u9a8c\u8bc1\u6700\u5927\u6cf0\u52d2-\u795e\u7ecf\u7f51\u7edc\u674e\u4e9a\u666e\u8bfa\u592b\u51fd\u6570 | \u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u79f0\u4e3a\u6cf0\u52d2\u795e\u7ecf\u674e\u4e9a\u666e\u8bfa\u592b\u51fd\u6570\uff08Taylor-neural Lyapunov functions\uff09\uff0c\u65e8\u5728\u901a\u8fc7\u5f62\u5f0f\u8ba4\u8bc1\u6765\u8fd1\u4f3c\u674e\u4e9a\u666e\u8bfa\u592b\u51fd\u6570\u3002\u8be5\u67b6\u6784\u521b\u65b0\u6027\u5730\u7f16\u7801\u5c40\u90e8\u8fd1\u4f3c\uff0c\u5e76\u901a\u8fc7\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u6765\u8fd1\u4f3c\u6b8b\u5dee\uff0c\u5c06\u8fd9\u4e9b\u5c40\u90e8\u8fd1\u4f3c\u6269\u5c55\u5230\u5168\u5c40\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5c06\u4f30\u8ba1\u6700\u5927\u5438\u5f15\u57df\u7684\u95ee\u9898\u2014\u2014\u7279\u522b\u662f\u9488\u5bf9\u6700\u5927\u674e\u4e9a\u666e\u8bfa\u592b\u51fd\u6570\u2014\u2014\u91cd\u65b0\u6784\u5efa\u6210\u4e00\u4e2a\u5b66\u4e60\u95ee\u9898\uff0c\u786e\u4fdd\u901a\u8fc7\u9c81\u68d2\u63a7\u5236\u7406\u8bba\u5728\u539f\u70b9\u5468\u56f4\u5b9e\u73b0\u6536\u655b\u3002\u7269\u7406\u4fe1\u606f\u9a71\u52a8\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\u8fdb\u4e00\u6b65\u7ec6\u5316\u4e86\u6700\u5927\u5438\u5f15\u57df\u7684\u4f30\u8ba1\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\uff0c\u5373\u4f7f\u5728\u7f3a\u4e4f\u6a21\u62df\u6570\u636e\u70b9\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u6709\u6548\u8fd0\u4f5c\u3002\u6211\u4eec\u901a\u8fc7\u5728\u591a\u4e2a\u793a\u4f8b\u4e2d\u63d0\u4f9b\u6536\u655b\u6027\u7684\u6570\u503c\u8bc1\u4e66\u6765\u9a8c\u8bc1\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u6211\u4eec\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u4e0e\u6700\u5148\u8fdb\u7684\u65b9\u6848\uff08\u5982\u5e73\u65b9\u548c\u4e0eLyZNet\uff09\u7d27\u5bc6\u7ade\u4e89\uff0c\u800c\u4e14\u5728\u6ca1\u6709\u6a21\u62df\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u53d6\u5f97\u53ef\u6bd4\u7684\u7ed3\u679c\u3002\u8fd9\u9879\u5de5\u4f5c\u4ee3\u8868\u4e86\u63a7\u5236\u7406\u8bba\u7684\u91cd\u5927\u8fdb\u5c55\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u4e0d\u4ec5\u9650\u4e8e\u7a33\u5b9a\u63a7\u5236\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3002 | Matthieu Barreau | PDF | N/A | Learning and Verifying Maximal Taylor-Neural Lyapunov functions | We introduce a novel neural network architecture, termed Taylor-neural Lyapunov functions, designed to approximate Lyapunov functions with formal certification. This architecture innovatively encodes local approximations and extends them globally by leveraging neural networks to approximate the residuals. Our method recasts the problem of estimating the largest region of attraction - specifically for maximal Lyapunov functions - into a learning problem, ensuring convergence around the origin through robust control theory. Physics-informed machine learning techniques further refine the estimation of the largest region of attraction. Remarkably, this method is versatile, operating effectively even without simulated data points. We validate the efficacy of our approach by providing numerical certificates of convergence across multiple examples. Our proposed methodology not only competes closely with state-of-the-art approaches, such as sum-of-squares and LyZNet, but also achieves comparable results even in the absence of simulated data. This work represents a significant advancement in control theory, with broad potential applications in the design of stable control systems and beyond. | | \u6df1\u5ea6\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684\u5206\u6b65\u52a0\u6743\u8109\u51b2\u7f16\u7801 | \u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNNs\uff09\u65e8\u5728\u6a21\u62df\u751f\u7269\u795e\u7ecf\u5143\u7684\u8109\u51b2\u884c\u4e3a\uff0c\u5e76\u6709\u671b\u5728\u795e\u7ecf\u8ba1\u7b97\u548c\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\u4e2d\u626e\u6f14\u5173\u952e\u89d2\u8272\u3002SNNs\u7684\u6548\u7387\u901a\u5e38\u7531\u795e\u7ecf\u7f16\u7801\u65b9\u6848\u51b3\u5b9a\u3002\u73b0\u6709\u7684\u7f16\u7801\u65b9\u6848\u8981\u4e48\u5bfc\u81f4\u5de8\u5927\u7684\u5ef6\u8fdf\u548c\u80fd\u91cf\u6d88\u8017\uff0c\u8981\u4e48\u9700\u8981\u590d\u6742\u7684\u795e\u7ecf\u5143\u6a21\u578b\u548c\u8bad\u7ec3\u6280\u672f\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9010\u6b65\u52a0\u6743\u8109\u51b2\uff08SWS\uff09\u7f16\u7801\u65b9\u6848\uff0c\u4ee5\u589e\u5f3a\u8109\u51b2\u4e2d\u7684\u4fe1\u606f\u7f16\u7801\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u795e\u7ecf\u8ba1\u7b97\u7684\u6bcf\u4e00\u6b65\u4e2d\u5bf9\u8109\u51b2\u7684\u91cd\u8981\u6027\u8fdb\u884c\u52a0\u6743\u6765\u538b\u7f29\u8109\u51b2\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u548c\u4f4e\u80fd\u8017\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u9759\u9ed8\u671f\u7684\u4e09\u5143\u81ea\u653e\u5927\uff08TSA\uff09\u795e\u7ecf\u5143\u6a21\u578b\uff0c\u4ee5\u652f\u6301\u57fa\u4e8eSWS\u7684\u8ba1\u7b97\uff0c\u65e8\u5728\u6700\u5c0f\u5316\u795e\u7ecf\u8ba1\u7b97\u4e2d\u9010\u6b65\u52a0\u6743\u4ea7\u751f\u7684\u6b8b\u4f59\u8bef\u5dee\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSWS\u7f16\u7801\u65b9\u6848\u5728\u975e\u5e38\u6df1\u7684SNNs\u4e2d\u4f18\u4e8e\u73b0\u6709\u7684\u795e\u7ecf\u7f16\u7801\u65b9\u6848\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u64cd\u4f5c\u548c\u5ef6\u8fdf\u3002 | Yiwen Gu | PDF | N/A | Stepwise Weighted Spike Coding for Deep Spiking Neural Networks | Spiking Neural Networks (SNNs) seek to mimic the spiking behavior of biological neurons and are expected to play a key role in the advancement of neural computing and artificial intelligence. The efficiency of SNNs is often determined by the neural coding schemes. Existing coding schemes either cause huge delays and energy consumption or necessitate intricate neuron models and training techniques. To address these issues, we propose a novel Stepwise Weighted Spike (SWS) coding scheme to enhance the encoding of information in spikes. This approach compresses the spikes by weighting the significance of the spike in each step of neural computation, achieving high performance and low energy consumption. A Ternary Self-Amplifying (TSA) neuron model with a silent period is proposed for supporting SWS-based computing, aimed at minimizing the residual error resulting from stepwise weighting in neural computation. Our experimental results show that the SWS coding scheme outperforms the existing neural coding schemes in very deep SNNs, and significantly reduces operations and latency. | | \u5206\u7c7b\u6570\u636e\u805a\u7c7b\uff1a\u8d85\u8d8aK-modes\u768425\u5e74\u53d1\u5c55 | \u5206\u7c7b\u6570\u636e\u805a\u7c7b\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\u4e00\u9879\u5e38\u89c1\u4e14\u91cd\u8981\u7684\u4efb\u52a1\uff0c\u5b83\u5728\u4f17\u591a\u5e94\u7528\u9886\u57df\u4e2d\u5177\u6709\u6df1\u8fdc\u7684\u610f\u4e49\u3002\u4e0e\u7eaf\u6570\u503c\u6570\u636e\u96c6\u4e0d\u540c\uff0c\u5206\u7c7b\u6570\u636e\u5f80\u5f80\u7f3a\u4e4f\u50cf\u540d\u4e49\u6570\u636e\u90a3\u6837\u7684\u56fa\u6709\u987a\u5e8f\uff0c\u6216\u50cf\u6709\u5e8f\u6570\u636e\u90a3\u6837\u5177\u6709\u4e0d\u540c\u5c42\u6b21\u7684\u987a\u5e8f\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u7684\u805a\u7c7b\u65b9\u6cd5\u6765\u8fdb\u884c\u6709\u6548\u7684\u7ec4\u7ec7\u548c\u5206\u6790\u3002\u672c\u7bc7\u7efc\u8ff0\u4eceK-modes\u7b97\u6cd5\u7684\u5f15\u5165\u5f00\u59cb\uff0c\u5168\u9762\u603b\u7ed3\u4e86\u8fc7\u53bb\u4e8c\u5341\u4e94\u5e74\u4e2d\u5206\u7c7b\u6570\u636e\u805a\u7c7b\u7684\u7814\u7a76\u8fdb\u5c55\u3002\u5b83\u9610\u660e\u4e86\u5206\u7c7b\u6570\u636e\u805a\u7c7b\u5728\u5065\u5eb7\u79d1\u5b66\u3001\u81ea\u7136\u79d1\u5b66\u3001\u793e\u4f1a\u79d1\u5b66\u3001\u6559\u80b2\u3001\u5de5\u7a0b\u548c\u7ecf\u6d4e\u7b49\u4f17\u591a\u9886\u57df\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002\u5bf9\u5177\u6709\u516c\u5f00\u5b9e\u73b0\u7b97\u6cd5\u7684\u5b9e\u9645\u6bd4\u8f83\u5206\u6790\uff0c\u7a81\u51fa\u4e86\u4e0d\u540c\u7684\u805a\u7c7b\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86\u8fd1\u671f\u7b97\u6cd5\u5728\u82e5\u5e72\u57fa\u51c6\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002\u6700\u540e\uff0c\u63a2\u8ba8\u4e86\u8be5\u9886\u57df\u9762\u4e34\u7684\u6311\u6218\u4e0e\u673a\u9047\u3002 | Tai Dinh | PDF | N/A | Categorical data clustering: 25 years beyond K-modes | The clustering of categorical data is a common and important task in computer science, offering profound implications across a spectrum of applications. Unlike purely numerical datasets, categorical data often lack inherent ordering as in nominal data, or have varying levels of order as in ordinal data, thus requiring specialized methodologies for efficient organization and analysis. This review provides a comprehensive synthesis of categorical data clustering in the past twenty-five years, starting from the introduction of K-modes. It elucidates the pivotal role of categorical data clustering in diverse fields such as health sciences, natural sciences, social sciences, education, engineering and economics. Practical comparisons are conducted for algorithms having public implementations, highlighting distinguishing clustering methodologies and revealing the performance of recent algorithms on several benchmark categorical datasets. Finally, challenges and opportunities in the field are discussed. | | \u5229\u7528\u91cf\u5b50\u6c42\u89e3\u6df1\u5ea6\u73bb\u5c14\u5179\u66fc\u673a\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u6570\u636e\u6548\u7387 | \u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\uff0c\u4f8b\u5982\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u4f7f\u7528\u7684\u90a3\u4e9b\uff0c\u901a\u5e38\u9700\u8981\u5927\u91cf\u6570\u636e\u624d\u80fd\u6709\u6548\u8bad\u7ec3\u3002\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u6570\u636e\u7684\u53ef\u7528\u6027\u5e76\u4e0d\u662f\u4e00\u4e2a\u91cd\u5927\u95ee\u9898\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u67d0\u4e9b\u60c5\u5883\uff0c\u4f8b\u5982\u5728\u81ea\u4e3b\u7f51\u7edc\u9632\u5fa1\u4e2d\uff0c\u6211\u4eec\u9700\u8981\u6570\u636e\u9ad8\u6548\u7684\u65b9\u6cd5\u3002\u6700\u8fd1\uff0c\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u548c\u73bb\u5c14\u5179\u66fc\u673a\u5df2\u88ab\u63d0\u51fa\u4f5c\u4e3a\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u7684\u65b9\u6848\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u5728\u73b0\u6709\u5de5\u4f5c\u7684\u57fa\u7840\u4e0a\uff0c\u5c06\u6df1\u5ea6\u73bb\u5c14\u5179\u66fc\u673a\u7684\u5e94\u7528\u6269\u5c55\u5230\u5f3a\u5316\u5b66\u4e60\u7f51\u7edc\u9632\u5fa1\u73af\u5883\u4e2d\u7684\u524d\u6cbf\u7b97\u6cd5\u2014\u2014\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u3002\u6211\u4eec\u5c55\u793a\uff0c\u5f53\u4f7f\u7528D-WAVE\u91cf\u5b50\u9000\u706b\u5668\u89e3\u51b3\u65f6\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u5bfc\u81f4\u6570\u636e\u6548\u7387\u7684\u53cc\u500d\u63d0\u5347\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9884\u671f\u5b83\u5c06\u88ab\u673a\u5668\u5b66\u4e60\u548c\u91cf\u5b50\u793e\u533a\u91c7\u7528\uff0c\u4ed6\u4eec\u5e0c\u671b\u5229\u7528\u6570\u636e\u9ad8\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6765\u83b7\u5f97\u4f18\u52bf\u3002 | Daniel Kent | PDF | N/A | Using Quantum Solved Deep Boltzmann Machines to Increase the Data Efficiency of RL Agents | Deep Learning algorithms, such as those used in Reinforcement Learning, often require large quantities of data to train effectively. In most cases, the availability of data is not a significant issue. However, for some contexts, such as in autonomous cyber defence, we require data efficient methods. Recently, Quantum Machine Learning and Boltzmann Machines have been proposed as solutions to this challenge. In this work we build upon the pre-existing work to extend the use of Deep Boltzmann Machines to the cutting edge algorithm Proximal Policy Optimisation in a Reinforcement Learning cyber defence environment. We show that this approach, when solved using a D-WAVE quantum annealer, can lead to a two-fold increase in data efficiency. We therefore expect it to be used by the machine learning and quantum communities who are hoping to capitalise on data-efficient Reinforcement Learning methods. | | \u57fa\u4e8eAI\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff08IDS\uff09\u5728ROAD\u6570\u636e\u96c6\u4e0a\u7684\u6bd4\u8f83\u5206\u6790\uff1a\u9488\u5bf9\u6c7d\u8f66\u63a7\u5236\u5668\u5c40\u57df\u7f51\u7edc\uff08CAN\uff09 | \u73b0\u4ee3\u8f66\u8f86\u4e2d\u6570\u5b57\u8bbe\u5907\u7684\u6574\u5408\u5f7b\u5e95\u6539\u53d8\u4e86\u6c7d\u8f66\u6280\u672f\uff0c\u63d0\u5347\u4e86\u5b89\u5168\u6027\u548c\u6574\u4f53\u9a7e\u9a76\u4f53\u9a8c\u3002\u63a7\u5236\u5668\u5c40\u57df\u7f51\u7edc\uff08CAN\uff09\u603b\u7ebf\u662f\u7ba1\u7406\u8f66\u8f86\u5185\u7535\u5b50\u63a7\u5236\u5355\u5143\uff08ECU\uff09\u95f4\u901a\u4fe1\u7684\u6838\u5fc3\u7cfb\u7edf\u3002\u7136\u800c\uff0c\u7531\u4e8eCAN\u534f\u8bae\u56fa\u6709\u7684\u8106\u5f31\u6027\uff0c\u7f3a\u4e4f\u52a0\u5bc6\u548c\u8ba4\u8bc1\u673a\u5236\uff0c\u52a0\u4e4b\u653b\u51fb\u9762\u7684\u4e0d\u65ad\u6269\u5927\uff0c\u9700\u8981\u5f3a\u6709\u529b\u7684\u5b89\u5168\u63aa\u65bd\u3002\u9488\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u5df2\u7ecf\u5f00\u53d1\u5e76\u90e8\u7f72\u4e86\u591a\u79cd\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff08IDS\uff09\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u73b0\u6709\u6587\u732e\u4e2d\u4ecd\u7f3a\u4e4f\u4e00\u4e2a\u5f00\u653e\u3001\u5168\u9762\u4e14\u771f\u5b9e\u7684\u6d4b\u8bd5IDS\u6709\u6548\u6027\u7684\u6570\u636e\u96c6\u3002\u672c\u6587\u901a\u8fc7\u8003\u8651\u6700\u65b0\u7684ROAD\u6570\u636e\u96c6\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u4e86\u9690\u79d8\u4e14\u590d\u6742\u7684\u6ce8\u5165\u653b\u51fb\u3002\u7814\u7a76\u65b9\u6cd5\u6d89\u53ca\u6570\u636e\u96c6\u6807\u8bb0\u4ee5\u53ca\u5b9e\u65bd\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u548c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4ee5\u5c55\u793a\u6587\u732e\u4e2d\u6700\u5e38\u7528\u7684\u6570\u636e\u96c6\u4e0e\u66f4\u771f\u5b9e\u7684ROAD\u6570\u636e\u96c6\u4e4b\u95f4\u5728\u6027\u80fd\u4e0a\u7684\u5dee\u5f02\u3002 | Lorenzo Guerra | PDF | N/A | AI-Driven Intrusion Detection Systems (IDS) on the ROAD dataset: A Comparative Analysis for automotive Controller Area Network (CAN) | The integration of digital devices in modern vehicles has revolutionized automotive technology, enhancing safety and the overall driving experience. The Controller Area Network (CAN) bus is a central system for managing in-vehicle communication between the electronic control units (ECUs). However, the CAN protocol poses security challenges due to inherent vulnerabilities, lacking encryption and authentication, which, combined with an expanding attack surface, necessitates robust security measures. In response to this challenge, numerous Intrusion Detection Systems (IDS) have been developed and deployed. Nonetheless, an open, comprehensive, and realistic dataset to test the effectiveness of such IDSs remains absent in the existing literature. This paper addresses this gap by considering the latest ROAD dataset, containing stealthy and sophisticated injections. The methodology involves dataset labelling and the implementation of both state-of-the-art deep learning models and traditional machine learning models to show the discrepancy in performance between the datasets most commonly used in the literature and the ROAD dataset, a more realistic alternative. | | \u95ea\u7535\u81ea\u6ce8\u610f\u529b\u51e0\u4f55\uff1a\u53ef\u8bc6\u522b\u6027\u4e0e\u7ef4\u5ea6 | \u6211\u4eec\u8003\u8651\u7531\u672a\u7ecf\u5f52\u4e00\u5316\u7684\u81ea\u6ce8\u610f\u529b\u7f51\u7edc\u5b9a\u4e49\u7684\u51fd\u6570\u7a7a\u95f4\uff0c\u5e76\u4ece\u7406\u8bba\u4e0a\u5206\u6790\u5176\u51e0\u4f55\u7ed3\u6784\u3002\u7531\u4e8e\u8fd9\u4e9b\u7f51\u7edc\u662f\u591a\u9879\u5f0f\u7684\uff0c\u6211\u4eec\u501f\u52a9\u4ee3\u6570\u51e0\u4f55\u7684\u5de5\u5177\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u901a\u8fc7\u63cf\u8ff0\u4efb\u610f\u5c42\u6570\u7684\u53c2\u6570\u5316\u901a\u7528\u7ea4\u7ef4\uff0c\u7814\u7a76\u4e86\u6df1\u5ea6\u6ce8\u610f\u529b\u7684\u53ef\u8bc6\u522b\u6027\uff0c\u5e76\u7531\u6b64\u8ba1\u7b97\u4e86\u51fd\u6570\u7a7a\u95f4\u7684\u7ef4\u5ea6\u3002\u6b64\u5916\uff0c\u5bf9\u4e8e\u5355\u5c42\u6a21\u578b\uff0c\u6211\u4eec\u523b\u753b\u4e86\u5947\u5f02\u70b9\u548c\u8fb9\u754c\u70b9\u3002\u6700\u540e\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u5c06\u6211\u4eec\u7684\u7ed3\u679c\u63a8\u5e7f\u5230\u5f52\u4e00\u5316\u81ea\u6ce8\u610f\u529b\u7f51\u7edc\u7684\u731c\u60f3\uff0c\u4e3a\u5355\u5c42\u60c5\u51b5\u63d0\u4f9b\u4e86\u8bc1\u660e\uff0c\u5e76\u5728\u6df1\u5ea6\u60c5\u51b5\u4e0b\u8fdb\u884c\u4e86\u6570\u503c\u9a8c\u8bc1\u3002 | Nathan W. Henry | PDF | N/A | Geometry of Lightning Self-Attention: Identifiability and Dimension | We consider function spaces defined by self-attention networks without normalization, and theoretically analyze their geometry. Since these networks are polynomial, we rely on tools from algebraic geometry. In particular, we study the identifiability of deep attention by providing a description of the generic fibers of the parametrization for an arbitrary number of layers and, as a consequence, compute the dimension of the function space. Additionally, for a single-layer model, we characterize the singular and boundary points. Finally, we formulate a conjectural extension of our results to normalized self-attention networks, prove it for a single layer, and numerically verify it in the deep case. | | \u5728\u975e\u6d32\u666e\u53ca\u4eba\u5de5\u667a\u80fd\uff1a\u9762\u5411\u4f4e\u8d44\u6e90\u8fb9\u7f18\u8bbe\u5907\u7684\u8054\u90a6\u5b66\u4e60 | \u975e\u6d32\u5728\u533b\u7597\u4fdd\u5065\u670d\u52a1\u65b9\u9762\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u4e3b\u8981\u6e90\u4e8e\u57fa\u7840\u8bbe\u65bd\u6709\u9650\u548c\u7f3a\u4e4f\u5148\u8fdb\u7684\u533b\u7597\u6280\u672f\u3002\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5229\u7528\u8054\u90a6\u5b66\u4e60\u6765\u514b\u670d\u8fd9\u4e9b\u969c\u788d\uff0c\u7279\u522b\u662f\u9488\u5bf9\u56f4\u4ea7\u671f\u5065\u5eb7\u9886\u57df\u3002\u6211\u4eec\u5229\u7528\u6765\u81ea\u4e94\u4e2a\u975e\u6d32\u56fd\u5bb6\uff08\u963f\u5c14\u53ca\u5229\u4e9a\u3001\u52a0\u7eb3\u3001\u57c3\u53ca\u3001\u9a6c\u62c9\u7ef4\u548c\u4e4c\u5e72\u8fbe\uff09\u4ee5\u53ca\u897f\u73ed\u7259\u533b\u9662\u7684\u56f4\u4ea7\u671f\u6570\u636e\uff0c\u8bad\u7ec3\u4e86\u4e00\u4e2a\u80ce\u513f\u5e73\u9762\u5206\u7c7b\u5668\u3002\u4e3a\u4e86\u8003\u8651\u5230\u8ba1\u7b97\u8d44\u6e90\u7684\u532e\u4e4f\uff0c\u6211\u4eec\u5728\u6a21\u578b\u8bad\u7ec3\u4e2d\u91c7\u7528\u4e86\u591a\u79cd\u8bbe\u5907\uff0c\u5305\u62ec\u6811\u8393\u6d3e\u548c\u591a\u53f0\u7b14\u8bb0\u672c\u7535\u8111\u3002\u5c3d\u7ba1\u5b58\u5728\u8ba1\u7b97\u9650\u5236\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u96c6\u4e2d\u5f0f\u6a21\u578b\u4e0e\u8054\u90a6\u6a21\u578b\u4e4b\u95f4\u7684\u6027\u80fd\u6bd4\u8f83\uff0c\u5e76\u4e14\u4e0e\u4ec5\u5728\u672c\u5730\u8bad\u7ec3\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u8054\u90a6\u6a21\u578b\u5728\u6a21\u578b\u6cdb\u5316\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u672a\u6765\u6709\u671b\u5927\u89c4\u6a21\u5b9e\u65bd\u8054\u90a6\u5b66\u4e60\u5e73\u53f0\uff0c\u4ee5\u5f25\u5408\u53ef\u53ca\u6027\u5dee\u8ddd\u5e76\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u800c\u6240\u9700\u7684\u6761\u4ef6\u6781\u4e3a\u6709\u9650\u3002 | Jorge Fabila | PDF | N/A | Democratizing AI in Africa: FL for Low-Resource Edge Devices | Africa faces significant challenges in healthcare delivery due to limited infrastructure and access to advanced medical technologies. This study explores the use of federated learning to overcome these barriers, focusing on perinatal health. We trained a fetal plane classifier using perinatal data from five African countries: Algeria, Ghana, Egypt, Malawi, and Uganda, along with data from Spanish hospitals. To incorporate the lack of computational resources in the analysis, we considered a heterogeneous set of devices, including a Raspberry Pi and several laptops, for model training. We demonstrate comparative performance between a centralized and a federated model, despite the compute limitations, and a significant improvement in model generalizability when compared to models trained only locally. These results show the potential for a future implementation at a large scale of a federated learning platform to bridge the accessibility gap and improve model generalizability with very little requirements. | | \u671d\u7740\u7b26\u53f7\u5316\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u2014\u2014 \u901a\u8fc7\u7279\u5f81\u95f4\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u903b\u8f91\u5173\u7cfb\u8fdb\u884c\u89e3\u91ca | \u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u5728\u4fc3\u8fdbAI\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u65b9\u9762\u626e\u6f14\u7740\u81f3\u5173\u91cd\u8981\u7684\u89d2\u8272\u3002\u4f20\u7edf\u7684XAI\u65b9\u6cd5\u901a\u5e38\u63d0\u4f9b\u4e00\u4e2a\u62bd\u8c61\u5c42\u6b21\u7684\u89e3\u91ca\uff0c\u8fd9\u4e9b\u89e3\u91ca\u5f80\u5f80\u4ee5\u70ed\u56fe\u7684\u5f62\u5f0f\u7a81\u51fa\u663e\u793a\u5355\u4e2a\u6216\u591a\u4e2a\u8f93\u5165\u7279\u5f81\u3002\u7136\u800c\uff0c\u6211\u4eec\u63a2\u8ba8\u4e86\u6a21\u578b\u7684\u62bd\u8c61\u63a8\u7406\u6216\u95ee\u9898\u89e3\u51b3\u7b56\u7565\u662f\u5426\u540c\u6837\u91cd\u8981\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u66f4\u63a5\u8fd1\u4eba\u7c7b\u89e3\u51b3\u95ee\u9898\u7684\u65b9\u5f0f\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u7b26\u53f7XAI\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u76f8\u5173\u6027\u5f52\u56e0\u4e8e\u8868\u8fbe\u8f93\u5165\u7279\u5f81\u4e4b\u95f4\u903b\u8f91\u5173\u7cfb\u7684\u7b26\u53f7\u67e5\u8be2\uff0c\u4ece\u800c\u6355\u6349\u6a21\u578b\u9884\u6d4b\u80cc\u540e\u7684\u62bd\u8c61\u63a8\u7406\u3002\u8be5\u65b9\u6cd5\u5efa\u7acb\u5728\u6a21\u578b\u9884\u6d4b\u7684\u7b80\u5355\u800c\u901a\u7528\u7684\u591a\u9636\u5206\u89e3\u57fa\u7840\u4e0a\u3002\u8fd9\u79cd\u5206\u89e3\u53ef\u4ee5\u901a\u8fc7\u57fa\u4e8e\u9ad8\u9636\u4f20\u64ad\u7684\u76f8\u5173\u6027\u65b9\u6cd5\uff08\u5982GNN-LRP\uff09\u6216XAI\u4e2d\u5e38\u7528\u7684\u57fa\u4e8e\u6270\u52a8\u7684\u89e3\u91ca\u65b9\u6cd5\u6765\u5177\u4f53\u5316\u3002\u6211\u4eec\u7684\u6846\u67b6\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u3001\u89c6\u89c9\u548c\u91cf\u5b50\u5316\u5b66\uff08QC\uff09\u7b49\u9886\u57df\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\uff0c\u8fd9\u4e9b\u9886\u57df\u62e5\u6709\u4e30\u5bcc\u7684\u62bd\u8c61\u7b26\u53f7\u9886\u57df\u77e5\u8bc6\uff0c\u5bf9\u7528\u6237\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u7b26\u53f7XAI\u6846\u67b6\u63d0\u4f9b\u4e86\u5bf9\u6a21\u578b\u51b3\u7b56\u8fc7\u7a0b\u7684\u7406\u89e3\uff0c\u65e2\u53ef\u4ee5\u6839\u636e\u7528\u6237\u9700\u6c42\u8fdb\u884c\u5b9a\u5236\uff0c\u53c8\u901a\u8fc7\u903b\u8f91\u516c\u5f0f\u4fdd\u6301\u4eba\u7c7b\u53ef\u8bfb\u6027\u3002 | Thomas Schnake | PDF | N/A | Towards Symbolic XAI -- Explanation Through Human Understandable Logical Relationships Between Features | Explainable Artificial Intelligence (XAI) plays a crucial role in fostering transparency and trust in AI systems, where traditional XAI approaches typically offer one level of abstraction for explanations, often in the form of heatmaps highlighting single or multiple input features. However, we ask whether abstract reasoning or problem-solving strategies of a model may also be relevant, as these align more closely with how humans approach solutions to problems. We propose a framework, called Symbolic XAI, that attributes relevance to symbolic queries expressing logical relationships between input features, thereby capturing the abstract reasoning behind a model's predictions. The methodology is built upon a simple yet general multi-order decomposition of model predictions. This decomposition can be specified using higher-order propagation-based relevance methods, such as GNN-LRP, or perturbation-based explanation methods commonly used in XAI. The effectiveness of our framework is demonstrated in the domains of natural language processing (NLP), vision, and quantum chemistry (QC), where abstract symbolic domain knowledge is abundant and of significant interest to users. The Symbolic XAI framework provides an understanding of the model's decision-making process that is both flexible for customization by the user and human-readable through logical formulas. | | \u57fa\u4e8e\u6df7\u5408LSSVM-SVMD\u65b9\u6cd5\u7684\u667a\u80fd\u7535\u7f51\u77ed\u671f\u98ce\u901f\u9884\u6d4b\u4e0e\u529f\u7387\u96c6\u6210 | \u7531\u4e8e\u5176\u6781\u4f4e\u7684\u6c61\u67d3\u548c\u9ad8\u6548\u7684\u80fd\u6e90\u5229\u7528\uff0c\u98ce\u80fd\u5df2\u6210\u4e3a\u6700\u5e7f\u6cdb\u5f00\u53d1\u7684\u53ef\u518d\u751f\u80fd\u6e90\u4e4b\u4e00\u3002\u6210\u529f\u5c06\u98ce\u7535\u5e76\u5165\u7535\u7f51\u7cfb\u7edf\u53d6\u51b3\u4e8e\u51c6\u786e\u7684\u98ce\u901f\u9884\u6d4b\u6a21\u578b\u3002\u7136\u800c\uff0c\u98ce\u901f\u9884\u6d4b\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u98ce\u901f\u672c\u8eab\u5177\u6709\u95f4\u6b47\u6027\u7279\u5f81\u3002\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u6df7\u5408\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6765\u9884\u6d4b\u77ed\u671f\u98ce\u901f\u3002\u9996\u5148\uff0c\u4f7f\u7528\u8fde\u7eed\u53d8\u5206\u6a21\u6001\u5206\u89e3\uff08SVMD\uff09\u5c06\u98ce\u6570\u636e\u5206\u89e3\u4e3a\u6a21\u6001\u5206\u91cf\u3002\u7136\u540e\uff0c\u6bcf\u4e2a\u5b50\u4fe1\u53f7\u88ab\u62df\u5408\u5230\u6700\u5c0f\u4e8c\u4e58\u652f\u6301\u5411\u91cf\u673a\uff08LSSVM\uff09\u6a21\u578b\u4e2d\uff0c\u5176\u8d85\u53c2\u6570\u901a\u8fc7\u91cf\u5b50\u884c\u4e3a\u7c92\u5b50\u7fa4\u4f18\u5316\uff08QPSO\uff09\u7684\u65b0\u53d8\u4f53\u2014\u2014\u7cbe\u82f1\u7e41\u6b96QPSO\uff08EBQPSO\uff09\u8fdb\u884c\u4f18\u5316\u3002\u5176\u6b21\uff0c\u7528\u4e8e\u5f25\u8865\u539f\u59cb\u98ce\u901f\u5e8f\u5217\u4e0eSVMD\u6a21\u6001\u603b\u548c\u4e4b\u95f4\u5dee\u5f02\u7684\u6b8b\u5dee\uff0c\u4f7f\u7528\u957f\u77ed\u671f\u8bb0\u5fc6\u6a21\u578b\uff08LSTM\uff09\u8fdb\u884c\u5efa\u6a21\u3002\u7136\u540e\uff0c\u5229\u7528LSSVM\u548cLSTM\u6a21\u578b\u7684\u603b\u548c\u8ba1\u7b97\u6574\u4f53\u9884\u6d4b\u503c\u3002\u6700\u540e\uff0c\u5c06\u6240\u63d0\u51fa\u7684\u6a21\u578b\u4e0e\u4ece\u5f53\u5730\u98ce\u7535\u573a\u6536\u96c6\u7684\u4e24\u4e2a\u72ec\u7acb\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u98ce\u901f\u9884\u6d4b\u7684\u6700\u5148\u8fdb\u57fa\u51c6\u6a21\u578b\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\u3002\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e0e\u57fa\u51c6\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5b9e\u73b0\u4e861.21%\u81f332.76%\u7684\u5747\u65b9\u6839\u8bef\u5dee\uff08RMSE\uff09\u964d\u4f4e\u548c2.05%\u81f340.75%\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u964d\u4f4e\u3002\u8fd9\u9879\u5de5\u4f5c\u7684\u5168\u90e8\u4ee3\u7801\u5b9e\u73b0\u5728Github\u4e0a\u514d\u8d39\u63d0\u4f9b\u3002 | Ephrem Admasu Yekun | PDF | N/A | Short-term Wind Speed Forecasting for Power Integration in Smart Grids based on Hybrid LSSVM-SVMD Method | Owing to its minimal pollution and efficient energy use, wind energy has become one of the most widely exploited renewable energy resources. The successful integration of wind power into the grid system is contingent upon accurate wind speed forecasting models. However, the task of wind speed forecasting is challenging due to the inherent intermittent characteristics of wind speed. In this paper, a hybrid machine learning approach is developed for predicting short-term wind speed. First, the wind data was decomposed into modal components using Successive Variational Mode Decomposition (SVMD). Then, each sub-signal was fitted into a Least Squares Support Vector Machines (LSSVM) model, with its hyperparameter optimized by a novel variant of Quantum-behaved Particle Swarm Optimization (QPSO), QPSO with elitist breeding (EBQPSO). Second, the residuals making up for the differences between the original wind series and the aggregate of the SVMD modes were modeled using long short-term model (LSTM). Then, the overall predicted values were computed using the aggregate of the LSSVM and the LSTM models. Finally, the performance of the proposed model was compared against state-of-the-art benchmark models for forecasting wind speed using two separate data sets collected from a local wind farm. Empirical results show significant improvement in performance by the proposed method, achieving a 1.21% to 32.76% reduction in root mean square error (RMSE) and a 2.05% to 40.75% reduction in mean average error (MAE) compared to the benchmark methods. The entire code implementation of this work is freely available in Github. | | \u6539\u8fdb\u4ece\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u63d0\u53d6\u4e34\u5e8a\u4e8b\u4ef6\u4e0a\u4e0b\u6587\u5c5e\u6027\u7684\u65b9\u6cd5\uff1a\u4e00\u9879\u6bd4\u8f83\u7814\u7a76 | \u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u662f\u5305\u542b\u5927\u91cf\u6709\u4ef7\u503c\u4e34\u5e8a\u6570\u636e\u7684\u5927\u578b\u5b58\u50a8\u5e93\uff0c\u5176\u4e2d\u5f88\u5927\u4e00\u90e8\u5206\u4ee5\u975e\u7ed3\u6784\u5316\u6587\u672c\u683c\u5f0f\u5b58\u50a8\u3002\u8fd9\u4e9b\u6587\u672c\u6570\u636e\u5305\u62ec\u4e34\u5e8a\u4e8b\u4ef6\uff08\u4f8b\u5982\uff0c\u75be\u75c5\u3001\u75c7\u72b6\u3001\u53d1\u73b0\u3001\u836f\u7269\u548c\u7a0b\u5e8f\uff09\uff0c\u5982\u679c\u80fd\u591f\u5927\u89c4\u6a21\u51c6\u786e\u63d0\u53d6\uff0c\u5c06\u80fd\u591f\u89e3\u9501\u6709\u4ef7\u503c\u7684\u4e0b\u6e38\u5e94\u7528\uff0c\u5982\u75be\u75c5\u9884\u6d4b\u3002\u4f7f\u7528\u73b0\u6709\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u94fe\u63a5\u65b9\u6cd5\uff0cMedCAT\uff0c\u8fd9\u4e9b\u8bc6\u522b\u7684\u6982\u5ff5\u9700\u8981\u8fdb\u4e00\u6b65\u5206\u7c7b\uff08\u4e0a\u4e0b\u6587\u5316\uff09\uff0c\u4ee5\u8bc4\u4f30\u5176\u5bf9\u60a3\u8005\u7684\u76f8\u5173\u6027\uff0c\u4ee5\u53ca\u5b83\u4eec\u7684\u65f6\u95f4\u72b6\u6001\u548c\u5426\u5b9a\u72b6\u6001\uff0c\u4ee5\u4fbf\u5728\u4e0b\u6e38\u5e94\u7528\u4e2d\u53d1\u6325\u4f5c\u7528\u3002\u672c\u7814\u7a76\u5bf9\u591a\u79cd\u81ea\u7136\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u6587\u672c\u5206\u7c7b\u65b9\u9762\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u7279\u522b\u662fBERT\uff0c\u5177\u6709\u663e\u8457\u7684\u6709\u6548\u6027\u3002\u5f53\u7ed3\u5408\u7c7b\u522b\u4e0d\u5e73\u8861\u7f13\u89e3\u6280\u672f\u65f6\uff0cBERT\u5728\u5c11\u6570\u7c7b\u522b\u7684\u53ec\u56de\u7387\u4e0a\u6bd4Bi-LSTM\u6a21\u578b\u9ad8\u51fa\u6700\u591a28%\uff0c\u6bd4\u57fa\u51c6BERT\u6a21\u578b\u9ad8\u51fa\u6700\u591a16%\u3002\u8be5\u65b9\u6cd5\u5df2\u4f5c\u4e3aCogStack/MedCAT\u6846\u67b6\u7684\u4e00\u90e8\u5206\u5b9e\u65bd\uff0c\u5e76\u5411\u793e\u533a\u5f00\u653e\uff0c\u4f9b\u8fdb\u4e00\u6b65\u7814\u7a76\u4f7f\u7528\u3002 | Shubham Agarwal | PDF | N/A | Improving Extraction of Clinical Event Contextual Properties from Electronic Health Records: A Comparative Study | Electronic Health Records are large repositories of valuable clinical data, with a significant portion stored in unstructured text format. This textual data includes clinical events (e.g., disorders, symptoms, findings, medications and procedures) in context that if extracted accurately at scale can unlock valuable downstream applications such as disease prediction. Using an existing Named Entity Recognition and Linking methodology, MedCAT, these identified concepts need to be further classified (contextualised) for their relevance to the patient, and their temporal and negated status for example, to be useful downstream. This study performs a comparative analysis of various natural language models for medical text classification. Extensive experimentation reveals the effectiveness of transformer-based language models, particularly BERT. When combined with class imbalance mitigation techniques, BERT outperforms Bi-LSTM models by up to 28% and the baseline BERT model by up to 16% for recall of the minority classes. The method has been implemented as part of CogStack/MedCAT framework and made available to the community for further research. | | \u8bc6\u522b\u548c\u805a\u7c7bPvP\u6e38\u620f\u4e2d\u961f\u4f0d\u6784\u6210\u7684\u5bf9\u6297\u5173\u7cfb\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u5e73\u8861\u5206\u6790 | \u5982\u4f55\u5728\u6e38\u620f\u8bbe\u7f6e\u4e2d\u91cf\u5316\u5e73\u8861\uff1f\u8fd9\u4e00\u95ee\u9898\u5bf9\u6e38\u620f\u8bbe\u8ba1\u5e08\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u73a9\u5bb6\u5bf9\u73a9\u5bb6\uff08PvP\uff09\u6e38\u620f\u4e2d\uff0c\u5206\u6790\u9884\u5b9a\u4e49\u56e2\u961f\u7ec4\u5408\u4e4b\u95f4\u7684\u529b\u91cf\u5173\u7cfb\u2014\u2014\u5982\u591a\u4eba\u5728\u7ebf\u6218\u6597\u7ade\u6280\u573a\uff08MOBA\uff09\u6e38\u620f\u4e2d\u7684\u82f1\u96c4\u7ec4\u5408\u6216\u5361\u724c\u6e38\u620f\u4e2d\u7684\u5957\u724c\u2014\u2014\u5bf9\u4e8e\u63d0\u5347\u6e38\u620f\u4f53\u9a8c\u548c\u5b9e\u73b0\u5e73\u8861\u81f3\u5173\u91cd\u8981\u3002\u6211\u4eec\u5f00\u53d1\u4e86\u4e24\u79cd\u9ad8\u7ea7\u5ea6\u91cf\u65b9\u6cd5\uff0c\u8d85\u8d8a\u4e86\u7b80\u5355\u7684\u80dc\u7387\uff0c\u7528\u4e8e\u91cf\u5316\u96f6\u548c\u7ade\u4e89\u573a\u666f\u4e2d\u7684\u5e73\u8861\u3002\u8fd9\u4e9b\u5ea6\u91cf\u65b9\u6cd5\u6e90\u81ea\u80dc\u4ef7\u503c\u4f30\u8ba1\uff0c\u901a\u8fc7\u91c7\u7528\u5e03\u62c9\u5fb7\u5229-\u7279\u91cc\u6a21\u578b\u8fdb\u884c\u5f3a\u5ea6\u8bc4\u7ea7\u8fd1\u4f3c\u548c\u901a\u8fc7\u5411\u91cf\u91cf\u5316\u8fdb\u884c\u5bf9\u6297\u5173\u7cfb\u8fd1\u4f3c\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4e0e\u4f20\u7edf\u80dc\u4ef7\u503c\u4f30\u8ba1\u76f8\u5173\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002\u5728\u8fd9\u4e9b\u6a21\u578b\u7684\u5b66\u4e60\u8fc7\u7a0b\u4e2d\uff0c\u6211\u4eec\u8bc6\u522b\u4e86\u6709\u7528\u7684\u7ec4\u5408\u7c7b\u522b\u5e76\u6307\u51fa\u4e86\u5b83\u4eec\u7684\u5bf9\u6297\u5173\u7cfb\uff0c\u4e0e\u4eba\u7c7b\u73a9\u5bb6\u7684\u4f53\u9a8c\u76f8\u7b26\uff0c\u800c\u65e0\u9700\u7279\u5b9a\u6e38\u620f\u77e5\u8bc6\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4e00\u79cd\u7b80\u5355\u6280\u672f\uff0c\u901a\u8fc7\u786e\u5b9a\u6027\u5411\u91cf\u91cf\u5316\u8fc7\u7a0b\uff0c\u5728\u6781\u5c0f\u72b6\u6001\u7a7a\u95f4\u7684\u79bb\u6563\u8868\u793a\u4e2d\u589e\u5f3a\u7801\u672c\u5229\u7528\u7387\u3002\u6211\u4eec\u7684\u6846\u67b6\u5df2\u5728\u591a\u6b3e\u70ed\u95e8\u5728\u7ebf\u6e38\u620f\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u5305\u62ec\u300a\u5e1d\u56fd\u65f6\u4ee3II\u300b\u3001\u300a\u7089\u77f3\u4f20\u8bf4\u300b\u3001\u300a\u8352\u91ce\u4e71\u6597\u300b\u548c\u300a\u82f1\u96c4\u8054\u76df\u300b\u3002\u5728\u8fd9\u4e9b\u6e38\u620f\u4e2d\u89c2\u5bdf\u5230\u7684\u5f3a\u5ea6\u5173\u7cfb\u51c6\u786e\u6027\u4e0e\u4f20\u7edf\u6210\u5bf9\u80dc\u4ef7\u503c\u9884\u6d4b\u76f8\u5f53\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u66f4\u6613\u4e8e\u7ba1\u7406\u7684\u5206\u6790\u590d\u6742\u6027\u3002\u6700\u7ec8\uff0c\u6211\u4eec\u7684\u7814\u7a76\u6210\u679c\u52a0\u6df1\u4e86\u5bf9PvP\u6e38\u620f\u52a8\u6001\u7684\u7406\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u663e\u8457\u6539\u8fdb\u6e38\u620f\u5e73\u8861\u8bc4\u4f30\u4e0e\u8bbe\u8ba1\u7684\u65b9\u6cd5\u3002 | Chiu-Chou Lin | PDF | N/A | Identifying and Clustering Counter Relationships of Team Compositions in PvP Games for Efficient Balance Analysis | How can balance be quantified in game settings? This question is crucial for game designers, especially in player-versus-player (PvP) games, where analyzing the strength relations among predefined team compositions-such as hero combinations in multiplayer online battle arena (MOBA) games or decks in card games-is essential for enhancing gameplay and achieving balance. We have developed two advanced measures that extend beyond the simplistic win rate to quantify balance in zero-sum competitive scenarios. These measures are derived from win value estimations, which employ strength rating approximations via the Bradley-Terry model and counter relationship approximations via vector quantization, significantly reducing the computational complexity associated with traditional win value estimations. Throughout the learning process of these models, we identify useful categories of compositions and pinpoint their counter relationships, aligning with the experiences of human players without requiring specific game knowledge. Our methodology hinges on a simple technique to enhance codebook utilization in discrete representation with a deterministic vector quantization process for an extremely small state space. Our framework has been validated in popular online games, including Age of Empires II, Hearthstone, Brawl Stars, and League of Legends. The accuracy of the observed strength relations in these games is comparable to traditional pairwise win value predictions, while also offering a more manageable complexity for analysis. Ultimately, our findings contribute to a deeper understanding of PvP game dynamics and present a methodology that significantly improves game balance evaluation and design. | | \u7f16\u89e3\u7801\u5668\u786e\u5b9e\u91cd\u8981\uff1a\u63a2\u7a76\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u4e2d\u7f16\u89e3\u7801\u5668\u7684\u8bed\u4e49\u7f3a\u9677 | \u8fd1\u5e74\u6765\uff0c\u97f3\u9891\u751f\u6210\u9886\u57df\u7684\u8fdb\u5c55\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u5f97\u76ca\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u80fd\u529b\u3002\u73b0\u6709\u5173\u4e8e\u97f3\u9891LLM\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u589e\u5f3a\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u7684\u67b6\u6784\u548c\u89c4\u6a21\uff0c\u5229\u7528\u66f4\u5927\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4e14\u901a\u5e38\u4f7f\u7528\u58f0\u5b66\u7f16\u89e3\u7801\u5668\uff0c\u5982EnCodec\uff0c\u6765\u8fdb\u884c\u97f3\u9891\u6807\u8bb0\u5316\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u7f16\u89e3\u7801\u5668\u6700\u521d\u8bbe\u8ba1\u7528\u4e8e\u97f3\u9891\u538b\u7f29\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u5728\u97f3\u9891LLM\u7684\u80cc\u666f\u4e0b\u6027\u80fd\u4e0d\u4f73\u3002\u6211\u4eec\u7684\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5f53\u524d\u97f3\u9891LLM\u7f16\u89e3\u7801\u5668\u7684\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5b83\u4eec\u5728\u751f\u6210\u97f3\u9891\u4e2d\u4fdd\u6301\u8bed\u4e49\u5b8c\u6574\u6027\u65b9\u9762\u7684\u6311\u6218\u3002\u4f8b\u5982\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u5982VALL-E\uff0c\u5728\u6839\u636e\u6587\u672c\u8f6c\u5f55\u6761\u4ef6\u751f\u6210\u58f0\u5b66\u6807\u8bb0\u65f6\uff0c\u5e38\u5e38\u56e0\u58f0\u5b66\u6807\u8bb0\u7684\u8bed\u4e49\u8bef\u89e3\u800c\u5bfc\u81f4\u5185\u5bb9\u4e0d\u51c6\u786e\u548c\u5355\u8bcd\u9519\u8bef\u7387\uff08WER\uff09\u4e0a\u5347\uff0c\u51fa\u73b0\u8df3\u8bcd\u548c\u9519\u8bef\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u76f4\u63a5\u800c\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3aX-Codec\u3002X-Codec\u5728\u6b8b\u5dee\u5411\u91cf\u91cf\u5316\uff08RVQ\uff09\u9636\u6bb5\u4e4b\u524d\u7ed3\u5408\u4e86\u9884\u8bad\u7ec3\u8bed\u4e49\u7f16\u7801\u5668\u7684\u8bed\u4e49\u7279\u5f81\uff0c\u5e76\u5728RVQ\u4e4b\u540e\u5f15\u5165\u4e86\u8bed\u4e49\u91cd\u5efa\u635f\u5931\u3002\u901a\u8fc7\u589e\u5f3a\u7f16\u89e3\u7801\u5668\u7684\u8bed\u4e49\u80fd\u529b\uff0cX-Codec\u663e\u8457\u964d\u4f4e\u4e86\u8bed\u97f3\u5408\u6210\u4efb\u52a1\u4e2d\u7684WER\uff0c\u5e76\u5c06\u8fd9\u4e9b\u4f18\u52bf\u6269\u5c55\u5230\u975e\u8bed\u97f3\u5e94\u7528\uff0c\u5305\u62ec\u97f3\u4e50\u548c\u58f0\u97f3\u751f\u6210\u3002\u6211\u4eec\u5728\u6587\u672c\u5230\u8bed\u97f3\u3001\u97f3\u4e50\u5ef6\u7eed\u548c\u6587\u672c\u5230\u58f0\u97f3\u4efb\u52a1\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6574\u5408\u8bed\u4e49\u4fe1\u606f\u663e\u8457\u63d0\u9ad8\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u97f3\u9891\u751f\u6210\u4e2d\u7684\u6574\u4f53\u6027\u80fd\u3002\u6211\u4eec\u7684\u4ee3\u7801\u548c\u6f14\u793a\u5df2\u516c\u5f00\uff08\u6f14\u793a\uff1ahttps://x-codec-audio.github.io \u4ee3\u7801\uff1ahttps://github.com/zhenye234/xcodec\uff09\u3002 | Zhen Ye | PDF | N/A | Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model | Recent advancements in audio generation have been significantly propelled by the capabilities of Large Language Models (LLMs). The existing research on audio LLM has primarily focused on enhancing the architecture and scale of audio language models, as well as leveraging larger datasets, and generally, acoustic codecs, such as EnCodec, are used for audio tokenization. However, these codecs were originally designed for audio compression, which may lead to suboptimal performance in the context of audio LLM. Our research aims to address the shortcomings of current audio LLM codecs, particularly their challenges in maintaining semantic integrity in generated audio. For instance, existing methods like VALL-E, which condition acoustic token generation on text transcriptions, often suffer from content inaccuracies and elevated word error rates (WER) due to semantic misinterpretations of acoustic tokens, resulting in word skipping and errors. To overcome these issues, we propose a straightforward yet effective approach called X-Codec. X-Codec incorporates semantic features from a pre-trained semantic encoder before the Residual Vector Quantization (RVQ) stage and introduces a semantic reconstruction loss after RVQ. By enhancing the semantic ability of the codec, X-Codec significantly reduces WER in speech synthesis tasks and extends these benefits to non-speech applications, including music and sound generation. Our experiments in text-to-speech, music continuation, and text-to-sound tasks demonstrate that integrating semantic information substantially improves the overall performance of language models in audio generation. Our code and demo are available (Demo: https://x-codec-audio.github.io Code: https://github.com/zhenye234/xcodec) | | SafeTail\uff1a\u901a\u8fc7\u8ba1\u7b97\u5197\u4f59\u7ba1\u7406\u5b9e\u73b0\u8fb9\u7f18\u670d\u52a1\u8c03\u5ea6\u4e2d\u7684\u9ad8\u6548\u5c3e\u90e8\u5ef6\u8fdf\u4f18\u5316 | \u5728\u8fb9\u7f18\u8ba1\u7b97\u4e2d\uff0c\u4f18\u5316\u5c3e\u90e8\u5ef6\u8fdf\u540c\u65f6\u9ad8\u6548\u7ba1\u7406\u8ba1\u7b97\u8d44\u6e90\u5bf9\u4e8e\u63d0\u4f9b\u9ad8\u6027\u80fd\u3001\u5ef6\u8fdf\u654f\u611f\u7684\u670d\u52a1\u81f3\u5173\u91cd\u8981\u3002\u65b0\u5174\u5e94\u7528\uff0c\u5982\u589e\u5f3a\u73b0\u5b9e\uff0c\u8981\u6c42\u5728\u7528\u6237\u8bbe\u5907\u4e0a\u63d0\u4f9b\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u53ef\u9760\u6027\u7684\u8ba1\u7b97\u670d\u52a1\uff0c\u800c\u8fd9\u4e9b\u8bbe\u5907\u5f80\u5f80\u8ba1\u7b97\u80fd\u529b\u6709\u9650\u3002\u56e0\u6b64\uff0c\u8fd9\u4e9b\u8bbe\u5907\u4f9d\u8d56\u9644\u8fd1\u7684\u8fb9\u7f18\u670d\u52a1\u5668\u8fdb\u884c\u5904\u7406\u3002\u7136\u800c\uff0c\u7531\u4e8e\u65e0\u7ebf\u7f51\u7edc\u7684\u53ef\u53d8\u6027\u548c\u670d\u52a1\u5668\u8d1f\u8f7d\u7684\u6ce2\u52a8\uff0c\u7f51\u7edc\u548c\u8ba1\u7b97\u5ef6\u8fdf\u5b58\u5728\u56fa\u6709\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4f7f\u5f97\u6309\u65f6\u4ea4\u4ed8\u670d\u52a1\u53d8\u5f97\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u901a\u5e38\u4e13\u6ce8\u4e8e\u4f18\u5316\u4e2d\u4f4d\u5ef6\u8fdf\uff0c\u4f46\u5728\u89e3\u51b3\u8fb9\u7f18\u73af\u5883\u4e2d\u5c3e\u90e8\u5ef6\u8fdf\u7684\u5177\u4f53\u6311\u6218\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u7f51\u7edc\u548c\u8ba1\u7b97\u6761\u4ef6\u4e0d\u786e\u5b9a\u7684\u60c5\u51b5\u4e0b\u3002\u5c3d\u7ba1\u4e00\u4e9b\u65b9\u6cd5\u786e\u5b9e\u89e3\u51b3\u4e86\u5c3e\u90e8\u5ef6\u8fdf\u95ee\u9898\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u4f9d\u8d56\u4e8e\u56fa\u5b9a\u6216\u8fc7\u5ea6\u7684\u5197\u4f59\uff0c\u7f3a\u4e4f\u5bf9\u52a8\u6001\u7f51\u7edc\u6761\u4ef6\u7684\u9002\u5e94\u6027\uff0c\u5e76\u4e14\u5f80\u5f80\u662f\u4e3a\u4e91\u73af\u5883\u8bbe\u8ba1\u7684\uff0c\u800c\u4e0d\u662f\u9488\u5bf9\u8fb9\u7f18\u8ba1\u7b97\u7684\u72ec\u7279\u9700\u6c42\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86SafeTail\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u540c\u65f6\u6ee1\u8db3\u4e2d\u4f4d\u548c\u5c3e\u90e8\u54cd\u5e94\u65f6\u95f4\u76ee\u6807\uff0c\u5176\u4e2d\u5c3e\u90e8\u5ef6\u8fdf\u5b9a\u4e49\u4e3a\u8d85\u8fc7\u7b2c90\u767e\u5206\u4f4d\u9608\u503c\u7684\u5ef6\u8fdf\u3002SafeTail\u901a\u8fc7\u5728\u591a\u4e2a\u8fb9\u7f18\u670d\u52a1\u5668\u4e0a\u9009\u62e9\u6027\u590d\u5236\u670d\u52a1\u6765\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u4ee5\u6ee1\u8db3\u76ee\u6807\u5ef6\u8fdf\u3002SafeTail\u91c7\u7528\u57fa\u4e8e\u5956\u52b1\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u6765\u5b66\u4e60\u6700\u4f18\u653e\u7f6e\u7b56\u7565\uff0c\u5e73\u8861\u5b9e\u73b0\u76ee\u6807\u5ef6\u8fdf\u548c\u6700\u5c0f\u5316\u989d\u5916\u8d44\u6e90\u4f7f\u7528\u7684\u9700\u6c42\u3002\u901a\u8fc7\u8ddf\u8e2a\u9a71\u52a8\u7684\u6a21\u62df\uff0cSafeTail\u5c55\u793a\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\uff0c\u5e76\u5728\u4e09\u79cd\u4e0d\u540c\u670d\u52a1\u4e2d\u4f18\u4e8e\u5927\u591a\u6570\u57fa\u7ebf\u7b56\u7565\u3002 | Jyoti Shokhanda | PDF | N/A | SafeTail: Efficient Tail Latency Optimization in Edge Service Scheduling via Computational Redundancy Management | Optimizing tail latency while efficiently managing computational resources is crucial for delivering high-performance, latency-sensitive services in edge computing. Emerging applications, such as augmented reality, require low-latency computing services with high reliability on user devices, which often have limited computational capabilities. Consequently, these devices depend on nearby edge servers for processing. However, inherent uncertainties in network and computation latencies stemming from variability in wireless networks and fluctuating server loads make service delivery on time challenging. Existing approaches often focus on optimizing median latency but fall short of addressing the specific challenges of tail latency in edge environments, particularly under uncertain network and computational conditions. Although some methods do address tail latency, they typically rely on fixed or excessive redundancy and lack adaptability to dynamic network conditions, often being designed for cloud environments rather than the unique demands of edge computing. In this paper, we introduce SafeTail, a framework that meets both median and tail response time targets, with tail latency defined as latency beyond the 90^th percentile threshold. SafeTail addresses this challenge by selectively replicating services across multiple edge servers to meet target latencies. SafeTail employs a reward-based deep learning framework to learn optimal placement strategies, balancing the need to achieve target latencies with minimizing additional resource usage. Through trace-driven simulations, SafeTail demonstrated near-optimal performance and outperformed most baseline strategies across three diverse services. |</p>"},{"location":"biorxiv_papers/","title":"BioRxiv Papers","text":"\u6807\u9898 \u6458\u8981 \u4f5c\u8005 PDF\u94fe\u63a5 \u4ee3\u7801\u4ed3\u5e93 Title Abstract"},{"location":"medrxiv_papers/","title":"MedRxiv Papers","text":"\u6807\u9898 \u6458\u8981 \u4f5c\u8005 PDF\u94fe\u63a5 \u4ee3\u7801\u4ed3\u5e93 Title Abstract"}]}