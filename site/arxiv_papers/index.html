
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../biorxiv_papers/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.37">
    
    
      
        <title>Arxiv Papers - Arxiv Daily</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8c3ca2c6.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#arxiv-papers" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Arxiv Daily" class="md-header__button md-logo" aria-label="Arxiv Daily" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Arxiv Daily
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Arxiv Papers
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Arxiv Daily" class="md-nav__button md-logo" aria-label="Arxiv Daily" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Arxiv Daily
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Arxiv Papers
  </span>
  

      </a>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../biorxiv_papers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BioRxiv Papers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../medrxiv_papers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MedRxiv Papers
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="arxiv-papers">Arxiv Papers</h1>
<table>
<thead>
<tr>
<th>标题</th>
<th>摘要</th>
<th>作者</th>
<th>PDF链接</th>
<th>代码仓库</th>
<th>Title</th>
<th>Abstract</th>
</tr>
</thead>
<tbody>
<tr>
<td>印度公务员模拟面试中的性别表现与偏见</td>
<td>本文做出了三个关键贡献。首先，通过从888个印度公务员候选人模拟面试的YouTube视频中收集的51,278个面试问题的大量语料库，我们展示了针对男性和女性候选人的问题在广义性质上存在明显的性别偏见。其次，我们对大型语言模型进行的实验显示，在性别推断任务中，LLM提供的解释中存在强烈的性别偏见。最后，我们提供了一个包含51,278个面试问题的新颖数据集，可以为未来的社会科学研究提供信息。</td>
<td>Somonnoy Banerjee</td>
<td><a href="http://arxiv.org/pdf/2409.12194v3">PDF</a></td>
<td>N/A</td>
<td>Gender Representation and Bias in Indian Civil Service Mock Interviews</td>
<td>This paper makes three key contributions. First, via a substantial corpus of 51,278 interview questions sourced from 888 YouTube videos of mock interviews of Indian civil service candidates, we demonstrate stark gender bias in the broad nature of questions asked to male and female candidates. Second, our experiments with large language models show a strong presence of gender bias in explanations provided by the LLMs on the gender inference task. Finally, we present a novel dataset of 51,278 interview questions that can inform future social science studies.</td>
</tr>
<tr>
<td>DynaMo：视觉-运动控制领域内动力学预训练</td>
<td>模仿学习已被证明是训练复杂视觉运动策略的强大工具。然而，当前的方法通常需要数百到数千个专家演示来处理高维视觉观察。这种数据效率低下的一个关键原因是视觉表征主要是在域外数据上预训练的，或者直接通过行为克隆目标进行训练。在这项工作中，我们提出了DynaMo，一种新的域内、自监督的视觉表征学习方法。给定一组专家演示，我们联合学习一个潜在的逆动力学模型和一个前向动力学模型，这些模型在图像嵌入序列上运行，预测潜在空间中的下一帧，无需增强、对比采样或访问真实动作。重要的是，DynaMo不需要任何域外数据，如互联网数据集或跨实体数据集。在六个模拟和真实环境的测试中，我们展示了使用DynaMo学习的表征显著提升了下游模仿学习的性能，超过了先前的自监督学习目标和预训练表征。使用DynaMo带来的性能提升在不同策略类别中都得到了体现，如行为转换器、扩散策略、多层感知机和最近邻算法。最后，我们对DynaMo的关键组件进行了消融实验，并测量了它们对下游策略性能的影响。机器人视频最佳观看地址为https://dynamo-ssl.github.io。</td>
<td>Zichen Jeff Cui</td>
<td><a href="http://arxiv.org/pdf/2409.12192v1">PDF</a></td>
<td>N/A</td>
<td>DynaMo: In-Domain Dynamics Pretraining for Visuo-Motor Control</td>
<td>Imitation learning has proven to be a powerful tool for training complex visuomotor policies. However, current methods often require hundreds to thousands of expert demonstrations to handle high-dimensional visual observations. A key reason for this poor data efficiency is that visual representations are predominantly either pretrained on out-of-domain data or trained directly through a behavior cloning objective. In this work, we present DynaMo, a new in-domain, self-supervised method for learning visual representations. Given a set of expert demonstrations, we jointly learn a latent inverse dynamics model and a forward dynamics model over a sequence of image embeddings, predicting the next frame in latent space, without augmentations, contrastive sampling, or access to ground truth actions. Importantly, DynaMo does not require any out-of-domain data such as Internet datasets or cross-embodied datasets. On a suite of six simulated and real environments, we show that representations learned with DynaMo significantly improve downstream imitation learning performance over prior self-supervised learning objectives, and pretrained representations. Gains from using DynaMo hold across policy classes such as Behavior Transformer, Diffusion Policy, MLP, and nearest neighbors. Finally, we ablate over key components of DynaMo and measure its impact on downstream policy performance. Robot videos are best viewed at https://dynamo-ssl.github.io</td>
</tr>
<tr>
<td>Qwen2-VL：提升视觉-语言模型在任意分辨率下对世界的感知能力</td>
<td>我们推出了Qwen2-VL系列，这是对之前Qwen-VL模型的先进升级，重新定义了视觉处理中的传统预定分辨率方法。Qwen2-VL引入了朴素动态分辨率机制，使模型能够将不同分辨率的图像动态处理为不同数量的视觉标记。这种方法使模型能够生成更高效和准确的视觉表示，更贴近人类的感知过程。模型还集成了多模态旋转位置嵌入（M-RoPE），促进了文本、图像和视频之间位置信息的有效融合。我们采用统一的范式来处理图像和视频，增强了模型的视觉感知能力。为了探索大型多模态模型的潜力，Qwen2-VL研究了大型视觉语言模型（LVLMs）的扩展规律。通过扩展模型规模（包括2B、8B和72B参数版本）和训练数据量，Qwen2-VL系列实现了极具竞争力的性能。值得注意的是，Qwen2-VL-72B模型在各种多模态基准测试中取得了与GPT-4o和Claude3.5-Sonnet等领先模型相媲美的结果，超越了其他通用模型。代码可在\url{https://github.com/QwenLM/Qwen2-VL}获取。</td>
<td>Peng Wang</td>
<td><a href="http://arxiv.org/pdf/2409.12191v1">PDF</a></td>
<td>N/A</td>
<td>Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution</td>
<td>We present the Qwen2-VL Series, an advanced upgrade of the previous Qwen-VL models that redefines the conventional predetermined-resolution approach in visual processing. Qwen2-VL introduces the Naive Dynamic Resolution mechanism, which enables the model to dynamically process images of varying resolutions into different numbers of visual tokens. This approach allows the model to generate more efficient and accurate visual representations, closely aligning with human perceptual processes. The model also integrates Multimodal Rotary Position Embedding (M-RoPE), facilitating the effective fusion of positional information across text, images, and videos. We employ a unified paradigm for processing both images and videos, enhancing the model's visual perception capabilities. To explore the potential of large multimodal models, Qwen2-VL investigates the scaling laws for large vision-language models (LVLMs). By scaling both the model size-with versions at 2B, 8B, and 72B parameters-and the amount of training data, the Qwen2-VL Series achieves highly competitive performance. Notably, the Qwen2-VL-72B model achieves results comparable to leading models such as GPT-4o and Claude3.5-Sonnet across various multimodal benchmarks, outperforming other generalist models. Code is available at \url{https://github.com/QwenLM/Qwen2-VL}.</td>
</tr>
<tr>
<td>大规模多人3D人体运动预测与场景上下文</td>
<td>预测长期的三维人体运动具有挑战性：人类行为的随机性使得仅从输入序列中生成真实的人体运动变得困难。场景环境和附近人的运动信息可以极大地辅助生成过程。我们提出了一种场景感知的社交变压器模型（SAST）来预测长期（10秒）的人体运动。与以往的模型不同，我们的方法能够模拟场景中人数和物体数量广泛变化之间的交互。我们将时间卷积编码器-解码器架构与基于变压器的瓶颈相结合，使我们能够有效地结合运动和场景信息。我们使用去噪扩散模型来建模条件运动分布。我们在“厨房中的人类”数据集上对我们的方法进行了基准测试，该数据集同时包含1到16个人和29到50个可见物体。在不同的指标和用户研究中，我们的模型在现实性和多样性方面优于其他方法。代码可在https://github.com/felixbmuller/SAST获取。</td>
<td>Felix B Mueller</td>
<td><a href="http://arxiv.org/pdf/2409.12189v1">PDF</a></td>
<td>N/A</td>
<td>Massively Multi-Person 3D Human Motion Forecasting with Scene Context</td>
<td>Forecasting long-term 3D human motion is challenging: the stochasticity of human behavior makes it hard to generate realistic human motion from the input sequence alone. Information on the scene environment and the motion of nearby people can greatly aid the generation process. We propose a scene-aware social transformer model (SAST) to forecast long-term (10s) human motion motion. Unlike previous models, our approach can model interactions between both widely varying numbers of people and objects in a scene. We combine a temporal convolutional encoder-decoder architecture with a Transformer-based bottleneck that allows us to efficiently combine motion and scene information. We model the conditional motion distribution using denoising diffusion models. We benchmark our approach on the Humans in Kitchens dataset, which contains 1 to 16 persons and 29 to 50 objects that are visible simultaneously. Our model outperforms other approaches in terms of realism and diversity on different metrics and in a user study. Code is available at https://github.com/felixbmuller/SAST.</td>
</tr>
<tr>
<td>Qwen2.5-Coder 技术报告</td>
<td>在本报告中，我们介绍了Qwen2.5-Coder系列，这是从其前身CodeQwen1.5的重大升级。该系列包含两个模型：Qwen2.5-Coder-1.5B和Qwen2.5-Coder-7B。作为专门针对代码的模型，Qwen2.5-Coder基于Qwen2.5架构构建，并在超过5.5万亿个标记的庞大数据集上进行了继续预训练。通过精细的数据清洗、可扩展的合成数据生成以及平衡的数据混合，Qwen2.5-Coder在展现出色代码生成能力的同时，仍保持了广泛的通用性。该模型已在多种代码相关任务上进行了评估，在包括代码生成、补全、推理和修复在内的超过10个基准测试中达到了最先进的（SOTA）性能，并且在相同模型大小的对比中持续优于更大的模型。我们相信，Qwen2.5-Coder系列的发布不仅将推动代码智能研究的前沿，还将通过其宽松的许可，鼓励开发者在实际应用中更广泛地采用。</td>
<td>Binyuan Hui</td>
<td><a href="http://arxiv.org/pdf/2409.12186v1">PDF</a></td>
<td>N/A</td>
<td>Qwen2.5-Coder Technical Report</td>
<td>In this report, we introduce the Qwen2.5-Coder series, a significant upgrade from its predecessor, CodeQwen1.5. This series includes two models: Qwen2.5-Coder-1.5B and Qwen2.5-Coder-7B. As a code-specific model, Qwen2.5-Coder is built upon the Qwen2.5 architecture and continues pretrained on a vast corpus of over 5.5 trillion tokens. Through meticulous data cleaning, scalable synthetic data generation, and balanced data mixing, Qwen2.5-Coder demonstrates impressive code generation capabilities while retaining general versatility. The model has been evaluated on a wide range of code-related tasks, achieving state-of-the-art (SOTA) performance across more than 10 benchmarks, including code generation, completion, reasoning, and repair, consistently outperforming larger models of the same model size. We believe that the release of the Qwen2.5-Coder series will not only push the boundaries of research in code intelligence but also, through its permissive licensing, encourage broader adoption by developers in real-world applications.</td>
</tr>
<tr>
<td>要使用“思维链”还是不使用？“思维链”主要在数学和符号推理方面发挥作用。</td>
<td>思维链（Chain-of-thought, CoT）通过提示是激发大型语言模型（LLMs）推理能力的事实标准方法。但这种额外的“思考”对哪些类型的任务真正有帮助呢？为了分析这一点，我们进行了一项定量元分析，涵盖了使用CoT的100多篇论文，并对14个模型上的20个数据集进行了我们自己的评估。我们的结果显示，CoT主要在涉及数学或逻辑的任务上提供了强大的性能优势，而在其他类型的任务上收益较小。在MMLU上，直接生成答案而不使用CoT的准确性与使用CoT几乎相同，除非问题或模型的回答中包含等号，这表明涉及符号操作和推理。基于这一发现，我们通过分离规划和执行，并将其与工具增强的LLMs进行比较，分析了CoT在这些问题上的行为。CoT的大部分收益来自于改进符号执行，但在使用符号求解器时表现相对较差。我们的结果表明，CoT可以有选择性地应用，既保持性能又节省推理成本。此外，这些结果还表明，需要超越基于提示的CoT，转向新的范式，以更好地利用LLM应用中的中间计算。</td>
<td>Zayne Sprague</td>
<td><a href="http://arxiv.org/pdf/2409.12183v1">PDF</a></td>
<td>N/A</td>
<td>To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning</td>
<td>Chain-of-thought (CoT) via prompting is the de facto method for eliciting reasoning capabilities from large language models (LLMs). But for what kinds of tasks is this extra ``thinking'' really helpful? To analyze this, we conducted a quantitative meta-analysis covering over 100 papers using CoT and ran our own evaluations of 20 datasets across 14 models. Our results show that CoT gives strong performance benefits primarily on tasks involving math or logic, with much smaller gains on other types of tasks. On MMLU, directly generating the answer without CoT leads to almost identical accuracy as CoT unless the question or model's response contains an equals sign, indicating symbolic operations and reasoning. Following this finding, we analyze the behavior of CoT on these problems by separating planning and execution and comparing against tool-augmented LLMs. Much of CoT's gain comes from improving symbolic execution, but it underperforms relative to using a symbolic solver. Our results indicate that CoT can be applied selectively, maintaining performance while saving inference costs. Furthermore, they suggest a need to move beyond prompt-based CoT to new paradigms that better leverage intermediate computation across the whole range of LLM applications.</td>
</tr>
<tr>
<td>关于大型语言模型中长上下文扩展和泛化的控制研究</td>
<td>广泛的文本理解和上下文学习需要利用整个文档上下文的语言模型。由于直接训练长上下文模型的实现挑战，许多方法被提出以扩展模型处理长上下文。然而，由于数据和模型类别的差异，比较这些方法一直很困难，导致如何评估长上下文性能以及它是否与标准评估不同存在不确定性。我们实施了一个带有标准化评估的扩展方法控制协议，利用一致的基础模型和扩展数据。我们的研究得出了关于长上下文行为的几个见解。首先，我们重申了困惑度作为长上下文任务中通用性能指标的关键作用。其次，我们发现当前的近似注意力方法在长上下文任务中系统性地表现不佳。最后，我们确认基于精确微调的方法在其扩展范围内通常是有效的，而外推仍然具有挑战性。所有代码库、模型和检查点将作为开源资源提供，促进透明度并推动这一关键人工智能发展领域的进一步研究。</td>
<td>Yi Lu</td>
<td><a href="http://arxiv.org/pdf/2409.12181v2">PDF</a></td>
<td>N/A</td>
<td>A Controlled Study on Long Context Extension and Generalization in LLMs</td>
<td>Broad textual understanding and in-context learning require language models that utilize full document contexts. Due to the implementation challenges associated with directly training long-context models, many methods have been proposed for extending models to handle long contexts. However, owing to differences in data and model classes, it has been challenging to compare these approaches, leading to uncertainty as to how to evaluate long-context performance and whether it differs from standard evaluation. We implement a controlled protocol for extension methods with a standardized evaluation, utilizing consistent base models and extension data. Our study yields several insights into long-context behavior. First, we reaffirm the critical role of perplexity as a general-purpose performance indicator even in longer-context tasks. Second, we find that current approximate attention methods systematically underperform across long-context tasks. Finally, we confirm that exact fine-tuning based methods are generally effective within the range of their extension, whereas extrapolation remains challenging. All codebases, models, and checkpoints will be made available open-source, promoting transparency and facilitating further research in this critical area of AI development.</td>
</tr>
<tr>
<td>微调语言模型以生成不确定性语言表达</td>
<td>大型语言模型（LLMs）在信息获取和决策任务中得到了越来越多的应用。尽管它们具有广泛的实用性，但LLMs往往生成与现实世界事实相冲突的信息，并且它们的劝说性风格使得这些不准确之处显得自信且有说服力。因此，终端用户难以持续地将LLMs表达的自信与它们预测的准确性相匹配，这通常导致对所有输出盲目信任或完全忽视其可靠性。在这项工作中，我们探讨了在不确定性增强的预测上进行监督微调的方法，以开发能够产生不确定性语言表达的模型。具体来说，我们测量了预训练模型的校准情况，然后对语言模型进行微调，以生成校准后的不确定性语言表达。通过在各种问答数据集上的实验，我们证明了LLMs在评估其预测时具有良好的校准性，并且基于模型自身信心的监督微调能够产生良好校准的不确定性表达，特别是在单项答案的情况下。</td>
<td>Arslan Chaudhry</td>
<td><a href="http://arxiv.org/pdf/2409.12180v1">PDF</a></td>
<td>N/A</td>
<td>Finetuning Language Models to Emit Linguistic Expressions of Uncertainty</td>
<td>Large language models (LLMs) are increasingly employed in information-seeking and decision-making tasks. Despite their broad utility, LLMs tend to generate information that conflicts with real-world facts, and their persuasive style can make these inaccuracies appear confident and convincing. As a result, end-users struggle to consistently align the confidence expressed by LLMs with the accuracy of their predictions, often leading to either blind trust in all outputs or a complete disregard for their reliability. In this work, we explore supervised finetuning on uncertainty-augmented predictions as a method to develop models that produce linguistic expressions of uncertainty. Specifically, we measure the calibration of pre-trained models and then fine-tune language models to generate calibrated linguistic expressions of uncertainty. Through experiments on various question-answering datasets, we demonstrate that LLMs are well-calibrated in assessing their predictions, and supervised finetuning based on the model's own confidence leads to well-calibrated expressions of uncertainty, particularly for single-claim answers.</td>
</tr>
<tr>
<td>你只需阅读一次（YORO）：学习将数据库知识内化以实现文本到SQL的转换</td>
<td>尽管在文本到SQL任务上已经取得了显著进展，但最近的解决方案在每次提问时都会重复编码相同的数据库模式，导致不必要的推理成本高昂，并且常常忽略关键的数据库知识。为了解决这些问题，我们提出了“你只读一次”（YORO），这是一种新颖的范式，它在训练期间将数据库知识直接内化到文本到SQL模型的参数知识中，并在推理过程中消除了模式编码的需求。YORO显著减少了输入令牌长度，减少了66%-98%。尽管输入较短，我们的实证结果表明，YORO在三个基准测试中与传统系统表现相当，并且在大型数据库上表现尤为突出。此外，YORO在处理具有挑战性的值检索问题（如缩写）时表现出色。</td>
<td>Hideo Kobayashi</td>
<td><a href="http://arxiv.org/pdf/2409.12172v1">PDF</a></td>
<td>N/A</td>
<td>You Only Read Once (YORO): Learning to Internalize Database Knowledge for Text-to-SQL</td>
<td>While significant progress has been made on the text-to-SQL task, recent solutions repeatedly encode the same database schema for every question, resulting in unnecessary high inference cost and often overlooking crucial database knowledge. To address these issues, we propose You Only Read Once (YORO), a novel paradigm that directly internalizes database knowledge into the parametric knowledge of a text-to-SQL model during training and eliminates the need for schema encoding during inference. YORO significantly reduces the input token length by 66%-98%. Despite its shorter inputs, our empirical results demonstrate YORO's competitive performances with traditional systems on three benchmarks as well as its significant outperformance on large databases. Furthermore, YORO excels in handling questions with challenging value retrievals such as abbreviation.</td>
</tr>
<tr>
<td>解码风格：利用偏好高效微调大型语言模型以实现图像引导的服装推荐</td>
<td>个性化服装推荐仍然是一个复杂的挑战，需要对时尚兼容性和潮流意识有深入的理解。本文提出了一种新颖的框架，利用大型语言模型（LLMs）的表达能力来解决这一任务，通过微调和直接反馈整合来缓解其“黑箱”和静态特性。我们通过采用多模态大型语言模型（MLLM）进行图像描述，弥合了物品描述中的视觉-文本差距。这使得LLM能够从人工精选的时尚图像中提取风格和颜色特征，为个性化推荐奠定基础。LLM在开源的Polyvore数据集上进行了高效的微调，优化了其推荐时尚服装的能力。通过使用负面示例的直接偏好机制，增强了LLM的决策过程。这创造了一个自我增强的AI反馈循环，持续根据季节性时尚趋势优化推荐。我们的框架在Polyvore数据集上进行了评估，展示了其在两个关键任务中的有效性：填空和互补物品检索。这些评估强调了框架生成时尚、符合潮流的服装建议的能力，并通过直接反馈不断改进。评估结果表明，我们提出的框架显著优于基础LLM，创造了更加连贯的服装组合。这些任务中性能的提升突显了所提出框架在通过准确建议增强购物体验方面的潜力，证明了其在基于普通LLM的服装生成中的有效性。</td>
<td>Najmeh Forouzandehmehr</td>
<td><a href="http://arxiv.org/pdf/2409.12150v1">PDF</a></td>
<td>N/A</td>
<td>Decoding Style: Efficient Fine-Tuning of LLMs for Image-Guided Outfit Recommendation with Preference</td>
<td>Personalized outfit recommendation remains a complex challenge, demanding both fashion compatibility understanding and trend awareness. This paper presents a novel framework that harnesses the expressive power of large language models (LLMs) for this task, mitigating their "black box" and static nature through fine-tuning and direct feedback integration. We bridge the item visual-textual gap in items descriptions by employing image captioning with a Multimodal Large Language Model (MLLM). This enables the LLM to extract style and color characteristics from human-curated fashion images, forming the basis for personalized recommendations. The LLM is efficiently fine-tuned on the open-source Polyvore dataset of curated fashion images, optimizing its ability to recommend stylish outfits. A direct preference mechanism using negative examples is employed to enhance the LLM's decision-making process. This creates a self-enhancing AI feedback loop that continuously refines recommendations in line with seasonal fashion trends. Our framework is evaluated on the Polyvore dataset, demonstrating its effectiveness in two key tasks: fill-in-the-blank, and complementary item retrieval. These evaluations underline the framework's ability to generate stylish, trend-aligned outfit suggestions, continuously improving through direct feedback. The evaluation results demonstrated that our proposed framework significantly outperforms the base LLM, creating more cohesive outfits. The improved performance in these tasks underscores the proposed framework's potential to enhance the shopping experience with accurate suggestions, proving its effectiveness over the vanilla LLM based outfit generation.</td>
</tr>
<tr>
<td>MAgICoRe：多智能体、迭代、由粗到细的推理优化</td>
<td>大型语言模型（LLM）的推理能力可以通过测试时聚合策略得到提升，即生成多个样本并在生成的样本之间进行投票。尽管这些方法提高了性能，但它们通常会达到一个饱和点。改进提供了一种替代方案，即利用LLM生成的反馈来提高解决方案的质量。然而，改进引入了三个关键挑战：（1）过度改进：对所有实例进行均匀改进可能导致过度校正，从而降低整体性能。（2）无法定位和解决错误：LLM在自我修正方面能力有限，难以识别和纠正自身的错误。（3）改进不足：决定需要多少次迭代改进并非易事，过早停止可能导致错误未被解决。为了应对这些问题，我们提出了MAgICoRe，它通过将问题难度分类为简单或困难，使用粗粒度聚合解决简单问题，而对困难问题则采用细粒度和迭代的多代理改进，从而避免了过度改进。为了提高错误定位能力，我们引入了外部逐步奖励模型（RM）评分。此外，为了确保有效改进，我们采用了包含三个代理的多代理循环：求解者、评审者（根据逐步RM评分生成针对性反馈）和改进者（整合反馈）。为了确保足够的改进，我们重新评估更新后的解决方案，并迭代启动进一步的改进轮次。我们在Llama-3-8B和GPT-3.5上评估了MAgICoRe，并展示了其在5个数学数据集上的有效性。即使只进行一次MAgICoRe迭代，其性能也分别比自一致性（Self-Consistency）高出3.4%，比最佳k（Best-of-k）高出3.2%，比自我改进（Self-Refine）高出4.0%，同时使用的样本数量不到一半。与基于基线的迭代改进不同，MAgICoRe随着迭代次数的增加继续改进。最后，我们的消融实验突显了MAgICoRe的RM和多代理通信的重要性。</td>
<td>Justin Chih-Yao Chen</td>
<td><a href="http://arxiv.org/pdf/2409.12147v1">PDF</a></td>
<td>N/A</td>
<td>MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for Reasoning</td>
<td>Large Language Models' (LLM) reasoning can be improved using test-time aggregation strategies, i.e., generating multiple samples and voting among generated samples. While these improve performance, they often reach a saturation point. Refinement offers an alternative by using LLM-generated feedback to improve solution quality. However, refinement introduces 3 key challenges: (1) Excessive refinement: Uniformly refining all instances can over-correct and reduce the overall performance. (2) Inability to localize and address errors: LLMs have a limited ability to self-correct and struggle to identify and correct their own mistakes. (3) Insufficient refinement: Deciding how many iterations of refinement are needed is non-trivial, and stopping too soon could leave errors unaddressed. To tackle these issues, we propose MAgICoRe, which avoids excessive refinement by categorizing problem difficulty as easy or hard, solving easy problems with coarse-grained aggregation and hard ones with fine-grained and iterative multi-agent refinement. To improve error localization, we incorporate external step-wise reward model (RM) scores. Moreover, to ensure effective refinement, we employ a multi-agent loop with three agents: Solver, Reviewer (which generates targeted feedback based on step-wise RM scores), and the Refiner (which incorporates feedback). To ensure sufficient refinement, we re-evaluate updated solutions, iteratively initiating further rounds of refinement. We evaluate MAgICoRe on Llama-3-8B and GPT-3.5 and show its effectiveness across 5 math datasets. Even one iteration of MAgICoRe beats Self-Consistency by 3.4%, Best-of-k by 3.2%, and Self-Refine by 4.0% while using less than half the samples. Unlike iterative refinement with baselines, MAgICoRe continues to improve with more iterations. Finally, our ablations highlight the importance of MAgICoRe's RMs and multi-agent communication.</td>
</tr>
<tr>
<td>GRIN：梯度引导的专家混合模型</td>
<td>混合专家（Mixture-of-Experts, MoE）模型由于通过专家路由进行稀疏计算，能够更有效地扩展规模，只选择性地激活一小部分专家模块。然而，稀疏计算对传统的训练实践提出了挑战，因为离散的专家路由阻碍了标准的反向传播和基于梯度的优化，而这些都是深度学习的基石。为了更好地追求MoE的扩展能力，我们引入了GRIN（GRadient-INformed MoE训练），它结合了稀疏梯度估计用于专家路由，并配置了模型并行性以避免令牌丢失。将GRIN应用于自回归语言建模，我们开发了一个top-2 16$\times$3.8B的MoE模型。我们的模型仅激活了6.6B参数，表现优于一个7B的密集模型，并与在相同数据上训练的14B密集模型性能相当。在多样任务上的广泛评估表明，GRIN具有显著提升MoE效率的潜力，在MMLU上达到79.4，在HellaSwag上达到83.7，在HumanEval上达到74.4，在MATH上达到58.9。</td>
<td>Liyuan Liu</td>
<td><a href="http://arxiv.org/pdf/2409.12136v1">PDF</a></td>
<td>N/A</td>
<td>GRIN: GRadient-INformed MoE</td>
<td>Mixture-of-Experts (MoE) models scale more effectively than dense models due to sparse computation through expert routing, selectively activating only a small subset of expert modules. However, sparse computation challenges traditional training practices, as discrete expert routing hinders standard backpropagation and thus gradient-based optimization, which are the cornerstone of deep learning. To better pursue the scaling power of MoE, we introduce GRIN (GRadient-INformed MoE training), which incorporates sparse gradient estimation for expert routing and configures model parallelism to avoid token dropping. Applying GRIN to autoregressive language modeling, we develop a top-2 16$\times$3.8B MoE model. Our model, with only 6.6B activated parameters, outperforms a 7B dense model and matches the performance of a 14B dense model trained on the same data. Extensive evaluations across diverse tasks demonstrate the potential of GRIN to significantly enhance MoE efficacy, achieving 79.4 on MMLU, 83.7 on HellaSwag, 74.4 on HumanEval, and 58.9 on MATH.</td>
</tr>
<tr>
<td>线性时序差分学习（Linear Temporal Difference Learning）在任意特征下的几乎必然收敛性</td>
<td>线性函数逼近的时间差分（TD）学习，简称线性TD，是强化学习中一种经典且强大的预测算法。虽然人们普遍理解线性TD几乎必然收敛到一个唯一点，但这种收敛传统上需要假设逼近器使用的特征是线性独立的。然而，在许多实际情况下，这种线性独立假设并不成立。这项工作首次在没有要求特征线性独立的情况下，确立了线性TD的几乎必然收敛性。实际上，我们对特征不做任何假设。我们证明了近似值函数收敛到一个唯一点，并且权重迭代收敛到一个集合。我们还建立了一种权重迭代局部稳定性的概念。重要的是，我们不需要引入任何其他额外假设，也不需要对线性TD算法进行任何修改。我们的分析关键在于对线性TD均值ODE的有界不变集进行了新的刻画。</td>
<td>Jiuqi Wang</td>
<td><a href="http://arxiv.org/pdf/2409.12135v1">PDF</a></td>
<td>N/A</td>
<td>Almost Sure Convergence of Linear Temporal Difference Learning with Arbitrary Features</td>
<td>Temporal difference (TD) learning with linear function approximation, abbreviated as linear TD, is a classic and powerful prediction algorithm in reinforcement learning. While it is well understood that linear TD converges almost surely to a unique point, this convergence traditionally requires the assumption that the features used by the approximator are linearly independent. However, this linear independence assumption does not hold in many practical scenarios. This work is the first to establish the almost sure convergence of linear TD without requiring linearly independent features. In fact, we do not make any assumptions on the features. We prove that the approximated value function converges to a unique point and the weight iterates converge to a set. We also establish a notion of local stability of the weight iterates. Importantly, we do not need to introduce any other additional assumptions and do not need to make any modification to the linear TD algorithm. Key to our analysis is a novel characterization of bounded invariant sets of the mean ODE of linear TD.</td>
</tr>
<tr>
<td>BERT-VBD：越南语多文档摘要框架</td>
<td>在应对多文档摘要（Multi-Document Summarization, MDS）的挑战中，已经提出了多种方法，涵盖了抽取式和生成式摘要技术。然而，每种方法都有其局限性，单纯依赖其中任何一种都难以达到理想效果。一种新兴且有前景的策略是融合抽取式和生成式摘要方法的协同作用。尽管该领域已有大量研究，但关于结合这两种方法的研究仍然稀缺，尤其是在越南语处理领域。本文提出了一种新颖的越南语MDS框架，采用两部分流水线架构，整合了抽取式和生成式技术。第一部分采用抽取式方法，通过修改预训练的BERT网络，利用孪生和三元网络结构提取每个文档中的关键句子。第二部分则利用VBD-LLaMA2-7B-50b模型进行生成式摘要，最终生成最终的摘要文档。我们提出的框架表现出良好的性能，在VN-MDS数据集上达到了39.6%的ROUGE-2评分，超越了当前最先进的基线模型。</td>
<td>Tuan-Cuong Vuong</td>
<td><a href="http://arxiv.org/pdf/2409.12134v1">PDF</a></td>
<td>N/A</td>
<td>BERT-VBD: Vietnamese Multi-Document Summarization Framework</td>
<td>In tackling the challenge of Multi-Document Summarization (MDS), numerous methods have been proposed, spanning both extractive and abstractive summarization techniques. However, each approach has its own limitations, making it less effective to rely solely on either one. An emerging and promising strategy involves a synergistic fusion of extractive and abstractive summarization methods. Despite the plethora of studies in this domain, research on the combined methodology remains scarce, particularly in the context of Vietnamese language processing. This paper presents a novel Vietnamese MDS framework leveraging a two-component pipeline architecture that integrates extractive and abstractive techniques. The first component employs an extractive approach to identify key sentences within each document. This is achieved by a modification of the pre-trained BERT network, which derives semantically meaningful phrase embeddings using siamese and triplet network structures. The second component utilizes the VBD-LLaMA2-7B-50b model for abstractive summarization, ultimately generating the final summary document. Our proposed framework demonstrates a positive performance, attaining ROUGE-2 scores of 39.6% on the VN-MDS dataset and outperforming the state-of-the-art baselines.</td>
</tr>
<tr>
<td>Linguini：一种语言无关的语言推理基准</td>
<td>我们提出了一种新的基准测试，用于衡量语言模型在不依赖现有特定语言知识的情况下的语言推理能力。该测试涵盖了894个问题，分为160个问题，跨越75种（大多数）极度低资源的语言，这些问题提取自国际语言学奥林匹克竞赛语料库。为了在这个基准测试中获得高准确率，模型不需要事先了解测试语言的知识，因为解决语言难题所需的所有信息都呈现在上下文中。我们发现，尽管所有分析的模型准确率都低于25%，但开源模型和闭源模型之间存在显著差距，表现最佳的专有模型准确率为24.05%，而表现最佳的开源模型准确率为8.84%。</td>
<td>Eduardo Sánchez</td>
<td><a href="http://arxiv.org/pdf/2409.12126v1">PDF</a></td>
<td>N/A</td>
<td>Linguini: A benchmark for language-agnostic linguistic reasoning</td>
<td>We propose a new benchmark to measure a language model's linguistic reasoning skills without relying on pre-existing language-specific knowledge. The test covers 894 questions grouped in 160 problems across 75 (mostly) extremely low-resource languages, extracted from the International Linguistic Olympiad corpus. To attain high accuracy on this benchmark, models don't need previous knowledge of the tested language, as all the information needed to solve the linguistic puzzle is presented in the context. We find that, while all analyzed models rank below 25% accuracy, there is a significant gap between open and closed models, with the best-performing proprietary model at 24.05% and the best-performing open model at 8.84%.</td>
</tr>
<tr>
<td>Qwen2.5-Math技术报告：通过自我改进迈向数学专家模型</td>
<td>在本报告中，我们介绍了一系列专门针对数学领域的大型语言模型：Qwen2.5-Math 和 Qwen2.5-Math-Instruct-1.5B/7B/72B。Qwen2.5 系列的核心创新在于在整个流程中贯穿了自我改进的理念，从预训练、后训练到推理阶段：（1）在预训练阶段，利用 Qwen2-Math-Instruct 生成了大规模、高质量的数学数据。（2）在后训练阶段，我们通过从 Qwen2-Math-Instruct 中进行大量采样，开发了一个奖励模型（RM）。该 RM 随后应用于监督微调（SFT）中数据的迭代进化。通过更强的 SFT 模型，可以迭代训练和更新 RM，进而指导下一轮 SFT 数据迭代。在最终的 SFT 模型上，我们采用终极 RM 进行强化学习，从而得到 Qwen2.5-Math-Instruct。（3）此外，在推理阶段，RM 用于指导采样，优化模型性能。Qwen2.5-Math-Instruct 支持中文和英文，并具备先进的数学推理能力，包括思维链（CoT）和工具集成推理（TIR）。我们在 10 个中英文数学数据集上评估了我们的模型，如 GSM8K、MATH、GaoKao、AMC23 和 AIME24，涵盖了从小学水平到数学竞赛问题的各种难度。</td>
<td>An Yang</td>
<td><a href="http://arxiv.org/pdf/2409.12122v1">PDF</a></td>
<td>N/A</td>
<td>Qwen2.5-Math Technical Report: Toward Mathematical Expert Model via Self-Improvement</td>
<td>In this report, we present a series of math-specific large language models: Qwen2.5-Math and Qwen2.5-Math-Instruct-1.5B/7B/72B. The core innovation of the Qwen2.5 series lies in integrating the philosophy of self-improvement throughout the entire pipeline, from pre-training and post-training to inference: (1) During the pre-training phase, Qwen2-Math-Instruct is utilized to generate large-scale, high-quality mathematical data. (2) In the post-training phase, we develop a reward model (RM) by conducting massive sampling from Qwen2-Math-Instruct. This RM is then applied to the iterative evolution of data in supervised fine-tuning (SFT). With a stronger SFT model, it's possible to iteratively train and update the RM, which in turn guides the next round of SFT data iteration. On the final SFT model, we employ the ultimate RM for reinforcement learning, resulting in the Qwen2.5-Math-Instruct. (3) Furthermore, during the inference stage, the RM is used to guide sampling, optimizing the model's performance.   Qwen2.5-Math-Instruct supports both Chinese and English, and possess advanced mathematical reasoning capabilities, including Chain-of-Thought (CoT) and Tool-Integrated Reasoning (TIR). We evaluate our models on 10 mathematics datasets in both English and Chinese, such as GSM8K, MATH, GaoKao, AMC23, and AIME24, covering a range of difficulties from grade school level to math competition problems.</td>
</tr>
<tr>
<td>低帧率语音编解码器：一种专为快速高质量语音大语言模型训练和推理设计的编解码器</td>
<td>大型语言模型（LLMs）通过音频编解码器将音频转换为离散的符号，显著推动了音频处理技术的发展，从而使得语言建模技术能够应用于音频数据。然而，音频编解码器通常以高帧率运行，导致训练和推理速度缓慢，尤其是在自回归模型中。为了应对这一挑战，我们提出了低帧率语音编解码器（LFSC）：一种利用有限标量量化和与大型语音语言模型相结合的对抗训练的神经音频编解码器，能够在1.89 kbps的比特率和每秒21.5帧的帧率下实现高质量的音频压缩。我们证明，这种新型编解码器可以使基于LLM的文本到语音模型的推理速度提高约三倍，同时提升语音的可理解性，并产生与之前模型相媲美的音质。</td>
<td>Edresson Casanova</td>
<td><a href="http://arxiv.org/pdf/2409.12117v1">PDF</a></td>
<td>N/A</td>
<td>Low Frame-rate Speech Codec: a Codec Designed for Fast High-quality Speech LLM Training and Inference</td>
<td>Large language models (LLMs) have significantly advanced audio processing through audio codecs that convert audio into discrete tokens, enabling the application of language modeling techniques to audio data. However, audio codecs often operate at high frame rates, resulting in slow training and inference, especially for autoregressive models. To address this challenge, we present the Low Frame-rate Speech Codec (LFSC): a neural audio codec that leverages finite scalar quantization and adversarial training with large speech language models to achieve high-quality audio compression with a 1.89 kbps bitrate and 21.5 frames per second. We demonstrate that our novel codec can make the inference of LLM-based text-to-speech models around three times faster while improving intelligibility and producing quality comparable to previous models.</td>
</tr>
<tr>
<td>更强的基线模型——使机器学习研究与临床效用相一致的关键要求</td>
<td>近年来，机器学习（ML）研究显著增加，这主要归功于预测建模在多个应用领域的成功。然而，在尝试将ML模型部署于高风险、临床环境中时，存在一些众所周知的障碍，包括模型透明度不足（或无法审计推理过程）、需要大量训练数据且数据来源孤立，以及衡量模型效用的复杂指标。在本文中，我们通过实证研究表明，在医疗ML评估中纳入更强的基线模型，对帮助从业者应对这些挑战具有重要的下游效应。通过一系列案例研究，我们发现，常见的做法——忽略基线模型或仅与弱基线模型（如未经优化的线性模型）进行比较——掩盖了研究文献中提出的ML方法的实际价值。基于这些见解，我们提出了一些最佳实践，这些实践将使从业者能够更有效地在临床环境中研究和部署ML模型。</td>
<td>Nathan Wolfrath</td>
<td><a href="http://arxiv.org/pdf/2409.12116v1">PDF</a></td>
<td>N/A</td>
<td>Stronger Baseline Models -- A Key Requirement for Aligning Machine Learning Research with Clinical Utility</td>
<td>Machine Learning (ML) research has increased substantially in recent years, due to the success of predictive modeling across diverse application domains. However, well-known barriers exist when attempting to deploy ML models in high-stakes, clinical settings, including lack of model transparency (or the inability to audit the inference process), large training data requirements with siloed data sources, and complicated metrics for measuring model utility. In this work, we show empirically that including stronger baseline models in healthcare ML evaluations has important downstream effects that aid practitioners in addressing these challenges. Through a series of case studies, we find that the common practice of omitting baselines or comparing against a weak baseline model (e.g. a linear model with no optimization) obscures the value of ML methods proposed in the research literature. Using these insights, we propose some best practices that will enable practitioners to more effectively study and deploy ML models in clinical settings.</td>
</tr>
<tr>
<td>帕累托数据框架：迈向资源高效决策的步骤——利用最小可行数据（MVD）</td>
<td>本文介绍了帕累托数据框架，这是一种用于识别和选择在嵌入式系统、移动设备和物联网（IoT）设备等受限平台上启用机器学习应用所需的最小可行数据（MVD）的方法。我们展示了战略性数据缩减可以在显著降低带宽、能源、计算和存储成本的同时保持高性能。该框架通过识别最小可行数据（MVD）来优化资源受限环境下的效率，而不会牺牲性能。它解决了物联网应用中常见的低效实践，如传感器过度配置、过度精确和信号过度采样，并提出了可扩展的解决方案，以实现最佳传感器选择、信号提取和传输以及数据表示。实验方法展示了在降采样、量化和截断后有效声学数据特征化的效果，以模拟降低保真度的传感器以及网络和存储约束；结果显示，在采样率降低75%、位深和剪辑长度减少50%的情况下，性能可以保持在95%以上，这转化为显著的成本和资源减少。这些发现对受限系统的设计和开发具有重要意义。本文还讨论了该框架的更广泛影响，包括在农业、交通和制造业等领域推广先进人工智能技术的潜力，以提高数据驱动洞察的获取并倍增其效益。</td>
<td>Tashfain Ahmed</td>
<td><a href="http://arxiv.org/pdf/2409.12112v1">PDF</a></td>
<td>N/A</td>
<td>Pareto Data Framework: Steps Towards Resource-Efficient Decision Making Using Minimum Viable Data (MVD)</td>
<td>This paper introduces the Pareto Data Framework, an approach for identifying and selecting the Minimum Viable Data (MVD) required for enabling machine learning applications on constrained platforms such as embedded systems, mobile devices, and Internet of Things (IoT) devices. We demonstrate that strategic data reduction can maintain high performance while significantly reducing bandwidth, energy, computation, and storage costs. The framework identifies Minimum Viable Data (MVD) to optimize efficiency across resource-constrained environments without sacrificing performance. It addresses common inefficient practices in an IoT application such as overprovisioning of sensors and overprecision, and oversampling of signals, proposing scalable solutions for optimal sensor selection, signal extraction and transmission, and data representation. An experimental methodology demonstrates effective acoustic data characterization after downsampling, quantization, and truncation to simulate reduced-fidelity sensors and network and storage constraints; results shows that performance can be maintained up to 95\% with sample rates reduced by 75\% and bit depths and clip length reduced by 50\% which translates into substantial cost and resource reduction. These findings have implications on the design and development of constrained systems. The paper also discusses broader implications of the framework, including the potential to democratize advanced AI technologies across IoT applications and sectors such as agriculture, transportation, and manufacturing to improve access and multiply the benefits of data-driven insights.</td>
</tr>
<tr>
<td>基于大型语言模型的生成心理测量法评估人类与人工智能的价值观</td>
<td>人类价值观及其衡量一直是跨学科的长期研究课题。近年来，人工智能的进步再次激发了对此领域的兴趣，大型语言模型（LLMs）作为价值衡量的工具和对象崭露头角。本研究引入了基于LLM的生成心理计量学（GPV），这是一种数据驱动的价值衡量范式，其理论基础在于文本揭示的选择性感知。我们首先对LLM进行微调，以实现精确的感知层面价值衡量，并验证LLM将文本解析为感知的能力，这构成了GPV流程的核心。将GPV应用于人类撰写的博客，我们展示了其稳定性、有效性以及优于先前心理工具的优势。随后，将GPV扩展到LLM的价值衡量，我们通过以下方式推进了当前的技术水平：1）一种心理计量学方法，基于LLM的可扩展和自由形式输出衡量其价值，实现情境特定的衡量；2）对衡量范式的比较分析，指出了先前方法的响应偏差；3）尝试连接LLM的价值与其安全性，揭示了不同价值体系的预测能力以及各种价值对LLM安全性的影响。通过跨学科的努力，我们的目标是利用AI推动下一代心理计量学的发展，并通过心理计量学实现价值一致的人工智能。</td>
<td>Haoran Ye</td>
<td><a href="http://arxiv.org/pdf/2409.12106v1">PDF</a></td>
<td>N/A</td>
<td>Measuring Human and AI Values based on Generative Psychometrics with Large Language Models</td>
<td>Human values and their measurement are long-standing interdisciplinary inquiry. Recent advances in AI have sparked renewed interest in this area, with large language models (LLMs) emerging as both tools and subjects of value measurement. This work introduces Generative Psychometrics for Values (GPV), an LLM-based, data-driven value measurement paradigm, theoretically grounded in text-revealed selective perceptions. We begin by fine-tuning an LLM for accurate perception-level value measurement and verifying the capability of LLMs to parse texts into perceptions, forming the core of the GPV pipeline. Applying GPV to human-authored blogs, we demonstrate its stability, validity, and superiority over prior psychological tools. Then, extending GPV to LLM value measurement, we advance the current art with 1) a psychometric methodology that measures LLM values based on their scalable and free-form outputs, enabling context-specific measurement; 2) a comparative analysis of measurement paradigms, indicating response biases of prior methods; and 3) an attempt to bridge LLM values and their safety, revealing the predictive power of different value systems and the impacts of various values on LLM safety. Through interdisciplinary efforts, we aim to leverage AI for next-generation psychometrics and psychometrics for value-aligned AI.</td>
</tr>
<tr>
<td>FedLF：联邦长尾学习中的自适应Logit调整与特征优化</td>
<td>联邦学习为分布式机器学习中的隐私保护提供了一种范式。然而，现实世界中分布在每个客户端的数据集不可避免地是异构的，并且如果这些数据集可以全局聚合，它们往往呈现长尾分布，这极大地影响了模型的性能。传统的联邦学习方法主要解决客户端之间的数据异构性，但未能解决全局长尾数据中的类别偏差现象。这导致训练出的模型偏向于头部类别，而忽视了同样重要的尾部类别。因此，开发一种全面考虑类别的策略至关重要。为了解决上述问题，我们提出了一种新的方法FedLF，在本地训练阶段引入了三个改进：自适应logit调整、连续类别中心优化和特征去相关。我们比较了七种具有不同程度数据异构性和长尾分布的最新方法。在基准数据集CIFAR-10-LT和CIFAR-100-LT上的广泛实验表明，我们的方法有效地缓解了由于数据异构性和长尾分布导致的模型性能下降问题。我们的代码可在https://github.com/18sym/FedLF获取。</td>
<td>Xiuhua Lu</td>
<td><a href="http://arxiv.org/pdf/2409.12105v1">PDF</a></td>
<td>N/A</td>
<td>FedLF: Adaptive Logit Adjustment and Feature Optimization in Federated Long-Tailed Learning</td>
<td>Federated learning offers a paradigm to the challenge of preserving privacy in distributed machine learning. However, datasets distributed across each client in the real world are inevitably heterogeneous, and if the datasets can be globally aggregated, they tend to be long-tailed distributed, which greatly affects the performance of the model. The traditional approach to federated learning primarily addresses the heterogeneity of data among clients, yet it fails to address the phenomenon of class-wise bias in global long-tailed data. This results in the trained model focusing on the head classes while neglecting the equally important tail classes. Consequently, it is essential to develop a methodology that considers classes holistically. To address the above problems, we propose a new method FedLF, which introduces three modifications in the local training phase: adaptive logit adjustment, continuous class centred optimization, and feature decorrelation. We compare seven state-of-the-art methods with varying degrees of data heterogeneity and long-tailed distribution. Extensive experiments on benchmark datasets CIFAR-10-LT and CIFAR-100-LT demonstrate that our approach effectively mitigates the problem of model performance degradation due to data heterogeneity and long-tailed distribution. our code is available at https://github.com/18sym/FedLF.</td>
</tr>
<tr>
<td>对称性增强学习：一种基于范畴论的鲁棒机器学习模型框架</td>
<td>本文稿提出了一种新颖的框架，将高阶对称性和范畴论融入机器学习中。我们引入了新的数学结构，包括超对称范畴和函子表示，以模拟学习算法中的复杂变换。我们的贡献包括设计对称丰富的学习模型，开发利用范畴对称的先进优化技术，以及对其在模型鲁棒性、泛化能力和收敛性方面影响的理论分析。通过严格的证明和实际应用，我们展示了引入高维范畴结构不仅增强了现代机器学习算法的理论基础，还提升了其实际能力，为研究和创新开辟了新的方向。</td>
<td>Ronald Katende</td>
<td><a href="http://arxiv.org/pdf/2409.12100v1">PDF</a></td>
<td>N/A</td>
<td>Symmetry-Enriched Learning: A Category-Theoretic Framework for Robust Machine Learning Models</td>
<td>This manuscript presents a novel framework that integrates higher-order symmetries and category theory into machine learning. We introduce new mathematical constructs, including hyper-symmetry categories and functorial representations, to model complex transformations within learning algorithms. Our contributions include the design of symmetry-enriched learning models, the development of advanced optimization techniques leveraging categorical symmetries, and the theoretical analysis of their implications for model robustness, generalization, and convergence. Through rigorous proofs and practical applications, we demonstrate that incorporating higher-dimensional categorical structures enhances both the theoretical foundations and practical capabilities of modern machine learning algorithms, opening new directions for research and innovation.</td>
</tr>
<tr>
<td>大规模技能匹配：自由职业者与项目的高效多语言候选人检索</td>
<td>在多语言环境下，找到工作提案与自由职业者之间的完美匹配并非易事。本文提出了一种新颖的神经检索器架构，专门解决这一多语言环境下的问题。我们的方法利用预训练的多语言语言模型来编码项目描述和自由职业者档案。这些模型作为定制变压器架构的骨干，旨在保持档案和项目的结构。该模型通过历史数据上的对比损失进行训练。通过多项实验，我们证明这种方法能够有效捕捉技能匹配的相似性，并促进高效的匹配，优于传统方法。</td>
<td>Warren Jouanneau</td>
<td><a href="http://arxiv.org/pdf/2409.12097v2">PDF</a></td>
<td>N/A</td>
<td>Skill matching at scale: freelancer-project alignment for efficient multilingual candidate retrieval</td>
<td>Finding the perfect match between a job proposal and a set of freelancers is not an easy task to perform at scale, especially in multiple languages. In this paper, we propose a novel neural retriever architecture that tackles this problem in a multilingual setting. Our method encodes project descriptions and freelancer profiles by leveraging pre-trained multilingual language models. The latter are used as backbone for a custom transformer architecture that aims to keep the structure of the profiles and project. This model is trained with a contrastive loss on historical data. Thanks to several experiments, we show that this approach effectively captures skill matching similarity and facilitates efficient matching, outperforming traditional methods.</td>
</tr>
<tr>
<td>元素顺序对语言模型代理性能的影响</td>
<td>人们对能够在网络或桌面等虚拟环境中导航的语言模型代理的兴趣激增。为了在这些环境中导航，代理从有关各种元素（例如按钮、文本或图像）的信息中受益。哪些元素属性对代理性能影响最大仍不清楚，尤其是在仅提供图形表示（即像素）的环境中。我们发现，元素呈现给语言模型的顺序出乎意料地具有影响力——在网页中随机化元素顺序会降低代理性能，相当于从代理的状态表示中移除所有可见文本。虽然网页提供了元素的分层排序，但从像素直接解析元素时没有这样的排序。此外，随着任务变得更加复杂，模型更加先进，我们的实验表明排序的影响增加。找到有效的排序并非易事。我们研究了在网络和桌面环境中各种元素排序方法的影响。我们发现，降维为仅像素环境提供了一种可行的排序。我们训练了一个UI元素检测模型，从像素中提取元素，并将我们的发现应用于一个代理基准——OmniACT——我们只能访问像素。与之前的最先进技术相比，我们的方法平均完成任务的数量是其两倍以上。</td>
<td>Wayne Chi</td>
<td><a href="http://arxiv.org/pdf/2409.12089v2">PDF</a></td>
<td>N/A</td>
<td>The Impact of Element Ordering on LM Agent Performance</td>
<td>There has been a surge of interest in language model agents that can navigate virtual environments such as the web or desktop. To navigate such environments, agents benefit from information on the various elements (e.g., buttons, text, or images) present. It remains unclear which element attributes have the greatest impact on agent performance, especially in environments that only provide a graphical representation (i.e., pixels). Here we find that the ordering in which elements are presented to the language model is surprisingly impactful--randomizing element ordering in a webpage degrades agent performance comparably to removing all visible text from an agent's state representation. While a webpage provides a hierarchical ordering of elements, there is no such ordering when parsing elements directly from pixels. Moreover, as tasks become more challenging and models more sophisticated, our experiments suggest that the impact of ordering increases. Finding an effective ordering is non-trivial. We investigate the impact of various element ordering methods in web and desktop environments. We find that dimensionality reduction provides a viable ordering for pixel-only environments. We train a UI element detection model to derive elements from pixels and apply our findings to an agent benchmark--OmniACT--where we only have access to pixels. Our method completes more than two times as many tasks on average relative to the previous state-of-the-art.</td>
</tr>
<tr>
<td>面向可解释的终末期肾病（ESRD）预测：利用行政索赔数据与可解释人工智能技术</td>
<td>本研究探讨了利用行政索赔数据，结合先进的机器学习与深度学习技术，预测慢性肾病（CKD）向终末期肾病（ESRD）进展的潜力。我们分析了一家主要健康保险机构提供的全面10年数据集，采用随机森林、XGBoost等传统机器学习方法以及长短期记忆（LSTM）网络等深度学习方法，针对多个观察窗口开发预测模型。研究结果表明，LSTM模型在24个月观察窗口下表现尤为出色，在预测ESRD进展方面优于现有文献中的模型。此外，我们应用SHapley加性解释（SHAP）分析来增强模型的可解释性，深入了解个体特征对个体患者预测结果的影响。本研究强调了利用行政索赔数据进行CKD管理及预测ESRD进展的价值。</td>
<td>Yubo Li</td>
<td><a href="http://arxiv.org/pdf/2409.12087v1">PDF</a></td>
<td>N/A</td>
<td>Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques</td>
<td>This study explores the potential of utilizing administrative claims data, combined with advanced machine learning and deep learning techniques, to predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major health insurance organization to develop prediction models for multiple observation windows using traditional machine learning methods such as Random Forest and XGBoost as well as deep learning approaches such as Long Short-Term Memory (LSTM) networks. Our findings demonstrate that the LSTM model, particularly with a 24-month observation window, exhibits superior performance in predicting ESRD progression, outperforming existing models in the literature. We further apply SHapley Additive exPlanations (SHAP) analysis to enhance interpretability, providing insights into the impact of individual features on predictions at the individual patient level. This study underscores the value of leveraging administrative claims data for CKD management and predicting ESRD progression.</td>
</tr>
<tr>
<td>用于高分辨率显微图像恢复的去噪扩散模型</td>
<td>显微成像技术的进步使研究人员能够在纳米尺度上观察结构，从而揭示生物组织的复杂细节。然而，图像噪声、荧光染料的光漂白以及生物样本对高光剂量的低耐受性等问题依然存在，限制了时间分辨率和实验持续时间。降低激光剂量虽然可以延长测量时间，但代价是分辨率降低和噪声增加，这阻碍了下游分析的准确性。在此，我们训练了一个去噪扩散概率模型（DDPM），通过基于低分辨率信息对模型进行条件化，来预测高分辨率图像。此外，DDPM的概率特性允许重复生成图像，从而进一步提高信噪比。我们的研究表明，在四个高度多样化的数据集中，我们的模型性能优于或与之前表现最佳的方法相当。重要的是，尽管之前的方法在某些数据集上表现出色，但并非所有数据集都能达到同等水平，而我们的方法在所有四个数据集中均能持续实现高性能，这表明其具有高度的普适性。</td>
<td>Pamela Osuna-Vargas</td>
<td><a href="http://arxiv.org/pdf/2409.12078v1">PDF</a></td>
<td>N/A</td>
<td>Denoising diffusion models for high-resolution microscopy image restoration</td>
<td>Advances in microscopy imaging enable researchers to visualize structures at the nanoscale level thereby unraveling intricate details of biological organization. However, challenges such as image noise, photobleaching of fluorophores, and low tolerability of biological samples to high light doses remain, restricting temporal resolutions and experiment durations. Reduced laser doses enable longer measurements at the cost of lower resolution and increased noise, which hinders accurate downstream analyses. Here we train a denoising diffusion probabilistic model (DDPM) to predict high-resolution images by conditioning the model on low-resolution information. Additionally, the probabilistic aspect of the DDPM allows for repeated generation of images that tend to further increase the signal-to-noise ratio. We show that our model achieves a performance that is better or similar to the previously best-performing methods, across four highly diverse datasets. Importantly, while any of the previous methods show competitive performance for some, but not all datasets, our method consistently achieves high performance across all four data sets, suggesting high generalizability.</td>
</tr>
<tr>
<td>通过数据修剪实现无监督领域自适应</td>
<td>从训练数据中移除精心挑选的样本，最近被证明是提高机器学习模型鲁棒性的有效方法。然而，如何最佳地选择这些样本仍然是一个悬而未决的问题。在本文中，我们从无监督领域自适应（UDA）的角度来考虑这个问题。我们提出了AdaPrune，一种UDA方法，通过移除训练样本，试图将训练分布与目标数据的分布对齐。通过采用最大均值差异（MMD）作为对齐标准，问题可以被简洁地表述并作为一个整数二次规划来解决。我们在一个真实的生物声学事件检测领域转移任务中评估了我们的方法。作为一种UDA方法，我们展示了AdaPrune优于相关技术，并且与其他UDA算法（如CORAL）是互补的。我们对MMD与模型准确性之间关系的分析，以及t-SNE图，验证了所提出的方法作为一种原则性强且有根据的数据修剪方式。</td>
<td>Andrea Napoli</td>
<td><a href="http://arxiv.org/pdf/2409.12076v1">PDF</a></td>
<td>N/A</td>
<td>Unsupervised Domain Adaptation Via Data Pruning</td>
<td>The removal of carefully-selected examples from training data has recently emerged as an effective way of improving the robustness of machine learning models. However, the best way to select these examples remains an open question. In this paper, we consider the problem from the perspective of unsupervised domain adaptation (UDA). We propose AdaPrune, a method for UDA whereby training examples are removed to attempt to align the training distribution to that of the target data. By adopting the maximum mean discrepancy (MMD) as the criterion for alignment, the problem can be neatly formulated and solved as an integer quadratic program. We evaluate our approach on a real-world domain shift task of bioacoustic event detection. As a method for UDA, we show that AdaPrune outperforms related techniques, and is complementary to other UDA algorithms such as CORAL. Our analysis of the relationship between the MMD and model accuracy, along with t-SNE plots, validate the proposed method as a principled and well-founded way of performing data pruning.</td>
</tr>
<tr>
<td>拟合多层次因子模型</td>
<td>我们研究了多层次因子模型的一个特殊情况，其协方差由多层次低秩（MLR）矩阵给出~\cite{parshakova2023factor}。我们为多层次因子模型开发了一种新颖且快速的期望最大化（EM）算法实现，旨在最大化观测数据的可能性。该方法适用于任何层次结构，并且在每次迭代中保持线性时间和存储复杂度。这一成果通过一种新的高效技术实现，该技术用于计算正定MLR矩阵的逆。我们证明，可逆PSD MLR矩阵的逆矩阵也是一个具有相同因子稀疏性的MLR矩阵，并利用递归的Sherman-Morrison-Woodbury矩阵恒等式来获得逆矩阵的因子。此外，我们还提出了一种算法，该算法以线性时间和空间复杂度计算扩展矩阵的Cholesky分解，从而得到协方差矩阵作为其Schur补码。本文附带了一个开源包，实现了所提出的方法。</td>
<td>Tetiana Parshakova</td>
<td><a href="http://arxiv.org/pdf/2409.12067v1">PDF</a></td>
<td>N/A</td>
<td>Fitting Multilevel Factor Models</td>
<td>We examine a special case of the multilevel factor model, with covariance given by multilevel low rank (MLR) matrix~\cite{parshakova2023factor}. We develop a novel, fast implementation of the expectation-maximization (EM) algorithm, tailored for multilevel factor models, to maximize the likelihood of the observed data. This method accommodates any hierarchical structure and maintains linear time and storage complexities per iteration. This is achieved through a new efficient technique for computing the inverse of the positive definite MLR matrix. We show that the inverse of an invertible PSD MLR matrix is also an MLR matrix with the same sparsity in factors, and we use the recursive Sherman-Morrison-Woodbury matrix identity to obtain the factors of the inverse. Additionally, we present an algorithm that computes the Cholesky factorization of an expanded matrix with linear time and space complexities, yielding the covariance matrix as its Schur complement. This paper is accompanied by an open-source package that implements the proposed methods.</td>
</tr>
<tr>
<td>PARAPHRASUS：一个全面评估释义检测模型的基准</td>
<td>判断两段文本是否为释义的任务在自然语言处理领域一直是一个挑战。然而，主流的释义概念往往过于简单，仅提供对广泛释义现象的有限视角。实际上，我们发现，在释义数据集上评估模型可能会对其真正的语义理解能力产生不确定性。为了缓解这一问题，我们发布了paraphrasus，这是一个用于多维度评估释义检测模型和进行更精细模型选择的基准。我们发现，在细粒度评估视角下，释义检测模型展现出的权衡关系无法通过单一的分类数据集来捕捉。</td>
<td>Andrianos Michail</td>
<td><a href="http://arxiv.org/pdf/2409.12060v1">PDF</a></td>
<td>N/A</td>
<td>PARAPHRASUS : A Comprehensive Benchmark for Evaluating Paraphrase Detection Models</td>
<td>The task of determining whether two texts are paraphrases has long been a challenge in NLP. However, the prevailing notion of paraphrase is often quite simplistic, offering only a limited view of the vast spectrum of paraphrase phenomena. Indeed, we find that evaluating models in a paraphrase dataset can leave uncertainty about their true semantic understanding. To alleviate this, we release paraphrasus, a benchmark designed for multi-dimensional assessment of paraphrase detection models and finer model selection. We find that paraphrase detection models under a fine-grained evaluation lens exhibit trade-offs that cannot be captured through a single classification dataset.</td>
</tr>
<tr>
<td>大型语言模型的双层训练与解码：同时思考与表达</td>
<td>大型语言模型能够合理地理解和生成人类表达，但可能缺乏深入的思考和推理机制。最近有几项研究增强了语言模型的思考能力，但大多数都不是基于数据驱动或训练的。在本文中，我们受到自然界认知机制的启发，设计了一种名为TaS的新型模型架构，使其能够首先考虑想法，然后根据查询表达响应。我们设计了几个流程来从提示-响应样本中注释或生成思维内容，然后在中间层添加语言头，作为思考层。我们通过思维增强的数据训练语言模型，成功地使思考层自动生成合理的思维，并最终输出更合理的响应。定性示例和定量结果都验证了TaS的有效性和性能。我们的代码可在https://anonymous.4open.science/r/TadE获取。</td>
<td>Ningyuan Xi</td>
<td><a href="http://arxiv.org/pdf/2409.12059v1">PDF</a></td>
<td>N/A</td>
<td>Dual-Layer Training and Decoding of Large Language Model with Simultaneously Thinking and Speaking</td>
<td>Large Language Model can reasonably understand and generate human expressions but may lack of thorough thinking and reasoning mechanisms. Recently there have been several studies which enhance the thinking ability of language models but most of them are not data-driven or training-based. In this paper, we are motivated by the cognitive mechanism in the natural world, and design a novel model architecture called TaS which allows it to first consider the thoughts and then express the response based upon the query. We design several pipelines to annotate or generate the thought contents from prompt-response samples, then add language heads in a middle layer which behaves as the thinking layer. We train the language model by the thoughts-augmented data and successfully let the thinking layer automatically generate reasonable thoughts and finally output more reasonable responses. Both qualitative examples and quantitative results validate the effectiveness and performance of TaS. Our code is available at https://anonymous.4open.science/r/TadE.</td>
</tr>
<tr>
<td>Cartan移动标架与数据流形</td>
<td>本文旨在运用Cartan活动标架的语言，通过数据信息度量及其在数据点处的曲率，研究数据流形的几何及其黎曼结构。利用这一框架并通过实验，通过指出从给定输入容易到达的输出类别，给出了对神经网络响应的解释。这强调了所提出的网络输出与输入几何之间的数学关系如何被利用作为可解释的人工智能工具。</td>
<td>Eliot Tron</td>
<td><a href="http://arxiv.org/pdf/2409.12057v1">PDF</a></td>
<td>N/A</td>
<td>Cartan moving frames and the data manifolds</td>
<td>The purpose of this paper is to employ the language of Cartan moving frames to study the geometry of the data manifolds and its Riemannian structure, via the data information metric and its curvature at data points. Using this framework and through experiments, explanations on the response of a neural network are given by pointing out the output classes that are easily reachable from a given input. This emphasizes how the proposed mathematical relationship between the output of the network and the geometry of its inputs can be exploited as an explainable artificial intelligence tool.</td>
</tr>
<tr>
<td>扩展的深度子模块函数</td>
<td>我们引入了一种新型集合函数类别，称为扩展深度子模函数（Extended Deep Submodular Functions, EDSFs），这些函数可以用神经网络表示。EDSFs 作为深度子模函数（Deep Submodular Functions, DSFs）的扩展，继承了 DSFs 的关键特性，同时解决了其固有的局限性。已知 DSFs 只能表示子模函数的一个有限子集。相比之下，通过对多面体性质的分析，我们确立了 EDSFs 具有表示所有单调子模函数的能力，相较于 DSFs 这是一个显著的增强。此外，我们的研究结果表明，EDSFs 可以表示任何单调集合函数，这意味着 EDSFs 族与所有单调集合函数族是等价的。此外，我们证明了当输入向量的分量为非负实数时，EDSFs 保持了 DSFs 固有的凹性——这是某些组合优化问题中的一个关键特征。通过广泛的实验，我们展示了在覆盖函数的学习中，EDSFs 的实证泛化误差显著低于 DSFs。这表明 EDSFs 在表示和学习具有改进泛化能力的集合函数方面展现出了有前景的进展。</td>
<td>Seyed Mohammad Hosseini</td>
<td><a href="http://arxiv.org/pdf/2409.12053v1">PDF</a></td>
<td>N/A</td>
<td>Extended Deep Submodular Functions</td>
<td>We introduce a novel category of set functions called Extended Deep Submodular functions (EDSFs), which are neural network-representable. EDSFs serve as an extension of Deep Submodular Functions (DSFs), inheriting crucial properties from DSFs while addressing innate limitations. It is known that DSFs can represent a limiting subset of submodular functions. In contrast, through an analysis of polymatroid properties, we establish that EDSFs possess the capability to represent all monotone submodular functions, a notable enhancement compared to DSFs. Furthermore, our findings demonstrate that EDSFs can represent any monotone set function, indicating the family of EDSFs is equivalent to the family of all monotone set functions. Additionally, we prove that EDSFs maintain the concavity inherent in DSFs when the components of the input vector are non-negative real numbers-an essential feature in certain combinatorial optimization problems. Through extensive experiments, we illustrate that EDSFs exhibit significantly lower empirical generalization error than DSFs in the learning of coverage functions. This suggests that EDSFs present a promising advancement in the representation and learning of set functions with improved generalization capabilities.</td>
</tr>
<tr>
<td>使用大型语言模型生成临床试验表格和图表</td>
<td>表格、图形和列表（TFLs）是总结临床试验数据的重要工具。在临床试验的执行过程中，创建TFLs用于报告活动通常是一项耗时的任务。本研究探讨了使用大型语言模型（LLMs）通过提示工程和少样本迁移学习来自动生成TFLs的方法。利用ADaM格式的公开临床试验数据，我们的结果表明，LLMs能够通过提示指令高效生成TFLs，展示了它们在这一领域的潜力。此外，我们开发了一个名为“临床试验TFL生成代理”的应用程序，该应用程序能够将用户查询与预定义的提示匹配，从而生成定制化的程序来生成特定的预定义TFLs。</td>
<td>Yumeng Yang</td>
<td><a href="http://arxiv.org/pdf/2409.12046v2">PDF</a></td>
<td>N/A</td>
<td>Using Large Language Models to Generate Clinical Trial Tables and Figures</td>
<td>Tables, figures, and listings (TFLs) are essential tools for summarizing clinical trial data. Creation of TFLs for reporting activities is often a time-consuming task encountered routinely during the execution of clinical trials. This study explored the use of large language models (LLMs) to automate the generation of TFLs through prompt engineering and few-shot transfer learning. Using public clinical trial data in ADaM format, our results demonstrated that LLMs can efficiently generate TFLs with prompt instructions, showcasing their potential in this domain. Furthermore, we developed a conservational agent named Clinical Trial TFL Generation Agent: An app that matches user queries to predefined prompts that produce customized programs to generate specific predefined TFLs.</td>
</tr>
<tr>
<td>在安全强化学习中处理长期安全性和不确定性</td>
<td>安全性是阻碍强化学习技术在真实机器人中应用的关键问题之一。尽管安全强化学习领域中的大多数方法不需要事先了解约束条件和机器人运动学，仅依赖数据，但在复杂的现实环境中部署它们往往十分困难。相反，基于模型的方法将约束条件和动力学的先验知识融入学习框架，已被证明能够直接在真实机器人上部署学习算法。遗憾的是，尽管通常可以获得机器人动力学的近似模型，但安全约束条件具有任务特定性且难以获取：它们可能过于复杂而无法进行解析编码，计算成本过高，或者难以事先预见长期的安全需求。本文通过扩展安全探索方法ATACOM，引入可学习的约束条件，特别关注于确保长期安全性和处理不确定性，从而填补了这一空白。我们的方法在最终性能上与最先进的方法相比具有竞争力或更优，同时在训练过程中保持了更安全的行为。</td>
<td>Jonas Günster</td>
<td><a href="http://arxiv.org/pdf/2409.12045v2">PDF</a></td>
<td>N/A</td>
<td>Handling Long-Term Safety and Uncertainty in Safe Reinforcement Learning</td>
<td>Safety is one of the key issues preventing the deployment of reinforcement learning techniques in real-world robots. While most approaches in the Safe Reinforcement Learning area do not require prior knowledge of constraints and robot kinematics and rely solely on data, it is often difficult to deploy them in complex real-world settings. Instead, model-based approaches that incorporate prior knowledge of the constraints and dynamics into the learning framework have proven capable of deploying the learning algorithm directly on the real robot. Unfortunately, while an approximated model of the robot dynamics is often available, the safety constraints are task-specific and hard to obtain: they may be too complicated to encode analytically, too expensive to compute, or it may be difficult to envision a priori the long-term safety requirements. In this paper, we bridge this gap by extending the safe exploration method, ATACOM, with learnable constraints, with a particular focus on ensuring long-term safety and handling of uncertainty. Our approach is competitive or superior to state-of-the-art methods in final performance while maintaining safer behavior during training.</td>
</tr>
<tr>
<td>理解百度-ULTR日志策略对双塔模型的影响</td>
<td>尽管双塔模型在无偏排序（ULTR）任务中广受欢迎，但近期研究表明，该模型存在一个重大局限性，可能导致其在工业应用中崩溃：日志策略混淆问题。尽管已经提出了几种潜在的解决方案，但这些方法的评估大多基于半合成模拟实验。本文通过在最大的真实世界数据集——百度-ULTR上研究混淆问题，填补了理论与实践之间的空白。我们的主要贡献有三点：1）我们展示了在百度-ULTR上存在混淆问题的条件；2）混淆问题对双塔模型没有显著影响；3）我们指出专家标注与用户点击行为之间可能存在潜在的不匹配，而专家标注在ULTR中被视为黄金标准。</td>
<td>Morris de Haan</td>
<td><a href="http://arxiv.org/pdf/2409.12043v1">PDF</a></td>
<td>N/A</td>
<td>Understanding the Effects of the Baidu-ULTR Logging Policy on Two-Tower Models</td>
<td>Despite the popularity of the two-tower model for unbiased learning to rank (ULTR) tasks, recent work suggests that it suffers from a major limitation that could lead to its collapse in industry applications: the problem of logging policy confounding. Several potential solutions have even been proposed; however, the evaluation of these methods was mostly conducted using semi-synthetic simulation experiments. This paper bridges the gap between theory and practice by investigating the confounding problem on the largest real-world dataset, Baidu-ULTR. Our main contributions are threefold: 1) we show that the conditions for the confounding problem are given on Baidu-ULTR, 2) the confounding problem bears no significant effect on the two-tower model, and 3) we point to a potential mismatch between expert annotations, the golden standard in ULTR, and user click behavior.</td>
</tr>
<tr>
<td>ASR基准测试：需要更具代表性的对话数据集</td>
<td>自动语音识别（ASR）系统在LibriSpeech和Fleurs等广泛使用的基准测试中取得了显著的性能表现。然而，这些基准测试并不能充分反映现实世界对话环境的复杂性，在这些环境中，语音往往是无结构的，并且包含诸如停顿、打断和多样口音等不流畅现象。在本研究中，我们引入了一个多语言对话数据集，该数据集源自TalkBank，包含成人之间的非结构化电话对话。我们的研究结果显示，在对话环境中测试时，各种最先进的ASR模型性能显著下降。此外，我们观察到单词错误率与语音不流畅现象的存在之间存在相关性，这突显了开发更真实、更具对话性的ASR基准测试的迫切需求。</td>
<td>Gaurav Maheshwari</td>
<td><a href="http://arxiv.org/pdf/2409.12042v1">PDF</a></td>
<td>N/A</td>
<td>ASR Benchmarking: Need for a More Representative Conversational Dataset</td>
<td>Automatic Speech Recognition (ASR) systems have achieved remarkable performance on widely used benchmarks such as LibriSpeech and Fleurs. However, these benchmarks do not adequately reflect the complexities of real-world conversational environments, where speech is often unstructured and contains disfluencies such as pauses, interruptions, and diverse accents. In this study, we introduce a multilingual conversational dataset, derived from TalkBank, consisting of unstructured phone conversation between adults. Our results show a significant performance drop across various state-of-the-art ASR models when tested in conversational settings. Furthermore, we observe a correlation between Word Error Rate and the presence of speech disfluencies, highlighting the critical need for more realistic, conversational ASR benchmarks.</td>
</tr>
<tr>
<td>一个统一的时间神经计算和学习框架</td>
<td>本文提出了哈密顿学习（Hamiltonian Learning），这是一种新颖的统一框架，用于在神经网络中“随时间”进行学习，即以在线方式从可能无限的数据流中学习，而无需访问未来的信息。现有研究主要集中在简化的设置上，其中数据流具有已知的有限长度或被分割成更小的序列，利用了统计机器学习中成熟的学习策略。本文从零开始重新思考了随时间学习的难题，利用了最优控制理论中的工具，从而对神经计算和学习的时序动态提供了一个统一的视角。哈密顿学习基于微分方程，这些方程具有以下特点：(i) 可以在不需要外部软件求解器的情况下进行积分；(ii) 推广了前馈和递归网络中基于梯度的学习这一成熟概念；(iii) 开启了新的视角。通过实验展示了所提出的框架，证明了它如何恢复基于梯度的学习，并将其与现成的优化器进行比较，还描述了它如何灵活地从完全局部切换到部分/非局部计算方案，这些方案可能分布在多个设备上，并且无需存储激活即可进行反向传播。哈密顿学习易于实现，可以帮助研究人员以有原则且创新的方式解决随时间学习的难题。</td>
<td>Stefano Melacci</td>
<td><a href="http://arxiv.org/pdf/2409.12038v1">PDF</a></td>
<td>N/A</td>
<td>A Unified Framework for Neural Computation and Learning Over Time</td>
<td>This paper proposes Hamiltonian Learning, a novel unified framework for learning with neural networks "over time", i.e., from a possibly infinite stream of data, in an online manner, without having access to future information. Existing works focus on the simplified setting in which the stream has a known finite length or is segmented into smaller sequences, leveraging well-established learning strategies from statistical machine learning. In this paper, the problem of learning over time is rethought from scratch, leveraging tools from optimal control theory, which yield a unifying view of the temporal dynamics of neural computations and learning. Hamiltonian Learning is based on differential equations that: (i) can be integrated without the need of external software solvers; (ii) generalize the well-established notion of gradient-based learning in feed-forward and recurrent networks; (iii) open to novel perspectives. The proposed framework is showcased by experimentally proving how it can recover gradient-based learning, comparing it to out-of-the box optimizers, and describing how it is flexible enough to switch from fully-local to partially/non-local computational schemes, possibly distributed over multiple devices, and BackPropagation without storing activations. Hamiltonian Learning is easy to implement and can help researches approach in a principled and innovative manner the problem of learning over time.</td>
</tr>
<tr>
<td>拓扑深度学习与状态空间模型：一种基于Mamba的单纯复形方法</td>
<td>基于消息传递（MP）机制的图神经网络（Graph Neural Networks）是处理图结构数据的主流方法。然而，它们本质上仅限于建模成对交互，这使得难以明确捕捉具有$n$体关系的系统的复杂性。为了解决这一问题，拓扑深度学习作为一个有前景的领域崭露头角，它利用各种拓扑域（如单纯复形和细胞复形）来研究和建模高阶交互。尽管这些新领域提供了强大的表示能力，但它们也引入了新的挑战，例如通过高阶MP有效建模高阶结构之间的交互。同时，结构化状态空间序列模型已被证明在序列建模中非常有效，并且最近通过将节点的邻域编码为序列，从而避免了MP机制，被适配用于图数据。在这项工作中，我们提出了一种新颖的架构，旨在与单纯复形一起操作，利用Mamba状态空间模型作为其骨干。我们的方法基于相邻单元生成节点的序列，使得所有高阶结构之间能够直接通信，无论其阶数如何。我们广泛验证了我们的模型，证明其在与为单纯复形开发的最先进模型相比时，表现出了竞争性的性能。</td>
<td>Marco Montagna</td>
<td><a href="http://arxiv.org/pdf/2409.12033v1">PDF</a></td>
<td>N/A</td>
<td>Topological Deep Learning with State-Space Models: A Mamba Approach for Simplicial Complexes</td>
<td>Graph Neural Networks based on the message-passing (MP) mechanism are a dominant approach for handling graph-structured data. However, they are inherently limited to modeling only pairwise interactions, making it difficult to explicitly capture the complexity of systems with $n$-body relations. To address this, topological deep learning has emerged as a promising field for studying and modeling higher-order interactions using various topological domains, such as simplicial and cellular complexes. While these new domains provide powerful representations, they introduce new challenges, such as effectively modeling the interactions among higher-order structures through higher-order MP. Meanwhile, structured state-space sequence models have proven to be effective for sequence modeling and have recently been adapted for graph data by encoding the neighborhood of a node as a sequence, thereby avoiding the MP mechanism. In this work, we propose a novel architecture designed to operate with simplicial complexes, utilizing the Mamba state-space model as its backbone. Our approach generates sequences for the nodes based on the neighboring cells, enabling direct communication between all higher-order structures, regardless of their rank. We extensively validate our model, demonstrating that it achieves competitive performance compared to state-of-the-art models developed for simplicial complexes.</td>
</tr>
<tr>
<td>侧扫声呐图像分类任务中的视觉变换器</td>
<td>侧扫声呐（SSS）图像在海底人造物体的分类中面临着独特的挑战，这是由于复杂多样的水下环境所致。传统上，专家们通过手工特征和常规机器学习技术来手动解读SSS图像。尽管卷积神经网络（CNNs）在这一领域显著推进了自动化分类，但它们在处理多样化的海底纹理（如岩石或波纹沙底）时往往表现不佳，可能导致误报率上升。最近，视觉变换器（ViTs）通过利用自注意力机制来捕捉图像块中的全局信息，展现出解决这些局限性的潜力，提供了在处理空间层次结构时更大的灵活性。本文严格比较了ViT模型与常用的CNN架构（如ResNet和ConvNext）在SSS图像二分类任务中的性能。数据集涵盖了多种地理海底类型，并且在人造物体的存在与否之间保持平衡。基于ViT的模型在f1分数、精确度、召回率和准确性等指标上表现出优越的分类性能，尽管代价是更高的计算资源。CNNs凭借其归纳偏置，展示了更好的计算效率，使其适合部署在资源受限的环境中，如水下车辆。未来的研究方向包括探索ViTs的自监督学习以及多模态融合，以进一步提升在具有挑战性的水下环境中的性能。</td>
<td>BW Sheffield</td>
<td><a href="http://arxiv.org/pdf/2409.12026v1">PDF</a></td>
<td>N/A</td>
<td>On Vision Transformers for Classification Tasks in Side-Scan Sonar Imagery</td>
<td>Side-scan sonar (SSS) imagery presents unique challenges in the classification of man-made objects on the seafloor due to the complex and varied underwater environments. Historically, experts have manually interpreted SSS images, relying on conventional machine learning techniques with hand-crafted features. While Convolutional Neural Networks (CNNs) significantly advanced automated classification in this domain, they often fall short when dealing with diverse seafloor textures, such as rocky or ripple sand bottoms, where false positive rates may increase. Recently, Vision Transformers (ViTs) have shown potential in addressing these limitations by utilizing a self-attention mechanism to capture global information in image patches, offering more flexibility in processing spatial hierarchies. This paper rigorously compares the performance of ViT models alongside commonly used CNN architectures, such as ResNet and ConvNext, for binary classification tasks in SSS imagery. The dataset encompasses diverse geographical seafloor types and is balanced between the presence and absence of man-made objects. ViT-based models exhibit superior classification performance across f1-score, precision, recall, and accuracy metrics, although at the cost of greater computational resources. CNNs, with their inductive biases, demonstrate better computational efficiency, making them suitable for deployment in resource-constrained environments like underwater vehicles. Future research directions include exploring self-supervised learning for ViTs and multi-modal fusion to further enhance performance in challenging underwater environments.</td>
</tr>
<tr>
<td>协作代码生成模型的承诺与风险：平衡有效性与记忆</td>
<td>在机器学习领域快速发展的背景下，使用来自不同地点和组织的数据集训练模型面临着重大的隐私和法律挑战。探索能够有效利用分布且孤立的数据集中宝贵知识的协作训练设置变得日益重要。本研究探讨了影响代码下一标记预测中协作训练方法效果的关键因素，以及生成代码的正确性和实用性，展示了此类方法的潜力。此外，我们评估了在不同协作训练设置（包括集中式、联邦式和增量式训练）中，不同参与者训练数据的记忆情况，突显了数据泄露的潜在风险。我们的研究结果表明，代码数据集的规模和多样性是影响协作训练代码模型成功的关键因素。我们发现，与集中式训练相比，联邦学习在提供更好数据保护的同时，实现了具有竞争力的性能，这在生成代码中较低的记忆率中得到了体现。然而，联邦学习仍可能从隐藏的训练数据中产生逐字的代码片段，这可能违反隐私或版权。我们的研究进一步探讨了增量学习中的效果和记忆模式，强调了引入个体参与者数据集的顺序。我们还识别了跨组织克隆作为集中式和联邦学习场景中的一个普遍挑战。我们的研究结果强调了即使在训练数据未被看到的情况下，推理过程中持续存在的数据泄露风险。最后，我们为从业者和研究人员提供了优化多源数据集的建议，推动跨组织协作向前发展。</td>
<td>Zhi Chen</td>
<td><a href="http://arxiv.org/pdf/2409.12020v1">PDF</a></td>
<td>N/A</td>
<td>Promise and Peril of Collaborative Code Generation Models: Balancing Effectiveness and Memorization</td>
<td>In the rapidly evolving field of machine learning, training models with datasets from various locations and organizations presents significant challenges due to privacy and legal concerns. The exploration of effective collaborative training settings capable of leveraging valuable knowledge from distributed and isolated datasets is increasingly crucial. This study investigates key factors that impact the effectiveness of collaborative training methods in code next-token prediction, as well as the correctness and utility of the generated code, demonstrating the promise of such methods. Additionally, we evaluate the memorization of different participant training data across various collaborative training settings, including centralized, federated, and incremental training, highlighting their potential risks in leaking data. Our findings indicate that the size and diversity of code datasets are pivotal factors influencing the success of collaboratively trained code models. We show that federated learning achieves competitive performance compared to centralized training while offering better data protection, as evidenced by lower memorization ratios in the generated code. However, federated learning can still produce verbatim code snippets from hidden training data, potentially violating privacy or copyright. Our study further explores effectiveness and memorization patterns in incremental learning, emphasizing the sequence in which individual participant datasets are introduced. We also identify cross-organizational clones as a prevalent challenge in both centralized and federated learning scenarios. Our findings highlight the persistent risk of data leakage during inference, even when training data remains unseen. We conclude with recommendations for practitioners and researchers to optimize multisource datasets, propelling cross-organizational collaboration forward.</td>
</tr>
<tr>
<td>跨量子化学层次的一体化基础模型学习</td>
<td>机器学习（ML）势能通常针对单一的量子化学（QC）水平，而针对多保真度学习的ML模型尚未显示出能为基础模型提供可扩展的解决方案。在此，我们介绍了一种基于多模态学习的全合一（AIO）ANI模型架构，该架构能够学习任意数量的QC水平。我们的全合一学习方法为迁移学习提供了一种更通用且更易使用的替代方案。我们利用它训练了AIO-ANI-UIP基础模型，该模型的泛化能力可与半经验GFN2-xTB和有机分子双ζ基组密度泛函理论（DFT）相媲美。我们展示了AIO-ANI模型能够跨越从半经验到密度泛函理论再到耦合簇的不同QC水平进行学习。我们还利用AIO模型设计了基于Δ学习的基础模型Δ-AIO-ANI，其准确性和鲁棒性相较于AIO-ANI-UIP有所提升。代码和基础模型可在https://github.com/dralgroup/aio-ani获取；它们将被整合到通用且可更新的AI增强量子力学（UAIQM）库中，并可通过MLatom包在线使用于XACS云计算平台（参见https://github.com/dralgroup/mlatom获取更新）。</td>
<td>Yuxinxin Chen</td>
<td><a href="http://arxiv.org/pdf/2409.12015v1">PDF</a></td>
<td>N/A</td>
<td>All-in-one foundational models learning across quantum chemical levels</td>
<td>Machine learning (ML) potentials typically target a single quantum chemical (QC) level while the ML models developed for multi-fidelity learning have not been shown to provide scalable solutions for foundational models. Here we introduce the all-in-one (AIO) ANI model architecture based on multimodal learning which can learn an arbitrary number of QC levels. Our all-in-one learning approach offers a more general and easier-to-use alternative to transfer learning. We use it to train the AIO-ANI-UIP foundational model with the generalization capability comparable to semi-empirical GFN2-xTB and DFT with a double-zeta basis set for organic molecules. We show that the AIO-ANI model can learn across different QC levels ranging from semi-empirical to density functional theory to coupled cluster. We also use AIO models to design the foundational model {\Delta}-AIO-ANI based on {\Delta}-learning with increased accuracy and robustness compared to AIO-ANI-UIP. The code and the foundational models are available at https://github.com/dralgroup/aio-ani; they will be integrated into the universal and updatable AI-enhanced QM (UAIQM) library and made available in the MLatom package so that they can be used online at the XACS cloud computing platform (see https://github.com/dralgroup/mlatom for updates).</td>
</tr>
<tr>
<td>将数据置于离线多智能体强化学习的中心</td>
<td>离线多智能体强化学习（MARL）是一个令人兴奋的研究方向，它利用静态数据集来为多智能体系统找到最优控制策略。尽管该领域本质上是以数据为驱动的，但迄今为止的努力在追求最先进成果的过程中忽视了数据的作用。我们首先通过文献调查来证实这一观点，展示了大多数研究如何在没有一致方法论的情况下生成自己的数据集，并且对这些数据集的特征提供的信息非常有限。然后，我们通过一些显著的例子来说明忽视数据本质的问题，这些例子展示了算法性能与所用数据集的紧密耦合关系，这要求该领域内的实验需要一个共同的基础。作为回应，我们在改进离线MARL中的数据使用和数据意识方面迈出了一大步，做出了三个关键贡献：（1）生成新数据集的明确指南；（2）对80多个现有数据集的标准化，这些数据集托管在一个公开可用的存储库中，采用一致的存储格式和易于使用的API；（3）一套分析工具，使我们能够更好地理解这些数据集，从而促进进一步的发展。</td>
<td>Claude Formanek</td>
<td><a href="http://arxiv.org/pdf/2409.12001v1">PDF</a></td>
<td>N/A</td>
<td>Putting Data at the Centre of Offline Multi-Agent Reinforcement Learning</td>
<td>Offline multi-agent reinforcement learning (MARL) is an exciting direction of research that uses static datasets to find optimal control policies for multi-agent systems. Though the field is by definition data-driven, efforts have thus far neglected data in their drive to achieve state-of-the-art results. We first substantiate this claim by surveying the literature, showing how the majority of works generate their own datasets without consistent methodology and provide sparse information about the characteristics of these datasets. We then show why neglecting the nature of the data is problematic, through salient examples of how tightly algorithmic performance is coupled to the dataset used, necessitating a common foundation for experiments in the field. In response, we take a big step towards improving data usage and data awareness in offline MARL, with three key contributions: (1) a clear guideline for generating novel datasets; (2) a standardisation of over 80 existing datasets, hosted in a publicly available repository, using a consistent storage format and easy-to-use API; and (3) a suite of analysis tools that allow us to understand these datasets better, aiding further development.</td>
</tr>
<tr>
<td>“它在技术上可能令人印象深刻，但对我们的实际应用毫无帮助”：新闻行业中围绕人工智能的跨职能协作的实践、挑战与机遇</td>
<td>近期，越来越多的新闻机构将人工智能（AI）融入其工作流程，导致更多的AI技术人员和数据工作者涌入新闻行业。这促成了这些专业人员与记者之间的跨职能合作。尽管已有研究探讨了与AI相关的角色进入新闻行业的影响，但关于AI专业人员与记者之间跨职能合作如何展开的研究尚显不足。通过对17名记者、6名AI技术人员以及3名来自领先新闻机构的具有跨职能经验的AI工作人员进行访谈，我们调查了当今新闻行业中围绕AI的跨职能合作的现状、挑战和机遇。首先，我们研究了记者和AI专业人员如何看待现有的跨合作策略。进一步探讨了跨职能合作的挑战，并为提升新闻行业中未来围绕AI的跨职能合作提供了建议。</td>
<td>Qing Xiao</td>
<td><a href="http://arxiv.org/pdf/2409.12000v1">PDF</a></td>
<td>N/A</td>
<td>"It Might be Technically Impressive, But It's Practically Useless to Us": Practices, Challenges, and Opportunities for Cross-Functional Collaboration around AI within the News Industry</td>
<td>Recently, an increasing number of news organizations have integrated artificial intelligence (AI) into their workflows, leading to a further influx of AI technologists and data workers into the news industry. This has initiated cross-functional collaborations between these professionals and journalists. While prior research has explored the impact of AI-related roles entering the news industry, there is a lack of studies on how cross-functional collaboration unfolds between AI professionals and journalists. Through interviews with 17 journalists, 6 AI technologists, and 3 AI workers with cross-functional experience from leading news organizations, we investigate the current practices, challenges, and opportunities for cross-functional collaboration around AI in today's news industry. We first study how journalists and AI professionals perceive existing cross-collaboration strategies. We further explore the challenges of cross-functional collaboration and provide recommendations for enhancing future cross-functional collaboration around AI in the news industry.</td>
</tr>
<tr>
<td>解开Hessian之谜：优化损失函数景观中的平滑收敛的关键</td>
<td>神经网络的损失景观是其训练过程中的关键方面，理解其特性对于提升性能至关重要。本文探讨了样本量增加时损失表面的变化情况，这是一个先前未被探索的问题。我们理论上分析了全连接神经网络中损失景观的收敛性，并推导出在样本中添加新对象时损失函数值差异的上界。我们的实证研究在多个数据集上验证了这些结果，展示了图像分类任务中损失函数表面的收敛性。我们的发现为神经损失景观的局部几何结构提供了见解，并对样本量确定技术的发展具有启示意义。</td>
<td>Nikita Kiselev</td>
<td><a href="http://arxiv.org/pdf/2409.11995v1">PDF</a></td>
<td>N/A</td>
<td>Unraveling the Hessian: A Key to Smooth Convergence in Loss Function Landscapes</td>
<td>The loss landscape of neural networks is a critical aspect of their training, and understanding its properties is essential for improving their performance. In this paper, we investigate how the loss surface changes when the sample size increases, a previously unexplored issue. We theoretically analyze the convergence of the loss landscape in a fully connected neural network and derive upper bounds for the difference in loss function values when adding a new object to the sample. Our empirical study confirms these results on various datasets, demonstrating the convergence of the loss function surface for image classification tasks. Our findings provide insights into the local geometry of neural loss landscapes and have implications for the development of sample size determination techniques.</td>
</tr>
<tr>
<td>一种高效的数据受限土壤测量应用中的不确定性估计模型无关方法</td>
<td>本文介绍了一种与模型无关的方法，旨在增强土壤属性预测建模中的不确定性估计，这是推进地统计学和数字土壤制图实践的关键因素。为了解决土壤研究中常见的数据稀缺挑战，我们提出了一种改进的不确定性估计技术。该方法基于将回归任务转化为分类问题，这不仅能够生成可靠的不确定性估计，还使得能够应用在性能上具有竞争力的成熟机器学习算法，而这些算法在目前的地统计学中尚未得到利用。从两个德国农业田地收集的数据集的实证结果展示了所提出方法的实际应用。我们的结果和发现表明，所提出的方法有可能提供比地统计学中常用模型更好的不确定性估计。</td>
<td>Viacheslav Barkov</td>
<td><a href="http://arxiv.org/pdf/2409.11985v1">PDF</a></td>
<td>N/A</td>
<td>An Efficient Model-Agnostic Approach for Uncertainty Estimation in Data-Restricted Pedometric Applications</td>
<td>This paper introduces a model-agnostic approach designed to enhance uncertainty estimation in the predictive modeling of soil properties, a crucial factor for advancing pedometrics and the practice of digital soil mapping. For addressing the typical challenge of data scarcity in soil studies, we present an improved technique for uncertainty estimation. This method is based on the transformation of regression tasks into classification problems, which not only allows for the production of reliable uncertainty estimates but also enables the application of established machine learning algorithms with competitive performance that have not yet been utilized in pedometrics. Empirical results from datasets collected from two German agricultural fields showcase the practical application of the proposed methodology. Our results and findings suggest that the proposed approach has the potential to provide better uncertainty estimation than the models commonly used in pedometrics.</td>
</tr>
<tr>
<td>基于图神经网络的度量-语义因子图生成</td>
<td>理解几何结构与语义概念之间的关系对于构建复杂环境的精确模型至关重要。在室内环境中，尽管布局有所变化，某些空间约束（如平面的相对位置）仍然保持一致。本文探讨了如何在图SLAM框架中捕捉这些不变关系，通过表示房间和墙壁等高级概念，并将它们与平面等几何元素通过可优化的因子图相连接。已有多种努力尝试通过为每个概念生成和手动定义因子来解决这一问题。本文提出了一种新的度量-语义因子图生成方法，该方法包括定义语义场景图、整合几何信息以及基于图神经网络（GNNs）学习互联因子。一个边分类网络（G-GNN）将平面之间的边分类为同一房间、同一墙壁或无类型。生成的关系被聚类，为每个聚类生成一个房间或墙壁。第二类网络（F-GNN）推断新节点的几何起源。因子定义采用了与生成节点度量属性相同的F-GNN。此外，与S-Graphs+算法共享新的因子图，扩展其图表达能力和场景表示，最终目标是提高SLAM性能。通过在L形房间上训练网络，将环境的复杂性增加到N平面房间。该框架在没有所需复杂布局的真实数据集的情况下，在合成和模拟场景中进行了评估。</td>
<td>Jose Andres Millan-Romera</td>
<td><a href="http://arxiv.org/pdf/2409.11972v1">PDF</a></td>
<td>N/A</td>
<td>Metric-Semantic Factor Graph Generation based on Graph Neural Networks</td>
<td>Understanding the relationships between geometric structures and semantic concepts is crucial for building accurate models of complex environments. In indoors, certain spatial constraints, such as the relative positioning of planes, remain consistent despite variations in layout. This paper explores how these invariant relationships can be captured in a graph SLAM framework by representing high-level concepts like rooms and walls, linking them to geometric elements like planes through an optimizable factor graph. Several efforts have tackled this issue with add-hoc solutions for each concept generation and with manually-defined factors.   This paper proposes a novel method for metric-semantic factor graph generation which includes defining a semantic scene graph, integrating geometric information, and learning the interconnecting factors, all based on Graph Neural Networks (GNNs). An edge classification network (G-GNN) sorts the edges between planes into same room, same wall or none types. The resulting relations are clustered, generating a room or wall for each cluster. A second family of networks (F-GNN) infers the geometrical origin of the new nodes. The definition of the factors employs the same F-GNN used for the metric attribute of the generated nodes. Furthermore, share the new factor graph with the S-Graphs+ algorithm, extending its graph expressiveness and scene representation with the ultimate goal of improving the SLAM performance. The complexity of the environments is increased to N-plane rooms by training the networks on L-shaped rooms. The framework is evaluated in synthetic and simulated scenarios as no real datasets of the required complex layouts are available.</td>
</tr>
<tr>
<td>从LLM衍生的嵌入表示中采样潜在材料属性信息</td>
<td>源自大型语言模型（LLMs）的向量嵌入在捕捉文献中的潜在信息方面显示出潜力。有趣的是，这些嵌入可以整合到材料嵌入中，可能对数据驱动的材料性质预测有用。我们研究了LLM衍生的向量在多大程度上捕捉到所需信息，以及它们在不进行额外训练的情况下提供材料性质见解的潜力。我们的研究结果表明，尽管LLMs可以用于生成反映某些性质信息的表示，但提取这些嵌入需要识别最佳的上下文线索和适当的比较对象。尽管存在这一限制，LLMs似乎仍然有可能在生成有意义的材料科学表示方面发挥作用。</td>
<td>Luke P. J. Gilligan</td>
<td><a href="http://arxiv.org/pdf/2409.11971v1">PDF</a></td>
<td>N/A</td>
<td>Sampling Latent Material-Property Information From LLM-Derived Embedding Representations</td>
<td>Vector embeddings derived from large language models (LLMs) show promise in capturing latent information from the literature. Interestingly, these can be integrated into material embeddings, potentially useful for data-driven predictions of materials properties. We investigate the extent to which LLM-derived vectors capture the desired information and their potential to provide insights into material properties without additional training. Our findings indicate that, although LLMs can be used to generate representations reflecting certain property information, extracting the embeddings requires identifying the optimal contextual clues and appropriate comparators. Despite this restriction, it appears that LLMs still have the potential to be useful in generating meaningful materials-science representations.</td>
</tr>
<tr>
<td>合成数据作为基准的有效性</td>
<td>大型语言模型（LLMs）在零样本和少样本学习环境中推动了一系列应用，包括用于训练和测试的合成数据集的生成。然而，为了可靠地使用这些合成数据集，了解它们在多大程度上代表了真实世界的数据是至关重要的。我们通过评估使用LLM生成合成数据并将其作为各种自然语言处理（NLP）任务基准的有效性来研究这一点。我们在六个数据集和三个不同任务上的实验表明，尽管合成数据可以有效地捕捉各种方法在简单任务（如意图分类）上的性能，但对于更复杂的任务（如命名实体识别）则表现不足。此外，我们提出了一种新的指标，称为偏差因子，用于评估当同一LLM既用于生成基准数据又用于执行任务时引入的偏差。我们发现，较小的LLMs对其自身生成的数据表现出偏差，而较大的模型则没有。总体而言，我们的研究结果表明，合成数据作为基准的有效性因任务而异，实践者应尽可能依赖由多个较大模型生成的数据。</td>
<td>Gaurav Maheshwari</td>
<td><a href="http://arxiv.org/pdf/2409.11968v1">PDF</a></td>
<td>N/A</td>
<td>Efficacy of Synthetic Data as a Benchmark</td>
<td>Large language models (LLMs) have enabled a range of applications in zero-shot and few-shot learning settings, including the generation of synthetic datasets for training and testing. However, to reliably use these synthetic datasets, it is essential to understand how representative they are of real-world data. We investigate this by assessing the effectiveness of generating synthetic data through LLM and using it as a benchmark for various NLP tasks. Our experiments across six datasets, and three different tasks, show that while synthetic data can effectively capture performance of various methods for simpler tasks, such as intent classification, it falls short for more complex tasks like named entity recognition. Additionally, we propose a new metric called the bias factor, which evaluates the biases introduced when the same LLM is used to both generate benchmarking data and to perform the tasks. We find that smaller LLMs exhibit biases towards their own generated data, whereas larger models do not. Overall, our findings suggest that the effectiveness of synthetic data as a benchmark varies depending on the task, and that practitioners should rely on data generated from multiple larger models whenever possible.</td>
</tr>
<tr>
<td>使用教师指导的混淆类指令进行数据高效声学场景分类</td>
<td>在本技术报告中，我们描述了SNTL-NTU团队针对2024年DCASE挑战赛中的任务1——数据高效低复杂度声学场景分类的提交内容。我们提出了三种系统来应对不同规模的训练数据集。对于小规模的训练数据集，我们通过减少基线模型的基本通道数量来降低其复杂性，并引入了mixup数据增强方法以增加训练样本的多样性。对于较大规模的训练数据集，我们使用FocusNet为多个Patchout faSt Spectrogram Transformer (PaSST)模型和基于原始采样率44.1 kHz训练的基线模型提供混淆类信息。我们采用知识蒸馏技术将集成模型蒸馏到基线学生模型中。在TAU Urban Acoustic Scene 2022 Mobile开发数据集上训练这些系统，分别在(100, 50, 25, 10, 5)%的分割比例下，三种系统的最高平均测试准确率分别为(62.21, 59.82, 56.81, 53.03, 47.97)%。</td>
<td>Jin Jie Sean Yeo</td>
<td><a href="http://arxiv.org/pdf/2409.11964v1">PDF</a></td>
<td>N/A</td>
<td>Data Efficient Acoustic Scene Classification using Teacher-Informed Confusing Class Instruction</td>
<td>In this technical report, we describe the SNTL-NTU team's submission for Task 1 Data-Efficient Low-Complexity Acoustic Scene Classification of the detection and classification of acoustic scenes and events (DCASE) 2024 challenge. Three systems are introduced to tackle training splits of different sizes. For small training splits, we explored reducing the complexity of the provided baseline model by reducing the number of base channels. We introduce data augmentation in the form of mixup to increase the diversity of training samples. For the larger training splits, we use FocusNet to provide confusing class information to an ensemble of multiple Patchout faSt Spectrogram Transformer (PaSST) models and baseline models trained on the original sampling rate of 44.1 kHz. We use Knowledge Distillation to distill the ensemble model to the baseline student model. Training the systems on the TAU Urban Acoustic Scene 2022 Mobile development dataset yielded the highest average testing accuracy of (62.21, 59.82, 56.81, 53.03, 47.97)% on split (100, 50, 25, 10, 5)% respectively over the three systems.</td>
</tr>
<tr>
<td>使用李群方向的强化学习用于机器人</td>
<td>处理机器人和物体的方向是许多应用中的关键方面。然而，在处理方向时，尤其是涉及到例如人工神经网络的学习流程时，往往缺乏数学上的正确性。在本文中，我们研究了带有方向的强化学习，并提出了一种简单的网络输入和输出的修改方法，该方法遵循方向的李群结构。结果，我们获得了一种易于实现且高效的方法，该方法可直接与现有的学习库一起使用，并且比其他常见的方向表示方法表现显著更好。我们简要介绍了专门针对机器人方向的李理论，以激发并概述我们的方法。随后，对状态和动作的不同方向表示组合进行了彻底的实证评估，结果表明，在不同场景下，包括直接方向控制、末端执行器方向控制和拾取放置任务，我们提出的方法表现优越。</td>
<td>Martin Schuck</td>
<td><a href="http://arxiv.org/pdf/2409.11935v1">PDF</a></td>
<td>N/A</td>
<td>Reinforcement Learning with Lie Group Orientations for Robotics</td>
<td>Handling orientations of robots and objects is a crucial aspect of many applications. Yet, ever so often, there is a lack of mathematical correctness when dealing with orientations, especially in learning pipelines involving, for example, artificial neural networks. In this paper, we investigate reinforcement learning with orientations and propose a simple modification of the network's input and output that adheres to the Lie group structure of orientations. As a result, we obtain an easy and efficient implementation that is directly usable with existing learning libraries and achieves significantly better performance than other common orientation representations. We briefly introduce Lie theory specifically for orientations in robotics to motivate and outline our approach. Subsequently, a thorough empirical evaluation of different combinations of orientation representations for states and actions demonstrates the superior performance of our proposed approach in different scenarios, including: direct orientation control, end effector orientation control, and pick-and-place tasks.</td>
</tr>
</tbody>
</table>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.d6f25eb3.min.js"></script>
      
    
  </body>
</html>